<<<<<<< HEAD 05 การใช้ความชัดเจนจากการสุ่มแบ่งข้อมูลฝึกเพื่อลดค่า loss ในการสอน neural network model ด้วย Tensorflow และ
    keras การทำความเข้าใจแนวคิดของ Stochatic Gradient Descent (SGD) เป็นสิ่งสำคัญในการทำให้สามารถปรับจูน Neural Network
    โดยเฉพาะ DeepLearning Model ให้มีปะสิทธิภามากยิ่งขึ้นในบทนี้จะทำความเข้าใจพฤติกรรมการเคลื่อนที่ของ Loss Value
    ในแต่ละรอบของการ Train Model แบบ Linear regression โดยใช้ TensorFlow และ Keras Frameworkซึ่งจะมีวิธีการ2แบบได้แก่
    Gradient Descent และ Stochastis Gradient Descent ตามลำดับ=======วิธีการ Gradient Descent(GD) คืออะไร
    หากแปลความหมายตามคำศัพท์แบบตรงตัว คำว่า"Gradient"จะมีคำแปลว่า"ความลาดชัน,เนินลาด"
    และ"Descent"จะมีคำแปลว่า "การตกลงมา,การเคลื่อนที่ลงมา"
    ดังนั้นเป้าหมายของวิธีการนี้ก็คือการเคลื่อนที่ลงมาตามเนินลาดชัน(เหมืนเดินลงไปในหุบเขา)เพื่อไปยังเป้าหมายซึ่งก็คือบริเวณที่ตำ่ที่สุดซึ่งเป็นแนวคิดที่สำคัญในการคำนวณ
    Error ของ NeuralNetworkหรือที่เรียกว่าค่า Loss หากต้องการให้ค่า Loss น้อยที่สุดจะต้องมีการปรับ Weight โดยการกำหนดตัว
    Optimizerวึ่งวิธีหนึ่งที่นิยมก็คือ Stochastic Gradient Descent (SGD)นั่นเอง ในงาน Deep learning วิธี Stochastic
    Gradient Descent (SGD) จะเป็นวิธีการหลักในการ Train NeuralNetwork Model โดยใช้