{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFynfXtE0gSmEPMoi5Cr00",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manassanant132/Fundamental-of-Deep-Learning/blob/main/Unit11_%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B9%80%E0%B8%A5%E0%B8%B7%E0%B8%AD%E0%B8%81%E0%B9%83%E0%B8%8A%E0%B9%89_Loss_Function_%E0%B9%83%E0%B8%99%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B8%9E%E0%B8%B1%E0%B8%92%E0%B8%99%E0%B8%B2_Deep_Learning_Model_(%E0%B8%95%E0%B8%AD%E0%B8%99%E0%B8%97%E0%B8%B5%E0%B9%88_2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ตอนที่ 2 ของบทความเรื่องการเลือกใช้ Loss Function ในการพัฒนา Deep Learning Model นี้ ผู้อ่านจะได้ทำ Workshop ที่มีการคอนฟิก Model แบบ Classification ด้วย Loss Function อีก 3 ตัว ได้แก่\n",
        "\n",
        "\n",
        "\n",
        "*   Binary Crossentropy Loss\n",
        "\n",
        "*   Categorical Crossentropy Loss\n",
        "\n",
        "*   Sparse Categorical Crossentropy Loss\n",
        "\n",
        "แต่ก่อนอื่นเราจะทำความเข้าใจแนวคิดของ Information, Entropy และ Cross-Entropy  ซึ่งเป็นพื้นฐานสำคัญของ Loss Function ทั้ง 3 ตัวกันก่อนครับ\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nB3a2x0byuM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Information Theory"
      ],
      "metadata": {
        "id": "81LFYIMJzLpt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Information Theory ถูกคิดค้นขึ้นโดย Claude Shannon วิศวกรไฟฟ้าและนักคณิตศาสตร์ชาวอเมริกัน ในปี พ.ศ.2491 ขณะที่เขาทำงานอยู่ที่ Bell Labs บริษัทโทรคมนาคมขนาดใหญ่ โดย Information Theory เป็นศาสตร์ที่ศึกษาเกี่ยวกับการหาปริมาณ Information การบีบอัดข้อมูล และขีดจำกัดของการประมวลผลสัญญาณ ฯลฯ\n",
        "\n",
        "ในการหาปริมาณของ Information จะใช้ความเข้าใจในเรื่องของเหตุการณ์ (Event) ตัวแปรสุ่ม (Random Variable) และการแจกแจงความน่าจะเป็น (Probability Distribution) ฯลฯ ซึ่งจะทำให้เราสามารถวัดปริมาณ Information จาก Data ที่มีการสื่อสารกัน โดยใช้แนวคิดที่ว่า\n",
        "\n",
        "\"เหตุการณ์ที่มีโอกาสเกิดขึ้นต่ำ (Low Probability) จะมีความน่า Surprise หรือมี Information (มูลค่า) สูง ในขณะที่เหตุการณ์ที่มีโอกาสเกิดขึ้นสูง (High Probability) จะมี Information (มูลค่า) ต่ำ\"\n"
      ],
      "metadata": {
        "id": "_v-TdW--2vp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ตามสูตรดังต่อไปนี้\n",
        "\n",
        "information(x) = -log(p(x))\n",
        "\n",
        "เราสามารถแทน information(x) ด้วย h(x) ได้เช่นกัน"
      ],
      "metadata": {
        "id": "fkFg4F35B1d7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def p(x):\n",
        "  return x\n",
        "\n",
        "-math.log2(p(0.7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1AVzYNRGHF1",
        "outputId": "536537fa-bddf-498e-becc-a2e50990063f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5145731728297583"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "โดยที่ log() คือ Logarithm ฐาน 2 และ p(x) คือความน่าจะเป็นที่จะเกิดเหตุการณ์ x\n",
        "\n",
        "ยกตัวอย่างในภาษาไทยของเราที่จะมีโอกาสพบคำว่า อาตมา ตามที่ต่างๆ น้อยกว่าคำว่า ผม และ ฉัน ซึ่งใช้แทนตัวผู้พูดโดยไม่เจาะจงว่าเป็นใคร แต่เมื่อมีการพบคำว่า อาตมา ในประโยค เราก็จะเข้าใจได้ในทันทีว่าผู้พูดเป็นบุคคลพิเศษ ไม่ได้ประกอบอาชีพทั่วไป ดังนั้นเหตุการณ์ที่เกิดคำว่า อาตมา จึงมี Information สูงว่าเหตุการณ์ที่จะพบคำว่า ผม และ ฉัน\n",
        "\n",
        "เนื่องจากเราใช้ Logarithm ฐาน 2 หน่วยของ Information จึงเป็นจำนวน bit (Binary Digit) ที่จำเป็นในการแสดงถึงเหตุการณ์หนึ่งๆ"
      ],
      "metadata": {
        "id": "2mhpT66h22NV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import log, log2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "qVL040i_236B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = 0.1\n",
        "h = -log2(p)\n",
        "\n",
        "print('p(x)=%.3f, information: %.3f bits' % (p, h))\n",
        "\n",
        "p = 0.5\n",
        "h = -log2(p)\n",
        "\n",
        "print('p(x)=%.3f, information: %.3f bits' % (p, h))"
      ],
      "metadata": {
        "id": "yF11LG8a25Q2",
        "outputId": "764fa965-dbcb-4a53-9a1e-d291eb375ff9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(x)=0.100, information: 3.322 bits\n",
            "p(x)=0.500, information: 1.000 bits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "p(x)=0.100, information: 3.322 bits\n",
        "p(x)=0.500, information: 1.000 bits\n",
        "\n",
        "ดังนั้น ยิ่งเหตุการณ์มีโอกาสเกิดขึ้นได้สูง ความ Surprise หรือ Information หรือจำนวน bit ที่จำเป็นในการแสดงถึงเหตุการณ์หนึ่งๆ จะยิ่งต่ำ ดังกราฟด้านล่าง"
      ],
      "metadata": {
        "id": "2eABKugq26eN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probs = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "\n",
        "info = [-log2(p) for p in probs]"
      ],
      "metadata": {
        "id": "sV3D9IU127u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list(zip(probs, info)), columns =['Probability', 'Information'])\n",
        "df"
      ],
      "metadata": {
        "id": "qEwdULrV29IO",
        "outputId": "1a298a11-0bbf-468f-e9f0-edcb688233dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Probability  Information\n",
              "0          0.1     3.321928\n",
              "1          0.2     2.321928\n",
              "2          0.3     1.736966\n",
              "3          0.4     1.321928\n",
              "4          0.5     1.000000\n",
              "5          0.6     0.736966\n",
              "6          0.7     0.514573\n",
              "7          0.8     0.321928\n",
              "8          0.9     0.152003\n",
              "9          1.0    -0.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af370145-79fb-4e1e-9965-109f2ec1fdab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Probability</th>\n",
              "      <th>Information</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.1</td>\n",
              "      <td>3.321928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.2</td>\n",
              "      <td>2.321928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.3</td>\n",
              "      <td>1.736966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4</td>\n",
              "      <td>1.321928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.5</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.736966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.7</td>\n",
              "      <td>0.514573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.8</td>\n",
              "      <td>0.321928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.152003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af370145-79fb-4e1e-9965-109f2ec1fdab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af370145-79fb-4e1e-9965-109f2ec1fdab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af370145-79fb-4e1e-9965-109f2ec1fdab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.line(df, x='Probability', y='Information', title='Probability vs Information')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "woo1DsUa2-UE",
        "outputId": "05c8e736-9176-4d22-90b7-8719dec692f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"7de0793e-d4e5-4e51-b9c7-1b410a160292\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7de0793e-d4e5-4e51-b9c7-1b410a160292\")) {                    Plotly.newPlot(                        \"7de0793e-d4e5-4e51-b9c7-1b410a160292\",                        [{\"hovertemplate\":\"Probability=%{x}<br>Information=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0],\"xaxis\":\"x\",\"y\":[3.321928094887362,2.321928094887362,1.7369655941662063,1.3219280948873622,1.0,0.7369655941662062,0.5145731728297583,0.3219280948873623,0.15200309344504995,-0.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Probability\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Information\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Probability vs Information\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7de0793e-d4e5-4e51-b9c7-1b410a160292');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "เราสามารถนำ Information Theory ไปประยุกต์ใช้ในการบีบอัดข้อมูลเพื่อประหยัดค่าใช้จ่ายในการสื่อสาร โดยสมมติว่าถ้าเรามีตัวอักษรอยู่ 4 ตัว ได้แก่ 'A', 'B', 'C' และ 'D' ซึ่งแต่ละตัวมีโอกาสปรากฏอยู่ในข้อความ (Text) ด้วยความน่าจะเป็น p เท่ากับ 1/2, 1/4, 1/8, และ 1/8 ตามลำดับ (รวมกันเท่ากับ 1.0) ดังนั้นเพื่อจะประหยัดจำนวน bit ในการส่งข้อมูล เราจะเข้ารหัสตัวอักษรทั้ง 4 ตัว ดังต่อไปนี้"
      ],
      "metadata": {
        "id": "uC9AzQC42_g1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Entropy"
      ],
      "metadata": {
        "id": "1VhCLvKr3BEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ดังนั้น เราสามารถคำนวณหาจำนวน bit โดยเฉลี่ยที่จำเป็นในการส่งข้อมูล สำหรับตัวอักษร 4 ตัว ที่มีการแจกแจงความน่าจะเป็น (Probability Distribution) เท่ากับ 1/2, 1/4, 1/8, และ 1/8 ได้ดังนี้"
      ],
      "metadata": {
        "id": "_PsFuhyH3Etl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average bit หรือ H(X) = (1/2 × 1) +  (1/4  × 2) + (1/8  × 3) + (1/8  × 3) = 1.75"
      ],
      "metadata": {
        "id": "BycyH0WhLGkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "เราเรียกจำนวน bit โดยเฉลี่ยดังกล่าวว่า Entropy (หรือ H(X) โดย X คือ Random Variable) ซึ่งคล้ายกับแนวคิดของ Entropy ที่เป็นระบบทางกายภาพในวิชาฟิสิกส์ โดยทั้ง 2 จะให้ความสำคัญกับเรื่องของความไม่แน่นอน (Uncertainty)\n",
        "\n",
        "สมมติว่ามีการโยนลูกเต๋า 1 ลูก ที่มีโอกาสออกแต่ละหน้าด้วยความน่าจะเป็น 1/6 (Uniform Probability Distribution) เราสามารถคาดหวังได้ว่าจำนวน bit โดยเฉลี่ย หรือ Entropy จะมีค่าดังนี้"
      ],
      "metadata": {
        "id": "vllVVula3Gug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P = [1/6, 1/6, 1/6, 1/6, 1/6, 1/6]\n",
        "\n",
        "entropy = -sum([p * log2(p) for p in P])\n",
        "\n",
        "print('entropy: %.3f bits' % entropy)"
      ],
      "metadata": {
        "id": "qJDABBFz3H_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4106064-05d0-4aa0-86bb-9d2f6a7c02d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entropy: 2.585 bits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ในอีกแง่หนึ่ง Entropy นั้นบอกถึงความ Surprise โดยเฉลี่ย ซึ่งขึ้นอยู่กับลักษณะของการแจกแจงความน่าจะเป็น (Probability Distribution) ของเหตุการณ์หนึ่งๆ ดังตัวอย่างด้านล่าง"
      ],
      "metadata": {
        "id": "hB5HtM7J3JB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(events, ets=1e-15):\n",
        "    return -sum([p * log2(p + ets) for p in events])\n",
        "\n",
        "probs = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "\n",
        "dists = [[p, 1.0 - p] for p in probs]\n",
        "\n",
        "ents = [entropy(d) for d in dists]"
      ],
      "metadata": {
        "id": "Jkv4H80x3KLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list(zip(probs, ents)), columns =['Probability Distribution', 'Entropy (bits)'])"
      ],
      "metadata": {
        "id": "cHp5FFNC3LZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.line(df, x='Probability Distribution', y='Entropy (bits)', title='Probability Distribution vs Entropy')\n",
        "fig.update_xaxes(ticktext=[str(d) for d in dists], tickvals = probs)"
      ],
      "metadata": {
        "id": "RUquK3Wz3Mt-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "160e38b7-cdaa-47d4-bc21-1a8df579a713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"39a7f5f7-12b4-412a-b73d-0dd1536adebf\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"39a7f5f7-12b4-412a-b73d-0dd1536adebf\")) {                    Plotly.newPlot(                        \"39a7f5f7-12b4-412a-b73d-0dd1536adebf\",                        [{\"hovertemplate\":\"Probability Distribution=%{x}<br>Entropy (bits)=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.0,0.1,0.2,0.3,0.4,0.5],\"xaxis\":\"x\",\"y\":[-1.601713251907458e-15,0.46899559358927834,0.7219280948873594,0.8812908992306898,0.9709505944546657,0.9999999999999971],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Probability Distribution\"},\"ticktext\":[\"[0.0, 1.0]\",\"[0.1, 0.9]\",\"[0.2, 0.8]\",\"[0.3, 0.7]\",\"[0.4, 0.6]\",\"[0.5, 0.5]\"],\"tickvals\":[0.0,0.1,0.2,0.3,0.4,0.5]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Entropy (bits)\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Probability Distribution vs Entropy\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('39a7f5f7-12b4-412a-b73d-0dd1536adebf');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ซึ่งจากกราฟจะเห็นว่ายิ่งมีการกระจายตัวของความน่าจะเป็นที่สมดุล (Balanced Probability Distribution) ตามแกน x มากขึ้นเท่าไหร่ ความ Surprise หรือ Entropy ก็จะยิ่งมากขึ้นเท่านั้น\n",
        "\n",
        "ยกตัวอย่างเช่น ในการโยนเหรียญที่มีโอกาสออกหัว 0% และออกก้อย 100% (Skewed Probability Distribution) ซึ่งไม่ว่าจะโยนกี่ครั้งมันก็จะออกก้อยตลอด ดังนั้นความ Surprise หรือ Entropy จึงเท่ากับ 0 ในขณะที่อีกกรณีหนึ่ง ถ้าในการโยนเหรียญมีโอกาสออกหัว 50% และออกก้อย 50% เท่ากัน (Balanced Probability Distribution) ความ Surprise หรือ Entropy จะมีค่าสูงสุดเท่ากับ 1 ครับ"
      ],
      "metadata": {
        "id": "09wVnP7W3R9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cross-Entropy"
      ],
      "metadata": {
        "id": "HkEP5UuO3Tdz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ทีนี้สมมติว่าในเวลาต่อมา การแจกแจงความน่าจะเป็น (Probability Distribution) ของตัวอักษร 4 ตัว ได้แก่ 'A', 'B', 'C' และ 'D' เปลี่ยนไปจากแบบ p = [1/2, 1/4, 1/8, 1/8] เป็นแบบ q = [1/8, 1/4, 1/2, 1/8]"
      ],
      "metadata": {
        "id": "bbsyQZmq3U45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "events = ['A', 'B', 'C', 'D']\n",
        "p = [1/2, 1/4, 1/8, 1/8]\n",
        "q = [1/8, 1/4, 1/2, 1/8]"
      ],
      "metadata": {
        "id": "Q2qRdkKU3WEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure(data=[\n",
        "    go.Bar(name='Probability Distribution เก่า (p)', x=events, y=p, text=p, textposition='auto'),\n",
        "    go.Bar(name='Probability Distribution ใหม่ (q)', x=events, y=q, text=q, textposition='auto')\n",
        "])\n",
        "\n",
        "fig.update_layout(barmode='group')"
      ],
      "metadata": {
        "id": "0mCCXwv_3XRB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "424c99a5-4a9c-46d6-e3b9-ce01b66a8512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"75ef61e9-ae09-460a-ac5a-902eef238278\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"75ef61e9-ae09-460a-ac5a-902eef238278\")) {                    Plotly.newPlot(                        \"75ef61e9-ae09-460a-ac5a-902eef238278\",                        [{\"name\":\"Probability Distribution \\u0e40\\u0e01\\u0e48\\u0e32 (p)\",\"text\":[\"0.5\",\"0.25\",\"0.125\",\"0.125\"],\"textposition\":\"auto\",\"x\":[\"A\",\"B\",\"C\",\"D\"],\"y\":[0.5,0.25,0.125,0.125],\"type\":\"bar\"},{\"name\":\"Probability Distribution \\u0e43\\u0e2b\\u0e21\\u0e48 (q)\",\"text\":[\"0.125\",\"0.25\",\"0.5\",\"0.125\"],\"textposition\":\"auto\",\"x\":[\"A\",\"B\",\"C\",\"D\"],\"y\":[0.125,0.25,0.5,0.125],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"barmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('75ef61e9-ae09-460a-ac5a-902eef238278');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "หากยังมีการเข้ารหัสตัวอักษรทั้ง 4 ตัว แบบเดิม จำนวน bit โดยเฉลี่ย ที่จำเป็นในการส่งข้อมูลจะเพิ่มขึ้นจาก 1.75 bit เป็น 2.5 bit!"
      ],
      "metadata": {
        "id": "eWl1YhlB3Yl5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average bit หรือ H(p,q) = (1/8 × 1) +  (1/4  × 2) + (1/2  × 3) + (1/8  × 3) = 2.5"
      ],
      "metadata": {
        "id": "zyxe34OHPX_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "เราเรียกจำนวน bit โดยเฉลี่ย เมื่อมีการเข้ารหัสตัวอักษรแบบเดิม (p) ด้วยการแจกแจงความน่าจะเป็นใหม่ (q) นี้ว่า Cross-Entropy"
      ],
      "metadata": {
        "id": "xqwDWi2w3dgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(p, q):\n",
        "    return -sum([q[i]*log2(p[i]) for i in range(len(p))])"
      ],
      "metadata": {
        "id": "3IBprmq03edf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ce = cross_entropy(p, q)\n",
        "print('H(P, Q): %.3f bits' % ce)"
      ],
      "metadata": {
        "id": "sAq7wrpL3fU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10615e8a-71ab-4f89-9409-ed36a6f16a8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H(P, Q): 2.500 bits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-Entropy ถูกใช้ในการประมาณ Error ของ Classification Model ที่เกิดจากการแจกแจงความน่าจะเป็น 2 แบบ คือ ระหว่าง p กับ q ซึ่ง q คือ การแจกแจงความน่าจะเป็นที่เราอยากได้ และ p คือ การแจกแจงความน่าจะเป็นที่ถูกประมาณโดย Model\n",
        "\n",
        "*H(P, Q) != H(Q, P)"
      ],
      "metadata": {
        "id": "ecWUkIeH3jLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Binary Classification Loss Functions"
      ],
      "metadata": {
        "id": "eyB4r0W53kRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary Classification เป็น Model ที่มีการกำหนด Label หรือ Class เพียง 2 Class คือ ไม่เป็น Class 0 ก็เป็น Class 1 โดย ผลลัพธ์จากการทำนายของ Model จะบอกค่าความน่าจะเป็นว่ามีโอกาสที่จะเป็น Class 1 กี่เปอร์เซ็นต์\n",
        "\n",
        "เราจะทดลอง Train Binary Classification Model โดยใช้ Binary Crossentropy Loss ของ Keras Framework ด้วย Dataset ที่ Make ขึ้นจากฟังก์ชัน make_circles ของ sklearn Library\n",
        "\n",
        "*เพื่อจะทำให้ Model ทำนายผลออกมาเป็นค่าความน่าจะเป็น [0, 1] ว่ามีโอกาสที่จะเป็น Class 1 กี่เปอร์เซ็นต์ เราจะต้องคอนฟิก Activate Function ใน Output Layer แบบ Sigmoid"
      ],
      "metadata": {
        "id": "SJtjCSaP3mT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1.0/(1+ np.exp(-x))\n",
        "\n",
        "data = 25\n",
        "result = sigmoid(data)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "x5vBcYE43oXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a90bfe6-300a-4606-a54f-ef66d5635e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.999999999986112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Binary Crossentropy Loss\n"
      ],
      "metadata": {
        "id": "z80dg7eI3pfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "events = ['Class 0', 'Class 1']\n",
        "actual = [1, 0, 1, 1, 0]\n",
        "predicted = [0.7, 0.45, 0.9, 0.5, 0.3]\n",
        "\n",
        "index = 0\n",
        "p = [1-actual[index], actual[index]]\n",
        "q = [1-predicted[index], predicted[index]]"
      ],
      "metadata": {
        "id": "OHyORxzv3rLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(p)\n",
        "print(q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHVlMV0rVchZ",
        "outputId": "ee92e2d3-6663-46c1-b58d-1eec629e4c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1]\n",
            "[0.30000000000000004, 0.7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(1-log2(0.7))+(0-log2(0.3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujDwo7zZZaZn",
        "outputId": "6aedfa23-fd7c-4990-f750-ae121ff4bd33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.2515387669959646"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure(data=[\n",
        "    go.Bar(name='Actual Probability Distribution', x=events, y=p, text=p, textposition='auto'),\n",
        "    go.Bar(name='Predicted Probability Distribution', x=events, y=q, text=list(np.round(q,2)), textposition='auto')\n",
        "])\n",
        "\n",
        "fig.update_layout(barmode='group', title='Record 1')\n",
        "#0.8812908992306927"
      ],
      "metadata": {
        "id": "VrYNrPnD3sv9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "688f7709-1372-4ba3-b9d7-4cea99e8e0ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"5682e172-2973-4c28-ab94-8ee5acce05ea\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5682e172-2973-4c28-ab94-8ee5acce05ea\")) {                    Plotly.newPlot(                        \"5682e172-2973-4c28-ab94-8ee5acce05ea\",                        [{\"name\":\"Actual Probability Distribution\",\"text\":[\"0\",\"1\"],\"textposition\":\"auto\",\"x\":[\"Class 0\",\"Class 1\"],\"y\":[0,1],\"type\":\"bar\"},{\"name\":\"Predicted Probability Distribution\",\"text\":[\"0.3\",\"0.7\"],\"textposition\":\"auto\",\"x\":[\"Class 0\",\"Class 1\"],\"y\":[0.30000000000000004,0.7],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"barmode\":\"group\",\"title\":{\"text\":\"Record 1\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5682e172-2973-4c28-ab94-8ee5acce05ea');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 1\n",
        "p = [1-actual[index], actual[index]]\n",
        "q = [1-predicted[index], predicted[index]]"
      ],
      "metadata": {
        "id": "d4VIqUH53uG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(p)\n",
        "print(q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-hHsPj1aAej",
        "outputId": "880d444f-5550-430b-dcd7-bbbe383b902d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0]\n",
            "[0.55, 0.45]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(1+log2(0.55))+(0+log2(0.45))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axxerslvZ-dw",
        "outputId": "8a247135-7bc3-48f2-95d0-5e15a0d8ed1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.014499569695115"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure(data=[\n",
        "    go.Bar(name='Actual Probability Distribution', x=events, y=p, text=p, textposition='auto'),\n",
        "    go.Bar(name='Predicted Probability Distribution', x=events, y=q, text=q, textposition='auto')\n",
        "])\n",
        "\n",
        "fig.update_layout(barmode='group', title='Record 2')\n",
        "#0.9927744539878083"
      ],
      "metadata": {
        "id": "LPy55AUR3vZa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "f4a087ce-7305-4ded-df3e-8b5baf637635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"8dba7efd-3663-440f-8dbf-1899ba83f664\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8dba7efd-3663-440f-8dbf-1899ba83f664\")) {                    Plotly.newPlot(                        \"8dba7efd-3663-440f-8dbf-1899ba83f664\",                        [{\"name\":\"Actual Probability Distribution\",\"text\":[\"1\",\"0\"],\"textposition\":\"auto\",\"x\":[\"Class 0\",\"Class 1\"],\"y\":[1,0],\"type\":\"bar\"},{\"name\":\"Predicted Probability Distribution\",\"text\":[\"0.55\",\"0.45\"],\"textposition\":\"auto\",\"x\":[\"Class 0\",\"Class 1\"],\"y\":[0.55,0.45],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"barmode\":\"group\",\"title\":{\"text\":\"Record 2\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8dba7efd-3663-440f-8dbf-1899ba83f664');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 2\n",
        "p = [1-actual[index], actual[index]]\n",
        "q = [1-predicted[index], predicted[index]]"
      ],
      "metadata": {
        "id": "Job_lJb_3wYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(p)\n",
        "print(q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bph7z1TJaQf2",
        "outputId": "acc1c108-cf51-4f0e-c0a0-efe38c7424b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1]\n",
            "[0.09999999999999998, 0.9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#(1+log2(1))+(0+log2(0))"
      ],
      "metadata": {
        "id": "bp0w1xIQaSb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure(data=[\n",
        "    go.Bar(name='Actual Probability Distribution', x=events, y=p, text=p, textposition='auto'),\n",
        "    go.Bar(name='Predicted Probability Distribution', x=events, y=q, text=np.round(q,2), textposition='auto')\n",
        "])\n",
        "\n",
        "fig.update_layout(barmode='group', title='Record 3')\n",
        "#0.4689955935892812"
      ],
      "metadata": {
        "id": "XSLNLZP131bl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "0029c733-982e-4591-e07a-0661a40bd0f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"df84960b-5bda-40ce-a29c-4c88d1e31021\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"df84960b-5bda-40ce-a29c-4c88d1e31021\")) {                    Plotly.newPlot(                        \"df84960b-5bda-40ce-a29c-4c88d1e31021\",                        [{\"name\":\"Actual Probability Distribution\",\"text\":[\"0\",\"1\"],\"textposition\":\"auto\",\"x\":[\"Class 0\",\"Class 1\"],\"y\":[0,1],\"type\":\"bar\"},{\"name\":\"Predicted Probability Distribution\",\"text\":[0.1,0.9],\"textposition\":\"auto\",\"x\":[\"Class 0\",\"Class 1\"],\"y\":[0.09999999999999998,0.9],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"barmode\":\"group\",\"title\":{\"text\":\"Record 3\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('df84960b-5bda-40ce-a29c-4c88d1e31021');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 3\n",
        "p = [1-actual[index], actual[index]]\n",
        "q = [1-predicted[index], predicted[index]]"
      ],
      "metadata": {
        "id": "MVrPti2L32uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure(data=[\n",
        "    go.Bar(name='Actual Probability Distribution', x=events, y=p, text=p, textposition='auto'),\n",
        "    go.Bar(name='Predicted Probability Distribution', x=events, y=q, text=q, textposition='auto')\n",
        "])\n",
        "\n",
        "fig.update_layout(barmode='group', title='Record 4')\n",
        "#1"
      ],
      "metadata": {
        "id": "DrdAMb8F33mo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "2d21143f-4e11-4ddb-d4fe-31d0fb57c3e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"cdce4604-a683-4429-b58d-0b9843502f17\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cdce4604-a683-4429-b58d-0b9843502f17\")) {                    Plotly.newPlot(                        \"cdce4604-a683-4429-b58d-0b9843502f17\",                        [{\"name\":\"Actual Probability Distribution\",\"text\":[\"0\",\"1\"],\"textposition\":\"auto\",\"x\":[\"Class 0\",\"Class 1\"],\"y\":[0,1],\"type\":\"bar\"},{\"name\":\"Predicted Probability Distribution\",\"text\":[\"0.5\",\"0.5\"],\"textposition\":\"auto\",\"x\":[\"Class 0\",\"Class 1\"],\"y\":[0.5,0.5],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"barmode\":\"group\",\"title\":{\"text\":\"Record 4\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('cdce4604-a683-4429-b58d-0b9843502f17');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 4\n",
        "p = [1-actual[index], actual[index]]\n",
        "q = [1-predicted[index], predicted[index]]"
      ],
      "metadata": {
        "id": "lTV9yZBf35F9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure(data=[\n",
        "    go.Bar(name='Actual Probability Distribution', x=events, y=p, text=p, textposition='auto'),\n",
        "    go.Bar(name='Predicted Probability Distribution', x=events, y=q, text=q, textposition='auto')\n",
        "])\n",
        "\n",
        "fig.update_layout(barmode='group', title='Record 5')\n",
        "#0.8812908992306927"
      ],
      "metadata": {
        "id": "5vhQvG6L35-c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "dff5f814-1a67-4eee-cdd9-85c0f03026e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"9eb243bb-3320-45c5-aff2-84efee0138fd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9eb243bb-3320-45c5-aff2-84efee0138fd\")) {                    Plotly.newPlot(                        \"9eb243bb-3320-45c5-aff2-84efee0138fd\",                        [{\"name\":\"Actual Probability Distribution\",\"text\":[\"1\",\"0\"],\"textposition\":\"auto\",\"x\":[\"Class 0\",\"Class 1\"],\"y\":[1,0],\"type\":\"bar\"},{\"name\":\"Predicted Probability Distribution\",\"text\":[\"0.7\",\"0.3\"],\"textposition\":\"auto\",\"x\":[\"Class 0\",\"Class 1\"],\"y\":[0.7,0.3],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"barmode\":\"group\",\"title\":{\"text\":\"Record 5\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9eb243bb-3320-45c5-aff2-84efee0138fd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary Crossentropy คือ ค่าเฉลี่ยของ Cross-Entropy ที่เกิดจากการแจกแจงความน่าจะเป็น 2 แบบ คือ การแจกแจงความน่าจะเป็นที่เราอยากได้ (Actual) กับการแจกแจงความน่าจะเป็นที่ถูกประมาณโดย Model (Predicted) ของ Class 0 และ Class 1 ดังภาพด้านบน ซึ่งการได้ค่าเฉลี่ยน้อยนั้นดีกว่าการได้ค่าเฉลี่ยมาก โดย Binary Crossentropy Loss จะให้ค่าเฉลี่ยต่ำสุดคือ 0\n",
        "\n",
        "อย่างไรก็ตาม Binary Crossentropy Loss ของ Keras จะมีการใช้งาน Logarithm ฐาน e แทนที่จะเป็น Logarithm ฐาน 2 เหมือนกับตัวอย่างที่ผ่านมาครับ"
      ],
      "metadata": {
        "id": "r8P859ee37MS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_cross_entropy_loss(actual, predicted):\n",
        "    sum = 0\n",
        "    for i in range(len(actual)):\n",
        "        sum=sum+actual[i]*log(predicted[i])+(1-actual[i])*log(1-predicted[i])\n",
        "\n",
        "    return -sum/len(actual)\n",
        "\n",
        "binary_cross_entropy_loss(actual, predicted)"
      ],
      "metadata": {
        "id": "bkfW7APb38WQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4082a907-1c37-4903-ce70-0a7ee7b58211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4219389169701714"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.binary_crossentropy(actual, predicted)\n",
        "loss.numpy()"
      ],
      "metadata": {
        "id": "_4rABi2j39Ys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65267ea7-5d35-4268-c5c4-35fd42362d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42193872"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actual = [1, 0, 1, 1, 0]\n",
        "predicted = [1.0, 0.0, 1.0, 1.0, 0.0]\n",
        "\n",
        "loss = tf.keras.losses.binary_crossentropy(actual, predicted)\n",
        "loss.numpy()"
      ],
      "metadata": {
        "id": "uK8_6RVb3-WL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "badcbf20-b47c-4c9e-a4c8-db7b58595523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Example"
      ],
      "metadata": {
        "id": "WY3gjLFR3_VH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "เราจะทดลอง Train Model แบบ Binary Classification จากข้อมูลที่ Make ขึ้นมาด้วยฟังก์ชัน make_circles ตามขั้นตอนต่อไปนี้"
      ],
      "metadata": {
        "id": "U7An4rfd4Bby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Library ที่จำเป็นต้องใช้ในการทดลอง"
      ],
      "metadata": {
        "id": "AM2Xnwy94CjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "to_categorical = tf.keras.utils.to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "KTh7aZ6W4DfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "สร้าง Dataset แบบ 2 Class โดยใช้ Function make_circles ของ Sklearn"
      ],
      "metadata": {
        "id": "J2wQUORo4Gk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y =  make_circles(n_samples=5000, noise=0.1, random_state=1)"
      ],
      "metadata": {
        "id": "CkqIj8oK4Hpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "แบ่งข้อมูลสำหรับ Train และ Test โดยการสุ่มในสัดส่วน 50:50"
      ],
      "metadata": {
        "id": "0hfMNmpB4I0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.4, shuffle= True)\n",
        "\n",
        "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
      ],
      "metadata": {
        "id": "8C-dmJkc4KGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d83aab6-361f-4257-ac77-5938398a1998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3000, 2), (2000, 2), (3000,), (2000,))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "นำ Dataset ส่วนที่ Train มาแปลงเป็น DataFrame โดยเปลี่ยนชนิดข้อมูลใน Column \"class\" เป็น String เพื่อทำให้สามารถแสดงสีแบบไม่ต่อเนื่องได้ แล้วนำไป Plot"
      ],
      "metadata": {
        "id": "42FkTQPH4LMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_pd = pd.DataFrame(x_train, columns=['x', 'y'])\n",
        "y_train_pd = pd.DataFrame(y_train, columns=['class'], dtype='str')\n",
        "\n",
        "df = pd.concat([x_train_pd, y_train_pd], axis=1)"
      ],
      "metadata": {
        "id": "n706JosL4ML_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(df, x=\"x\", y=\"y\", color=\"class\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "w4mdPbMu4NEA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "8e116614-a171-4792-b256-c6db0c9e4d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"78455e34-287f-41de-961a-70211c3d4ec3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"78455e34-287f-41de-961a-70211c3d4ec3\")) {                    Plotly.newPlot(                        \"78455e34-287f-41de-961a-70211c3d4ec3\",                        [{\"hovertemplate\":\"class=0<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"0\",\"showlegend\":true,\"x\":[0.6333050808665484,0.9307862775576421,-0.7943830942400153,-1.2558614160313577,0.9864952003215826,-0.4458477526622394,0.05865154805243111,-0.17513043780432175,0.2646652898085248,-0.4769857507297728,1.0830612217533606,0.5033473083537711,0.26628573124060767,0.5333823457298054,-1.0061361456685205,-0.45203387056363753,-0.07226736504218068,-0.5905783621177465,0.13759598525175876,-0.24870806085894775,0.7546768127874139,0.7918087573474742,1.00292882741543,0.42737623117046136,-0.8702499072080123,0.17629771259615254,-0.905058372412717,-0.28885014379241664,-0.7791914071065374,-0.4386107211268738,-0.7661974367405884,0.5125183419555845,-0.8465648286880745,0.12818839242346491,-0.7555823780567954,1.226412824663143,-0.47109570934249495,0.3048028404242465,-0.4307850508849105,-0.9500869041810728,-0.3890331250384473,-0.22706126895946077,-0.0396926349597482,0.7428976887745677,0.5630618500026361,-0.5789322847128052,1.0767609322145693,-0.9482966261963536,-0.3302606297410569,0.3420927182682118,0.9914683456523514,-0.49554182011411335,-0.9766037061389516,0.20084227746376626,-0.5924002873097693,-0.6999025583453171,-1.0325837474556618,-0.5020568329663081,-0.3776031293129093,-0.730364367151074,-0.7560465994881141,0.7750918056293874,-0.7121180602625906,0.2406242976130267,0.49685227339026644,0.7998731790788064,0.11060606455614687,0.5382187229526229,0.35335294132250433,-0.5638834221847675,0.9363269387873192,0.7125445393652206,0.9810434041548476,-0.17857310059734988,0.6468649817167049,-0.7866013871372632,0.5113627478401028,-0.4090097998990269,-0.6198726297659514,0.7631004711924128,-0.7931301020380357,-0.8816265658674275,-0.7981008129493308,-0.35513919738969874,-0.5555777124695023,0.8013693650782436,0.08071295335904147,-0.36482052633994755,-0.8335054300164809,-0.7649383616450808,-0.2567495831631564,0.9410473134339458,0.8023165020635681,0.35510195852020016,-0.7621287709088931,-0.8487959877225465,1.0164871599137277,-0.5378941038272862,0.2744140788544547,0.8900641850818289,-0.710508321472317,0.003675958143689515,-0.8125690571510163,-0.7428146724061955,-0.8659530096922137,0.6982050875016013,-0.24134148383853546,0.14901930016308,-0.12545568538252197,0.8058744324952082,0.8819327067581493,-0.8193446959181667,-0.435587158097951,1.0622736209473564,0.8146440974652531,0.39307060661535864,-0.8941776384794979,1.0711227898086984,0.7061091935877337,1.0321671398476482,-0.571917328728672,-0.6396857653128014,-0.6164074877306793,-0.8336605705479248,0.8637791657294166,0.7275755246528783,-0.9805606806876181,0.2605918722329066,0.3918781851073678,-1.1090756247896727,0.617830257728722,0.5409157390192454,0.15134019154326073,0.4951745288691384,-0.6011858683914589,1.0176437471045383,-0.8083222423330128,0.980061592656316,-0.8745045886390562,-0.8749298359364095,-0.018199910662894062,0.8113158661902196,0.5529700929125974,-0.47813950872246247,0.5375300806333339,-0.1045873594939366,0.10078311926275632,0.519884265413088,0.729405331066669,-0.19264484373143248,-0.02603952643598073,-0.6368924465327692,1.039103802200294,0.5755695976053606,0.08242932702124584,-0.7442510168420413,0.6701637788439907,-0.8284606816394976,-0.8971641201068045,0.7500862804972566,-1.081492867333685,0.9717474194079034,0.8501612645696227,-0.6344774451725828,-0.9599151884908049,-0.633220577326754,-0.1330634491702313,-0.8039804226807566,0.3144199461252202,-0.5077955839314204,-0.8488157986301695,0.41664887437032566,0.5903697539305981,-0.6018521564573831,-1.0696843320327076,0.9890152761928864,0.23497851633079228,0.47253775060479436,0.7884703733436866,-0.5051201652860892,-1.000039916246057,1.0201980704520655,1.2063073595304123,-1.098576633376278,-1.0988670131902536,-0.5553973341324534,-1.0397080642725245,-0.48737273036144,-0.29014683103162464,-0.02976001394015139,-0.5788328349927906,0.7494581721026194,0.10125841786350592,-0.9505841500839175,-0.7372562658605959,0.45213500817207947,0.8019091493808451,0.3593555092508766,0.3989026445339818,0.907696352732169,-0.2405469491960816,-0.9058046897168405,0.6133785097531231,-0.9014433579229703,0.7264526510797022,0.6952087386649324,0.5418007584177641,-0.6840581744429632,0.9881467975242637,0.850643464281706,-0.3633031592569156,-0.039856011599939255,0.6624426707882014,0.07654001598939865,-0.018212766045486883,1.2282249029387549,-0.2643890693240709,0.8348565844584329,0.808773634438458,1.093641701382548,-0.1367748255103125,0.007833446991028614,-0.4071444578084908,1.088166796353487,1.0022188170211221,0.01303249904423099,-0.5546694985972108,0.5867636724462718,-0.5473866909113124,0.5778929345325229,0.0989420934123382,0.4754723168389933,0.8358300700399575,-0.8126896364752886,0.34612202736722086,-0.118004398519021,-0.8343967570865914,0.943573055146572,-0.27308170738349974,-0.8003190285797367,-0.6147103818834725,-0.8382641934702764,-0.8459789662131613,0.1922988332777057,-0.5955243711356142,-0.9561773092949012,1.0563022215042759,0.7530037825972684,0.47789576211447726,0.8634942355557865,0.8968121079783135,-0.36842404713303734,0.04427514913581157,-0.1816617824069074,-0.2579344609289154,0.2523550679953256,-0.37792100083865676,-0.4880640349171793,-1.0372460615275754,0.8255026571110111,0.2081002767006404,1.029685296587941,0.2899485694078558,1.132333043739708,-0.139016610627254,1.0495502541180501,-0.12496344474784414,0.9591127478808918,0.0877688425565189,0.8762410558153523,-0.5943255924285469,-0.39740437483005014,-0.3287959841504269,-0.08490248194550705,0.5340249452859387,0.05649070489966254,0.8200086899949178,1.0286421903119165,1.0263115450905522,-0.0183844894273229,-0.5235230507449946,0.33549722252747993,1.0021854821977723,0.5469765342228513,0.4084258824034948,-0.05787751119813258,1.0963956695970083,0.9605466562841211,-0.8654972610960587,-0.6763736524181122,1.2006375790605448,-0.4511183139272008,0.6563702483177513,0.871575902238644,-0.9771105722745664,-1.0557545138863793,0.8951946000992267,0.9059501747849155,1.0068118755983604,-1.1399250202736226,0.748737694186987,0.09524195782612209,-0.8236143813737697,0.9288872449769706,-1.2341328904293118,0.23879467289425024,0.5380615766163575,-1.0509482327971444,0.8568682982701378,-0.8587112471496869,0.4001841627100769,0.13071371039200405,0.8724580277213785,-0.529971874151929,-0.8184353481857831,-1.0407252507719063,0.2422366279374182,-0.20862869112704624,-0.6545790724252074,1.0446675733689164,-0.8395847301749739,-0.9884728498468743,1.142868765417454,-0.06429203539194533,1.0100878820943102,1.0138300657124284,-0.47453652363246923,0.9246508168788672,0.8581348163681021,0.21198565786405502,-1.0201002083237565,-0.2716054133228515,0.9324270295562958,-0.38114576487931806,-0.11689610939191646,0.863514229696338,-0.5646363053036264,0.9678467917410291,-0.9512192524589977,-0.09804047969747819,-1.0020296113730838,0.23666512008420704,0.4169291299263922,0.588385547085561,0.7841543127016187,-0.4701651566751995,0.8880377714206033,-0.23427459033847653,-0.17103218576011175,-0.7987856463945722,-0.3565193713713596,-0.8712473575176419,-0.5412905491580561,0.6235968086317667,0.43409611637280093,0.9126527999632765,-1.0404230023879448,1.099037746418255,0.6315999402065483,-0.6607260195671448,1.035406466796793,0.940787574633177,-0.9213259796677242,-0.3262721665810892,0.037838988844726765,0.2572863117095486,-0.45254396887285914,-0.8444443218277812,0.6420557595238254,-0.9883217175617695,1.1478577293082473,0.9940388799600344,0.8861304838336386,0.12665674118112677,0.4781392830163007,-0.49439443017346546,1.0170444871040618,0.10858334146831825,-0.056735155950502186,-0.7011285596797259,0.05160776377796486,-0.47491666739355726,0.5565295487285067,-0.9871914322241564,-0.9456301721102185,-1.1637249737338096,0.6695350039181848,-0.01919526346497827,0.8463898517620977,-0.9318854962060441,0.5103173464293648,0.7709932660218111,1.1834808646492212,-0.41672005917019095,-0.9365391986779529,-1.0081202134642397,-0.7187753725743558,0.8143918015963155,-1.0559411465253412,0.5037123907289218,-0.7710003714269623,0.9768330937892433,-0.8564638214304903,-0.7116052514036384,0.76523075483406,0.9053803304860273,0.14229891329106265,0.47702790156032243,1.1636585709883385,-0.6797043817205952,0.9750694179074216,-0.07408056868093477,-0.84163536100257,-0.8765958638516044,0.27422574382270337,-0.9741304666952039,-0.31669412785946804,-0.533562146151476,0.709502910815796,0.8836355477644019,0.5445896286245053,-0.27277521737606264,-0.18732758509267367,-1.0033878532200515,0.9575453380530844,-0.7639263449999236,0.533470708267335,-0.18595029059653645,0.06473274435832369,-0.9188477460430831,-1.1074901852910382,0.1467261323689056,0.20846028767921848,0.24833345152961767,0.10962609693839492,-0.09832052929993372,0.37984418342316534,0.5480604311291439,-0.7560097877558305,-0.12845909599353994,1.0009465553942145,-0.6741371443743648,0.9578543629455154,-0.5323374904274232,0.4185407279420885,0.43267093000429263,-0.7427324284992791,-0.800275587891782,0.8103527333746434,1.0565546629291542,-0.6673678643239437,-0.7576665425496907,0.014642918020827927,-0.8453436018212436,1.0789167093077239,0.6693358043872583,-0.9434943369215838,0.07261907245480172,-0.8379217892347208,-0.9956521473695978,-0.873457739050526,-0.9642572734026584,-0.6623743722248681,-1.1111955751122577,0.8409501165745032,-0.5948005109570419,-0.0257930513673712,-0.45760044043888454,-0.3607018204112697,0.511700322772569,-0.046167718572700106,-0.3721517184012403,0.8895307911055007,0.19862821460940533,1.0937545152510122,-0.9344534132444358,0.6900408651673331,-0.4380436850984942,-0.4815850602829401,0.38267211824185765,-0.7807056575756849,-1.0693051026381002,-0.24012563074951535,-0.9982299247732841,0.4699843208549976,0.07059182752974685,-0.8930459379175775,-0.8373095730890339,-0.2749029947046163,-0.9254863727793115,-0.5708790302942466,0.4165096294162937,0.6347725631700293,-0.9146443520714079,-0.7481536316327798,-1.0057407506604927,0.6913106060813412,0.1409558552413438,0.6138273662702236,-0.21728508666518698,0.0721079660970067,-0.8984004039932819,-1.0028594835092939,0.8921574318960952,0.3009724303617386,0.5160090388627498,0.39044465253027766,0.2830637755752225,-0.7098580256967365,-0.1480618831978481,-0.9918868418697856,0.7183808348037951,-0.6271007393133565,1.0242451278844547,0.005152138160464913,0.35130519070766236,0.020965149372185896,-1.0265389467922146,0.8222202406230641,-0.9436502870715382,-0.91250210542249,0.5837768288982793,0.7738720057567706,-0.07603661970485213,0.761171514933091,-0.7581508179636489,-1.0173475185821121,0.6798817378937883,0.7161044138003071,0.8251080720990474,-1.0493918018854043,-0.40802941759474753,-0.35300807239686816,-1.0362170499056902,-0.14949336306933314,-0.7299729127570257,1.0594686188339644,-0.5024946281067274,0.8108527706396519,1.064694445202747,0.21475948092115513,-0.26619286347957877,0.011908467196686083,0.7161149813280759,0.32214161132912383,-0.35145119293882854,-0.7252028675236031,0.8112661777798119,-0.7602854072200681,0.5878903007495946,0.6183270074246698,-0.6562578338480601,0.9498197340002237,-0.9994235517127287,-0.7329162486369847,-1.0068800890603582,0.812958009744238,0.6773886588277955,0.567835344906848,-1.1149453034755805,0.7394086990073915,-0.1401199905065966,0.3271315229261137,-0.4321640175384248,-0.2855531518111583,-0.8393178048636429,0.06238466211196607,0.35033858766646747,1.0373931392147808,0.8233243997259735,-0.04750793199548681,0.6612367032166799,0.9758999715003283,0.8295648420611484,0.23654729633571903,-0.32344467257569964,0.9868469495060898,1.033724458817881,0.8448992889094387,0.0213250204797983,-0.6911941935195238,0.22144122760572854,-0.16402331788055075,0.15294127232197857,-1.0362026652492906,-1.0053496463251317,-0.46212870275198625,0.34598235801521116,0.22154390794088724,0.9529633926811013,-0.49124496040216453,-0.1543499801873361,0.4789192173679874,-0.1238396532725847,-0.23616871515959215,-0.6549254809128126,-0.820270647912652,0.17480569483723502,-0.8308910665807768,-0.35352376234389793,0.9288372773784254,0.4621918404305115,0.7233952195130374,0.4439284561761292,-0.9108127982506513,-0.9431360589708131,-0.4223968881506407,-0.3712343463039115,-0.912768811874126,0.4015917597524642,-0.6772876995006484,0.09608204192781275,0.817528928036804,0.8328204035306657,0.353053354560075,0.17994183941394562,1.0243123967831025,1.0705224264297093,0.8786446544783041,-0.13905263895323378,-0.9212703089065576,0.3891153836930313,0.7082223843386911,0.6948705031663095,-0.32559082835957637,-0.9816602935607556,-1.0241046319068199,-1.2330032450972066,0.4502015097892881,-0.9620192301705256,0.8577298256342332,0.9179394001018374,0.4522452726829195,-1.009504613665625,-0.821308690839358,-0.9530563626149042,0.6761010411716739,0.9636414039384409,-0.07628235411962757,1.063377393163026,-0.45877167476606306,0.12374891560826504,0.2213750733634707,-0.0069004638698316806,0.7872189635786009,-0.28575353353243527,-0.3690354588152467,-0.05975374081895775,-0.17447121424864248,0.09646498878845604,0.10896789697732998,0.42504137160827293,-0.607358446667531,0.7224983329599922,-0.5565055666357208,1.0108563519491114,0.8948761400098875,0.7110958307129699,0.06051410680702422,-0.568101312101879,1.021791279169403,-0.9708677445248792,-0.12552698356996903,-0.1940741687903063,0.0665759430338472,0.7370765090464152,0.9100326489398856,0.6238935153504216,0.5124681850209262,0.8701562650972059,0.9456318389644085,-0.18405592914927704,0.8771104442769382,-0.1508037220038314,1.0050246242451177,1.0925075141519547,-0.8010765477411437,-0.6490227225168554,0.9372108288903043,0.3503391586535494,0.3966914227148334,0.8183365428162013,0.89490793125971,0.6289957147612018,0.911710713680771,-0.4433396734457317,0.2849114617120962,0.23046554751619028,-0.8639483845630705,-0.6441067783502676,-0.8397260768019777,-1.0652945588199816,-0.6397486324388334,0.966842800761708,0.4888974653091878,0.8670596216601262,0.9319269523245973,0.13014868104107072,0.5844953049873307,-1.0579882258555708,-1.1123215032061573,0.9457248170909531,0.12086555069248936,0.9762397065562589,1.0297090609624426,-1.0970588015177625,-0.04661584364412148,1.097459095953344,-0.6695705130118895,0.7412934809259397,-0.8665733451362456,-0.9929494601585253,-0.986915200995189,0.5039124831180936,-0.29331630183289414,-0.8389676766748226,0.7154659049231119,1.0106482810621749,0.6934436897597056,0.5844735017648605,0.3075027968665418,0.6512614406717588,0.8901335413322338,-0.34552374466699426,-0.8932819005927943,1.1274971678846886,-0.5663493938700056,0.6884202761205149,0.11272341053995759,0.8296580545982155,-0.7032310515759941,-0.878353389586699,0.54203090845361,0.9402090135311538,-1.0581809642804316,-0.9145405304313582,-1.057539095305717,-0.7302685887618746,-0.8474751185086371,-0.7528969182391307,-0.60347036392536,0.8727078019575514,-0.42344479268878193,0.2717586746169928,0.32710857211038474,-0.33239767996796726,-0.762351358365829,-0.519402450100142,0.8811285089473243,0.285165196355202,1.119752991040816,0.17884968792169953,-0.09053058682911133,0.22005574244319404,-0.7098373200055678,1.1254833894560878,-0.8105192775116388,-0.291825169443612,0.6722298547008018,0.8155021215671817,-0.620748615279016,-0.8211014133196434,0.9920429196722891,-1.0089938759636827,-0.27713686875604754,0.8856922321440931,-0.2769226585965147,0.13346736702156853,-0.6853824573412676,-0.6514281486667578,-0.9023456731356533,0.7766354042852396,-0.888164475716764,0.365356998943785,0.5852546454703602,-0.7468643830361887,-0.9615635432948476,0.9544956091791512,-0.18256703610134364,-0.9989560908203726,-0.46266946494921674,0.838048712706819,0.3139935671051708,0.27397414317051916,0.6737109697886636,0.1689061117448358,0.7855522966588775,-1.0354673348317247,0.6625650277595796,0.7547075879781575,0.7888907421256783,-0.35007390395102234,0.9135768167132776,-0.8401779312981028,-1.0586409050552477,-0.7418539111448368,0.9152620817133374,0.6400761956464792,0.8618558011892925,-0.2974430342337766,0.5037258670050593,0.1913643738449821,-0.7220103404860981,-0.8607383740882981,-0.5950064638507851,0.6591014037323942,-0.6024175416980279,0.4289211163855345,0.39253557715498,-0.9472275034926646,0.6457436911423171,-0.9572426547301319,-0.8445480189205357,-0.4729413084346459,0.3604521013686295,-1.053483119974182,-0.23640842788782337,-0.9896980493444402,0.08745467074164184,1.0416712241357322,-0.7137366836211847,0.5675540183894188,0.46067536325350855,0.9455958333358406,0.7740914730509177,-0.08295804171085533,-0.9153676545813901,-0.30615741125562707,-0.2049571480125058,-0.6339089441767671,0.29916487718507295,0.8648390887219332,0.7063321279065493,0.6762650684223913,0.5178454779311635,0.990903042252926,-0.16902854064784248,-0.4726756702309921,1.075198274803649,-0.521481366695345,-0.40776859978292124,1.1968088272464128,1.0067265984921845,-0.9731158320200555,0.9460275938430456,0.3892412740940646,-0.7981580917494627,-0.9194729904083029,-0.44792861748721136,0.5622831226914526,-1.1032585462974953,-0.6893699411311046,-0.1853845074752979,-0.6433746582267817,0.8977542714313604,-0.4251808308077681,0.3760605407431373,0.9839472383333803,0.35538177240162505,0.7519237058860712,0.043983152657171704,0.5273342858302053,-0.9273650632006687,0.2384702636598369,0.9053687744794197,0.09480736642115586,-0.9019966216290857,-0.7002891880402797,0.2552386634264724,0.8427108067305054,0.6260454334656368,0.7006762551502177,0.8250179272896657,0.9490578745401659,0.988280130472007,-1.1155749225839655,-0.859852586937531,-1.0989714611725787,0.41074128243062646,0.6832862936505798,0.9862427173258425,0.9146842133427937,-0.7440598680931935,0.1832326009825591,-0.8135506169744122,-1.1065599526917325,-1.0631275427813753,-0.971703180265308,-0.7901540230398034,0.5467549730735888,-0.0323781445711271,-0.34668997868854373,-0.74940183236983,0.31281030547258465,0.9368464087950819,0.6339709844058231,0.5919959384753847,1.0287468779142157,-0.812672248754391,0.6623114762448628,-0.7165243718806423,-0.3589357407427581,0.20246662066597834,-0.2003334159902102,0.9136685352670122,0.5241646008069476,0.023159989627292276,0.7423239136864764,0.6524116053646043,1.0860286476736296,-1.0230055192818202,-0.5346483560458989,0.7193490613772799,0.4972454592673034,0.8854217977578498,-0.8690291296152749,-0.612251165719383,-0.25691249316281395,-0.6018751782800827,-0.7918128281597802,-0.570781358172008,-0.9497928164309178,-0.011840316622101433,0.7801000957434975,-0.8045738889091232,0.10027930723551073,-0.8655762765650484,-0.08228632318041204,0.26820750560526685,-0.9873721767245649,-0.9070170734209736,0.5954444997578202,-0.5435751111596615,-0.8832747784190298,0.8260671182711186,1.022306731365743,1.0937258358122148,0.9291559124135237,1.055224343865487,-0.7116303789340035,-1.0164656538764807,0.9049007179145994,-0.8454686961063227,-0.5744061341922624,0.9327937673180172,-0.9520663496752604,0.25983083886657005,1.097526523727634,0.2764020806306935,0.7009470312191823,-0.10809449985646408,0.8482365913110929,0.1499656255515095,0.6897407726991224,0.1151284139128422,-0.8584973084403809,0.16248368408561276,-0.6570942562829631,-0.7260536103995521,-0.6234164085599001,0.6853146950316831,-0.5035443305472116,-0.7757563598466917,0.6529304048381216,-0.015322996192508057,0.2270001625131042,0.7443054078494076,0.32350746275868036,-0.13616928272798826,-0.7023473589874487,0.0964031094607295,0.7972114324945787,0.44219369977902245,-0.9370474273482263,-0.28177977131195897,-0.9261036206100668,-0.3668016879166757,1.0697160527505711,-0.6031332782772966,0.04583459720412286,-0.06183569886809989,0.024022474983302997,1.076641328249578,-0.1290013263744634,-0.6380265669166665,0.6710859443189858,-0.3421928323864004,0.2307725391529672,-0.6311098932753334,-0.922294876568576,0.8155442787273574,0.334528349215423,0.918682447413985,-0.6320700972437759,-0.795432173633317,0.8874000373197664,0.5783927294733486,-0.8914335989721588,0.709689626843716,0.8013186462005153,0.7016123971935958,0.7371812754868367,-0.10719582863291376,0.3483513937368225,-0.761116017289748,-1.109919512172604,-0.5392124678512531,0.9751361691062524,0.8409415351397592,0.8123372855967579,0.25018267901512303,-0.6962566701866504,0.5549410147742088,-0.8961731926738397,-0.38196045514145527,0.8626075306302702,-0.4189774082012222,-0.31643771701913626,-1.0474397317172734,-0.2140493995803439,-0.6514156888153113,-0.12245680750569249,0.3930030705901177,1.1951995961224051,0.21656614602761218,-0.7805277907333097,0.8844729002867976,0.9109200480102267,-1.0678093693917925,1.1332266500180608,-0.6607613565341277,-0.8029984397002001,-0.8507442502657842,0.37790032087553227,-1.0920231384589874,0.025438450943271504,0.13602722234810324,-0.9497839697282489,1.0438786316314936,-0.7638397569887787,-0.7142838235805224,0.2376660558759311,0.9574600364014164,0.28788703624753326,-0.08571141179320033,0.5511187337349731,0.3757791882593433,-0.9396609494953981,0.10772303093979806,0.8051616016634521,-0.9421289543273715,0.1428511483620122,0.5218246146593116,0.29102442272876666,-0.8196925674501572,0.5784114416151347,0.7574733538544774,-0.9413257076092856,-0.8915823047384087,0.511880321682493,-0.9585715229229353,1.0430858545361705,-0.6054125606550685,-0.7808603787240362,0.9870236807928136,-0.4643124959616243,0.3225210596296069,0.724307008332395,-0.5054197006975654,-0.44588866446474595,-1.1559929979732746,0.002294138804142698,-0.7989076663878033,0.12714137920335236,-0.9522018314210172,-0.6656427561231733,-0.6290278786360679,-0.6988895222302586,-0.9882049126979477,-1.1185195070103084,0.6731164821978344,0.9330996037371241,0.5642881378608291,-0.18803192043937705,-0.8488653518906689,0.33819322155123055,0.22549173164333397,0.6907312351976724,0.9262138385055966,-0.7520681119733027,0.6948125070164721,0.7754311408709291,0.05791327821727233,0.09290391761993042,-0.10164789515238393,0.5194603570902365,-0.87412998129311,-0.8006738074080134,-1.1763224055098223,-0.8800818933635731,0.05467516165999453,0.8475796267221329,0.9089650099863595,0.365936521153881,0.6616458811744756,0.3374499952435957,-0.5402284270980244,-0.6221957317502085,-0.5930083108765173,-0.40222469288476353,-0.1058098618066684,-0.7403182472608576,0.19443078063281724,-0.4986247297040196,-0.8273175514640179,1.1678282995705906,-0.7208347364882512,0.6827998205915498,-0.33326932023581407,0.8325139057258619,0.45798753950316184,-0.24338932025219795,-0.9463572298282241,-0.35011375610574214,0.8405337692746775,-0.7740812968943672,-0.6529059236131031,-0.7946142270041587,-1.0003921797265993,-1.1542356876127557,-0.017675478196568863,-0.28867497756372684,-0.16376753266716187,-0.9362379043200634,-0.9764636075700147,1.086507433643142,-0.37911231830905695,0.39996026881370017,0.93283396314514,0.9844916002218949,0.9687215170308313,0.9808569473731374,1.0051444001399048,0.8709764630637443,-0.20525994441137796,0.5795882142847655,1.1223759607859969,0.49150121023269344,-0.8549698015358247,-0.21997163518707788,0.9326601281403444,-0.16417332076988303,-0.8732241327744756,0.9800193040239681,-0.14106485118973186,0.37452516455818985,-0.8718396459532487,-1.0003642556134111,-0.32647362125875945,-0.4091039067580501,-0.49987259661436234,0.17246093684153607,-0.723588458902572,0.3580448247751283,-0.79869669368087,0.4320453761374333,0.6874628862356094,0.8182039493826091,-1.0710716854084277,0.8008659961538391,0.7286740884073861,-0.7006778353872047,0.8818401683997397,-0.979057547056223,0.9904027421517382,-0.43350843744878553,0.36893678041314765,1.0468665894976628,0.3590309288930198,-0.5199194600776076,0.5329286648892594,-0.6667023986067047,-0.14225377946264764,0.901065930468668,-0.23068376356205206,-0.8800186415683642,0.26587326343502116,0.8927687451330372,-0.39927254334282997,-0.774127355383472,-0.8747422273508471,-1.0121799812906545,0.874494036469729,-1.0098644756072805,-0.09614193708557481,-0.1689720787728178,-0.5744788221601547,-0.24446510727877513,-0.9792288542842562,-0.8315565331736835,0.3348267109280395,0.9015848246765179,-0.6776916463701987,-0.8913890662111491,-0.9373417274131252,-0.2791938851124859,0.5333766288161216,0.5542070408027254,-0.10387779242208323,0.6330318435148521,-0.955492360258656,0.09696893815119775,-0.7896988837982046,0.15009737777052334,0.863667855474652,-0.10688540395823024,0.8635224764626022,0.7943511518008629,-0.12474847657274651,-0.9557632425691678,1.019750406762751,1.3259045459180612,0.552807934117883,0.6290696367982954,0.7183086595720939,0.7719582157313516,-0.9237884617547497,-1.031899232600161,-0.7375099042678354,-0.9441445897523121,-0.9052894511560889,-1.0945983485967665,0.9187786959337781,0.9642353454007506,0.523432952977098,0.7928518889749379,-0.7797119988925589,1.031166889225906,-0.19274318973563845,0.6842421804479305,-1.0025549261105786,1.0833164665120003,-0.8973275092657321,0.8608224533176978,-0.15982925458266325,0.13210270883792133,0.9344110949273218,0.3679654487745294,0.2824737611988074,1.0192021587230222,0.41675424731599425,-0.7509401421005024,-0.3472081838053782,0.20615787272482733,-0.6504589076012808,-0.05641541266635383,0.9820549882265567,-0.24555001774930246,-0.9034779046041034,0.15680157634187403,-0.5898740554347623,-1.126315910054028,-1.094196381182198,-0.9851159700226254,0.8128288879512415,-0.5408833619863342,-0.5284093323965272,0.36614929661415935,0.9296495046635329,-0.08118795256431699,0.8979028707415799,0.5477637642885957,0.9000326944788238,-0.5301968101888089,-0.01820377262458972,0.7028418434901268,-0.6004605594231515,0.7217420705257035,-0.6442497774362781,0.1834305228124073,-0.8021053556091685,0.9182199178419332,0.11549722007581001,0.9847838587064005,-1.038784027688381,-0.4465507808651534,-0.17941281389652142,0.8265189223706745,1.0852794826862588,-0.9004525977750554,-0.610665131136037,1.0807963322391423,0.44629540905553616,0.7841891524560205,-0.9741923857699848,1.1234099470972234,0.9668251734767417,-0.6829822829064319,0.31111943992663227,0.6360488534238734,-0.2528308232192962,-0.868083611998377,-0.3833730716105863,-0.5054415812112881,0.38503323931155786,-0.06629088800100624,0.9532534257213277,-0.3698925569880858,0.03648498749713594,0.37335666650850746,0.5757977614172668,-0.9858262569444987,-0.28732331187400834,-0.8635496959587052,0.46076999826707354,0.9000183395969114,-0.2923657755211124,-0.40125576458693285,1.2628469757380474,-0.7378714776687734,0.78872946658896,-0.3525784749885073,-0.8901112335455625,-0.1134787794589924,-0.5139431867447457,1.1010643486413436,-0.4333936280439634,-0.9096134261987074,-0.8301842889551745,1.0105307484834631,-0.9287388964690224,-0.821130158362507,0.9343575173403745,-0.16714100689021993,-0.5086687599619077,0.8012624337583292,-0.9578929534378925,-0.8332428780062469,0.22147921716866192,0.115795758097362,0.7785896538529616,-0.8569035623946839,0.5349427083478538,-0.10424638231564387,-0.9145822212106051,1.0875703447519112,-0.763906245464052,0.25703934800487815,-0.9290202507295361,0.6149614769784238,0.9465841548898644,0.8209675549534811,-0.9312165158050904,-0.8527706806126255,0.7494388002721889,-1.0205965761525584,-0.3055036764642872,0.970633956264656,0.763505886732379,-0.18800505025362857,-0.7581350225004156,0.7840295769899992,-0.36250850318498384,0.6493067681077677,0.9950927096872331,0.7747136315790311,-0.22060762494000066,1.0404021857853896,-0.5697941266855718,-0.40060791561337905,-0.7159945278071085,-0.7159253648385575,-1.0837740552828787,-0.1296837564355307,0.7696636446904871,1.039477813490477,-0.3901984082442329,-0.7352190042389998,-0.6899118818125732,-0.34533710987658933,0.1739238942377049,0.21138298160341412,-0.2646971672453506,0.7807764032450298,0.8331016898926993,-0.7620387844682095,-0.690561140187225,-0.09627716156956828,-0.38982162051164604,0.9025921445602522,0.08569579207623239,-0.6170416163191377,-0.8939050322307119,-0.6171489156874571,-0.8521184031846325,-1.0853854272850003,-1.01195119149869,-0.22134132174033191,1.0407283347980711,-0.28942108002103606,0.5400660418547067,1.0590375816433841,0.6684857519179362,0.06866285310374552,-0.8898526437749328,0.9374538579249669,0.20870915654293257,-0.034785177596691266,0.4883715657595209,-0.08691379614091078,0.46849863348106396,0.583614119567195,0.6083182514862263,-0.008734800709977592,0.8165833525257393,0.9778173935231075,-0.8962321830355635,-1.0308892546095372,0.8688070188466456,0.12188583599528952,-0.8053030503178468,0.7303532454998417,-0.6823562668969957,0.9536774828020439,0.23015844644915479,0.9739114090411662,1.0877247946577522,-0.4626069005328441,0.5260027645180336,0.7319006970828307,-0.8286176323681705,0.6363566826457879,0.54689330741019,-0.40972273777199847,-0.9752978502643478,-0.040798036335417065,-0.8214807146559363,-0.48808429179260576,0.6899000807992146,-0.8379198778247768,0.7697597749448694,-0.10666374214939714,0.5726044035414565,-0.48243245777594057,-0.40350369922025686,-0.9351742037690522,1.0339931541692362,0.9826647412587195,0.5284110815859623,-0.8283599636115271,-0.9110724686088358,0.5656604780230202,0.802924707217978,0.9634251334871987,-0.8968983870785858,-1.0221555900639738,-0.23887153586450044,-0.42695490766244715,1.0857205907595813,0.8784297865097396,0.9404553108998769,-0.966757351195104,0.9016425669232364,-0.8486008003466863,1.0806915810888322,0.6967210688055088,0.5087048664821223,0.2782830183312127,0.32728380173519944,1.061519662825353,-0.684259802329543,-0.8310689950547586,0.5824244205800195,-0.7711658459227438,0.935159841818007,-1.1413945683571014,0.45924994903012745,0.1699155307502857,0.3510732530903516,0.17356079947636802,1.1160573620059067,-0.3893820275902107,-0.24785161217160806,-1.021576431211335,-0.8470617145451631,-1.0175835911052418,-1.0500320015751556,-0.8961008291884426,-0.23215133648987563,-0.8608821035912145,-0.9982653486037488,0.024464784695685117],\"xaxis\":\"x\",\"y\":[-0.6038104331200215,0.08622829611227148,0.13955194566550602,-0.3032314990548589,0.33112640983656877,0.7213361370607214,0.8094664222258908,-0.9773297250056436,-1.070100214791048,-0.8053192444179101,0.3704967754101843,-0.8257329065324138,0.9503980619597625,0.9593938429475033,-0.040382525384253465,1.0023901341099222,1.1485686163706252,-0.7583171537395503,0.9716014340917666,-0.9829925067954529,0.9177567949707461,-0.7141020849250879,0.0040522438206695155,-0.9258703511258238,0.4603004256768741,1.0808861190918306,-0.5800944392435001,-0.7722533172573582,0.5522890631608977,1.1036439997757512,0.7381057818336827,0.7354795020596661,0.5946535385449339,-0.9735818959292314,-0.7487382242203843,-0.10595983600463894,-0.8355263295445292,-0.8192829350199258,0.8163129981494454,0.12565454169772622,0.9846315676278228,-1.0055965288844806,-0.8340598100114028,-0.7693791199335993,-0.9758188435270734,0.8007140049904306,0.11431918450449546,0.24156171912068491,1.0202362096319713,-0.8887086306087575,-0.23632132102512174,0.8563746794551758,-0.3656147997405132,0.8423104485060692,0.8778559161442291,-0.5039814072572518,-0.09467569308679258,-0.731075512611582,0.9905209258273789,-0.38369841141067806,0.8109269573717086,0.31769848886481383,0.6240435460770134,-0.942726631010963,0.9667121010014973,-0.6542572965885094,1.0637354651248376,-0.8976815628075834,0.9236256216745032,-0.801880230883756,0.591115347278957,0.5436051164087436,-0.16048133672794848,-1.044597258410178,0.7505436895717831,0.6273030221280501,-0.8230678174177729,-1.0331947916206967,0.9409025066325261,0.61454324459852,-0.35745811457556137,0.012340560956339744,-0.4219126824212939,-0.714973352711685,-0.7118663169069394,0.5332442997341366,0.9578071178958575,0.851821561376929,0.0693016282471565,-0.49287347838509227,-0.9180591102729586,-0.32498005368458904,-0.5119080630591037,-0.9044502032606885,0.4806359863366495,0.5422812569810534,0.27146852694586276,0.7368473091877487,-1.0235368085716965,-0.5920218660353139,0.6902903518773849,1.0581410137870826,-0.8446768477126787,0.17853114599437814,0.5532057009043019,-0.5405617159906279,-0.9429868008819836,-1.0240742371577087,1.0290082765163158,-0.2988328700430089,0.04315235379071264,0.5055510016477702,-0.8368031644138904,-0.2191166740815083,-0.15004074329411607,-0.9999959582530692,0.35845431338418,-0.14051410564979927,-0.6203745129493831,0.18602022733666182,-0.8844913294475757,-0.5548561661451804,0.7144494136656555,0.3246652828042609,-0.1324506026428589,-0.6621680094060453,0.1630837521339975,-1.0357888024077444,-1.0439794155922835,-0.2966420721552404,-0.8038614814657771,0.9291958944200315,-0.925079657907792,-0.7250978123555102,0.9949212398395761,-0.48339379999401116,0.5415175482277865,-0.38173886115414807,-0.21611200484948517,0.24131789541247545,0.7809732206731899,-0.45144391969902803,-0.9034633000729623,0.6748644640742847,-0.833538218227941,-1.052185684002895,-0.9013844071344398,0.8759632262056072,0.8276497848725978,-0.7870295465232352,-0.8647871737021442,0.7876785609596565,0.3487835683838846,0.8458875814891803,1.1896560479554341,-0.583955562413588,0.753534319606809,-0.5551034220415819,-0.8056889773583004,-0.760383782368043,-0.3871068445190333,-0.45414979957249624,-0.16585889647057425,0.857663914989724,-0.008178605861437956,-0.7515674623137152,1.050043081344515,0.5394352090255696,1.0798586037422047,0.9737470674120636,0.36530623467771245,0.7963987625994713,-0.7533023538444046,-0.7544425629314981,-0.21649992401577317,-0.3748722060262024,-1.0860417722021847,0.9466390812068719,-0.524111166698847,0.7116812481488934,-0.01177300020370907,0.0841140062153285,-0.32331776406805623,0.22869439236131311,-0.3623519622255633,-0.739990082096053,0.20405919957570268,-0.958828653337972,-0.9848784512270486,-0.8334358459686391,-0.732831728226425,0.7179776868582992,-0.9696498633186705,-0.39472646719346505,-0.38609338039102337,-0.9024833301824333,0.6663162210276584,0.9766245489966981,0.8887412875053807,-0.2409768551066988,-0.8625303097449629,-0.20033937647895897,0.7038990553144745,-0.7488127110187922,0.5349034187334893,0.44466080848692313,-0.8906524144264556,0.7608036724835332,0.06242304296865204,0.41404921639009895,0.7638464480756378,1.1047717030627595,-0.010391157600172708,1.0357875870599493,1.0001488926243718,-0.1699718692127368,0.9327687683696608,0.4199325178281706,0.5363448128230294,-0.3802490485321045,0.8896572426681634,-1.173278668011843,0.9526502998982381,-0.47936791182297034,-0.559641823546857,-0.9136814205061469,-0.899209948907896,-0.9276755307432549,0.7789935484169858,-0.733676953867419,-1.136089462580829,1.0484559313989201,-0.5353782178940623,-0.6932518925493714,0.8640747018661261,0.9565841335979824,-0.3055264507975185,-0.07736686375837343,-0.8435420912529991,0.41711957125725574,0.6705075239187863,-0.2781402750174353,-0.367416998263197,1.0050189862133214,0.7895364463086334,0.3692369422263964,0.4417419544901327,-0.778343817894729,-0.7437700015395022,0.6609794558774271,0.5061629533801602,-0.7796704624549652,-0.9006877816838552,-0.839627275652322,1.0467365918038165,1.0904449040563906,-1.0399074022106227,0.8814009325764557,0.17418374844703682,0.619656798136939,0.9608767042801984,-0.16854339710723942,-0.7737698483825196,0.18489993411735467,1.075811712660914,0.20866387536968745,0.8991414130099034,-0.1271250182699383,1.0077816471175782,-0.3605823189030369,0.6963956795688652,0.75823034706441,-0.9574693686855928,-1.037731255693879,-0.5685307847620868,0.9697568495890591,0.5991178286181694,-0.2959082101154498,-0.05747454242273414,1.06932171762877,0.8546375041923615,0.9179123557759603,0.13462154337896964,-0.793146737767892,-0.8902854244210605,1.0116379034447862,0.2852141283596258,-0.14397542698440133,0.028630717395749336,0.6310263141713902,0.2287508517704954,-0.6995612886068349,-0.6705218798643948,-0.46218461275917966,0.46568485615958466,0.09716815495690984,-0.526585275838001,-0.260876648235857,-0.12897249876898764,0.11746376532876211,0.5498093052004174,1.0082567778689657,-0.672611069728658,0.3487376975689802,0.5072258737231028,0.8822773864888586,-0.7264807786620298,-0.23915954274607978,0.31685665097289295,0.8015247557839877,-0.6268615960549336,0.851195503203428,-0.5290384471322217,-0.7642571456134178,0.49537546461610993,-0.5682907283277909,-0.8634264918710495,1.1924763372564078,0.7759731397451819,-0.31316074204424704,-0.41571479280190693,-0.5221771343720081,0.41575905704975724,-1.1652288110772764,-0.42513368370351845,-0.18478693194074985,0.6356508321009643,-0.29876282847083685,0.6330668748140903,0.8889808740521898,-0.29621228832604907,1.1047605111759382,-0.3221775163002465,-1.066086119597524,0.9537532050314323,0.193350168661073,-0.7592441908806178,0.32641609038229386,0.4962046418081429,0.9556025236219957,0.006457084437842178,-0.964710602261835,-0.7904971491636068,0.5165259695074955,-0.08556031719030155,-0.943518940284374,-0.08264498601651678,0.9282411991704618,-0.9901582191490164,-0.8608679601598417,0.8914489801488504,0.5257698216876215,-0.7505106289837874,-0.7312693481743824,-0.9866479472069797,0.3896538402474084,0.5084022606091871,-0.029044674783416758,0.8702989726372523,0.4365299025337961,0.21700859176634227,-0.3921132592860454,-0.6202813479178154,0.9594086013657777,-0.9706316152985363,0.9882014834340996,-0.8605445278423313,-0.2689757037050178,-0.6702183276029142,-0.3696194246418027,0.3362837643934514,0.3456324935409428,0.06831488066705049,0.9041497303723012,1.117797121244383,-0.8518732602717866,0.13480248264605843,0.9174359287617683,1.1186213983753979,-0.4381534007701122,-1.132279217323807,0.742527701359522,1.0827274813050152,0.26703749674146415,-0.5264019786001606,-0.25828267710106423,0.896077428367117,-1.012632961103657,-0.2846060045820227,0.5511202034065826,0.7212697447448038,0.5347930361845328,-0.3932028963649647,-0.8809862876980853,0.02046773704285329,-0.01291709200099004,0.7317044675263606,0.040480649816314426,-0.03609982058924002,0.7903097428365917,0.7421013888069954,-0.5686241068578518,-0.05758381564623842,0.443434905913189,-0.7149844201741656,-0.0018447714057072476,-0.9072998706875881,-1.084289815318194,0.18914335880431177,0.6222612298132225,-0.25636727817989513,1.033524738442572,-0.6929041588721795,-0.4976858623786448,-0.9348206726426278,0.2939886809415315,-0.9408496792494789,-0.7472378090028907,0.880535761394246,-0.48519604069284683,0.6069469019057302,-0.9945725380031367,1.0811707732393416,0.1818371572891155,0.23914870040968725,0.8071707987573808,-0.9630351228900021,0.9381709474140598,1.0731818040396732,-0.03184349708250429,-0.3430388319354068,-0.9858281957737689,1.0320882395202475,-0.8046762324799337,0.9366404874772641,-0.9329434969036595,-0.7676761175179722,-0.7968438787003022,0.6691997211782525,1.0126626142910788,-0.1345250928733241,0.5748241206407246,0.544880255031757,-0.9173863985282901,-0.819620734113676,-0.8388390522766473,0.608466941535157,0.5632026303080244,-0.9365278429727626,-0.118621994305179,-0.46936095363853053,0.3844564406709865,1.047435427860628,0.2798721546415219,0.6253578849882294,0.7624969907025158,0.22758501798348704,0.9214041472775406,-0.43125340849780053,-0.2687649791023546,-0.5448093219332202,0.3089910173632462,-0.8123687428132503,-0.16552901829013092,0.9794768408763257,0.73096553112629,1.0648830660724795,-0.9159633288429088,-1.045571115692614,-1.09350355949904,1.1525029235378892,-0.9002385504990803,0.4945308841835613,1.061173838780552,-0.5988043854132349,-0.059637135453278554,0.57146598373629,0.8273292440131089,0.9245128493012474,1.0593602318586577,-0.536381042678701,0.281025074792706,1.1186600675640221,-0.7651111180689082,-0.7224251991174362,0.9792643539978861,-0.35544425573787775,0.15755237819143797,0.6888295935768584,-0.23697135298826538,0.5590934349349799,0.6542562861381506,0.9553537370477312,-0.3884202513018963,0.7790877631852539,0.10925756999699157,0.587480184408731,0.9663599616305362,0.9199369444754826,0.914167883502471,-0.9141699179753211,-0.5232719344546122,-0.1874138615950914,-0.67732475463266,-0.9677044278855252,-0.7963191691362014,0.8494580587110291,-0.9266368129396322,-0.5680467484746865,0.817474707072934,-0.20794745472101528,-0.6549987417519251,-0.6980761193385718,0.7015062245833381,1.1404096182194254,-0.9421981112977389,-1.0168255231491852,0.3966152058657414,-0.10849659589180258,-0.24772003169271317,-0.5146272215039001,0.8490007269917278,0.07101181772862371,1.2462121665005699,-0.8582351669375244,0.896987482645956,0.5645492336221917,0.4023273707170554,-0.5354961745522816,-0.5260835723770948,0.15658846679577587,0.9038959856629362,-0.9229590229658972,0.4380640914768941,1.0460073461329966,-0.7919741409022529,-0.048296690512530334,0.8822295569294135,0.7176821894098632,-0.004791630381039134,0.8829354121044027,1.1164421318853297,1.0430280725831984,-0.5637963112063782,-1.1124814679952977,-0.8539595030551682,0.7988304338293974,-0.6100672593949433,0.9200992620355727,0.7873554102957359,0.8819534397822402,-0.7120688621124089,-0.42641882587517843,0.48960138776313983,-0.41826380945816005,-0.13044228704589833,0.35617737035194097,-0.5624216417473094,0.7344198482256151,0.1526713931678107,0.7110619296623009,0.9654512359190877,0.8473779199389991,1.0786429928096395,0.9271422136709462,-0.787765838911149,-0.9532557599771251,-1.1041911747466833,0.2773011078268612,-0.7322810617333108,0.9217665571711271,-0.8175502581222853,-0.6648236979441927,0.5480189829638327,-0.9549481010424256,-0.8315476453855647,-0.48170153547180816,-0.125154013577432,0.3066193437949542,1.0096647121037983,-0.8855769360144611,-0.9432676081489498,-1.0344635449360662,0.882387878579121,0.09671664549826103,0.18558374122009824,0.850886335926791,-1.077050885006533,0.8982988656496965,-0.06520429792697613,-0.8905070809978477,-0.9829880405089655,-0.9849034325269228,1.0965525250439672,0.9383667910137103,0.694306378044047,-0.2976052745668246,0.9895168653408452,-0.6215432587416593,-1.1282100190679363,-0.6859555599347503,0.934315037963795,-0.8733871700787803,-0.9424051154768484,-0.7074505209587386,-0.0002293268066486942,0.8576922598016573,-0.9288664987780456,0.24734064007889614,-1.0731806431175155,0.6771631173973226,0.8860918123446161,-0.14590623490035606,0.5550854950585541,0.9425494930546243,-0.8724568276650502,-0.2878710787347121,0.23187308906067355,0.6021611222252263,0.9390158339473784,0.6340399069325964,0.9753251257572143,-0.791080779416611,-0.4798262311832479,-0.8588373814384113,-0.15574431172248804,0.6126490003055216,0.4970931861234886,-0.9422326551297969,-0.31249342273633585,-0.10271013749379444,0.4582354835462258,-0.7946767656019396,0.5492432127390564,0.9060195088967615,-0.03137058797022431,-0.645689055241967,0.2549889255948694,-0.9028971681042333,-0.13730259473329182,0.8504907577247185,0.9378967623858769,-0.9149197251765749,0.9802376775149643,0.6568186031423743,-0.9278648161522705,0.9570111748629999,0.8433741690864277,0.9360516229291587,0.9257894204548178,1.184365988714533,-0.8504957430206207,1.0727271919605852,0.5863708011116787,-0.9034233924512535,-0.35391663006456725,-0.4262283219363724,-0.20685079888796556,-1.0825781565349715,0.9195276423921239,0.18288352904218622,-0.2746877214266366,-0.8810855600918697,0.8869115830925107,-1.0800079475525808,0.7944655674777694,-0.232453452573165,0.9553288705490978,-0.8284886208843375,0.3812921509428511,-0.301807960045797,-0.82817631439697,0.2716188273308686,0.9894953851354543,-0.21805606476249983,-0.09150690592710722,-0.7439959200902453,-0.7887092318446076,0.3414592423870111,-0.737733738646908,-1.0150679985206976,-0.29092474494868503,-0.42919323522164116,-0.7767339042296287,-0.2308183696529664,-0.9282692949879424,-0.9284708729904556,-0.9262680114254624,0.18312518580481008,0.7007771378743317,-0.6145008479225031,0.14639994139521245,0.7278034210215856,0.23066140055580603,0.8806555747562017,0.06620938904459062,-0.5319094788836932,-1.1050872984626496,0.6444470540343954,-0.49680380477858643,-0.1030008148256884,-0.46141783887405813,-0.9749453326330704,-0.17640303030919144,-0.16415112274460317,0.30427507504325874,0.9512163035747602,-0.014761528952949,-0.5884583147057474,-0.8937135049642874,0.08920623320952578,0.2697836687250599,0.3098893007148158,0.8195594102070328,-0.994495844494361,0.48391058124416714,-0.6208178099543448,-0.1464955436722045,0.4950588728110664,-0.8470640090503224,-0.8666837809189304,0.8803647549777596,-0.3912145192076446,0.8647390751860445,-0.516875090176082,0.10402297189363852,-0.7330693913304844,-0.5264286150742895,0.8944662622051459,0.9535334119703013,0.7751192159741973,-0.5434245220951125,-0.907493263169536,-0.3881984782034621,0.22103151358181183,0.6344983420609852,-0.5095496942130033,-0.595346945427818,0.2531575724380015,0.5370247584840577,0.6669835091109724,0.6390263440970929,0.788533035897198,-1.0326690465403592,0.9838530477944181,1.0253882747601746,0.7950563970391686,-0.8639785700940599,0.1266445018674589,-1.0877794935646685,0.033547775106554434,0.9717335366184807,0.8562775672978653,-0.8792535455423187,-0.5018440284571859,0.037103173028858606,-0.6341435736707652,0.9794231033716827,0.821923243286574,-0.21138348244819039,-0.8559153645928943,0.25374410461738,0.40745079968336884,0.26734817353661494,0.9364327019318253,-0.43995491255058633,-0.9660258011110066,-1.0924142359769315,-0.63730166891298,-0.8150022841562986,-0.24375835129329868,-0.7038947152157706,-0.5205823206667218,0.9789659364884068,-0.632690676471122,-0.8949151734343261,-0.37118186850596435,0.524530540161975,0.9414410329229866,0.32533974704235147,0.7958808272586649,0.8194915477164135,0.8606416143522022,0.9335803938490388,0.6914894635404697,-1.1442054483047357,0.6637355104098679,0.2509113891245644,0.5344696670725826,-0.5370225409497602,0.4674043599957318,-0.9231776456234753,0.10270709563673142,-0.5493695904852508,0.29201389435723824,-0.7375333017711924,0.19807662435206688,-0.7620301547568753,-0.07167887852891612,0.974950816996751,-0.9696696554909361,-0.898954645285085,-0.7803236196914908,0.43759638717964233,-0.6809468834133285,-0.9621803752384789,-0.6401509410232321,-0.9863569114738794,0.7501093565362023,0.3370472479003049,-0.5007172164663707,0.1540176108092984,-0.00075808445463596,-0.7934309664704281,0.7655547679039623,0.4028410876681488,-1.1274379349947132,0.4371283592896593,0.9843226850236461,-0.13741960098908954,0.6643546824718158,0.7101926172796785,1.0910029318536736,0.11768028332059474,0.6768968000445353,0.9481314216985681,0.3353876678505656,-0.9911751158947345,1.0445314442719287,-0.782917232249299,-0.7316362584661944,-0.7530259649552662,0.8929483840546862,0.7898727366020861,0.7201996733969821,0.32024546824040595,1.07214270406553,0.7854319123505109,-0.04751889921879425,1.1141953601534755,-0.8780398408103269,0.052054131601976604,-0.11737024385195827,0.3318227578837455,0.6266333731562039,-1.0027041956310574,-0.639540592862528,-0.12400518493401053,-0.7787253406669206,0.8394447559400738,0.11790018315963491,-0.6466441015442677,-0.9852610639566299,-0.45990696008111925,-0.3071321199291755,0.8884028759040561,1.073064577011301,-0.017915011480583512,-0.8778292852905204,-0.714753278551548,-0.9678044355370239,-0.8583718981861912,0.007586256035393063,0.9519263004085622,0.5013794613797162,-0.8414665379235321,-0.09268070534729325,-0.8754499419115683,-1.086976225493399,-0.510631115824103,0.7924903979606716,-0.6821292469904628,0.30481987300857954,0.4457647691901427,0.08104354544883713,-0.42117356060670297,0.49400132626808096,0.15757439439176552,-0.7487866607761379,-0.786199595471957,0.32984032694912585,-0.1231634796976688,-0.6755162465290203,-0.9490812104268618,-0.4042664772171758,0.6647408615757155,0.09330038666274555,-0.3579456065817976,-0.6415431608552168,0.9414390727418337,1.0399759625370173,1.0093719727179178,0.5187234418482711,0.9665355368620667,-0.2308444499385407,-0.8179950630438291,0.8443689526995091,0.39012117682947345,-0.5561489074640215,0.6698091693925067,0.8601916426755368,0.9285498179167467,-0.9946202805715975,0.9026908067833721,0.22441690162289923,0.7709606537646302,1.0597145747157088,-0.6758786376561301,0.4791851331715069,-0.18651639888611707,-0.12238576510238572,0.6632343161954313,0.5333702866621746,-0.6661804604451009,0.42571496881708887,-0.28387994043740294,0.7313696583407878,-0.9072567725851473,-0.8495630710993062,-0.687447299521444,-0.6793016399178682,-0.32073524948837073,0.9162991166097658,-0.6100824223956631,-0.5647286172457033,-0.9454617600338011,0.5362080443975336,0.8567405937926201,0.9827798189968308,-0.28924751323119796,-0.29037263429187765,0.8113757167555256,-0.7542068802832127,0.5517554030045014,0.8655666682235357,0.6231957208736643,-0.2647642214779398,-0.03736932192107571,-0.12031003219584321,-0.7450066907428048,0.17483198684902018,-0.5988955249948755,0.4971551385418449,-0.8583428110897817,0.01328860455040723,0.4251533186230602,-1.039968212175102,0.18152016387428405,-0.7769284656945363,0.6132329914486636,-1.0168119265771225,0.34012138695215444,-0.9360705373450382,0.5265062169255771,0.9968018540704809,-0.15817332526523736,-0.9442560235852214,-0.7229607700171417,-0.5526972044296452,-0.8837909548010878,0.72765590769633,0.7361597548114298,0.49285767024445903,0.8464802180624734,-1.1013650741953003,0.8874440861987895,0.6356454170918168,-0.9665516154060239,1.129807464648225,-0.7684263839174933,1.0346543555372973,0.5167332725732593,0.8210509630028626,0.23519970468604132,1.0088869555380566,0.16669803772085015,-0.8605810227766361,-0.15601602929449923,-0.5763715080891302,-1.1361108745844803,0.8708584981326255,-1.0244056847339538,-0.0696189953032977,1.0193938717514581,-0.715539061742564,0.609101448573698,-0.8829616998231425,-1.0613647390580736,-0.8539562618047829,-0.32426315362424396,0.7028938257852776,-1.031487659473624,-0.18159449349590906,-0.5805117590349489,-0.18274839896811493,-0.17935107681868362,-0.9591587868297763,0.294394107161496,0.5351133719719009,-0.41895926796836,-0.904478676722774,-0.7982378172051673,-1.198824139092678,0.9846755862279005,-0.7907789790474763,0.015743202287075903,0.9946331584807536,0.01901860182948986,-0.5179305179159022,-0.5751420615385144,-0.9452393876528369,0.7391030681288652,-0.7899995259929695,-0.4560468152252819,-0.9459343209340277,-0.4054976471287042,1.038289777057961,0.8765843118238976,-0.12807692790777367,0.9877131178634183,-0.8968505893013259,1.0994500234635614,0.9374474051782584,0.2136829017024695,-0.9860110693990912,-0.8855504932225103,-0.16874695308952564,-0.20616376550399734,-0.027896000699636034,0.4550609278055804,-0.7720247222782642,0.8259670318862112,-0.4940524200780531,0.9023710051553735,-0.38017212733235733,0.9046569890824248,0.8410511206357657,0.6454086067350964,-0.15307897394499723,-0.7644911763691482,-0.6120471796891135,1.1781306731344052,-0.03904268806487143,0.8479254555044131,-1.0052193594406311,-0.8051714764693154,-0.9933846521069638,-0.20537508076136585,0.8588502783311969,0.5460390568172246,-0.08035093868817281,-1.0027389598297358,0.7749979815329412,-0.8523147427241126,-0.7065380484069952,-0.7700580080804,-0.5075017460218914,-0.11851211497005837,-0.6061913206710043,-0.6940541800942471,-0.19818103434875284,-0.1432453926463336,0.7670735542773954,-0.7871510471248003,0.05262540805790106,0.8898383766043784,-0.9327539868806013,-0.8317145350448379,-0.87969594959064,-0.5300184404564734,0.17267808109069585,-0.750879698444394,-0.45261033850083326,0.6946534508315727,-0.08444784408450247,-0.8215466108089635,-0.9232491305808392,-0.6186618747930546,-0.07666731858642505,-0.1798672296632553,0.39149036988665603,-0.28997929033347514,0.8224145768726892,1.1211449875413804,-0.0423929904632032,0.8718634257741865,-1.0533415030683282,-0.9649263291548622,-0.13939410823920434,-0.6314610667760191,0.8177089464078665,-0.6598942562356133,-0.991589395723654,0.9994510718864907,-0.8852957978466817,0.7996324329758134,-0.1389197703548572,-0.6601919415587061,-0.06262751734298018,0.5081705962907831,-0.8687816765702612,-0.22964533095734774,0.5700079104728318,0.9149605931107756,0.715723488563423,0.8385105405148616,0.7958180643688211,-0.8271816261090909,-0.9373687511378159,0.8577677507716864,1.0914196581870792,-0.623033091782521,-0.9264065424554669,0.49244710431339356,0.7684713083162352,-0.10950472563619318,0.46841064696531787,0.5250365811711496,0.9118569668642407,-0.41378166374112524,-0.8315234386316582,-0.9198931749500194,0.35229314867914396,0.806769687137009,-0.555327602970428,-0.6718536472289388,0.7565377285417186,0.5732958034438138,-0.05289188896467917,-0.0032519598565952934,-0.9809458432947902,-1.0088324123573607,1.0525659042889992,-0.29266100385706534,-0.5218483566223568,0.5711697468765184,0.9532377924098929,0.9589894805351623,0.33420167640009507,0.1801407913947599,0.21895303554992246,0.09555435376692266,0.08529297170967126,-0.7851087619435632,1.1058665125398222,0.7247443826677546,0.2792929194169229,0.7619921336772056,0.2768153130206153,1.0882791646634018,-0.45803673666550004,-1.0353840008735857,0.5761241751323457,0.04191472630205813,-1.2833655348827702,1.0049434705990417,0.4103128047243538,-0.2722003454146583,1.028710135035943,-1.0051850337929331,0.9073422774190332,-1.012300881078096,0.8467013050881336,-0.8050355446516486,-0.9329590279997994,0.8519577792476517,0.5248168508649107,0.4185678937126522,-0.08183482475908019,-0.5380547429225142,0.6259567626586241,0.695195349076998,-0.3116197791424506,-0.422980604968848,0.376933392154734,0.806149766986261,0.8646623586571348,-0.1859210775098476,0.8946886999741978,0.6477593703818688,-0.8556066779103544,0.8530434343113695,1.0423903265888714,0.3349306065985195,0.9453887255631462,0.538692979815593,-0.7649532267062744,-0.42380972909806885,-0.9671950982071928,0.44562882525935316,0.3485159265400499,0.10173013892792931,-0.4606256051072567,-0.01351929642954279,-1.079927677305198,0.9975913810409982,-0.8099981935913085,0.9633606505525104,0.034573541014025794,-0.28421946457510194,-0.9638789206677887,-0.3561846872381067,0.8001157206361755,0.5256585762816508,0.36862318361128354,-1.0114175836990829,0.6704259056519577,-0.6669932007406817,-1.0633252521650924,0.6327636000465588,-0.49968686153918745,-0.98725111209613,-0.38266361952436123,1.022625783225735,0.08845504387316384,-0.8661708999020952,-0.6407863011191869,0.778441350995051,-1.1433725153408,-0.501769248445607,-0.26559836169463036,-0.18281441909151996,-0.7690521962176654,-0.8527866806457294,-0.6239342597979214,-0.6854321564114958,-0.32002089276937284,0.04528923455246314,-0.9905072027030088,0.5986395901058221,0.4378831913652892,0.3637925647576724,-0.24501856597542326,0.5759218314041068,1.0528431110398744,0.48700452837219993,-0.5063651457104498,-0.057480587697596536,-0.9028962859177012,-0.7873778232595092,0.2112581096674413,0.08361014040091935,0.06893851290768317,-0.6579115586237164,-1.1010166941426303,0.8823005749975498,0.4252051496463746,-1.0458294634051655,-0.8045646213466555,-0.4726787390263413,0.9554757385758186,0.3969186332523094,0.8249132543997995,-0.7320730089927645,-0.9506318607267715,-0.8167887971146248,-0.45184359689960835,-0.9926158527445009,-0.6687655085370798,1.0868690412839597,0.8647156795230494,-0.33169087077081855,-0.38935962739124774,-0.683706101572795,0.7647422207146684,-1.01537041601342,-0.9228914872982037,-0.8767487462826876,-0.5098128448729642,-0.9394068625360529,0.46182597352426724,-0.9279207033013773,0.22154235817422052,-0.8613724171838343,0.9594580091031946,0.9507931977726084,0.9550907540861999,-0.7655394637032227,-0.7091003932902207,-0.9530431213543453,-0.48776324477625865,0.023161255562743524,-0.9243034912931002,-0.2984292496962465,0.3105125925916527,0.8677563492173745,0.8808916723603222,0.6949015030309134,0.1686629669161499,0.48680778106740097,0.8209532311860528,0.23510379262119108,-1.0395857738787597,-0.2998342163821308,0.4582244208509531,-0.28348795384542735,-0.5138055948148417,0.6117611907408257,0.7690211792109198,0.6959088555790688,1.110407600015149,0.5041719869755301,0.8276604944407251,1.045753362326531,1.0855841048135748,-0.8626092720173106,0.4904457837504021,1.0006479325333792,0.896054723587842,-0.878903730852305,-0.9503963408523618,-0.3007322523688985,0.9965467135963281,0.546238817917172,0.7423708145575123,-0.14820844996401716,1.172294677880775,0.9502341202122706,-0.1256358486540986,0.11300324994689373,0.8485639924041728,-0.9841146796256166,0.6239956690258187,-0.9142431158811427,0.9793755439986862,-0.13237004093909088,0.9224585830922778,-0.5851260956384206,-0.1941239862030091,0.2373846995761119,0.07241457671371535,0.5763094273455088,-0.22544859757698046,1.1165999297587441,0.9681417067189659,0.754233461592541,-0.25568498544576124,-0.2615752428936435,0.8811739003749403,-1.0160548870533428,0.5755933544305162,-0.35467986607148205,0.8371506838798264,0.9358114998435229,0.23918777350273102,-0.5002851947464275,-0.5298229787598131,0.8562806892867914,0.43441539869927137,-0.7874884015583418,0.33849275549041197,0.7592270459584715,0.0697507442484119,-0.6223310265092616,0.5404867512370936,0.37100400156191765,0.9143654939348229,0.5997917553455765,-0.5934620567135208,-0.8138061420163524,0.49822834053059284,-0.46263579964571944,-1.0524012932071853,-0.7549109384965877,0.018081744243767336,-0.7182285870146521,1.0729268106795173,-0.21462650692099866,0.7944007467618686,-1.0199937812232256,-0.6298260450209209,0.5639763603733159,-0.01643011844248851,1.0150721129097477,-0.6203209427756926,-0.1803884726202615,0.9928812882421405,0.7818505959784156,0.7967898048563403,0.7960933525812667,0.9014164502542831,0.9137497124955176,-0.8574624664726058,0.34920214470872146,-0.7712303880530353,0.5340143934431635,0.9250051210869049,0.8839175641994124,0.878027789073095,-0.6327700221555062,1.0620373788684934,0.8437256955359879,0.34131589215032276,0.46023655094767957,0.400284193996875,0.3165647633496121,0.15082808228924727,-1.034945780973816,0.2268945040480058,1.0081629803090841,0.8180057115028355,-0.06689485119559571,0.8395935051189953,1.0614225691044983,-0.44670738508474,0.6401344710136031,-0.9403105864727018,0.941165385356029,0.8689818183264902,-0.8495365914965035,-0.8700438066035336,0.8648506968942213,0.8192752781646453,-0.8927172969825512,-0.6328176712509792,0.0880639659949341,-0.016330732493312843,-0.44971729211597455,-0.8415079053268699,0.9062858517018686,0.38333298430822105,-0.5594735459274792,-0.5883923293535277,-0.36314982660418094,1.044907534789641,-0.19140260715950425,0.25413488930647704,0.9251225174898277,-0.9106765657571065,-0.7543773498762326,0.5690869278304861,0.90209828435793,1.002008460841485,-0.9771611857259264,-0.36589819433781856,0.9512577740082693,-0.6317427332793676,-0.9921464947833059,-0.7623062183197662,0.12757681294076323,1.0552482418257458,-0.8476470945175119,0.9223396827917333,0.9118370820853084,-0.8005106894434335,0.564454281559419,0.5183367751209706,-0.26173159534091756,-0.9119632586720124,-0.22307085344382213,0.65749839357654,0.7130779602961942,0.08161981243060049,-0.020193816793380386,0.6649422554158244,-0.6339859859208197,-0.9582233059564488,-0.9389416133241644,0.4607122102400575,0.5997670854580106,-0.2966315730133549,-0.0001914643687983275,0.3035154431317452,0.4527603956337211,0.12375358618953713,-0.7046335354699349,0.8971063563285298,-1.1150272867924742,0.9784596818756346,0.043330634582487766,0.2342046712644253,0.22235403058550493,-0.7613365216255523,-0.70592343386018,-0.004102684439058896,-0.04666681632383737,0.8131706121427821,-1.1437064397210506,-0.9909748092541324,-0.994097424421379,-0.07562541124935815,0.7279813486286725,-1.0599718961002436,-0.09314759236264415,0.6726650667217038,0.514919408028978,-0.14943127023062586,0.18721084067465127,0.8743072098760276,0.515586878530451,0.38137872170782705,0.8986310614405304],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=1<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"1\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"1\",\"showlegend\":true,\"x\":[-0.8564794316702206,-0.9463009778909406,-0.6839633348580567,-0.5236992731211666,0.3631251754133315,0.07585097225393161,-0.38413756455328185,-0.4603837157272627,0.7451201411764481,-0.5841877659812946,0.14181961308835975,-0.24478438275479397,0.16744170557706461,-0.837426877050756,0.626715097812426,0.41250184691373804,-0.5307999827379806,0.2510510068476795,0.258159186262234,0.276470983050867,0.7447259069426082,-0.45774833988999974,0.8171062812667388,-0.5517745641631748,-0.4218804953758233,-0.7017728813256698,-0.6662106872786866,0.35045416588559664,0.39934129800380935,-0.4729314137324623,0.8010318023244338,0.39480731064651886,0.8292436387435569,0.061880257779751785,-0.38009477747658693,0.5676667739618434,0.037759708899954586,-0.08638944476232932,0.07739741215122228,-0.5945371134786791,0.48681583453822774,0.2201921982057538,-0.5831857316431703,-0.21528287743746669,-0.6582068223035547,0.2170547511803105,-0.1454199897086152,0.2190137888723262,-0.6722144593874805,0.8448084863901167,0.35361503611106176,0.647354195107883,-0.4377918473060879,0.7511987592595867,-0.5485315284104006,0.8560164795205966,0.7595929386108005,0.819241396053591,0.08725239174742927,-0.6522919177767756,0.3151091199296158,-0.8431688985960726,-0.8714393272336448,0.47421073723596135,0.01455250329958288,0.25407476065367474,-0.40113414522596724,0.44950493785431256,-0.914028626334457,-0.7805136775392545,-0.31867463124269596,-0.720950251339867,-0.09603791446941001,0.6570945397974322,0.12435535996617852,-0.2781457769752679,-0.8391130381735388,-0.7975991656235384,0.33174314246388426,-0.7328336092167033,-0.08314983235681997,0.11864256061835185,0.45208719091211785,0.48415419750646377,-0.4401204739276251,-0.14698004772571072,0.514380252277468,-0.5951480196518983,0.7681798249828257,-0.35391755020902715,0.8921161614853462,0.14667285291737037,0.20402755004305637,-0.5290908935067073,0.22225056604400462,-0.268372004038141,-0.402818483018329,-0.48554331536198947,0.6869709862865433,0.5389664065191522,-0.0855638270008161,-0.1523483827303059,0.2530977405384465,0.5128014053508984,0.6491928282284346,-0.893250942278407,-0.30940912494112816,-0.8147240435314079,0.6607833513726186,0.40571043222835157,0.24611141816079912,-0.6063448855930249,0.7130927461694102,-0.6973733176349671,-0.8618994158007991,-0.08141625685616653,-0.10241736309597095,0.3022694031794556,-0.402641700924752,-0.4934306098853964,-0.3659923114150284,-0.9618383208225064,-0.7809289233007657,0.9629732356679814,-0.3935766528365439,-0.24951284398318113,-0.24161702830605633,-0.27529501058436656,-0.61935465536558,0.6790427805041681,0.59986195239342,0.19450508454467952,0.2685483260896819,0.7961210288892275,0.8572070374319023,0.2119296512688491,0.21713710915268208,0.6646300823669355,0.5265199492012378,-0.6085300187047888,-0.7615656390502519,-0.37557856744789386,0.7173550556224696,0.7397962796097292,-0.7676458418909259,0.179631217625685,-0.7318724454624118,0.2319739119386397,0.7292216063698408,0.8056562642771072,0.9208310873660962,0.8529753842582277,0.7319686824601133,-0.6842452502659838,-0.3634183169261419,0.6771616201389078,-0.6781338954338688,0.682743796388773,-0.4198045514678207,0.2027356131589956,-0.3892463535672902,-0.7918254106397721,0.5565172204838232,0.5614570152047934,-0.19001922521441245,0.7641777786310432,-0.5968159317100767,-1.0498288647651322,0.33685250286145824,-0.45593743269554465,0.6778433647673997,0.3962877550936402,0.6870790548701263,0.7820470624479342,-0.7619898360629291,0.7278416469706586,-0.6829981278505226,0.0892183119720916,-0.5716251771659985,-0.9115864668765495,-0.5847260367142686,-0.5476276785181563,0.6632680326624371,0.2727192223344145,0.872229820520239,-0.2830547238857579,-0.2020086935126718,0.30263785440681684,0.6577253416692711,0.3021679645611287,0.4448161372773673,0.5128529403584567,-0.23619869400676646,0.5660705795934027,-0.15139346942060042,-0.2918799325756135,-0.6107455179517274,-0.770401299617184,0.8626240650354149,-0.6154576965675901,0.37712890433163027,-0.6117458873904529,0.9550038393167568,-0.21745230663790185,-0.8557959582605073,-0.596911012093389,0.001441953473963334,-0.6060124946294372,-0.8466429371900593,-0.6975036445011488,0.7220055924393008,0.7514382228911862,-0.32923272449255914,0.3314007811301957,-0.1415250471059469,0.7604451483817266,0.26045483032511363,0.6831869610934734,0.27503518458762183,0.15261486291736734,-0.8878447002425185,-0.21760183012728548,-0.39817720525787315,-0.0030618420359522225,-0.4371904726206529,0.7436608506658492,0.0995214872417966,-0.5417872063274219,0.6741741050561635,0.6411711334308458,0.13810036344342888,-0.823789184938249,-0.6178199824628801,0.3828149611726965,0.08980544214510927,1.0267485982692612,0.7977377557880986,0.6316159899279792,-0.6992374952776326,0.7636461437056715,0.6646131906392263,0.37461691789775026,-0.7024612513595196,0.6135581164132047,0.7210467966293637,-0.4081239723152647,0.8086560172371466,0.31061586061936775,0.5644592798408326,-0.30973088317248987,0.016258984644513683,-0.4638258935131349,0.00940588764752879,-0.8462281865408537,0.61542935950291,0.6286244848811575,0.7797770055978358,0.9107282023817408,-0.744749433300272,-0.4455818119206364,-0.265277037601764,-0.7333206120328885,-0.8484424520912692,-0.4267353033565303,0.6001106822178311,-0.7253742621084216,0.4424931209646419,-0.6422302677778563,0.23360543727459437,0.9944845783051253,-0.3058694405392596,-0.7952664688277168,-0.4239215861601071,0.5738323622068426,-0.8018311638742982,-0.6515705378942581,0.6653115484908239,-0.826339976858971,0.49530787980974855,0.23477787312656528,-0.15881477380445982,-0.7720191157046189,0.7701625746276592,-0.718417433389133,-0.2072779608980832,-0.8393206526869705,0.7067063769180832,0.6305069943021102,0.1534372042635768,0.7459289134799865,0.012226139268719696,0.19273627235659893,-0.6957775619103239,0.947536855426871,0.5449270775266029,0.6291135667456811,-0.7291523640053785,-0.20227371639028824,0.08492667742071663,0.36785371437221936,0.5386984039750318,0.7444725459689797,0.14287235398217166,0.4277305100908868,-0.39718919916421985,-0.5932851084848398,0.6265694566220799,-0.4519297077152628,-0.7073606671314272,0.4196382603935602,0.7966273562381095,-0.4111785220929869,0.8890402272245108,0.48662597792193474,-0.6325957110623742,0.9022112662730309,-0.628238144448526,0.6266197756337212,-0.8729757530036296,0.5524791024213167,0.5468426509600448,-0.5052727324879427,-0.6751193156020467,-0.38622175207991005,0.9239698017658917,-0.4914366550366759,-0.5916773541669229,-0.2762120447893782,0.4168011538570927,0.4986061822290428,0.6674993315608236,-0.20739412544811026,0.47151667061931124,0.5643424701575109,-0.28546393647740986,-0.5818892869955204,0.5348526471722908,-0.19371456783847352,-0.5206487727912599,-0.9082659540681748,0.8481914379739282,0.5185296315590616,0.1871118324926219,0.6730568435037821,0.8197252798872439,-0.11784236707961032,0.3840939664955411,-0.4477980630106488,0.7596688586344277,0.6215478206761619,-0.8394056885355984,-0.570931626648828,0.4711113305405402,-0.4862976181832699,-0.4845774047996965,-0.2158262493605619,-0.11628006556953469,1.0294242993510683,-0.5469262988667883,0.432130012172721,0.4745404937037516,0.7261583728317739,0.2709671281635125,0.09016853015149358,-0.44218054967978726,0.34519475909812164,0.6295900594897686,0.6605552293960406,0.6961954368096944,0.8078697073020227,0.727801146287155,0.7426795657946976,-0.09655958253422228,0.8341397490394944,0.3007811558379226,0.8026398634850143,0.35318615832677636,-0.34842692948967874,0.10780990877175729,-0.5560051971548529,0.7167819758428421,-0.831085716913863,-0.46803728337723166,-0.8910288157196473,0.874681933691364,-0.6864650121775394,0.8884160629736854,-0.6228661018980711,0.10011686184772157,-0.6764580260358442,0.23261792087339467,-0.3541544005064159,0.1431013830017209,0.7920474906155092,0.6863915050239311,0.7608608951474168,-0.18031810673356424,0.20474094870964682,0.8291257793628829,-0.7183814675575527,-0.3417590166747693,0.2986912794946262,0.43567252607659346,0.09753837042798043,0.8816771932117022,0.6551883779988829,0.04088358573976264,-0.6751653829889005,0.4704894074911873,0.4550080305836897,-0.3145459948951269,0.7823620049153415,-0.8193282345415694,-0.6766314680606436,0.7055810189899054,-0.7565081411726988,0.8366543930751428,-0.8647992249884868,-0.5541057158020573,-0.545017404221526,0.3969475405146602,-0.26381842062034083,-0.4231007901495402,-0.1473363329880788,0.5515097363480859,0.7793986357338132,-0.5904730879935167,0.7510113118728533,-0.07900375547053812,0.061146575408060545,0.0598389788004032,0.5495342392475749,-0.020934474946883032,0.4323168149234176,0.8218565686977027,-0.7308212228569666,0.4623262845768207,-0.36691180429939463,-0.6863232617927596,0.6497563658818062,-0.7295669232512753,-0.3715941649483414,-0.4423492989564797,-0.5017299799227932,0.5054961477660506,0.6081522829929127,-0.7344311939653304,-0.7867027930017993,-0.6762624179108323,-0.7127871208738252,-0.23497184612049082,-0.8090512574658144,0.03293810206716807,0.6084424961007198,-0.20200805464835153,-0.29877413791325913,-0.8910852848142728,0.34154119555169804,-0.9535287209084499,0.7140452145826817,-0.6237433557433245,0.8867726222591021,-0.6337804177055408,0.19569268029854098,-0.7668718476561712,0.6699427342462639,-0.5481646733981196,-0.6842328970348416,0.3933875202493185,-0.6373352219784744,-0.4507345308021409,0.4658646601159415,-0.712705581708578,-0.18006391998640428,0.7940447302582367,-0.9902123048198848,0.4468906938556429,0.7826177100564302,0.7220501091131932,-0.7964013086614371,0.6621972712147965,0.8334880549368666,0.12250758456831914,-0.11935219944908543,-0.5401643315111215,0.42639855401943977,-0.5734557629716016,-0.6330467299192176,0.48171779504111356,-0.8042592353482976,-0.7581465881257795,0.2615132652391256,0.7085026482377412,0.11721575355705713,0.04769207978500383,-0.12501421155475162,0.5433993023150627,-0.5979677011609952,0.37871420373057996,-0.7535418524367818,-0.10164572898130944,-0.6596441747233586,-0.6945369158001823,-0.7370024729896827,-0.5805646282327754,0.4732931942677406,-0.6324644114214475,-0.05180137280454952,0.6726963855199118,0.15753062363666798,0.6956803248726752,-0.1569189125434512,-0.5538364402177202,-0.7401023424331615,0.6531979598758052,-0.1228987605014574,-0.09075723240060515,0.11765053901278116,0.7052342590017265,0.21773176175650122,0.6034078875903365,-0.11862448458469738,0.6102657672760545,-0.7363892197081889,0.5435304792492835,0.2448150317650767,-0.5760004664363783,-0.6973161349699495,-0.5509180635308627,-0.26180675170947787,-0.3736545415205087,-0.8286897896318398,-0.27609446904475676,0.13491263251017374,0.12789657858794368,-0.3559181284560873,0.5964927489939031,-0.3776493825743891,-0.6930639299623262,-0.3419630036776679,0.009839237286539508,-0.8423941116221934,0.7612682712055423,-0.7614986201277534,-0.24725974898687195,-0.5008350722035178,-0.7065629262680825,0.41381700347058636,0.13017621222390235,0.7099994510226129,-0.1345521595029639,-0.5480216790247457,0.3139610519974991,-0.4965611044207811,-0.457178920227663,0.4629959521479366,-0.5938651942384126,0.5461410077700887,-0.8127296188669428,0.8084855985654263,0.7524891566223983,0.4684686369536224,-0.25840896643294586,-0.6459338223709917,0.4599868239322584,-0.07717799815400933,-0.7311551699492913,-0.6668834287924318,0.5914047086701639,-0.403042392489706,-0.3696980763154951,0.27262452596248965,-0.4088859416173175,-0.8842362371009607,0.4159642902790348,-0.6528291937016415,0.8433265244971238,0.3673154457287867,-0.5208385157882317,0.3228986524263918,-0.4159410559400476,-0.5584117280679836,0.40996589699838354,-0.6418416175701078,-0.1919588649271279,0.34365244681948104,-0.21635222724691133,-0.7482773671764157,-0.7822316722296685,0.8106371787339449,0.3263859600546458,-0.030548737116857336,0.6393438981224815,-0.8275710595581193,-0.7547185035258887,0.7664586612641738,-0.7856443568666521,-0.5838497422726876,0.7746885108876266,0.23769554724929404,-0.7570149401836453,-0.6018656706527563,0.6674514079808872,-0.4896316857821293,-0.6394337254080283,0.5174773234990213,-0.7892151478961351,0.5502954293761431,-0.5342704596671958,0.8537373782029011,0.19988866108441164,0.32215317163492674,0.776522122084295,0.47070081405303504,0.26081338998405373,-0.518869217659568,-0.4466990681691577,0.6955348268713155,-0.7509064709508322,-0.8023031284148711,-0.2740301137607015,0.696474101365032,0.5779887106435871,0.501224948867945,0.29717849344823916,0.8811013220395184,0.1838270656758571,0.322473685597847,0.2277449172479695,-0.7248987622028601,0.19205773591383368,0.1453117066960949,-0.688670510285986,-0.49413070120948127,0.6970745841320892,0.642373697742249,0.6771804139599098,-0.6428740668145891,0.773999072387382,-0.42690711405389103,0.6557336237463496,-0.6247090402626871,0.47920158716470374,-0.5503087274844538,0.4185528723936128,0.5095742015420349,-0.6764937258820626,-0.44933206350616206,-0.532647883630414,0.1210895784803038,0.034320482965000135,0.7268984270049217,0.23336657505974798,0.2857175067828938,0.6788561834878216,-0.23793022253147483,0.015106175742960873,0.34552783332108916,-0.523964289514048,-0.05295376738188834,-0.5250120992707991,0.1330049387393894,0.3803717560432676,-0.7136561921299414,-0.3022859986735613,0.08352734395410533,0.5592858156805978,-0.8490074136222691,-0.707202887767633,0.10916071116869072,-0.5355777790843128,-0.6935572300573167,-0.15153270637692087,0.09115311625426067,0.5190487435964766,0.5870695025476663,-0.85272087358648,0.8390400219529157,-0.3360027075440706,-0.13388759097785335,-0.4361792999174308,-0.1261259193873323,-0.5815336173977609,-0.8074413777371173,-0.1963552082279815,-0.7448672561750724,0.14754955434543746,0.5984099764646972,0.8367367631595735,-0.7697522400084371,-0.44539146075075114,0.5567363021191288,-0.12586098889221986,-0.685124546067318,0.0966317448968828,0.4057313450882845,-0.7439228741325337,-0.810598433457243,0.35874579449966715,0.6845593204260939,-0.49729027811006304,0.18771076359451427,-0.5858192606903567,-0.7083468011131915,0.4100011104952249,0.33730301381478883,0.08556965008861186,0.8175324366141031,0.6778827846830089,0.15588067650896167,0.2918269053734622,-0.2707059503866705,-0.7339393558844579,-0.44377590710600956,-0.03124419656308472,-0.17995430376672,0.9297076142763756,0.2426543294498783,0.4600183721949327,0.725654379753461,0.8301027025418624,0.8070521147145538,-0.6983461692293068,-0.6635478412787007,0.741128070706488,0.8013039549309701,-0.7620432123005442,0.011438840444676818,-0.7199807364058146,-0.8908388153120641,-0.7583294733992894,0.3819981498944929,-0.5172868629835368,-0.026781054895185976,0.5744308642425037,-0.9064190068200325,-0.6457249923939161,-0.6618920329901353,0.639651676834767,-0.0261520265960411,0.5576784943344427,-0.6586926602606531,-0.46556895978555923,-0.5706471059765604,-0.018418786203830834,0.18330183872332806,-0.5209110540975541,0.575414657991133,-0.4785659265493157,-0.7394087801697222,-0.7692130476335935,0.5471312485347142,0.6960550357660784,-0.9184313100607664,0.45933628639114626,0.8327295063832563,-0.13739454382907484,-0.19830767314293474,-0.24917262436137635,-0.8080203861948896,-0.3147538481322837,0.06975787885036386,-0.5906249148402698,-0.2553207022914505,0.01816698942128795,-0.5761709227057917,0.7683365862305744,-0.8201240806266337,0.6491651085319345,-0.07327949816253618,0.8908721093456389,0.6378366890242742,0.29745826649017015,0.6522799912412091,-0.6151203533477521,-0.49159928218558124,0.8105070022926198,0.5363471270460398,-0.32877572859312143,-0.5744312991619144,0.8330477859614556,0.5032436687472951,-0.6905833914363805,-0.08486309434938066,-0.2518471924952276,-0.23408240383098053,-0.674521034801371,-0.46131111054962165,-0.6057415864226033,0.45524691354608376,0.4886353482113478,0.8136774806528605,0.9720311847018255,0.2197141677225624,0.7351750311557392,0.3039367293066178,-0.9053839648212697,0.4898103819253117,-0.32798689646373214,-0.7299581485997642,-0.8730665295158888,-0.28423509028217614,0.5196829587385489,-0.47978771975888285,-0.5630482260948335,-0.7325648069594316,0.20051616452827495,0.7334072682422623,0.665162394810727,0.6863405937983872,0.7170493843629071,-0.20401906726101046,0.5477010608635867,0.7374764097107472,-0.7293330559423935,-0.4063927753820017,0.265600857090055,-0.7161602379020026,-0.6959241521173418,0.5955462130274026,0.7125445702333334,-0.4939876041414033,0.30833792654128334,-0.2509415820052056,-0.9910200219063925,0.312258534077474,0.6970016304768553,0.8402489300651127,0.28255970593515545,0.7673704116970645,0.9195053854035546,-0.5785922875621635,-0.7082049363599585,-0.6822472952838667,0.5669414133125438,-0.7227481465587636,-0.011628577191187664,-0.00801217663472033,0.36468178299259985,0.13525030607725938,-0.2700679971277862,-0.4459548434148987,0.06657203201295134,-0.21421834291002867,-0.689284047736894,-0.25352201775923366,0.6764094966588751,0.812784851154362,-0.7454318687042539,-0.7706198538269093,0.8368117737352736,-0.27178403743488144,-0.03649906690047307,-0.38019986737180245,-0.19627095415197823,-0.5297486344677366,0.7862572546824372,-0.5542253698739531,0.6028021680738247,0.5645758751060687,0.7178244322723976,-0.34752182193741943,0.30312738302983405,0.5115645872591529,-0.2530222232306719,0.5138538398283315,-0.5547541108886661,-0.7851843567745201,0.4095257876107289,0.774269241640525,0.5302026546279572,-0.5154267357070944,0.5586265549499425,0.7556196036859005,0.472588940600141,0.7084010250833761,-0.5999473158408348,-0.010787924153676659,-0.37798909499641764,-0.7572838893352909,-0.9993188523133643,0.19255965113306095,-0.8508045723890252,0.21846501569122034,0.6062025018317381,0.4176521150521178,0.7701337762799725,0.5879599283881864,0.331615643973507,0.07249990304260198,-0.6960887023955923,0.6070591465840017,0.6400072232127821,-1.0091994655216732,0.22491207479679948,-0.7607574011182122,0.2899675070601191,-0.5248314903757889,-0.5384667122247263,0.15551073299914486,0.6530946869382078,0.08824322944494467,-0.5090689877985378,-0.8045896333351635,0.10887636505820444,0.7754466200146688,-0.24237016578033,-0.5340039775340794,-0.6056914343038651,-0.6812298968696167,0.04293749292570681,0.8104054757126843,-0.6927672891146505,-0.6679951356406713,0.7021389770602776,0.019527072765662033,0.5569450763003545,0.6959684504702892,-0.554898633499314,0.6025577025529939,0.22912818929932594,0.7886264334743369,0.050677967000906377,-0.3254606244717545,0.7448058000043928,-0.4832645849111552,0.6213960845843621,-0.7581441748424425,0.3307190321686526,0.5706480476961318,-0.07189873593615566,-0.5578126469693739,0.821330322659301,-0.04484987472717613,0.008078225719955895,0.6122732173838559,0.1729829793715424,-0.40041755108529536,-0.07691502831266112,0.5615782509066435,0.6338307644493494,-0.3094238298247305,-0.41661278016028397,-0.15363534171148052,-0.5661127311137396,0.00516087701690391,0.7785569015125142,-0.9931999264347081,0.6979463260810962,0.8603098206439402,0.7348997923541672,-0.036136303627545885,0.30551794084040107,-0.8620858935001998,0.40187119372760394,0.755770656512393,-0.3113271220504333,0.6336731287470347,-0.7456246359523746,0.7251632062218817,-0.32689603774174364,-0.5190935658263985,-0.6840951501925,0.33152600488877765,0.2609613848671055,-0.8150498215512287,0.7339372360596779,-0.8722541066678727,-0.7159849170613559,0.1429757379500901,0.8976529271438192,0.4874075275617852,-0.489373925762823,0.5281799621027305,1.0134568526868648,-0.310443687187884,-0.2578269644216484,0.2363243197535021,0.8299514689077299,-0.34710612516746947,-0.2951094892702597,-0.7191586738422516,-0.5303619736055422,-0.008695790271867853,-0.6444665717918688,0.8058152269166968,0.9083088076783293,0.23156598496142655,0.9404545636403244,0.7898906346308023,-0.6333066259312945,-0.22190824611125143,0.36904002575619477,-0.32508452457676806,-0.028753796943254,-0.5577056175951993,-0.10006727096454791,-0.779601160053895,-0.8298945745333618,0.8228863657422597,-0.7197723288819772,-0.6348248728757703,-0.7941902115299027,-0.22757517602322602,-0.6982689333809424,0.20398365882951838,-0.7396993172353971,0.49925571977134997,0.36234761964402706,0.4592068392769559,-0.8220389346390782,-0.8153081379092371,-0.6955450753129792,-0.19071061503129627,-0.3106568736253734,0.6829436578342063,-0.7255789940817804,-0.40365515209659175,0.70785027086172,0.6803433541208584,0.4764932066912072,0.104546369108884,-0.13513435869036663,0.6057592301423963,-0.05985422163182126,-0.4487191467927296,0.22201461553892657,-0.7964982294875569,-0.7673259189988227,0.30787750386028695,-0.6425598884888041,0.020567156577788043,0.5541899500401536,-0.6767349402681201,0.7425213308763761,0.6738690214099635,-0.6443616660488317,0.78996984270087,-0.7374513827164553,0.758206614098111,0.849024097558561,-0.5526221166229688,-0.8878809375770607,-0.723732131065968,-0.7041371240482316,0.8273671716011636,0.6268921721745689,0.7637237631668379,0.734163280555399,-0.9179175191078698,0.5664344591553596,0.7185731930993983,0.03975936291184537,-0.7129687368351745,0.2690679833464984,0.54887674917589,0.569597209563115,0.4217997812543885,0.7863642867120907,0.46578643283189264,-0.05671924185740118,0.1987406801698097,0.3629684643225362,0.22881477245608078,0.36987965222691566,-0.6231029205969378,-0.05520206184706522,-0.311395115778912,-0.3916585488791579,0.47362056776594286,-0.7452533433983758,-0.045758936910564985,-0.5621266996107851,-0.7688409303362422,-0.4615651191334175,-0.17850602604136212,0.405689049920798,-0.05602347932927823,1.0200028291337317,-0.2980157200868028,-0.0065973550559156185,0.14378113130643405,0.3696643214245137,0.09514607624213683,0.23742188727790908,-0.7449404705345252,0.5775029180768514,-0.180502046151561,0.6774228964907727,-0.17055307721462182,-0.3677564511845534,-0.5568831964803138,0.79236976961996,0.3000923486310937,0.47848599847500173,0.23676855878270664,-0.11970383592785705,-0.7052432529467549,0.41493355541851595,0.6755840853723946,0.7946303221405474,0.39932431104595206,-0.9368789265387709,0.25614100561365133,0.8273313624383116,-0.8059043479687482,-0.39093498858823983,0.5803371710682279,0.6425773618526484,-0.45850199780321443,0.5020124365973668,-0.4493405977120893,-0.012603020536881032,-0.6101999849567042,0.8590155133279463,0.6354693522551349,-0.404925310761698,0.6416039843935167,-0.6913210813559134,-0.665780544881508,-0.8720580441338661,-0.0432750185631647,0.47380089190245434,0.681772468454989,0.6992960302336821,0.5071118707328619,-0.7353194695348645,0.6158667740289253,0.4253350252241107,-0.5245561208401429,0.7187861408353323,-0.7840583494404294,0.13641644604491657,-0.7558941967711427,-0.46661736276698,0.37275314067649173,0.43713433782421607,-0.4023487481180111,0.6844463847005182,-0.19844558063610263,-0.2568167575192103,1.000849748607284,-0.2345576029461891,0.6416914445897355,0.31525148469091024,0.0035615472393338427,0.3615563966853065,-0.2220542085679218,-0.20263562357004977,-0.012859721689544946,-0.43423917472226037,0.7174139356797309,0.11177223055438124,-0.5653711782618758,-0.7697514849843803,0.7474338456118588,0.5477387919415877,-0.5988539925835208,-0.6941000206510749,-0.6101739728145262,-0.4196916438927535,0.5484241679304525,0.8586392267556822,0.3734804935880912,0.02245134733799925,-0.7357503346600387,-0.03632683913477106,-0.7956382176183042,-0.7054144151827081,0.7388200243501171,0.102073724239541,-0.29748310789756927,0.04116364083464694,-0.6017988508098178,0.759599605439336,0.5906526155164762,-0.0971940062201234,-0.16806191870122364,0.22561814820025117,0.5425894479431975,-0.3406695752651671,-0.40200890093337566,-0.5885059098830712,-0.5608544580538719,0.3771964262972065,-0.46342069565687527,0.43114184325093297,0.5346404077376417,-0.7290134407516172,0.12063774719599626,-0.05818293050870187,-0.9199412720482003,0.49293920321956847,-0.6979577971923626,-0.4427580366754249,0.7546866081886002,-0.2623560114555216,-0.8303991774729412,0.13876608279236904,0.22268122919285624,-0.37689641405387286,-0.7558125833246773,0.5644734207297362,-0.16899754914753434,-0.46427044806241363,-0.8275395885209365,0.45335534904647856,-0.4982219789858945,0.12099996357972022,0.6909400506340474,0.6978753485544065,-0.2792503366015723,-0.7831265601659186,-0.7739598435725292,0.05508745662020432,0.2526932534237847,0.7657436137083289,-0.09926215652782995,0.29429629426806825,0.6943491445813017,0.5229290513363998,-0.6203800888061427,0.01750281538122081,-0.49477046350335413,0.5937755204311953,0.3596233957760486,-0.6582349891324462,0.4059935294097237,-0.33184471052517317,0.38961861786990437,0.6753098803682138,-0.47147933952093346,0.006130889676661373,-0.4724521068026272,-0.11858659805899784,0.5247504429486068,0.160419772086576,0.19559213757747357,-0.4177923348534631,-0.12619030239341797,-0.7538736930114784,-0.7707295496840476,-0.7985539631019782,0.19501331149432233,-0.5870803017779361,-0.7338531397685576,-0.29135537181658666,-0.6357999140581458,-0.3761875981367933,0.4325526903880575,0.6082792177161328,0.09333876580597422,0.24478956698789278,-0.08858335446999094,0.7872386594375999,-0.7265374994268509,0.8310763395387993,-0.5462644452118428,0.4127279544030935,-0.5248188613020944,0.682469920464005,-0.5885935159320841,-0.07793839909752034,0.7666007345388801,-0.15775495728733435,-0.6761924300647788,-0.19917065555400013,0.4760582098155158,-0.13381930011988374,-0.25579177621315935,-0.7877800977145151,-0.2817350217843253,-0.6513382633840619,-0.4445490980940532,-0.34453349757822427,0.928560962058103,0.6423024402641369,-0.32670738007308414,0.8177849584926111,-0.025295808268551347,-0.5205349242156183,0.9251684296727408,-0.27087119108365265,0.8047365716675684,0.829560267832558,-0.6038996383714484,-0.5342359902453541,-0.865576553842618,-0.12837341919461076,0.26530673547425243,0.0349154969522627,-0.3171934080138444,-0.16449742559801575,-0.7080244437403851,0.15856834008852458,0.5711945512299486,0.3447305260808862,0.05463959934337444,0.6408455209935477,-0.7687874377665291,-0.42902923410335303,0.7926371502338245,-0.12116480277620305,-0.7910542623643065,-0.5781516114179156,-0.7917609776095614,-0.521568822426656,0.5857044259193251,0.46323729560911764,-0.3787451578723012,0.19562782028580966,0.27188106863912465,0.6381310767592948,0.7518375142274233,0.6689719511996847,0.57196006148935,0.40445969369668255,-0.5927806649022184,-0.23787135840245194,-0.34848986161315487,-0.761212063423894,-0.13896319181113503,-0.15233301581179323,0.1214378120195258,0.6706084585087101,-0.5745150809344668,0.35145843313954306,-0.38191603774180916,-0.179829265488278,0.8747448348573832,-0.0043802849719510074,-0.7771734845496606,-0.22219313273757266,0.4178729176204915,-0.32897317233582224,-0.4363426912439277,-0.5587069406675417,0.24790760765120587,0.7873438177568265,-0.4577692312357621,-0.04259884239550947,-0.7602761801536857,-0.47381480753876126,0.6454807798843046,0.5168849378788329,-0.4447690602740902,-0.22598252336181415,-0.6470523949829728,-0.8282488635160734,0.8075816072228943,-0.8044238293305267,0.44882707282891954,-0.5535002501831253,0.39890944170613546,0.025780314109142125,-0.6779391248282629,0.13560010333200906,0.942266507294356,-0.9005424163288416,0.28462977377948195,0.7914106533652362,-0.45653057405952147,0.9575399578208212,0.48697384962086454,-0.5541289109646701,0.7431788953183747,0.8414173136330125,0.19552796404135495,0.6790274085371473,0.8385006755014747,-0.8451196791973954,-0.6754474299472585,-0.6421164752392106,0.21171212307199824,0.5620599314143866,-0.8306467700030941,-0.6274180879009564,0.7538230086596469,-0.14352378202051658,0.923970700094072,0.7161620160313853,-0.4080065394288062,-0.528405441328294,0.23106219600828504,0.7993925864510556,-0.43594521158101546,-0.7442003014514826,0.3604695675620915,0.14531137556907156,-0.6209594525529971,0.5236747924422006,0.6117864634645026,-0.02877054417308713,0.3646292702985296,-0.5097084474992407,0.13581450439747253,0.41403228350197535,-0.20642461247945887,-0.3319228663101187,-0.3454480501743284,0.10543437994568941,-0.4781389085109316,0.12470520741036134,0.17801634942841826,-0.8257940191796405,0.5458974901244116,-0.7822890296514398,-0.6908567003728023,-0.2232059922827473,-0.5749216580035119,-0.8153875852695746,0.7597898571701992,-0.753219931627189,-0.4580987597486267,-0.4484559620112401,-0.07522441537508531,0.6589391852057009,-0.4573127088346979,-0.06902083975610926,-0.7415385543005766,0.008174342909904667,0.6085271838897096,-0.45233350777179515,-0.36677794587920176,0.8669153075664423,0.45918143192977956,0.5352991607804339,-0.7312483898743415,0.779936383353147,0.19306457782906847,0.4416098901463701,-0.4988908440830609,0.9695075285717248,-0.7374195529687562,0.8131838271449263,-0.3600244655822895,-0.40816302075431576,-0.29138227801225725,0.10573705513398132,-0.8123765222405036,-0.10112102721986674,0.7106190091589973,-0.2813696722058053,0.7731005013960036,0.1969323998612942,-0.25282389137850225,-0.7391385860971436,0.605980356900921,-0.7618530116802571,0.2768519828420359,0.5537781933210033,-0.36842233801764035,0.9135894099206948,0.5135240672204427,-0.8899517076972259,0.702790271116181,-0.8310030574450475,-0.8280262612412634,0.6997408088282965,-0.7780769253263825,-0.45013398160916895,-0.5635806125001532,0.4350471557559273,-0.6742886398667536,-0.8160785919620601,0.2343853447313738,0.6421428734189132,0.8113558819198641,0.48350441502439934,-0.1997089591383104,-0.8358017753346063,0.23911810227285477,0.8521650723419092,0.04221617649603032,-0.6733019588251269,-0.7988079342945257,-0.4474331292234581,0.5562408143591003,-0.3689801024858371,0.04134603448907773,-0.8425402891134108,-0.5155171516408541,0.9000925519158711,-0.7889753902727983,0.24830670654239442,0.28980775166841555,-0.7333999442134201,0.7600027562354494,0.7865430429583922,-0.8451090947492941,-0.28720094338961333,0.27763920276607396,0.6391714495325995,-0.8381614538495615,-0.4637685196854153,-0.5853254056184635,-0.7561439236063765,0.5952444072197753,-0.5277688879171086,0.8056279853044178,0.2210750668148158,-0.2622164264401208,0.19048451955860213,-0.31243257504062877,-0.6614010021861974,0.5526520694601457,-0.8233193335188957,-0.6398567235205264],\"xaxis\":\"x\",\"y\":[0.38668017042756025,-0.4063122117700862,0.3068262609838258,-0.5430295751155093,-0.7638234019405593,-0.6734006783299299,-0.8770291357037638,-0.704697889575978,0.12795088002502308,0.6165995935650488,0.6917360845583321,-0.8060192253092222,-0.7839720996608792,0.26169176906473307,0.2901406558651714,-0.8718435111505194,0.3170641344181347,-0.8950063552526123,0.5497270429783463,-0.803424142365409,0.34256114640481244,0.4921548430109177,0.061707359667039774,0.612716403639936,0.5245313260290828,-0.29318209490651914,-0.4251903287323775,-0.7233372036816635,0.6370511469501674,-0.874865010861503,-0.10938091812578676,0.5568415665676931,0.0962091896636106,-0.8603725029724583,-0.40480105278340917,0.7102927554795357,-0.8950825442650003,-0.8527750659104026,-0.6823298445468218,0.3784888124876588,0.5911492628116131,-0.8156739303446082,-0.6627795953528371,0.8523480549240764,0.43720690023689723,0.7737286209921896,0.7876984943845582,-0.676147214512679,0.33776196280223986,-0.1615603579113441,-0.7258050520464058,0.43973890667923576,-0.8030237965491439,0.13556901791058096,-0.5127251922175448,-0.3319907111184875,-0.40986882315975703,0.32740351033900744,-0.8440904799077147,0.4754392037737206,-0.8029617783107529,0.35793178464918596,-0.3104011061958285,-0.7242718542108947,-0.7851642066383491,-0.8991802803423019,-0.751183352923732,-0.5144346072210882,-0.510871462981709,-0.5172325000434884,0.6373107513369126,0.01666272544373032,0.8416294855709949,-0.3358905039426734,-0.8096030792620517,0.7313651601272881,-0.4827711212497436,0.012806132491603103,0.7774725205089072,0.35203408479962917,-0.7566148093085173,-0.8034044220991445,0.7663799934787042,-0.6042831323496305,0.44690771855405004,-0.6506145341013116,-0.5107928155089326,0.31171311620552794,-0.018825513872318705,0.5695996451543843,-0.13883374711370622,-0.842679960910115,-0.694917393672169,0.43680469928305565,0.7027562429691658,-0.675272797937376,0.5321255141611241,-0.6147562316868029,0.1671874289838755,0.3909255266495518,0.9209879841946421,1.0150548933660137,-0.6877860411846328,0.5456973495343822,0.5458635277568039,0.46645461316494563,-0.6917052921270889,-0.0479494338954595,0.28013817885130093,-0.7851769082755793,-0.8563780570631527,0.4735786607426623,0.16900058462926076,-0.32723699882074625,0.14794871479990246,0.9204490773464028,-0.9446017218978806,0.8590479502513905,0.7332992743091084,0.5627197837263558,0.7206590330835999,-0.40550319601859214,-0.30192191950586356,0.2807205457283215,-0.561852227798726,-0.7881732936026646,-0.821396222076766,0.9611624560957543,0.586152476563572,-0.32065746262277234,-0.33944735585777586,0.7194655045247816,0.7274552974480931,0.36766343427329107,0.01826075321084356,0.7464463736405258,-0.6376214821006274,0.7343523257842783,0.6487266430228695,-0.02371168995445231,0.39940396654288973,-0.6949888302251648,-0.5130554575784944,0.48732700200456813,0.6363478468935406,0.8394458966009655,0.595123406753962,-0.8247289577091044,-0.1747914818631363,0.005832814647434806,0.11450506972436661,-0.2997641733727058,0.20846448909929324,0.4122156103191604,0.5803568838802332,-0.4618553710202222,0.16078662282475753,-0.28548883170154493,0.6335500517879401,0.8222445526187478,0.5475882971028537,-0.4067015481645939,0.7040601734540909,-0.45562129264320717,-0.6431325842283683,-0.3919390292696392,0.4557190048422405,0.40721052287615533,0.9483044151209887,0.5349865025266025,0.5880007536108917,0.540365350804693,0.6534088065779764,-0.25542503385760384,0.20368893326515347,-0.04171527751517183,0.18926734081386282,-0.8203078711795528,0.556723721178325,0.36165053076568937,0.5199015386517275,-0.014685971965138045,0.5323725372685937,-0.9630316383250013,0.27169922255153267,0.6595366326167282,0.7392278321730624,-0.6500484084070468,-0.07964824711408838,-0.8649129859851075,-1.0034680255912438,0.591379360355129,-0.7571584128966863,0.6253544817551653,-0.6975269777753227,-0.615358687486965,-0.728945973136967,0.3478862735965194,-0.12045017629184614,-0.6471678955933076,-0.6937178486274097,-0.7188436435652171,-0.14825907772265468,-0.6015201400627146,0.14167205330357982,-0.5896904778322348,0.784631327001553,-0.4656897658183368,-0.047991567919438094,0.1458975337467581,-0.22421350816493124,-0.5585530724254406,-0.8021625087034827,0.6612920993489081,0.9452277033403071,0.35208278788050484,-0.629396636206917,0.09483304128188522,0.7184771503038658,0.7786716173622367,-0.017988740781941195,-0.8846506284838809,-0.8467939036705792,0.7396492565372188,0.5827614702532476,-0.304186706914452,0.7137542061469746,0.5102685311958184,-0.7049215307735679,-0.5392324021361232,-0.7220144621976998,-0.13390695340005848,-0.32973081870809845,-0.5985375484141857,0.695522338334776,-0.05046500481544858,0.058483052619868,-0.49311794020197125,0.5047943239459829,0.03616815478286349,-0.24850505563663144,0.7744135529160502,-0.47923350054531993,-0.5866129448366009,0.2481608364940709,-0.5655102642601418,-0.21471146131921465,-0.6182472070219983,-0.15411227284158033,0.6798163272614016,-0.6298203328425338,-0.6306114789298293,-0.7832083987504004,0.0837247754745845,0.5448021113925184,0.380896956358896,0.09892389237365973,0.032781062254471596,0.24500060175850658,-0.7504473894022816,-0.870826780136163,-0.2839360311602728,0.21848077787985465,0.6266396363904143,0.2622659486984529,0.24331935423455464,-0.6604737048935667,0.5939202566496165,-0.7378611018705429,0.1418160416072266,0.7378792900452305,0.39436237907397287,-0.5173932733288206,0.7230643185228057,-0.04465092947042201,-0.4386525856322796,-0.1845772562144315,0.38550803470757145,-0.38302803463474966,-0.7004828649724321,0.8265846770512069,0.15238805451233983,0.3778557911598848,-0.316689343414755,0.8356477303950903,0.334901419378676,-0.021211982685590713,0.5351447995999186,0.8838926272189961,0.1751742115116513,-0.8010233216094036,-0.692394889152141,0.3765085830156898,0.14630643361709267,-0.3684694344622904,0.617948513926517,-0.4901354654357552,0.8028649528799006,-0.9032331827233625,0.7369370872420395,-0.772062809626256,0.2479936171461386,0.6213061410055356,-0.784758107844765,0.6552996520944195,-0.4068098075418671,0.7820072165298086,0.5154075175287325,0.5228174474645336,-0.39943159602549483,0.005499961178280763,0.76592284168784,0.23572292103996517,0.6923083611998838,0.5178016870763951,-0.35721379776127593,0.6194621918868761,-0.5432702821086655,-0.0676202996331084,0.26423947188176944,0.5825252555221174,0.6111295198912905,0.05277198477367764,0.8751168974274003,-0.12344450269997856,-0.7237364545995133,0.5011831248612332,-0.6280459423443701,0.771249318840782,-0.6915237682877793,0.37671351097859146,-0.8225129100509432,0.49210287620617726,-0.4440058750208081,0.7755163921810747,-0.44729948524581986,-0.5483852705005756,-0.7264180542583568,-0.5593925351940519,-0.18805504465164422,0.5227922127940985,-0.710596974997218,-0.9488659020667225,-0.58687097489052,-0.40607329057216957,0.9563599310349877,-0.628099263019581,-0.367399419095485,0.35777812475203075,-0.764943369394937,0.16337396401979298,0.5539516254308983,0.6100117668235808,-0.25192617039279813,-0.6399135256870667,-0.6972626352743658,0.9441212184704917,0.31481653092866824,-0.611666967316859,-0.6867073259617864,-0.4520997132797559,-0.15028011023535726,0.698891496505232,0.8607638483186708,0.6591423915073531,0.4517782655714714,-0.509931900759922,0.08166617602405023,0.0250060614940412,-0.014647903369181432,0.11356917438603824,0.26399970813588164,-0.8681682352834612,0.36355939272097754,0.8042830062160128,0.05226198266698837,0.6968319610586112,-0.6938596125428107,0.7388732897905874,-0.43299684307977654,0.3448168296993659,0.3592615524508073,-0.6244154017541506,-0.18021730450534695,-0.06902670814193587,-0.5207518638890207,0.10142592324411553,0.5832258750873813,0.750755754982628,-0.40952403759868683,-0.6620409229665843,0.71577402681954,0.7178686107559228,-0.3598113296895912,-0.2369762172354658,-0.15953330744603972,0.7991846185387464,0.6456731481540232,-0.11190893145191713,-0.25762605197277305,-0.7017186221107734,-0.7380362421732378,-0.8153682940024918,-0.9180854807060664,0.3278665604451173,0.3689037550243256,0.8551943989719799,0.08937805776787161,-0.7179166007386123,0.7075751384362071,-0.5524261375016861,-0.3371281128071695,0.3184296848543818,-0.544320049752745,0.4696501374081621,-0.39366095498301606,0.3185112979423062,-0.02459612244330206,0.878558852145858,-0.6307368809745257,0.8909971131617186,-0.5547031576844282,-0.5120808400273127,1.0197698710250525,0.5156757033199405,0.044948405872625476,-0.6606380817525492,0.23500983967596892,1.060704263973229,-0.78217618146881,0.9375447243794528,-0.6870501301601164,0.7371202757933548,-0.6595920880733722,0.1936523954075149,-0.5631400717213144,0.7618747307882737,-0.768571370600381,-0.2648148048080051,-0.32949315838292126,-0.5130090496140008,0.6506418729205042,-0.18914444783246645,-0.7809021389803236,0.7955133292412452,0.5007011509987536,-0.3055166581317016,-0.020233572360544502,0.1916184195222408,0.051729679259774536,0.7782087750852298,0.1557465307261866,-0.7380211616136318,-0.4094759162590948,-0.5695644463012309,-0.8043758461598224,0.2543701383384222,-0.7703145369207519,-0.2445675378746331,0.5128622160227909,-0.47373239025296987,0.2432807163785325,0.3972313583411795,-0.8117785886571526,-0.4545121444651991,0.47396364057753343,0.6830791407350534,0.7373863050017504,0.8115380369318924,0.37866025819211185,-0.45975682535900797,-0.8352270078576868,-0.12941158151486126,0.7275166586417855,-0.20997864483119397,0.11617718882322012,-0.7189077172149712,-0.40230346280496404,0.14738193298881216,-0.07261868652926078,0.5859317956483665,-0.011517807291818005,0.8881256170551908,0.8491468588508683,0.5388580141076007,-0.3085969906250072,0.559536132592971,-0.3754939951201821,-0.5745815631925172,-0.2707533048693588,0.2944224246701491,0.7737885706985703,-0.43409037284909074,-0.7248338617162358,-0.7621353633046857,-0.6605919326720271,-0.5483248998036508,0.4029048824965786,0.6689739335096863,0.23581359076355768,-0.7963405872995126,-0.28595612565210216,0.3387618727980232,0.5230260821814386,-0.4308053649760643,0.679283145409179,-0.304601472731284,0.6927383160960838,-0.4369861787379408,-0.6244118778276398,-0.376270975150184,-0.8229616083530831,-0.8278798561399683,-0.03891573031534093,0.5637294465912394,0.9199978638163816,0.7628234592225014,-0.7884356681609864,-0.2715702529960304,-0.9657313673976013,-0.5664484120359473,0.7668213658875225,-0.6157199910037472,0.3456655931113503,0.46587180775451814,0.6222400039770257,-0.4403492774226017,0.47426164594398224,-0.47934463117854575,0.9135274843052665,-0.60471845876714,0.004231783331269862,-0.8160758708913941,0.8832936934941761,0.7007976540683044,-0.6312719020970438,0.7702857402972777,0.6155594785333841,0.5231219481393169,-0.7300309793299635,0.5999755773078488,0.32614243345144883,0.673115173517376,-0.2516130190648024,0.9349666945911673,-0.6796726028820557,0.07323748052857751,0.627117906007861,-0.687670566539016,0.0013735835817097891,-0.7108034574791245,-0.648703222979008,-0.8714991084849706,0.7432286904159181,-0.4593420630213053,-0.34355619110307856,0.47566861683926853,-0.6528282504596269,-0.1795869228444803,0.27348922870940423,-0.7499879456213361,0.6349156760892722,0.6750483561367306,0.3974825022064451,-0.6426755964857122,-0.6953930161340891,-0.592247186713371,-0.3111921959384207,-0.27099142355728645,-0.6634185357162989,0.6423092420128476,0.7195693826960214,-0.6721002999534312,-0.16799814156640427,0.6337320684495343,0.06979760273288171,0.2005173336596292,0.5671507889826043,0.4660895419637038,-0.7418989255605711,0.733518108746158,0.7338177777213529,-0.6228789799965104,0.25851406937455057,0.6127301181379994,0.5872742467099286,-0.7804084321042583,-0.29750303103260195,-0.5728968119621282,-0.057133339634046355,0.7817794768467594,0.8390867276288169,0.45422332188263204,0.1838970182383305,-0.46838259272741545,0.10890043440698491,0.12451192867280284,0.3800181075262848,-0.19298267848317746,0.7967344122205695,-0.026715715089300728,-0.7137605861747172,0.35058584325475445,-0.687315041167706,0.48159455018637976,-0.74511147404301,-0.2628012205297257,-0.6536426026567355,-0.7116967479063624,-0.20656103050625668,0.6030810763462416,-0.6036178006459725,-0.27227493659318075,-0.5508650167008782,-0.7040979676157766,0.40440991534848925,-0.6825358705900039,0.21542600804953432,-0.4399143943539711,0.5032063901441095,-0.8758345758918854,-0.2759969093920028,0.39277284924068867,-0.5335561354120627,0.8501489489584059,0.3544859411177419,0.84693408106284,0.425295867271845,0.9184511271850881,0.044109326498597556,0.7629666515968201,0.841296697316353,0.054692064681184614,-0.32468919354435194,-0.015280013442182286,-0.555060259454104,-0.7569990774500547,-0.19185682463510384,0.6143064009158838,0.830634286628682,-0.37151909377793785,-0.5091797949600436,-0.6432830167627865,-0.4200281505482457,-0.6932919470296108,-0.7035517219643083,0.13502224828636358,-0.5056565215977169,-0.5162026926687214,-0.9965814284585722,-0.6685555057044172,0.0029543002554947295,-0.6498015638033738,0.8240776130489658,-0.16158813226779323,-0.7086564673623879,-0.5554708957345057,-0.6138828169897843,-0.37936821275268745,0.7661259117605846,0.624165779394163,0.7018352773793743,-0.8292750456055278,-0.5077984906255123,0.7025045475332452,-0.7369658348746596,0.3494272737833364,-0.031117227227870678,-0.13030495824811217,-0.7185294029699825,-0.434889312433699,-0.3590464632768567,-0.6644521973206762,-0.8507456001625914,0.7294167795516768,-0.6106695232219781,-0.2994367892809416,0.2766363249552896,-0.6231312197571053,-0.7736726868625535,-0.7698171256743238,0.8066886018706831,-0.5251893479572234,0.17168957915815597,0.9371144649410861,-0.45809281071147273,0.5976139200325193,0.3699330540720206,0.5225000814981986,-0.24732277266002997,0.7607878227630025,-0.7335620518665451,0.8889950581976565,-0.14833938439624952,0.8769481963071668,-0.6048452531374665,0.12010258044052545,0.11493148747189844,-0.7382683040481578,-0.36301772029907337,-0.6897942200418647,-0.7802741390271167,-0.7092256246343853,0.19974167910131088,-0.737019855251749,-0.7370329639264149,-0.9178606841515184,0.049176365035900116,-0.44721201336384603,0.6257676096891964,-0.5150430872064383,-0.8184616744134252,-0.20713978993518226,-0.5350306623461112,-0.7219688673305229,0.6256430066479839,-0.15469881604993438,0.7216883354169894,-0.6390173523997719,0.47008917003347284,0.21596342025005638,-0.17180330912730513,-0.41631862819318444,-0.38239589299255405,0.7688850877796439,0.4178681755236921,0.048413170087753754,0.7390380310051955,0.14824917061133658,-0.08056134755609941,-0.12948875638347218,-0.6730105380022928,-0.4991416576774539,0.8184005106118001,0.06681123225305426,0.09314474033427764,0.04059576399971941,-0.16787797899522602,-0.5091046524588102,0.6635707535460679,0.4875371247831788,0.032071285414157845,0.736574090008428,0.7688109541247157,1.0324891126839584,0.820002532577043,0.6616806215124998,-0.4320693785144623,-0.5518773094657118,0.38576942047713775,0.42189264792001213,0.5435956405062049,-0.1004688700620947,0.011562488881183067,0.6697072476311596,-0.405645424058028,-0.6697225819401791,-1.073336843615581,0.6587556733070494,0.0688812492990582,0.7463378798855723,0.7378796296375112,-0.12113562713060592,-0.8648342685376607,0.877329962184437,0.04391911767800756,-0.10320939945840936,-0.25641914881664196,-0.500061741723812,0.693072305820327,-0.2466956956690598,-0.5215330345214557,-0.804784869591146,0.4559718702875392,0.5678696407005482,0.5187126118259542,-0.09543488748362135,-0.28746164233390004,0.662644550788788,0.8511856389395773,-0.12791322500367602,0.739280098721435,-0.37750177651099426,0.8677674728780599,0.7279497552009815,0.7280142328436967,-0.4194723196161291,0.3844304572223327,-0.08285839228724665,0.5366470752444846,-0.7201962841978253,0.4425563039424494,-0.2600566104390221,0.6589392089057264,-0.05589282843033132,0.7256009612907004,-0.371332080518416,0.6047412885934802,0.776935049043058,0.20920705860509728,-0.11478929472071693,-0.8433231152446016,-0.7145666716288652,0.8311320539016932,0.4988709641167932,0.09074180370791836,-0.78337391436752,-0.5139469178571112,0.0744677150046042,0.6511052558154675,-0.01502950342159344,-0.7915471665280152,-0.49930741079578966,0.4320022434961768,-0.416307799290089,-0.8755424553688803,-0.8297684884288303,0.19876055425894587,0.08144836055168753,0.6356788661435713,0.019787324372201515,0.5960088062304092,0.7208103559699655,0.6748277491576286,0.29405297840356953,-0.7238593197304364,0.24131819353202916,0.1891712941356365,0.6996419427429822,-0.4684977146636562,-0.20137430231353515,0.4829530179357765,0.1812509820612308,0.2982942018484127,-0.5221232517520455,-0.343971875943056,0.8677588795632555,0.7627927932130808,-0.6781359326483776,0.7297308436560472,-0.4919581638697016,-0.6357993670979886,-0.6700557631935384,0.883583039211345,-0.4754555097092885,0.8407974198871393,-0.5312378229034063,0.09992419916472364,0.291138112358128,-0.1563977866797846,-0.08389139900071907,-0.7312260716779446,0.9655025623038582,-0.6120363053267868,-0.5144941319506999,0.6180452024329126,-0.019273549346030663,0.619386747098369,-0.740847253373191,0.54815955161185,-0.04218857216592459,-0.6202513087052627,-0.7808076911753205,0.7333898008370338,-1.007386179251963,-0.5467332811811649,0.603085134828847,-0.007679903662886893,-0.7509869799869497,0.6443171011561649,0.6959270247517303,-0.4955206801711311,0.23009381261294035,0.17421324095984952,0.4913443068913663,0.63220737209973,-0.7751374978190394,0.8072226210780703,-0.7998651294605272,-0.34396141197356944,-0.40669133935512275,-0.6458152465819362,-0.10608677366539795,-0.706112413280888,0.2553641753062399,-0.6925346292707021,0.18166747572988262,-0.7514641026071596,-0.8796517467699998,0.7444551068032214,0.7142304426071656,0.36208918293187853,0.3629900560403446,0.11482339920994108,-0.6338692199739551,-0.22941192457140167,0.7038381735883372,0.6768786003304832,0.41488046897137254,0.8713134581387825,-0.2569574618262843,-0.8004841741694804,-0.6680771881409968,-0.28287820224904076,-0.8976336882591889,-0.016590312288208703,-0.8441929014071952,0.5646641833400872,-0.3399493026198429,0.4884175830640527,0.8644318040951764,-0.10459939919369513,-0.22003526035166673,-0.4167429194251404,0.3350080020257792,0.7765905495857137,-0.5637122911213027,-0.05586012935875842,-0.5484104653962796,-0.7227104270208797,-0.7015314429078272,-0.4122002100461623,0.8180693597937904,-0.7039894097758209,0.31997401233544154,-0.7606795006210468,0.4612346255493025,0.3091066795877072,-0.8591529408844454,-0.594333779339332,-0.8769318987559845,0.5995411608366914,0.38246761699075,-0.7161417407939452,0.6577585124981473,0.42075765372165586,0.8768026286804967,-0.5426461630374244,-0.7626330007317951,0.5098854870484657,-0.7559618001337511,0.8401556956617877,0.6099310202883494,0.8594328618704122,0.7512762713726169,0.8620442578813041,0.41748378732548386,0.1867636162245502,-0.5061558953121372,0.09490761249548643,-0.6285448686715609,1.0061834048510536,0.5699765491440358,-0.07622436890530142,-0.8304818537788865,-0.4082424518971814,-0.6451945149137276,0.20189826935179758,-0.39078300541732164,0.3756364343757157,-0.6909545483493555,0.41772940324303376,-0.020655053523436488,-0.5406600700638183,-0.8081422401694753,-0.36266791552157446,-0.3412668038978376,-0.2897120567685833,0.039387417744986636,-0.9277738780118842,-0.42424173586141173,0.9123372257291968,-0.8576305253455779,-0.7066878246949153,0.07324201436951172,0.7470135301422645,0.7743845711736652,-0.7462028394916665,-0.2324276487325051,0.7732995779601173,-0.6296052311840675,0.28274434310287383,-0.5367336709302355,0.7155124020524897,0.30797414774827736,-0.317777536669834,0.22038540427509448,0.5246316002706486,0.4625279510284172,0.17830503414504445,-0.6791144707985286,0.7619948039589997,-0.8676979259121539,-0.6937586845672137,0.7299441408448565,0.7791540978197438,-0.8697124818276553,0.31808563603067197,0.02365523412772682,0.3601637024964598,0.5462349139852981,-0.20855000349020955,-0.18238964001636715,0.699638518171746,-0.6286582471266597,0.865090661760753,0.3259797927673212,-0.7966434635603544,-0.7239577210784908,0.5763111404229793,-0.39458639454513655,-0.5539705773885599,-0.09234433076411701,0.752637175261849,0.6703674439008944,0.45619658666515683,-0.2826229803363571,0.6712404152079001,0.4858441560256716,0.45300801613238345,0.6321726109532387,-0.7191098931580915,0.5928793601438571,-0.6821291361921547,0.7243039503048809,-0.6467082227876657,-0.7980352490506238,-0.31549642593721916,0.569189963202481,-0.748901805300455,0.5665277655520325,0.8267781825406364,0.4174343594827466,0.5593777330439805,-0.5383087404879066,0.21178370937401675,-0.12933784947988203,-0.10008554883187437,0.5010023757848477,-0.1141264855297261,0.15074986907710675,-0.35066816115833294,0.0006557740020556591,0.41091678259117326,-0.3979196433558569,-0.38249421309691334,-0.17354084547461768,-0.020432570537074604,0.4965877791932405,-0.1291803025427144,-0.6492440958870335,0.3843630056715244,0.787951082417873,0.38979811756688226,-0.7267187457185927,-0.6558647245210131,-0.5532630923038409,0.6936282955267454,0.4558042137429029,0.41151631940071465,-0.8110291297582563,0.8507510345166321,-0.6714855883778879,-0.7341383769521451,0.7585149925372099,0.5715079464570862,0.7478877468772743,0.8988579417610981,0.7139353218849815,0.7974367082812926,0.07281618628623393,-0.8178991843697816,-0.6198452440797723,0.10571385983882968,0.7198744625815118,1.0020795231225117,-0.6259424978678132,0.8135446204378955,0.07194015702670074,0.6296730033267105,-0.8456325992069788,0.6900664466502205,-0.805122680434901,0.7999762449269541,0.7527185266577476,0.18604497198678593,-0.49376073203363324,-0.6850998399223721,0.059491226464474384,-0.9559555353153051,0.807409750756587,0.16095065530134656,-0.5657293264624826,0.8148163617785884,0.6245495122042868,0.7606158203512907,0.8683716686736511,-0.1894736407704794,-0.6843529690165707,-0.18950691342214976,-0.10132712532792884,0.8848747106730437,0.2893243427959198,1.0459289216053738,0.10640605274576864,0.010920501196758359,0.5890525583745924,0.4446305812612655,0.32511704524359525,0.5479750666657951,0.2012445884345087,-0.8477034936959075,-0.8370038859626615,0.5479144236527627,-0.30656483970870824,0.5690531085968462,-0.863326764207509,-0.417279550847942,-0.10869569041008344,-0.19844684024217077,0.266660109791367,-0.8801262966656187,-0.03724267085537053,0.2722902961064363,-0.4002864378807719,0.8881813281838293,0.4243483826058055,0.6086431280412483,0.5885509795870638,-0.7320342652233486,0.3731253077537732,-0.40232495340044794,0.7059434038046344,-0.2225692141511153,0.6052085444327263,0.6877489136011314,-0.48931156313971036,-0.6997956559366167,-0.2392121703754388,-0.8493985483570796,0.7152587420192014,0.03174221541587213,-0.7988335807446296,-0.5800363376311607,-0.6834319924361196,-0.8189658468448608,-0.6206894794458466,0.7394378267644774,-0.6036634042317671,-0.9268459247233642,-0.49934279400753523,-0.1672659843899047,0.8316981329148003,-0.703112853301477,0.07790037573448377,-0.25634552368037833,0.7697386296841802,-0.34068360155273036,-0.46298917277918195,-0.6476566272959355,0.5581830926518159,0.5435369880419675,-0.4502919750463734,-0.5756243957340006,-0.8966499747020676,0.17043079500265215,0.6078340108598704,-0.3530672432779845,-0.5248138054739855,-0.3283888414655328,-0.5672530044745905,-0.806610858941303,-0.8442273712194961,-0.79356876125451,-0.03206609413979291,0.2107741125590813,0.7994907653811744,0.9018620331677013,-0.7327193981378285,-0.5539383846613566,-0.7469803941372163,-0.5022796391711787,-0.6819167949890804,-0.3083752827423686,0.5978659961995408,0.6981868131698838,0.787630948883728,-0.6247071356372972,0.3354814740697664,-0.8941344853222494,0.7881633659661921,-0.2733274558812294,0.7305206555790589,0.6786233373520618,-0.6792062888502555,-0.04317073762891356,0.8230677481758087,-0.12256745811112475,0.8589815248331463,0.9131178585595418,0.7990811491181506,0.18239304669414838,-0.5060715163809308,0.7926741171955689,-0.7627170375674281,-0.2276290994596203,-0.7173224730174494,-0.6964320192197688,-0.8519692265894225,-0.6961671657493386,0.28628631801428495,0.7395851423333721,0.12798430747043868,0.47508959063006295,-0.7175740113603195,0.6878484280584563,0.03985117915446201,0.7846185761378197,-0.6703636210492047,0.057397566092404,0.5188207247592367,0.6182276517673572,-0.6670432219353235,0.6352828202956615,0.377227535932568,-0.5494040430879185,0.4453857904712853,-0.5835425235572917,-0.582497628250927,-0.5580992086209106,0.2430003730075494,0.3748916381304589,-0.7343194570445017,-0.464128435267668,-0.767256737704909,-0.5562576503926426,0.9174446690566036,-0.7125349653584114,0.3497296690697784,-0.8123706879182566,-0.23574591522226832,-0.28365626045737846,0.0018099342132317786,-0.7582177571601858,0.26529471567978585,-0.19754944518780315,-0.6696976640622979,0.3096099800159646,-0.5967228664559068,-0.9110079295845803,-0.6452766561804568,-0.6692440473243053,0.7014466995064185,-0.8118044514689869,0.22701732923704163,-0.3823093379365316,-0.1794224900843146,-0.7731982183388746,0.7521977930974012,-0.7415853563195105,0.4755559345374915,-0.5598375074874211,-0.6023244340046331,0.03400306692586805,0.7705261609339433,-0.296185709556282,-0.6839270454365161,-0.7120036433694004,-0.7645444809850724,0.7979883703150873,0.10027187036263964,0.6833528528056305,-0.3527469905618357,-0.9810080411627864,-0.6910532099512666,0.08603764873594069,0.4185464520402422,0.6821502205695062,-0.1997822950385463,0.8241317093775207,-0.43120815549115477,0.01687307527546282,0.8264760185317845,0.05927683569111771,-0.36329900462136944,-0.545322852283837,-0.6052338120261166,0.1893524129234417,0.9007987364790846,-0.8708837561027145,-0.5395601543006434,-0.7448999546344257,-0.4894713920415037,-0.06402619967309117,0.9576591231859497,0.7392165531709076,0.6471651738521208,0.6295493034884426,-0.5597473420507659,0.39229998651587394,-0.5420119986389957,0.45047528949877214,-0.8717133320779333,0.1258069379990713,-0.5467119871573205,0.057517502591841456,-0.5984938088097231,0.4949983999783026,-0.4301619801962423,0.8051040491356377,0.6919330448056182,0.7324749592747095,0.6544184711537455,-0.2831531924032073,0.18496104699058447,0.6298458049541005,-0.7655946046401231,0.3861999046063859,-0.6487724379475126,0.765202357127046,0.13653534161807532,0.8599043993127737,-0.656637369931706,0.7974049790155646,-0.3129393040805829,0.8484032395161415,0.661109765246595,0.5840456528537132,-0.8356424201912859,-0.11089754454588727,-0.7400683755041657,0.02639339929926035,-0.8058346171199281,0.573918868969613,-0.7914131757575004,-0.6487433185446893,-0.6355872273347444,0.854466103797378,-0.2308032672143691,-0.7107495205498909,-0.7506192373201664,-0.054779548252791355,0.5608137996173529,0.36000400689412837,-0.6819668842484605,-0.7379720956231473,0.7393611462793966,-0.38358140119152845,-0.05772160505459716,-0.3426384918857365,0.39737159812133405,0.7697347556082971,0.5884130529880628,0.6947799196323501,0.7670133985913177,0.13309049172527496,-0.8324105044932234,-0.12955522380632517,-0.08704593356600404,-0.8111510618971197,0.21933170344508396,-0.2829515881438255,-0.29922352664028606,-0.7633061459322603,0.6155347213537044,-0.46614075363959023,0.17528047369215524,-0.7816016264749283,0.2580120240159716,-0.0019188524628506454,0.14478138959785047,-0.5986879792917821,0.6423997436971012,0.4204911952061677,0.6086775894608563,0.2921114164311916,-0.6029520967327254,-0.6412152315311013,0.7519348993759073,0.1922308500667811,-0.1942471418848348,0.7849479553669051,0.6963278972066813,0.7060120505946693,-0.03281388143532164,-0.523095003878884,-0.14062181855740813,0.8208677247239362,-1.006000739600991,0.4843051868101336,0.6721718175039963,-0.5776144404358723,-0.8059713732795235,-0.7753843778544144,0.4302842090698751,0.9067588251001177,0.4981246890146198,0.7276592466775422,-0.7359634126062904,0.7606429933868376,-0.7837083257429869,0.7967847201763297,0.9149056576920653,0.7715905535852765,-0.18282444155256583,0.43409777686232875,-0.015628551430251172,-0.29631808233502305,0.6731419202328603,-0.5334367394078667,-0.3384816765947426,0.33229329598884166,-0.31276969669203397,-0.6854774953752469,-0.11283655758889162,0.918154783872434,0.6073263827880006,0.49875940396684293,-0.958092274361233,0.17308357200990648,-0.6476244031568693,0.48761674366394214,-0.53445876150807,-0.6569076992460234,-0.07973678744054473,0.6302934869760406,-0.6704343748441303,-0.27169401710581215,0.3006271497348024,0.7568875682881664,0.8583568962374793,0.032611832672301035,-0.040088662444815064,-0.008751848158897223,-0.08569586349705186,0.5628603521586726,0.7501350542196477,0.5841950655626895,-0.7635754943131053,-0.503317363732944,0.7013803242499516,0.10940032068515013,-0.630571710822132,-0.42627532221592074,-0.7767311112103038,-0.7346257786380654,0.2153358062085761,-0.5413558365347255,-0.09156799608417428,0.7712457382412516,0.5878572323316081,0.6587164701407842,0.17907012362197874,-0.5336163129142711,-0.337353375878287,-0.12840065329781064,-0.05591113008183973,-0.18841925745835844,-0.06758040576039266,0.40165953125421794,0.5451833689664182,-0.49253230892050337,-0.6784050950795598,0.4472398079961919,0.23812817766212455,-0.8519538180020801,-0.513248743377752,-0.09037127598473907,-0.5561877700349587,-0.8583229589070358,-0.33384418070007454,-0.521954977630836,-0.014938654303389351,-0.7708048371307978,-0.4962770509366461,-0.25473944169207907,0.6271354620318172,0.5566903706647142,0.6373522382453356,-0.9665003702223063,-0.29110781545898856,-0.703890851516247,-0.060142845607435255,0.04196564857843592,0.6824480339738775,0.6631723473547176,-0.5734186864165166,-0.3142360732585837,-0.09520307622390808,-0.2772020979562957,-0.5909317782311987,0.758265676188757,-0.4345446696597171,0.16478003868744365,-0.5582795742952117,0.7572793515415037,-0.4376356688861617,-0.50097711174438,-0.32426006042612765,-0.5662972277022855,-0.6331526829497077,0.7709200453096723,0.7580705542840219,0.7694492686661273,-0.563192191266065,0.3692057937013789,-0.12043153645621339,-0.18125029429861417],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"title\":{\"text\":\"class\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('78455e34-287f-41de-961a-70211c3d4ec3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "นิยาม Model โดยกำหนด Activation Function ใน Layer สุดท้ายเป็น sigmoid"
      ],
      "metadata": {
        "id": "VyGFbFdP4N6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(60, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) #sigmoid"
      ],
      "metadata": {
        "id": "Wcb6_8nf4Oyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile Model โดยกำหนด Loss Function เป็น binary_crossentropy"
      ],
      "metadata": {
        "id": "EjKEcNJW4P7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YkPZkKc84Qx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce93ae75-8ae2-45e6-c686-5788a43ba41b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model"
      ],
      "metadata": {
        "id": "BDSuOApt4Rkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "his = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=2000, verbose=1, batch_size = 256)"
      ],
      "metadata": {
        "id": "yoG9nKOP4TPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1860a4d6-7868-4b15-e771-367e1a8eeec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "12/12 [==============================] - 1s 15ms/step - loss: 0.7355 - accuracy: 0.4970 - val_loss: 0.6975 - val_accuracy: 0.5140\n",
            "Epoch 2/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7214 - accuracy: 0.4977 - val_loss: 0.6852 - val_accuracy: 0.5345\n",
            "Epoch 3/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7022 - accuracy: 0.5173 - val_loss: 0.6797 - val_accuracy: 0.5395\n",
            "Epoch 4/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6982 - accuracy: 0.5177 - val_loss: 0.6751 - val_accuracy: 0.5440\n",
            "Epoch 5/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6949 - accuracy: 0.5283 - val_loss: 0.6724 - val_accuracy: 0.5165\n",
            "Epoch 6/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6831 - accuracy: 0.5437 - val_loss: 0.6691 - val_accuracy: 0.5450\n",
            "Epoch 7/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6820 - accuracy: 0.5523 - val_loss: 0.6655 - val_accuracy: 0.5895\n",
            "Epoch 8/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6765 - accuracy: 0.5573 - val_loss: 0.6618 - val_accuracy: 0.5620\n",
            "Epoch 9/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6721 - accuracy: 0.5703 - val_loss: 0.6583 - val_accuracy: 0.5760\n",
            "Epoch 10/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6676 - accuracy: 0.5860 - val_loss: 0.6552 - val_accuracy: 0.6555\n",
            "Epoch 11/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6644 - accuracy: 0.5780 - val_loss: 0.6521 - val_accuracy: 0.5935\n",
            "Epoch 12/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.5930 - val_loss: 0.6496 - val_accuracy: 0.6785\n",
            "Epoch 13/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6594 - accuracy: 0.6113 - val_loss: 0.6459 - val_accuracy: 0.6535\n",
            "Epoch 14/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6529 - accuracy: 0.6170 - val_loss: 0.6428 - val_accuracy: 0.7000\n",
            "Epoch 15/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.6090 - val_loss: 0.6402 - val_accuracy: 0.6650\n",
            "Epoch 16/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6502 - accuracy: 0.6127 - val_loss: 0.6378 - val_accuracy: 0.6995\n",
            "Epoch 17/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6437 - accuracy: 0.6530 - val_loss: 0.6349 - val_accuracy: 0.7200\n",
            "Epoch 18/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6429 - accuracy: 0.6393 - val_loss: 0.6318 - val_accuracy: 0.7000\n",
            "Epoch 19/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6390 - accuracy: 0.6440 - val_loss: 0.6295 - val_accuracy: 0.7515\n",
            "Epoch 20/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6376 - accuracy: 0.6513 - val_loss: 0.6282 - val_accuracy: 0.7175\n",
            "Epoch 21/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6322 - accuracy: 0.6647 - val_loss: 0.6241 - val_accuracy: 0.7275\n",
            "Epoch 22/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.6627 - val_loss: 0.6205 - val_accuracy: 0.7725\n",
            "Epoch 23/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6295 - accuracy: 0.6630 - val_loss: 0.6183 - val_accuracy: 0.7610\n",
            "Epoch 24/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6299 - accuracy: 0.6523 - val_loss: 0.6165 - val_accuracy: 0.7310\n",
            "Epoch 25/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6216 - accuracy: 0.6893 - val_loss: 0.6131 - val_accuracy: 0.8070\n",
            "Epoch 26/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6235 - accuracy: 0.6890 - val_loss: 0.6101 - val_accuracy: 0.7610\n",
            "Epoch 27/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6170 - accuracy: 0.7017 - val_loss: 0.6079 - val_accuracy: 0.7690\n",
            "Epoch 28/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6198 - accuracy: 0.7040 - val_loss: 0.6050 - val_accuracy: 0.8030\n",
            "Epoch 29/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6111 - accuracy: 0.7063 - val_loss: 0.6017 - val_accuracy: 0.7675\n",
            "Epoch 30/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.7087 - val_loss: 0.5990 - val_accuracy: 0.8015\n",
            "Epoch 31/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6083 - accuracy: 0.7017 - val_loss: 0.5967 - val_accuracy: 0.7855\n",
            "Epoch 32/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.7087 - val_loss: 0.5937 - val_accuracy: 0.8105\n",
            "Epoch 33/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6032 - accuracy: 0.7173 - val_loss: 0.5911 - val_accuracy: 0.8030\n",
            "Epoch 34/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6017 - accuracy: 0.7167 - val_loss: 0.5881 - val_accuracy: 0.8035\n",
            "Epoch 35/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5917 - accuracy: 0.7297 - val_loss: 0.5855 - val_accuracy: 0.8065\n",
            "Epoch 36/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6011 - accuracy: 0.7177 - val_loss: 0.5831 - val_accuracy: 0.8030\n",
            "Epoch 37/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6011 - accuracy: 0.7123 - val_loss: 0.5809 - val_accuracy: 0.8070\n",
            "Epoch 38/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5894 - accuracy: 0.7323 - val_loss: 0.5788 - val_accuracy: 0.8200\n",
            "Epoch 39/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5917 - accuracy: 0.7273 - val_loss: 0.5770 - val_accuracy: 0.8170\n",
            "Epoch 40/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.7400 - val_loss: 0.5732 - val_accuracy: 0.8105\n",
            "Epoch 41/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5833 - accuracy: 0.7387 - val_loss: 0.5703 - val_accuracy: 0.8115\n",
            "Epoch 42/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5820 - accuracy: 0.7380 - val_loss: 0.5690 - val_accuracy: 0.8130\n",
            "Epoch 43/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5829 - accuracy: 0.7357 - val_loss: 0.5655 - val_accuracy: 0.8215\n",
            "Epoch 44/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5795 - accuracy: 0.7473 - val_loss: 0.5632 - val_accuracy: 0.8175\n",
            "Epoch 45/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5791 - accuracy: 0.7317 - val_loss: 0.5610 - val_accuracy: 0.8195\n",
            "Epoch 46/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5695 - accuracy: 0.7470 - val_loss: 0.5586 - val_accuracy: 0.8235\n",
            "Epoch 47/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5742 - accuracy: 0.7357 - val_loss: 0.5555 - val_accuracy: 0.8220\n",
            "Epoch 48/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.7377 - val_loss: 0.5526 - val_accuracy: 0.8240\n",
            "Epoch 49/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5682 - accuracy: 0.7493 - val_loss: 0.5511 - val_accuracy: 0.8230\n",
            "Epoch 50/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5671 - accuracy: 0.7397 - val_loss: 0.5491 - val_accuracy: 0.8245\n",
            "Epoch 51/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5663 - accuracy: 0.7493 - val_loss: 0.5466 - val_accuracy: 0.8285\n",
            "Epoch 52/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5665 - accuracy: 0.7433 - val_loss: 0.5439 - val_accuracy: 0.8310\n",
            "Epoch 53/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5602 - accuracy: 0.7473 - val_loss: 0.5414 - val_accuracy: 0.8270\n",
            "Epoch 54/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.7423 - val_loss: 0.5394 - val_accuracy: 0.8300\n",
            "Epoch 55/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5563 - accuracy: 0.7537 - val_loss: 0.5370 - val_accuracy: 0.8315\n",
            "Epoch 56/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5539 - accuracy: 0.7623 - val_loss: 0.5347 - val_accuracy: 0.8320\n",
            "Epoch 57/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5586 - accuracy: 0.7513 - val_loss: 0.5327 - val_accuracy: 0.8305\n",
            "Epoch 58/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5558 - accuracy: 0.7480 - val_loss: 0.5301 - val_accuracy: 0.8340\n",
            "Epoch 59/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5504 - accuracy: 0.7527 - val_loss: 0.5275 - val_accuracy: 0.8340\n",
            "Epoch 60/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5462 - accuracy: 0.7530 - val_loss: 0.5255 - val_accuracy: 0.8250\n",
            "Epoch 61/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5501 - accuracy: 0.7480 - val_loss: 0.5235 - val_accuracy: 0.8370\n",
            "Epoch 62/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5431 - accuracy: 0.7590 - val_loss: 0.5208 - val_accuracy: 0.8340\n",
            "Epoch 63/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5513 - accuracy: 0.7323 - val_loss: 0.5192 - val_accuracy: 0.8210\n",
            "Epoch 64/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5477 - accuracy: 0.7487 - val_loss: 0.5175 - val_accuracy: 0.8370\n",
            "Epoch 65/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7513 - val_loss: 0.5152 - val_accuracy: 0.8380\n",
            "Epoch 66/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7510 - val_loss: 0.5129 - val_accuracy: 0.8300\n",
            "Epoch 67/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.7513 - val_loss: 0.5112 - val_accuracy: 0.8335\n",
            "Epoch 68/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5388 - accuracy: 0.7487 - val_loss: 0.5097 - val_accuracy: 0.8380\n",
            "Epoch 69/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5410 - accuracy: 0.7493 - val_loss: 0.5075 - val_accuracy: 0.8295\n",
            "Epoch 70/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5272 - accuracy: 0.7627 - val_loss: 0.5064 - val_accuracy: 0.8395\n",
            "Epoch 71/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7533 - val_loss: 0.5043 - val_accuracy: 0.8380\n",
            "Epoch 72/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7587 - val_loss: 0.5030 - val_accuracy: 0.8395\n",
            "Epoch 73/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5384 - accuracy: 0.7407 - val_loss: 0.5006 - val_accuracy: 0.8370\n",
            "Epoch 74/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7620 - val_loss: 0.4990 - val_accuracy: 0.8325\n",
            "Epoch 75/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5307 - accuracy: 0.7600 - val_loss: 0.4974 - val_accuracy: 0.8310\n",
            "Epoch 76/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5254 - accuracy: 0.7573 - val_loss: 0.4958 - val_accuracy: 0.8410\n",
            "Epoch 77/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5239 - accuracy: 0.7677 - val_loss: 0.4936 - val_accuracy: 0.8355\n",
            "Epoch 78/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5259 - accuracy: 0.7527 - val_loss: 0.4922 - val_accuracy: 0.8340\n",
            "Epoch 79/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5194 - accuracy: 0.7703 - val_loss: 0.4906 - val_accuracy: 0.8400\n",
            "Epoch 80/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5187 - accuracy: 0.7697 - val_loss: 0.4893 - val_accuracy: 0.8425\n",
            "Epoch 81/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7603 - val_loss: 0.4869 - val_accuracy: 0.8340\n",
            "Epoch 82/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7573 - val_loss: 0.4861 - val_accuracy: 0.8400\n",
            "Epoch 83/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5198 - accuracy: 0.7660 - val_loss: 0.4845 - val_accuracy: 0.8420\n",
            "Epoch 84/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5174 - accuracy: 0.7723 - val_loss: 0.4832 - val_accuracy: 0.8435\n",
            "Epoch 85/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5128 - accuracy: 0.7597 - val_loss: 0.4819 - val_accuracy: 0.8445\n",
            "Epoch 86/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5177 - accuracy: 0.7687 - val_loss: 0.4798 - val_accuracy: 0.8375\n",
            "Epoch 87/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.7603 - val_loss: 0.4790 - val_accuracy: 0.8445\n",
            "Epoch 88/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5135 - accuracy: 0.7603 - val_loss: 0.4772 - val_accuracy: 0.8390\n",
            "Epoch 89/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5114 - accuracy: 0.7657 - val_loss: 0.4759 - val_accuracy: 0.8440\n",
            "Epoch 90/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5133 - accuracy: 0.7613 - val_loss: 0.4750 - val_accuracy: 0.8415\n",
            "Epoch 91/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.7563 - val_loss: 0.4733 - val_accuracy: 0.8400\n",
            "Epoch 92/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7580 - val_loss: 0.4724 - val_accuracy: 0.8385\n",
            "Epoch 93/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7587 - val_loss: 0.4713 - val_accuracy: 0.8430\n",
            "Epoch 94/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5095 - accuracy: 0.7647 - val_loss: 0.4696 - val_accuracy: 0.8410\n",
            "Epoch 95/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7590 - val_loss: 0.4685 - val_accuracy: 0.8425\n",
            "Epoch 96/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5057 - accuracy: 0.7617 - val_loss: 0.4676 - val_accuracy: 0.8400\n",
            "Epoch 97/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5093 - accuracy: 0.7690 - val_loss: 0.4667 - val_accuracy: 0.8470\n",
            "Epoch 98/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5038 - accuracy: 0.7667 - val_loss: 0.4654 - val_accuracy: 0.8415\n",
            "Epoch 99/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5071 - accuracy: 0.7617 - val_loss: 0.4644 - val_accuracy: 0.8410\n",
            "Epoch 100/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4993 - accuracy: 0.7743 - val_loss: 0.4633 - val_accuracy: 0.8435\n",
            "Epoch 101/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7590 - val_loss: 0.4622 - val_accuracy: 0.8390\n",
            "Epoch 102/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7650 - val_loss: 0.4606 - val_accuracy: 0.8455\n",
            "Epoch 103/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4965 - accuracy: 0.7873 - val_loss: 0.4593 - val_accuracy: 0.8430\n",
            "Epoch 104/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4988 - accuracy: 0.7667 - val_loss: 0.4583 - val_accuracy: 0.8420\n",
            "Epoch 105/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4947 - accuracy: 0.7740 - val_loss: 0.4574 - val_accuracy: 0.8465\n",
            "Epoch 106/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4953 - accuracy: 0.7707 - val_loss: 0.4562 - val_accuracy: 0.8455\n",
            "Epoch 107/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4998 - accuracy: 0.7707 - val_loss: 0.4549 - val_accuracy: 0.8430\n",
            "Epoch 108/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.7697 - val_loss: 0.4542 - val_accuracy: 0.8450\n",
            "Epoch 109/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7837 - val_loss: 0.4533 - val_accuracy: 0.8475\n",
            "Epoch 110/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5074 - accuracy: 0.7710 - val_loss: 0.4524 - val_accuracy: 0.8455\n",
            "Epoch 111/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.7720 - val_loss: 0.4515 - val_accuracy: 0.8450\n",
            "Epoch 112/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4931 - accuracy: 0.7680 - val_loss: 0.4505 - val_accuracy: 0.8445\n",
            "Epoch 113/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7773 - val_loss: 0.4496 - val_accuracy: 0.8475\n",
            "Epoch 114/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7800 - val_loss: 0.4481 - val_accuracy: 0.8430\n",
            "Epoch 115/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4966 - accuracy: 0.7727 - val_loss: 0.4476 - val_accuracy: 0.8440\n",
            "Epoch 116/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7837 - val_loss: 0.4472 - val_accuracy: 0.8470\n",
            "Epoch 117/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.7807 - val_loss: 0.4454 - val_accuracy: 0.8450\n",
            "Epoch 118/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7767 - val_loss: 0.4442 - val_accuracy: 0.8440\n",
            "Epoch 119/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7800 - val_loss: 0.4432 - val_accuracy: 0.8440\n",
            "Epoch 120/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.7757 - val_loss: 0.4427 - val_accuracy: 0.8435\n",
            "Epoch 121/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4869 - accuracy: 0.7823 - val_loss: 0.4418 - val_accuracy: 0.8420\n",
            "Epoch 122/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4829 - accuracy: 0.7840 - val_loss: 0.4410 - val_accuracy: 0.8425\n",
            "Epoch 123/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4756 - accuracy: 0.7887 - val_loss: 0.4400 - val_accuracy: 0.8425\n",
            "Epoch 124/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7690 - val_loss: 0.4389 - val_accuracy: 0.8435\n",
            "Epoch 125/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7753 - val_loss: 0.4385 - val_accuracy: 0.8440\n",
            "Epoch 126/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7783 - val_loss: 0.4376 - val_accuracy: 0.8425\n",
            "Epoch 127/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4851 - accuracy: 0.7807 - val_loss: 0.4370 - val_accuracy: 0.8440\n",
            "Epoch 128/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4856 - accuracy: 0.7740 - val_loss: 0.4360 - val_accuracy: 0.8440\n",
            "Epoch 129/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4750 - accuracy: 0.7900 - val_loss: 0.4354 - val_accuracy: 0.8420\n",
            "Epoch 130/2000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4767 - accuracy: 0.7757 - val_loss: 0.4344 - val_accuracy: 0.8430\n",
            "Epoch 131/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4870 - accuracy: 0.7773 - val_loss: 0.4344 - val_accuracy: 0.8430\n",
            "Epoch 132/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4740 - accuracy: 0.7820 - val_loss: 0.4334 - val_accuracy: 0.8435\n",
            "Epoch 133/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4800 - accuracy: 0.7780 - val_loss: 0.4326 - val_accuracy: 0.8455\n",
            "Epoch 134/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4781 - accuracy: 0.7757 - val_loss: 0.4318 - val_accuracy: 0.8455\n",
            "Epoch 135/2000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4677 - accuracy: 0.7880 - val_loss: 0.4309 - val_accuracy: 0.8440\n",
            "Epoch 136/2000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4736 - accuracy: 0.7883 - val_loss: 0.4301 - val_accuracy: 0.8425\n",
            "Epoch 137/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4845 - accuracy: 0.7743 - val_loss: 0.4296 - val_accuracy: 0.8430\n",
            "Epoch 138/2000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.4756 - accuracy: 0.7817 - val_loss: 0.4290 - val_accuracy: 0.8440\n",
            "Epoch 139/2000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4710 - accuracy: 0.7893 - val_loss: 0.4279 - val_accuracy: 0.8445\n",
            "Epoch 140/2000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.4704 - accuracy: 0.7820 - val_loss: 0.4270 - val_accuracy: 0.8440\n",
            "Epoch 141/2000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4700 - accuracy: 0.7867 - val_loss: 0.4263 - val_accuracy: 0.8435\n",
            "Epoch 142/2000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4748 - accuracy: 0.7770 - val_loss: 0.4256 - val_accuracy: 0.8420\n",
            "Epoch 143/2000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4700 - accuracy: 0.7883 - val_loss: 0.4254 - val_accuracy: 0.8420\n",
            "Epoch 144/2000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.4735 - accuracy: 0.7760 - val_loss: 0.4244 - val_accuracy: 0.8430\n",
            "Epoch 145/2000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4680 - accuracy: 0.7883 - val_loss: 0.4238 - val_accuracy: 0.8430\n",
            "Epoch 146/2000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4688 - accuracy: 0.7910 - val_loss: 0.4232 - val_accuracy: 0.8420\n",
            "Epoch 147/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4696 - accuracy: 0.7817 - val_loss: 0.4226 - val_accuracy: 0.8415\n",
            "Epoch 148/2000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4613 - accuracy: 0.7907 - val_loss: 0.4220 - val_accuracy: 0.8465\n",
            "Epoch 149/2000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4652 - accuracy: 0.7880 - val_loss: 0.4211 - val_accuracy: 0.8425\n",
            "Epoch 150/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4639 - accuracy: 0.7897 - val_loss: 0.4208 - val_accuracy: 0.8435\n",
            "Epoch 151/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4709 - accuracy: 0.7873 - val_loss: 0.4199 - val_accuracy: 0.8420\n",
            "Epoch 152/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.7910 - val_loss: 0.4193 - val_accuracy: 0.8465\n",
            "Epoch 153/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4676 - accuracy: 0.7877 - val_loss: 0.4184 - val_accuracy: 0.8430\n",
            "Epoch 154/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4648 - accuracy: 0.7860 - val_loss: 0.4175 - val_accuracy: 0.8430\n",
            "Epoch 155/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4659 - accuracy: 0.7853 - val_loss: 0.4170 - val_accuracy: 0.8430\n",
            "Epoch 156/2000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4647 - accuracy: 0.7877 - val_loss: 0.4165 - val_accuracy: 0.8430\n",
            "Epoch 157/2000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.4667 - accuracy: 0.7893 - val_loss: 0.4161 - val_accuracy: 0.8455\n",
            "Epoch 158/2000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.4595 - accuracy: 0.7873 - val_loss: 0.4153 - val_accuracy: 0.8430\n",
            "Epoch 159/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4631 - accuracy: 0.7940 - val_loss: 0.4149 - val_accuracy: 0.8425\n",
            "Epoch 160/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4565 - accuracy: 0.7893 - val_loss: 0.4145 - val_accuracy: 0.8435\n",
            "Epoch 161/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4493 - accuracy: 0.7980 - val_loss: 0.4136 - val_accuracy: 0.8435\n",
            "Epoch 162/2000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4568 - accuracy: 0.7930 - val_loss: 0.4130 - val_accuracy: 0.8415\n",
            "Epoch 163/2000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4509 - accuracy: 0.7890 - val_loss: 0.4126 - val_accuracy: 0.8425\n",
            "Epoch 164/2000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4585 - accuracy: 0.7903 - val_loss: 0.4119 - val_accuracy: 0.8440\n",
            "Epoch 165/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4616 - accuracy: 0.7917 - val_loss: 0.4109 - val_accuracy: 0.8445\n",
            "Epoch 166/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4490 - accuracy: 0.7967 - val_loss: 0.4103 - val_accuracy: 0.8455\n",
            "Epoch 167/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4518 - accuracy: 0.7977 - val_loss: 0.4096 - val_accuracy: 0.8435\n",
            "Epoch 168/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4553 - accuracy: 0.7967 - val_loss: 0.4095 - val_accuracy: 0.8440\n",
            "Epoch 169/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7870 - val_loss: 0.4091 - val_accuracy: 0.8430\n",
            "Epoch 170/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.7987 - val_loss: 0.4082 - val_accuracy: 0.8425\n",
            "Epoch 171/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7870 - val_loss: 0.4076 - val_accuracy: 0.8420\n",
            "Epoch 172/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.7900 - val_loss: 0.4068 - val_accuracy: 0.8425\n",
            "Epoch 173/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7940 - val_loss: 0.4064 - val_accuracy: 0.8435\n",
            "Epoch 174/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7940 - val_loss: 0.4061 - val_accuracy: 0.8430\n",
            "Epoch 175/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7983 - val_loss: 0.4058 - val_accuracy: 0.8445\n",
            "Epoch 176/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7900 - val_loss: 0.4051 - val_accuracy: 0.8440\n",
            "Epoch 177/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.7983 - val_loss: 0.4046 - val_accuracy: 0.8450\n",
            "Epoch 178/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4453 - accuracy: 0.7907 - val_loss: 0.4036 - val_accuracy: 0.8420\n",
            "Epoch 179/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4490 - accuracy: 0.7940 - val_loss: 0.4034 - val_accuracy: 0.8435\n",
            "Epoch 180/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4452 - accuracy: 0.7970 - val_loss: 0.4029 - val_accuracy: 0.8445\n",
            "Epoch 181/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.7993 - val_loss: 0.4028 - val_accuracy: 0.8455\n",
            "Epoch 182/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7943 - val_loss: 0.4022 - val_accuracy: 0.8460\n",
            "Epoch 183/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4573 - accuracy: 0.7833 - val_loss: 0.4016 - val_accuracy: 0.8450\n",
            "Epoch 184/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7963 - val_loss: 0.4008 - val_accuracy: 0.8430\n",
            "Epoch 185/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.8080 - val_loss: 0.4005 - val_accuracy: 0.8410\n",
            "Epoch 186/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7983 - val_loss: 0.4003 - val_accuracy: 0.8450\n",
            "Epoch 187/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4497 - accuracy: 0.7947 - val_loss: 0.3995 - val_accuracy: 0.8415\n",
            "Epoch 188/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.7977 - val_loss: 0.3990 - val_accuracy: 0.8415\n",
            "Epoch 189/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.7897 - val_loss: 0.3985 - val_accuracy: 0.8455\n",
            "Epoch 190/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7977 - val_loss: 0.3984 - val_accuracy: 0.8450\n",
            "Epoch 191/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.7893 - val_loss: 0.3982 - val_accuracy: 0.8450\n",
            "Epoch 192/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.7950 - val_loss: 0.3978 - val_accuracy: 0.8440\n",
            "Epoch 193/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.7910 - val_loss: 0.3972 - val_accuracy: 0.8430\n",
            "Epoch 194/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.8000 - val_loss: 0.3973 - val_accuracy: 0.8460\n",
            "Epoch 195/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7980 - val_loss: 0.3965 - val_accuracy: 0.8430\n",
            "Epoch 196/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4460 - accuracy: 0.7867 - val_loss: 0.3965 - val_accuracy: 0.8435\n",
            "Epoch 197/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.7957 - val_loss: 0.3958 - val_accuracy: 0.8480\n",
            "Epoch 198/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7907 - val_loss: 0.3953 - val_accuracy: 0.8470\n",
            "Epoch 199/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4395 - accuracy: 0.8000 - val_loss: 0.3948 - val_accuracy: 0.8425\n",
            "Epoch 200/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.8010 - val_loss: 0.3944 - val_accuracy: 0.8430\n",
            "Epoch 201/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.8013 - val_loss: 0.3945 - val_accuracy: 0.8455\n",
            "Epoch 202/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.8023 - val_loss: 0.3939 - val_accuracy: 0.8465\n",
            "Epoch 203/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.7937 - val_loss: 0.3931 - val_accuracy: 0.8455\n",
            "Epoch 204/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7860 - val_loss: 0.3930 - val_accuracy: 0.8450\n",
            "Epoch 205/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 0.8050 - val_loss: 0.3930 - val_accuracy: 0.8455\n",
            "Epoch 206/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.8013 - val_loss: 0.3919 - val_accuracy: 0.8440\n",
            "Epoch 207/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.7907 - val_loss: 0.3918 - val_accuracy: 0.8460\n",
            "Epoch 208/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.8073 - val_loss: 0.3914 - val_accuracy: 0.8455\n",
            "Epoch 209/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4362 - accuracy: 0.7993 - val_loss: 0.3910 - val_accuracy: 0.8470\n",
            "Epoch 210/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7950 - val_loss: 0.3912 - val_accuracy: 0.8450\n",
            "Epoch 211/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4356 - accuracy: 0.8030 - val_loss: 0.3905 - val_accuracy: 0.8460\n",
            "Epoch 212/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.8027 - val_loss: 0.3901 - val_accuracy: 0.8475\n",
            "Epoch 213/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.7943 - val_loss: 0.3898 - val_accuracy: 0.8475\n",
            "Epoch 214/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.8020 - val_loss: 0.3895 - val_accuracy: 0.8460\n",
            "Epoch 215/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4356 - accuracy: 0.8047 - val_loss: 0.3891 - val_accuracy: 0.8480\n",
            "Epoch 216/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7947 - val_loss: 0.3884 - val_accuracy: 0.8455\n",
            "Epoch 217/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.7970 - val_loss: 0.3885 - val_accuracy: 0.8470\n",
            "Epoch 218/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.8040 - val_loss: 0.3883 - val_accuracy: 0.8480\n",
            "Epoch 219/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.8047 - val_loss: 0.3879 - val_accuracy: 0.8470\n",
            "Epoch 220/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.7980 - val_loss: 0.3874 - val_accuracy: 0.8460\n",
            "Epoch 221/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.8013 - val_loss: 0.3869 - val_accuracy: 0.8450\n",
            "Epoch 222/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.8037 - val_loss: 0.3868 - val_accuracy: 0.8465\n",
            "Epoch 223/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8053 - val_loss: 0.3863 - val_accuracy: 0.8475\n",
            "Epoch 224/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7980 - val_loss: 0.3861 - val_accuracy: 0.8485\n",
            "Epoch 225/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.8073 - val_loss: 0.3860 - val_accuracy: 0.8470\n",
            "Epoch 226/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.8080 - val_loss: 0.3857 - val_accuracy: 0.8485\n",
            "Epoch 227/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7997 - val_loss: 0.3851 - val_accuracy: 0.8475\n",
            "Epoch 228/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.8127 - val_loss: 0.3850 - val_accuracy: 0.8450\n",
            "Epoch 229/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.8063 - val_loss: 0.3847 - val_accuracy: 0.8460\n",
            "Epoch 230/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4257 - accuracy: 0.7957 - val_loss: 0.3842 - val_accuracy: 0.8460\n",
            "Epoch 231/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4307 - accuracy: 0.8057 - val_loss: 0.3840 - val_accuracy: 0.8470\n",
            "Epoch 232/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.8107 - val_loss: 0.3838 - val_accuracy: 0.8475\n",
            "Epoch 233/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8120 - val_loss: 0.3834 - val_accuracy: 0.8480\n",
            "Epoch 234/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.8007 - val_loss: 0.3830 - val_accuracy: 0.8460\n",
            "Epoch 235/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.8050 - val_loss: 0.3825 - val_accuracy: 0.8470\n",
            "Epoch 236/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4307 - accuracy: 0.8033 - val_loss: 0.3821 - val_accuracy: 0.8490\n",
            "Epoch 237/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.8003 - val_loss: 0.3819 - val_accuracy: 0.8480\n",
            "Epoch 238/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.8107 - val_loss: 0.3816 - val_accuracy: 0.8485\n",
            "Epoch 239/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8060 - val_loss: 0.3815 - val_accuracy: 0.8470\n",
            "Epoch 240/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.8110 - val_loss: 0.3812 - val_accuracy: 0.8475\n",
            "Epoch 241/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8040 - val_loss: 0.3811 - val_accuracy: 0.8480\n",
            "Epoch 242/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.8077 - val_loss: 0.3810 - val_accuracy: 0.8480\n",
            "Epoch 243/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.8033 - val_loss: 0.3806 - val_accuracy: 0.8470\n",
            "Epoch 244/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.8020 - val_loss: 0.3801 - val_accuracy: 0.8475\n",
            "Epoch 245/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.8093 - val_loss: 0.3804 - val_accuracy: 0.8480\n",
            "Epoch 246/2000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4225 - accuracy: 0.8033 - val_loss: 0.3797 - val_accuracy: 0.8480\n",
            "Epoch 247/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4332 - accuracy: 0.8037 - val_loss: 0.3791 - val_accuracy: 0.8470\n",
            "Epoch 248/2000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4222 - accuracy: 0.8090 - val_loss: 0.3791 - val_accuracy: 0.8485\n",
            "Epoch 249/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4222 - accuracy: 0.8117 - val_loss: 0.3790 - val_accuracy: 0.8465\n",
            "Epoch 250/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4265 - accuracy: 0.8087 - val_loss: 0.3790 - val_accuracy: 0.8470\n",
            "Epoch 251/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4301 - accuracy: 0.8067 - val_loss: 0.3787 - val_accuracy: 0.8480\n",
            "Epoch 252/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4179 - accuracy: 0.8153 - val_loss: 0.3788 - val_accuracy: 0.8465\n",
            "Epoch 253/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4297 - accuracy: 0.8040 - val_loss: 0.3782 - val_accuracy: 0.8465\n",
            "Epoch 254/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4234 - accuracy: 0.8097 - val_loss: 0.3783 - val_accuracy: 0.8470\n",
            "Epoch 255/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4182 - accuracy: 0.8087 - val_loss: 0.3778 - val_accuracy: 0.8485\n",
            "Epoch 256/2000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.4234 - accuracy: 0.8007 - val_loss: 0.3776 - val_accuracy: 0.8485\n",
            "Epoch 257/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4207 - accuracy: 0.8067 - val_loss: 0.3771 - val_accuracy: 0.8465\n",
            "Epoch 258/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.8063 - val_loss: 0.3771 - val_accuracy: 0.8460\n",
            "Epoch 259/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.8157 - val_loss: 0.3768 - val_accuracy: 0.8465\n",
            "Epoch 260/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.8047 - val_loss: 0.3767 - val_accuracy: 0.8455\n",
            "Epoch 261/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8147 - val_loss: 0.3767 - val_accuracy: 0.8480\n",
            "Epoch 262/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4289 - accuracy: 0.7993 - val_loss: 0.3765 - val_accuracy: 0.8475\n",
            "Epoch 263/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4193 - accuracy: 0.8123 - val_loss: 0.3760 - val_accuracy: 0.8480\n",
            "Epoch 264/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4231 - accuracy: 0.8043 - val_loss: 0.3758 - val_accuracy: 0.8470\n",
            "Epoch 265/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4186 - accuracy: 0.8140 - val_loss: 0.3754 - val_accuracy: 0.8480\n",
            "Epoch 266/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.7967 - val_loss: 0.3754 - val_accuracy: 0.8480\n",
            "Epoch 267/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.8040 - val_loss: 0.3752 - val_accuracy: 0.8465\n",
            "Epoch 268/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4128 - accuracy: 0.8167 - val_loss: 0.3749 - val_accuracy: 0.8465\n",
            "Epoch 269/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.8097 - val_loss: 0.3744 - val_accuracy: 0.8460\n",
            "Epoch 270/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.8110 - val_loss: 0.3745 - val_accuracy: 0.8455\n",
            "Epoch 271/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8110 - val_loss: 0.3740 - val_accuracy: 0.8455\n",
            "Epoch 272/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4223 - accuracy: 0.8090 - val_loss: 0.3737 - val_accuracy: 0.8455\n",
            "Epoch 273/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.8003 - val_loss: 0.3737 - val_accuracy: 0.8480\n",
            "Epoch 274/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.8080 - val_loss: 0.3741 - val_accuracy: 0.8470\n",
            "Epoch 275/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8063 - val_loss: 0.3735 - val_accuracy: 0.8475\n",
            "Epoch 276/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.8127 - val_loss: 0.3735 - val_accuracy: 0.8480\n",
            "Epoch 277/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4138 - accuracy: 0.8170 - val_loss: 0.3733 - val_accuracy: 0.8485\n",
            "Epoch 278/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4157 - accuracy: 0.8083 - val_loss: 0.3730 - val_accuracy: 0.8460\n",
            "Epoch 279/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.8067 - val_loss: 0.3728 - val_accuracy: 0.8450\n",
            "Epoch 280/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4205 - accuracy: 0.8053 - val_loss: 0.3727 - val_accuracy: 0.8455\n",
            "Epoch 281/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4215 - accuracy: 0.8070 - val_loss: 0.3726 - val_accuracy: 0.8465\n",
            "Epoch 282/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8133 - val_loss: 0.3724 - val_accuracy: 0.8465\n",
            "Epoch 283/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8153 - val_loss: 0.3725 - val_accuracy: 0.8455\n",
            "Epoch 284/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8137 - val_loss: 0.3721 - val_accuracy: 0.8460\n",
            "Epoch 285/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8163 - val_loss: 0.3716 - val_accuracy: 0.8465\n",
            "Epoch 286/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.8050 - val_loss: 0.3712 - val_accuracy: 0.8460\n",
            "Epoch 287/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8140 - val_loss: 0.3712 - val_accuracy: 0.8445\n",
            "Epoch 288/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8180 - val_loss: 0.3717 - val_accuracy: 0.8450\n",
            "Epoch 289/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8163 - val_loss: 0.3715 - val_accuracy: 0.8470\n",
            "Epoch 290/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8073 - val_loss: 0.3711 - val_accuracy: 0.8475\n",
            "Epoch 291/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8187 - val_loss: 0.3707 - val_accuracy: 0.8485\n",
            "Epoch 292/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8090 - val_loss: 0.3707 - val_accuracy: 0.8465\n",
            "Epoch 293/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4099 - accuracy: 0.8160 - val_loss: 0.3706 - val_accuracy: 0.8455\n",
            "Epoch 294/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8070 - val_loss: 0.3704 - val_accuracy: 0.8440\n",
            "Epoch 295/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.8193 - val_loss: 0.3703 - val_accuracy: 0.8440\n",
            "Epoch 296/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8087 - val_loss: 0.3698 - val_accuracy: 0.8465\n",
            "Epoch 297/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4206 - accuracy: 0.8090 - val_loss: 0.3698 - val_accuracy: 0.8465\n",
            "Epoch 298/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4174 - accuracy: 0.8083 - val_loss: 0.3698 - val_accuracy: 0.8460\n",
            "Epoch 299/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8177 - val_loss: 0.3693 - val_accuracy: 0.8450\n",
            "Epoch 300/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8177 - val_loss: 0.3691 - val_accuracy: 0.8450\n",
            "Epoch 301/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8197 - val_loss: 0.3692 - val_accuracy: 0.8450\n",
            "Epoch 302/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8197 - val_loss: 0.3695 - val_accuracy: 0.8430\n",
            "Epoch 303/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8130 - val_loss: 0.3696 - val_accuracy: 0.8455\n",
            "Epoch 304/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8140 - val_loss: 0.3692 - val_accuracy: 0.8460\n",
            "Epoch 305/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8150 - val_loss: 0.3690 - val_accuracy: 0.8430\n",
            "Epoch 306/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8133 - val_loss: 0.3686 - val_accuracy: 0.8455\n",
            "Epoch 307/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8133 - val_loss: 0.3683 - val_accuracy: 0.8450\n",
            "Epoch 308/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8110 - val_loss: 0.3681 - val_accuracy: 0.8465\n",
            "Epoch 309/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8083 - val_loss: 0.3683 - val_accuracy: 0.8455\n",
            "Epoch 310/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8093 - val_loss: 0.3682 - val_accuracy: 0.8415\n",
            "Epoch 311/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8123 - val_loss: 0.3678 - val_accuracy: 0.8460\n",
            "Epoch 312/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.8147 - val_loss: 0.3673 - val_accuracy: 0.8470\n",
            "Epoch 313/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8207 - val_loss: 0.3673 - val_accuracy: 0.8445\n",
            "Epoch 314/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8117 - val_loss: 0.3676 - val_accuracy: 0.8430\n",
            "Epoch 315/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8100 - val_loss: 0.3672 - val_accuracy: 0.8445\n",
            "Epoch 316/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8093 - val_loss: 0.3674 - val_accuracy: 0.8440\n",
            "Epoch 317/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4024 - accuracy: 0.8213 - val_loss: 0.3674 - val_accuracy: 0.8420\n",
            "Epoch 318/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8113 - val_loss: 0.3667 - val_accuracy: 0.8455\n",
            "Epoch 319/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4083 - accuracy: 0.8093 - val_loss: 0.3663 - val_accuracy: 0.8455\n",
            "Epoch 320/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.8077 - val_loss: 0.3665 - val_accuracy: 0.8440\n",
            "Epoch 321/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8090 - val_loss: 0.3665 - val_accuracy: 0.8420\n",
            "Epoch 322/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8127 - val_loss: 0.3664 - val_accuracy: 0.8450\n",
            "Epoch 323/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8143 - val_loss: 0.3664 - val_accuracy: 0.8425\n",
            "Epoch 324/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8167 - val_loss: 0.3658 - val_accuracy: 0.8455\n",
            "Epoch 325/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8130 - val_loss: 0.3660 - val_accuracy: 0.8455\n",
            "Epoch 326/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8130 - val_loss: 0.3658 - val_accuracy: 0.8455\n",
            "Epoch 327/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8060 - val_loss: 0.3662 - val_accuracy: 0.8425\n",
            "Epoch 328/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8137 - val_loss: 0.3655 - val_accuracy: 0.8440\n",
            "Epoch 329/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.8107 - val_loss: 0.3654 - val_accuracy: 0.8445\n",
            "Epoch 330/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8073 - val_loss: 0.3654 - val_accuracy: 0.8440\n",
            "Epoch 331/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8160 - val_loss: 0.3650 - val_accuracy: 0.8475\n",
            "Epoch 332/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8240 - val_loss: 0.3649 - val_accuracy: 0.8465\n",
            "Epoch 333/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8143 - val_loss: 0.3647 - val_accuracy: 0.8455\n",
            "Epoch 334/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8207 - val_loss: 0.3645 - val_accuracy: 0.8460\n",
            "Epoch 335/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8143 - val_loss: 0.3647 - val_accuracy: 0.8455\n",
            "Epoch 336/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8120 - val_loss: 0.3647 - val_accuracy: 0.8450\n",
            "Epoch 337/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8100 - val_loss: 0.3646 - val_accuracy: 0.8440\n",
            "Epoch 338/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8080 - val_loss: 0.3643 - val_accuracy: 0.8440\n",
            "Epoch 339/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8103 - val_loss: 0.3642 - val_accuracy: 0.8465\n",
            "Epoch 340/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8087 - val_loss: 0.3640 - val_accuracy: 0.8460\n",
            "Epoch 341/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8123 - val_loss: 0.3642 - val_accuracy: 0.8425\n",
            "Epoch 342/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.8170 - val_loss: 0.3638 - val_accuracy: 0.8440\n",
            "Epoch 343/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8160 - val_loss: 0.3636 - val_accuracy: 0.8485\n",
            "Epoch 344/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8147 - val_loss: 0.3636 - val_accuracy: 0.8465\n",
            "Epoch 345/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8103 - val_loss: 0.3634 - val_accuracy: 0.8455\n",
            "Epoch 346/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8207 - val_loss: 0.3635 - val_accuracy: 0.8445\n",
            "Epoch 347/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8117 - val_loss: 0.3636 - val_accuracy: 0.8440\n",
            "Epoch 348/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4003 - accuracy: 0.8263 - val_loss: 0.3635 - val_accuracy: 0.8465\n",
            "Epoch 349/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.8117 - val_loss: 0.3634 - val_accuracy: 0.8455\n",
            "Epoch 350/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8197 - val_loss: 0.3636 - val_accuracy: 0.8425\n",
            "Epoch 351/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8193 - val_loss: 0.3634 - val_accuracy: 0.8430\n",
            "Epoch 352/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8207 - val_loss: 0.3627 - val_accuracy: 0.8450\n",
            "Epoch 353/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8167 - val_loss: 0.3625 - val_accuracy: 0.8460\n",
            "Epoch 354/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.8110 - val_loss: 0.3626 - val_accuracy: 0.8460\n",
            "Epoch 355/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8147 - val_loss: 0.3626 - val_accuracy: 0.8445\n",
            "Epoch 356/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8150 - val_loss: 0.3627 - val_accuracy: 0.8430\n",
            "Epoch 357/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8240 - val_loss: 0.3625 - val_accuracy: 0.8425\n",
            "Epoch 358/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8173 - val_loss: 0.3628 - val_accuracy: 0.8440\n",
            "Epoch 359/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8163 - val_loss: 0.3624 - val_accuracy: 0.8455\n",
            "Epoch 360/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8153 - val_loss: 0.3623 - val_accuracy: 0.8435\n",
            "Epoch 361/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8173 - val_loss: 0.3624 - val_accuracy: 0.8440\n",
            "Epoch 362/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8180 - val_loss: 0.3623 - val_accuracy: 0.8460\n",
            "Epoch 363/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8247 - val_loss: 0.3620 - val_accuracy: 0.8450\n",
            "Epoch 364/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8073 - val_loss: 0.3619 - val_accuracy: 0.8440\n",
            "Epoch 365/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8163 - val_loss: 0.3617 - val_accuracy: 0.8450\n",
            "Epoch 366/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4024 - accuracy: 0.8193 - val_loss: 0.3618 - val_accuracy: 0.8460\n",
            "Epoch 367/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8133 - val_loss: 0.3616 - val_accuracy: 0.8450\n",
            "Epoch 368/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8103 - val_loss: 0.3614 - val_accuracy: 0.8440\n",
            "Epoch 369/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4043 - accuracy: 0.8197 - val_loss: 0.3612 - val_accuracy: 0.8465\n",
            "Epoch 370/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4038 - accuracy: 0.8147 - val_loss: 0.3613 - val_accuracy: 0.8440\n",
            "Epoch 371/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8137 - val_loss: 0.3611 - val_accuracy: 0.8455\n",
            "Epoch 372/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8083 - val_loss: 0.3610 - val_accuracy: 0.8465\n",
            "Epoch 373/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8123 - val_loss: 0.3611 - val_accuracy: 0.8435\n",
            "Epoch 374/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8183 - val_loss: 0.3607 - val_accuracy: 0.8455\n",
            "Epoch 375/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8190 - val_loss: 0.3610 - val_accuracy: 0.8460\n",
            "Epoch 376/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8137 - val_loss: 0.3610 - val_accuracy: 0.8450\n",
            "Epoch 377/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8097 - val_loss: 0.3612 - val_accuracy: 0.8435\n",
            "Epoch 378/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8160 - val_loss: 0.3605 - val_accuracy: 0.8440\n",
            "Epoch 379/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8180 - val_loss: 0.3604 - val_accuracy: 0.8470\n",
            "Epoch 380/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.8130 - val_loss: 0.3602 - val_accuracy: 0.8455\n",
            "Epoch 381/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8163 - val_loss: 0.3604 - val_accuracy: 0.8430\n",
            "Epoch 382/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8187 - val_loss: 0.3604 - val_accuracy: 0.8450\n",
            "Epoch 383/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8127 - val_loss: 0.3603 - val_accuracy: 0.8430\n",
            "Epoch 384/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8127 - val_loss: 0.3601 - val_accuracy: 0.8445\n",
            "Epoch 385/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8193 - val_loss: 0.3599 - val_accuracy: 0.8435\n",
            "Epoch 386/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8227 - val_loss: 0.3601 - val_accuracy: 0.8450\n",
            "Epoch 387/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4035 - accuracy: 0.8110 - val_loss: 0.3598 - val_accuracy: 0.8440\n",
            "Epoch 388/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8107 - val_loss: 0.3595 - val_accuracy: 0.8440\n",
            "Epoch 389/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3998 - accuracy: 0.8180 - val_loss: 0.3593 - val_accuracy: 0.8460\n",
            "Epoch 390/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.8180 - val_loss: 0.3593 - val_accuracy: 0.8450\n",
            "Epoch 391/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8240 - val_loss: 0.3593 - val_accuracy: 0.8450\n",
            "Epoch 392/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8217 - val_loss: 0.3596 - val_accuracy: 0.8425\n",
            "Epoch 393/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8080 - val_loss: 0.3598 - val_accuracy: 0.8435\n",
            "Epoch 394/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8123 - val_loss: 0.3596 - val_accuracy: 0.8425\n",
            "Epoch 395/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8083 - val_loss: 0.3593 - val_accuracy: 0.8425\n",
            "Epoch 396/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8113 - val_loss: 0.3590 - val_accuracy: 0.8440\n",
            "Epoch 397/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8200 - val_loss: 0.3592 - val_accuracy: 0.8435\n",
            "Epoch 398/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.8180 - val_loss: 0.3589 - val_accuracy: 0.8445\n",
            "Epoch 399/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8140 - val_loss: 0.3588 - val_accuracy: 0.8435\n",
            "Epoch 400/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8203 - val_loss: 0.3587 - val_accuracy: 0.8455\n",
            "Epoch 401/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8150 - val_loss: 0.3588 - val_accuracy: 0.8445\n",
            "Epoch 402/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8267 - val_loss: 0.3586 - val_accuracy: 0.8455\n",
            "Epoch 403/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.8187 - val_loss: 0.3586 - val_accuracy: 0.8445\n",
            "Epoch 404/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8180 - val_loss: 0.3586 - val_accuracy: 0.8420\n",
            "Epoch 405/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8307 - val_loss: 0.3586 - val_accuracy: 0.8435\n",
            "Epoch 406/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8273 - val_loss: 0.3587 - val_accuracy: 0.8430\n",
            "Epoch 407/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8107 - val_loss: 0.3581 - val_accuracy: 0.8440\n",
            "Epoch 408/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8167 - val_loss: 0.3584 - val_accuracy: 0.8440\n",
            "Epoch 409/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.8103 - val_loss: 0.3580 - val_accuracy: 0.8435\n",
            "Epoch 410/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8237 - val_loss: 0.3581 - val_accuracy: 0.8440\n",
            "Epoch 411/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8063 - val_loss: 0.3581 - val_accuracy: 0.8435\n",
            "Epoch 412/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8177 - val_loss: 0.3580 - val_accuracy: 0.8440\n",
            "Epoch 413/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8190 - val_loss: 0.3580 - val_accuracy: 0.8440\n",
            "Epoch 414/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8147 - val_loss: 0.3581 - val_accuracy: 0.8445\n",
            "Epoch 415/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8100 - val_loss: 0.3578 - val_accuracy: 0.8445\n",
            "Epoch 416/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8103 - val_loss: 0.3578 - val_accuracy: 0.8445\n",
            "Epoch 417/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8293 - val_loss: 0.3579 - val_accuracy: 0.8440\n",
            "Epoch 418/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8210 - val_loss: 0.3584 - val_accuracy: 0.8460\n",
            "Epoch 419/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8253 - val_loss: 0.3578 - val_accuracy: 0.8455\n",
            "Epoch 420/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8210 - val_loss: 0.3580 - val_accuracy: 0.8460\n",
            "Epoch 421/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4002 - accuracy: 0.8083 - val_loss: 0.3581 - val_accuracy: 0.8450\n",
            "Epoch 422/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8123 - val_loss: 0.3578 - val_accuracy: 0.8445\n",
            "Epoch 423/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8153 - val_loss: 0.3578 - val_accuracy: 0.8455\n",
            "Epoch 424/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4030 - accuracy: 0.8120 - val_loss: 0.3575 - val_accuracy: 0.8475\n",
            "Epoch 425/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4070 - accuracy: 0.8083 - val_loss: 0.3576 - val_accuracy: 0.8445\n",
            "Epoch 426/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4038 - accuracy: 0.8153 - val_loss: 0.3577 - val_accuracy: 0.8435\n",
            "Epoch 427/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4038 - accuracy: 0.8173 - val_loss: 0.3574 - val_accuracy: 0.8445\n",
            "Epoch 428/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4023 - accuracy: 0.8163 - val_loss: 0.3574 - val_accuracy: 0.8445\n",
            "Epoch 429/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4003 - accuracy: 0.8170 - val_loss: 0.3574 - val_accuracy: 0.8455\n",
            "Epoch 430/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4027 - accuracy: 0.8163 - val_loss: 0.3574 - val_accuracy: 0.8430\n",
            "Epoch 431/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3903 - accuracy: 0.8230 - val_loss: 0.3574 - val_accuracy: 0.8435\n",
            "Epoch 432/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3973 - accuracy: 0.8153 - val_loss: 0.3575 - val_accuracy: 0.8445\n",
            "Epoch 433/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8237 - val_loss: 0.3571 - val_accuracy: 0.8440\n",
            "Epoch 434/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8233 - val_loss: 0.3572 - val_accuracy: 0.8455\n",
            "Epoch 435/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8183 - val_loss: 0.3572 - val_accuracy: 0.8455\n",
            "Epoch 436/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8280 - val_loss: 0.3571 - val_accuracy: 0.8450\n",
            "Epoch 437/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4090 - accuracy: 0.8137 - val_loss: 0.3572 - val_accuracy: 0.8460\n",
            "Epoch 438/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8203 - val_loss: 0.3572 - val_accuracy: 0.8460\n",
            "Epoch 439/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4029 - accuracy: 0.8133 - val_loss: 0.3569 - val_accuracy: 0.8460\n",
            "Epoch 440/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3997 - accuracy: 0.8140 - val_loss: 0.3569 - val_accuracy: 0.8460\n",
            "Epoch 441/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3993 - accuracy: 0.8150 - val_loss: 0.3571 - val_accuracy: 0.8420\n",
            "Epoch 442/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3983 - accuracy: 0.8187 - val_loss: 0.3572 - val_accuracy: 0.8450\n",
            "Epoch 443/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3953 - accuracy: 0.8167 - val_loss: 0.3570 - val_accuracy: 0.8450\n",
            "Epoch 444/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3929 - accuracy: 0.8233 - val_loss: 0.3572 - val_accuracy: 0.8465\n",
            "Epoch 445/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3941 - accuracy: 0.8233 - val_loss: 0.3569 - val_accuracy: 0.8450\n",
            "Epoch 446/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8183 - val_loss: 0.3567 - val_accuracy: 0.8435\n",
            "Epoch 447/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8193 - val_loss: 0.3568 - val_accuracy: 0.8455\n",
            "Epoch 448/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8163 - val_loss: 0.3568 - val_accuracy: 0.8430\n",
            "Epoch 449/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8157 - val_loss: 0.3568 - val_accuracy: 0.8445\n",
            "Epoch 450/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8217 - val_loss: 0.3570 - val_accuracy: 0.8445\n",
            "Epoch 451/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.8250 - val_loss: 0.3566 - val_accuracy: 0.8425\n",
            "Epoch 452/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8177 - val_loss: 0.3565 - val_accuracy: 0.8435\n",
            "Epoch 453/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8280 - val_loss: 0.3562 - val_accuracy: 0.8440\n",
            "Epoch 454/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3910 - accuracy: 0.8260 - val_loss: 0.3564 - val_accuracy: 0.8440\n",
            "Epoch 455/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8177 - val_loss: 0.3563 - val_accuracy: 0.8450\n",
            "Epoch 456/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4000 - accuracy: 0.8147 - val_loss: 0.3565 - val_accuracy: 0.8450\n",
            "Epoch 457/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8210 - val_loss: 0.3564 - val_accuracy: 0.8435\n",
            "Epoch 458/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4009 - accuracy: 0.8117 - val_loss: 0.3563 - val_accuracy: 0.8435\n",
            "Epoch 459/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8147 - val_loss: 0.3565 - val_accuracy: 0.8435\n",
            "Epoch 460/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8223 - val_loss: 0.3564 - val_accuracy: 0.8435\n",
            "Epoch 461/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.8210 - val_loss: 0.3566 - val_accuracy: 0.8450\n",
            "Epoch 462/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8180 - val_loss: 0.3564 - val_accuracy: 0.8440\n",
            "Epoch 463/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8180 - val_loss: 0.3561 - val_accuracy: 0.8435\n",
            "Epoch 464/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8180 - val_loss: 0.3559 - val_accuracy: 0.8445\n",
            "Epoch 465/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8200 - val_loss: 0.3563 - val_accuracy: 0.8440\n",
            "Epoch 466/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8193 - val_loss: 0.3564 - val_accuracy: 0.8450\n",
            "Epoch 467/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8170 - val_loss: 0.3562 - val_accuracy: 0.8445\n",
            "Epoch 468/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8183 - val_loss: 0.3560 - val_accuracy: 0.8440\n",
            "Epoch 469/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.8160 - val_loss: 0.3559 - val_accuracy: 0.8425\n",
            "Epoch 470/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8147 - val_loss: 0.3560 - val_accuracy: 0.8430\n",
            "Epoch 471/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8183 - val_loss: 0.3562 - val_accuracy: 0.8440\n",
            "Epoch 472/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8183 - val_loss: 0.3561 - val_accuracy: 0.8445\n",
            "Epoch 473/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3922 - accuracy: 0.8187 - val_loss: 0.3559 - val_accuracy: 0.8435\n",
            "Epoch 474/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8130 - val_loss: 0.3558 - val_accuracy: 0.8445\n",
            "Epoch 475/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8187 - val_loss: 0.3558 - val_accuracy: 0.8450\n",
            "Epoch 476/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8147 - val_loss: 0.3558 - val_accuracy: 0.8450\n",
            "Epoch 477/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.8283 - val_loss: 0.3557 - val_accuracy: 0.8450\n",
            "Epoch 478/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8180 - val_loss: 0.3559 - val_accuracy: 0.8460\n",
            "Epoch 479/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.8277 - val_loss: 0.3555 - val_accuracy: 0.8455\n",
            "Epoch 480/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8287 - val_loss: 0.3556 - val_accuracy: 0.8450\n",
            "Epoch 481/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8133 - val_loss: 0.3559 - val_accuracy: 0.8460\n",
            "Epoch 482/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8127 - val_loss: 0.3563 - val_accuracy: 0.8450\n",
            "Epoch 483/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8150 - val_loss: 0.3559 - val_accuracy: 0.8445\n",
            "Epoch 484/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8210 - val_loss: 0.3559 - val_accuracy: 0.8450\n",
            "Epoch 485/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8190 - val_loss: 0.3560 - val_accuracy: 0.8435\n",
            "Epoch 486/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8203 - val_loss: 0.3560 - val_accuracy: 0.8420\n",
            "Epoch 487/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8230 - val_loss: 0.3557 - val_accuracy: 0.8420\n",
            "Epoch 488/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8157 - val_loss: 0.3557 - val_accuracy: 0.8435\n",
            "Epoch 489/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8213 - val_loss: 0.3555 - val_accuracy: 0.8450\n",
            "Epoch 490/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8190 - val_loss: 0.3558 - val_accuracy: 0.8455\n",
            "Epoch 491/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8210 - val_loss: 0.3555 - val_accuracy: 0.8450\n",
            "Epoch 492/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.8187 - val_loss: 0.3552 - val_accuracy: 0.8435\n",
            "Epoch 493/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8197 - val_loss: 0.3551 - val_accuracy: 0.8475\n",
            "Epoch 494/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8237 - val_loss: 0.3552 - val_accuracy: 0.8455\n",
            "Epoch 495/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8193 - val_loss: 0.3551 - val_accuracy: 0.8450\n",
            "Epoch 496/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8213 - val_loss: 0.3551 - val_accuracy: 0.8450\n",
            "Epoch 497/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8197 - val_loss: 0.3554 - val_accuracy: 0.8455\n",
            "Epoch 498/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8243 - val_loss: 0.3552 - val_accuracy: 0.8445\n",
            "Epoch 499/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8157 - val_loss: 0.3549 - val_accuracy: 0.8465\n",
            "Epoch 500/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8230 - val_loss: 0.3552 - val_accuracy: 0.8435\n",
            "Epoch 501/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8183 - val_loss: 0.3553 - val_accuracy: 0.8455\n",
            "Epoch 502/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8213 - val_loss: 0.3549 - val_accuracy: 0.8445\n",
            "Epoch 503/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.8197 - val_loss: 0.3547 - val_accuracy: 0.8425\n",
            "Epoch 504/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8170 - val_loss: 0.3547 - val_accuracy: 0.8455\n",
            "Epoch 505/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8240 - val_loss: 0.3548 - val_accuracy: 0.8455\n",
            "Epoch 506/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8170 - val_loss: 0.3550 - val_accuracy: 0.8450\n",
            "Epoch 507/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8197 - val_loss: 0.3548 - val_accuracy: 0.8450\n",
            "Epoch 508/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8130 - val_loss: 0.3547 - val_accuracy: 0.8445\n",
            "Epoch 509/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.8190 - val_loss: 0.3544 - val_accuracy: 0.8450\n",
            "Epoch 510/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8260 - val_loss: 0.3546 - val_accuracy: 0.8455\n",
            "Epoch 511/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8240 - val_loss: 0.3546 - val_accuracy: 0.8465\n",
            "Epoch 512/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.8237 - val_loss: 0.3548 - val_accuracy: 0.8470\n",
            "Epoch 513/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3834 - accuracy: 0.8270 - val_loss: 0.3548 - val_accuracy: 0.8445\n",
            "Epoch 514/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8257 - val_loss: 0.3547 - val_accuracy: 0.8460\n",
            "Epoch 515/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3900 - accuracy: 0.8200 - val_loss: 0.3545 - val_accuracy: 0.8450\n",
            "Epoch 516/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8217 - val_loss: 0.3544 - val_accuracy: 0.8445\n",
            "Epoch 517/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8277 - val_loss: 0.3545 - val_accuracy: 0.8420\n",
            "Epoch 518/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8193 - val_loss: 0.3546 - val_accuracy: 0.8405\n",
            "Epoch 519/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3840 - accuracy: 0.8320 - val_loss: 0.3545 - val_accuracy: 0.8445\n",
            "Epoch 520/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.8243 - val_loss: 0.3545 - val_accuracy: 0.8465\n",
            "Epoch 521/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8200 - val_loss: 0.3545 - val_accuracy: 0.8470\n",
            "Epoch 522/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8280 - val_loss: 0.3543 - val_accuracy: 0.8445\n",
            "Epoch 523/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8257 - val_loss: 0.3541 - val_accuracy: 0.8455\n",
            "Epoch 524/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3914 - accuracy: 0.8187 - val_loss: 0.3540 - val_accuracy: 0.8450\n",
            "Epoch 525/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8210 - val_loss: 0.3541 - val_accuracy: 0.8440\n",
            "Epoch 526/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8187 - val_loss: 0.3539 - val_accuracy: 0.8455\n",
            "Epoch 527/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8200 - val_loss: 0.3539 - val_accuracy: 0.8480\n",
            "Epoch 528/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.8247 - val_loss: 0.3538 - val_accuracy: 0.8455\n",
            "Epoch 529/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8183 - val_loss: 0.3537 - val_accuracy: 0.8460\n",
            "Epoch 530/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8310 - val_loss: 0.3538 - val_accuracy: 0.8425\n",
            "Epoch 531/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8197 - val_loss: 0.3535 - val_accuracy: 0.8425\n",
            "Epoch 532/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8220 - val_loss: 0.3537 - val_accuracy: 0.8420\n",
            "Epoch 533/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8243 - val_loss: 0.3539 - val_accuracy: 0.8440\n",
            "Epoch 534/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8203 - val_loss: 0.3535 - val_accuracy: 0.8450\n",
            "Epoch 535/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.8190 - val_loss: 0.3534 - val_accuracy: 0.8445\n",
            "Epoch 536/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8227 - val_loss: 0.3537 - val_accuracy: 0.8445\n",
            "Epoch 537/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8217 - val_loss: 0.3534 - val_accuracy: 0.8450\n",
            "Epoch 538/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8233 - val_loss: 0.3534 - val_accuracy: 0.8435\n",
            "Epoch 539/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8170 - val_loss: 0.3532 - val_accuracy: 0.8460\n",
            "Epoch 540/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8200 - val_loss: 0.3533 - val_accuracy: 0.8470\n",
            "Epoch 541/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8203 - val_loss: 0.3535 - val_accuracy: 0.8455\n",
            "Epoch 542/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8257 - val_loss: 0.3535 - val_accuracy: 0.8445\n",
            "Epoch 543/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8210 - val_loss: 0.3534 - val_accuracy: 0.8455\n",
            "Epoch 544/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8187 - val_loss: 0.3532 - val_accuracy: 0.8440\n",
            "Epoch 545/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3869 - accuracy: 0.8260 - val_loss: 0.3532 - val_accuracy: 0.8430\n",
            "Epoch 546/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3897 - accuracy: 0.8213 - val_loss: 0.3530 - val_accuracy: 0.8490\n",
            "Epoch 547/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.8207 - val_loss: 0.3531 - val_accuracy: 0.8455\n",
            "Epoch 548/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.8187 - val_loss: 0.3530 - val_accuracy: 0.8425\n",
            "Epoch 549/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8263 - val_loss: 0.3530 - val_accuracy: 0.8445\n",
            "Epoch 550/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3924 - accuracy: 0.8270 - val_loss: 0.3532 - val_accuracy: 0.8455\n",
            "Epoch 551/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.8287 - val_loss: 0.3532 - val_accuracy: 0.8440\n",
            "Epoch 552/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8203 - val_loss: 0.3532 - val_accuracy: 0.8450\n",
            "Epoch 553/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8210 - val_loss: 0.3534 - val_accuracy: 0.8450\n",
            "Epoch 554/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3842 - accuracy: 0.8290 - val_loss: 0.3532 - val_accuracy: 0.8460\n",
            "Epoch 555/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3887 - accuracy: 0.8230 - val_loss: 0.3530 - val_accuracy: 0.8455\n",
            "Epoch 556/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8217 - val_loss: 0.3526 - val_accuracy: 0.8435\n",
            "Epoch 557/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8290 - val_loss: 0.3527 - val_accuracy: 0.8430\n",
            "Epoch 558/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8153 - val_loss: 0.3531 - val_accuracy: 0.8460\n",
            "Epoch 559/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8243 - val_loss: 0.3530 - val_accuracy: 0.8445\n",
            "Epoch 560/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8287 - val_loss: 0.3529 - val_accuracy: 0.8455\n",
            "Epoch 561/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8110 - val_loss: 0.3528 - val_accuracy: 0.8455\n",
            "Epoch 562/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.8203 - val_loss: 0.3533 - val_accuracy: 0.8430\n",
            "Epoch 563/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.8277 - val_loss: 0.3526 - val_accuracy: 0.8445\n",
            "Epoch 564/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8227 - val_loss: 0.3525 - val_accuracy: 0.8460\n",
            "Epoch 565/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8243 - val_loss: 0.3525 - val_accuracy: 0.8465\n",
            "Epoch 566/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8233 - val_loss: 0.3525 - val_accuracy: 0.8455\n",
            "Epoch 567/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8240 - val_loss: 0.3527 - val_accuracy: 0.8445\n",
            "Epoch 568/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8183 - val_loss: 0.3531 - val_accuracy: 0.8435\n",
            "Epoch 569/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.8243 - val_loss: 0.3527 - val_accuracy: 0.8430\n",
            "Epoch 570/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.8230 - val_loss: 0.3524 - val_accuracy: 0.8440\n",
            "Epoch 571/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8227 - val_loss: 0.3525 - val_accuracy: 0.8440\n",
            "Epoch 572/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8203 - val_loss: 0.3524 - val_accuracy: 0.8450\n",
            "Epoch 573/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3830 - accuracy: 0.8273 - val_loss: 0.3522 - val_accuracy: 0.8440\n",
            "Epoch 574/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8247 - val_loss: 0.3524 - val_accuracy: 0.8450\n",
            "Epoch 575/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8217 - val_loss: 0.3527 - val_accuracy: 0.8455\n",
            "Epoch 576/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8217 - val_loss: 0.3526 - val_accuracy: 0.8455\n",
            "Epoch 577/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3868 - accuracy: 0.8300 - val_loss: 0.3525 - val_accuracy: 0.8455\n",
            "Epoch 578/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8277 - val_loss: 0.3525 - val_accuracy: 0.8460\n",
            "Epoch 579/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.8237 - val_loss: 0.3526 - val_accuracy: 0.8450\n",
            "Epoch 580/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8237 - val_loss: 0.3523 - val_accuracy: 0.8465\n",
            "Epoch 581/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8213 - val_loss: 0.3525 - val_accuracy: 0.8460\n",
            "Epoch 582/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8210 - val_loss: 0.3527 - val_accuracy: 0.8455\n",
            "Epoch 583/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3848 - accuracy: 0.8293 - val_loss: 0.3525 - val_accuracy: 0.8435\n",
            "Epoch 584/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3922 - accuracy: 0.8243 - val_loss: 0.3522 - val_accuracy: 0.8445\n",
            "Epoch 585/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3870 - accuracy: 0.8237 - val_loss: 0.3522 - val_accuracy: 0.8450\n",
            "Epoch 586/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8233 - val_loss: 0.3521 - val_accuracy: 0.8465\n",
            "Epoch 587/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3910 - accuracy: 0.8207 - val_loss: 0.3526 - val_accuracy: 0.8455\n",
            "Epoch 588/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8193 - val_loss: 0.3526 - val_accuracy: 0.8445\n",
            "Epoch 589/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3869 - accuracy: 0.8250 - val_loss: 0.3525 - val_accuracy: 0.8445\n",
            "Epoch 590/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3966 - accuracy: 0.8150 - val_loss: 0.3524 - val_accuracy: 0.8465\n",
            "Epoch 591/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3981 - accuracy: 0.8150 - val_loss: 0.3521 - val_accuracy: 0.8430\n",
            "Epoch 592/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3882 - accuracy: 0.8183 - val_loss: 0.3520 - val_accuracy: 0.8470\n",
            "Epoch 593/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3827 - accuracy: 0.8313 - val_loss: 0.3524 - val_accuracy: 0.8450\n",
            "Epoch 594/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.8197 - val_loss: 0.3526 - val_accuracy: 0.8430\n",
            "Epoch 595/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3883 - accuracy: 0.8233 - val_loss: 0.3523 - val_accuracy: 0.8445\n",
            "Epoch 596/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.8180 - val_loss: 0.3527 - val_accuracy: 0.8455\n",
            "Epoch 597/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.8293 - val_loss: 0.3526 - val_accuracy: 0.8445\n",
            "Epoch 598/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.8257 - val_loss: 0.3521 - val_accuracy: 0.8460\n",
            "Epoch 599/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3914 - accuracy: 0.8200 - val_loss: 0.3521 - val_accuracy: 0.8460\n",
            "Epoch 600/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3893 - accuracy: 0.8220 - val_loss: 0.3522 - val_accuracy: 0.8445\n",
            "Epoch 601/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3869 - accuracy: 0.8277 - val_loss: 0.3520 - val_accuracy: 0.8450\n",
            "Epoch 602/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3885 - accuracy: 0.8233 - val_loss: 0.3518 - val_accuracy: 0.8465\n",
            "Epoch 603/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8250 - val_loss: 0.3521 - val_accuracy: 0.8445\n",
            "Epoch 604/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.8277 - val_loss: 0.3521 - val_accuracy: 0.8455\n",
            "Epoch 605/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3864 - accuracy: 0.8323 - val_loss: 0.3522 - val_accuracy: 0.8480\n",
            "Epoch 606/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3893 - accuracy: 0.8273 - val_loss: 0.3520 - val_accuracy: 0.8460\n",
            "Epoch 607/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3921 - accuracy: 0.8263 - val_loss: 0.3517 - val_accuracy: 0.8445\n",
            "Epoch 608/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3898 - accuracy: 0.8257 - val_loss: 0.3517 - val_accuracy: 0.8455\n",
            "Epoch 609/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3767 - accuracy: 0.8313 - val_loss: 0.3519 - val_accuracy: 0.8465\n",
            "Epoch 610/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8260 - val_loss: 0.3520 - val_accuracy: 0.8445\n",
            "Epoch 611/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8217 - val_loss: 0.3520 - val_accuracy: 0.8455\n",
            "Epoch 612/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3912 - accuracy: 0.8217 - val_loss: 0.3521 - val_accuracy: 0.8475\n",
            "Epoch 613/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8200 - val_loss: 0.3519 - val_accuracy: 0.8460\n",
            "Epoch 614/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8263 - val_loss: 0.3523 - val_accuracy: 0.8445\n",
            "Epoch 615/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3871 - accuracy: 0.8233 - val_loss: 0.3523 - val_accuracy: 0.8440\n",
            "Epoch 616/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8210 - val_loss: 0.3522 - val_accuracy: 0.8440\n",
            "Epoch 617/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3869 - accuracy: 0.8223 - val_loss: 0.3519 - val_accuracy: 0.8465\n",
            "Epoch 618/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8283 - val_loss: 0.3517 - val_accuracy: 0.8455\n",
            "Epoch 619/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3983 - accuracy: 0.8117 - val_loss: 0.3517 - val_accuracy: 0.8455\n",
            "Epoch 620/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8277 - val_loss: 0.3515 - val_accuracy: 0.8470\n",
            "Epoch 621/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3857 - accuracy: 0.8203 - val_loss: 0.3515 - val_accuracy: 0.8470\n",
            "Epoch 622/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8203 - val_loss: 0.3516 - val_accuracy: 0.8445\n",
            "Epoch 623/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.8273 - val_loss: 0.3518 - val_accuracy: 0.8440\n",
            "Epoch 624/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8230 - val_loss: 0.3517 - val_accuracy: 0.8470\n",
            "Epoch 625/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3874 - accuracy: 0.8227 - val_loss: 0.3519 - val_accuracy: 0.8470\n",
            "Epoch 626/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8253 - val_loss: 0.3520 - val_accuracy: 0.8460\n",
            "Epoch 627/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8223 - val_loss: 0.3518 - val_accuracy: 0.8455\n",
            "Epoch 628/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.8213 - val_loss: 0.3516 - val_accuracy: 0.8465\n",
            "Epoch 629/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3805 - accuracy: 0.8253 - val_loss: 0.3517 - val_accuracy: 0.8440\n",
            "Epoch 630/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.8300 - val_loss: 0.3517 - val_accuracy: 0.8470\n",
            "Epoch 631/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8240 - val_loss: 0.3518 - val_accuracy: 0.8480\n",
            "Epoch 632/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.8213 - val_loss: 0.3517 - val_accuracy: 0.8480\n",
            "Epoch 633/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8237 - val_loss: 0.3517 - val_accuracy: 0.8465\n",
            "Epoch 634/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.8260 - val_loss: 0.3517 - val_accuracy: 0.8475\n",
            "Epoch 635/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8240 - val_loss: 0.3517 - val_accuracy: 0.8470\n",
            "Epoch 636/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.8153 - val_loss: 0.3516 - val_accuracy: 0.8485\n",
            "Epoch 637/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8210 - val_loss: 0.3518 - val_accuracy: 0.8450\n",
            "Epoch 638/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3840 - accuracy: 0.8230 - val_loss: 0.3515 - val_accuracy: 0.8465\n",
            "Epoch 639/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8210 - val_loss: 0.3517 - val_accuracy: 0.8460\n",
            "Epoch 640/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3879 - accuracy: 0.8253 - val_loss: 0.3517 - val_accuracy: 0.8465\n",
            "Epoch 641/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3776 - accuracy: 0.8313 - val_loss: 0.3516 - val_accuracy: 0.8465\n",
            "Epoch 642/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.8307 - val_loss: 0.3515 - val_accuracy: 0.8470\n",
            "Epoch 643/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8200 - val_loss: 0.3513 - val_accuracy: 0.8475\n",
            "Epoch 644/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8223 - val_loss: 0.3517 - val_accuracy: 0.8440\n",
            "Epoch 645/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8200 - val_loss: 0.3516 - val_accuracy: 0.8450\n",
            "Epoch 646/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8170 - val_loss: 0.3514 - val_accuracy: 0.8460\n",
            "Epoch 647/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8287 - val_loss: 0.3514 - val_accuracy: 0.8450\n",
            "Epoch 648/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8217 - val_loss: 0.3513 - val_accuracy: 0.8475\n",
            "Epoch 649/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8190 - val_loss: 0.3512 - val_accuracy: 0.8465\n",
            "Epoch 650/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3918 - accuracy: 0.8223 - val_loss: 0.3512 - val_accuracy: 0.8450\n",
            "Epoch 651/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3888 - accuracy: 0.8250 - val_loss: 0.3513 - val_accuracy: 0.8445\n",
            "Epoch 652/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3868 - accuracy: 0.8257 - val_loss: 0.3515 - val_accuracy: 0.8450\n",
            "Epoch 653/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.8253 - val_loss: 0.3511 - val_accuracy: 0.8470\n",
            "Epoch 654/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8257 - val_loss: 0.3510 - val_accuracy: 0.8470\n",
            "Epoch 655/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8227 - val_loss: 0.3509 - val_accuracy: 0.8465\n",
            "Epoch 656/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3868 - accuracy: 0.8230 - val_loss: 0.3510 - val_accuracy: 0.8475\n",
            "Epoch 657/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.8260 - val_loss: 0.3508 - val_accuracy: 0.8445\n",
            "Epoch 658/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.8173 - val_loss: 0.3512 - val_accuracy: 0.8470\n",
            "Epoch 659/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8230 - val_loss: 0.3511 - val_accuracy: 0.8455\n",
            "Epoch 660/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3838 - accuracy: 0.8310 - val_loss: 0.3513 - val_accuracy: 0.8450\n",
            "Epoch 661/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8160 - val_loss: 0.3513 - val_accuracy: 0.8465\n",
            "Epoch 662/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.8283 - val_loss: 0.3511 - val_accuracy: 0.8440\n",
            "Epoch 663/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3836 - accuracy: 0.8247 - val_loss: 0.3510 - val_accuracy: 0.8455\n",
            "Epoch 664/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8213 - val_loss: 0.3510 - val_accuracy: 0.8475\n",
            "Epoch 665/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.8240 - val_loss: 0.3513 - val_accuracy: 0.8475\n",
            "Epoch 666/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3820 - accuracy: 0.8300 - val_loss: 0.3515 - val_accuracy: 0.8460\n",
            "Epoch 667/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.8317 - val_loss: 0.3513 - val_accuracy: 0.8480\n",
            "Epoch 668/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8310 - val_loss: 0.3514 - val_accuracy: 0.8465\n",
            "Epoch 669/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8243 - val_loss: 0.3510 - val_accuracy: 0.8470\n",
            "Epoch 670/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8217 - val_loss: 0.3512 - val_accuracy: 0.8465\n",
            "Epoch 671/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8217 - val_loss: 0.3512 - val_accuracy: 0.8460\n",
            "Epoch 672/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8220 - val_loss: 0.3511 - val_accuracy: 0.8465\n",
            "Epoch 673/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.8197 - val_loss: 0.3511 - val_accuracy: 0.8440\n",
            "Epoch 674/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8200 - val_loss: 0.3510 - val_accuracy: 0.8445\n",
            "Epoch 675/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8220 - val_loss: 0.3511 - val_accuracy: 0.8445\n",
            "Epoch 676/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8260 - val_loss: 0.3512 - val_accuracy: 0.8455\n",
            "Epoch 677/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8290 - val_loss: 0.3511 - val_accuracy: 0.8460\n",
            "Epoch 678/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.8263 - val_loss: 0.3511 - val_accuracy: 0.8455\n",
            "Epoch 679/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8207 - val_loss: 0.3511 - val_accuracy: 0.8450\n",
            "Epoch 680/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8247 - val_loss: 0.3510 - val_accuracy: 0.8460\n",
            "Epoch 681/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3839 - accuracy: 0.8297 - val_loss: 0.3511 - val_accuracy: 0.8465\n",
            "Epoch 682/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8163 - val_loss: 0.3513 - val_accuracy: 0.8440\n",
            "Epoch 683/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8227 - val_loss: 0.3511 - val_accuracy: 0.8445\n",
            "Epoch 684/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3868 - accuracy: 0.8247 - val_loss: 0.3511 - val_accuracy: 0.8460\n",
            "Epoch 685/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3894 - accuracy: 0.8240 - val_loss: 0.3510 - val_accuracy: 0.8445\n",
            "Epoch 686/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8277 - val_loss: 0.3509 - val_accuracy: 0.8450\n",
            "Epoch 687/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8240 - val_loss: 0.3509 - val_accuracy: 0.8460\n",
            "Epoch 688/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8193 - val_loss: 0.3511 - val_accuracy: 0.8460\n",
            "Epoch 689/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8147 - val_loss: 0.3510 - val_accuracy: 0.8460\n",
            "Epoch 690/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.8237 - val_loss: 0.3512 - val_accuracy: 0.8445\n",
            "Epoch 691/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3905 - accuracy: 0.8157 - val_loss: 0.3512 - val_accuracy: 0.8445\n",
            "Epoch 692/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8283 - val_loss: 0.3511 - val_accuracy: 0.8465\n",
            "Epoch 693/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.8273 - val_loss: 0.3506 - val_accuracy: 0.8450\n",
            "Epoch 694/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8190 - val_loss: 0.3505 - val_accuracy: 0.8460\n",
            "Epoch 695/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3835 - accuracy: 0.8237 - val_loss: 0.3507 - val_accuracy: 0.8455\n",
            "Epoch 696/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8200 - val_loss: 0.3507 - val_accuracy: 0.8465\n",
            "Epoch 697/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3859 - accuracy: 0.8260 - val_loss: 0.3507 - val_accuracy: 0.8460\n",
            "Epoch 698/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8260 - val_loss: 0.3507 - val_accuracy: 0.8455\n",
            "Epoch 699/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3873 - accuracy: 0.8277 - val_loss: 0.3507 - val_accuracy: 0.8465\n",
            "Epoch 700/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8283 - val_loss: 0.3505 - val_accuracy: 0.8450\n",
            "Epoch 701/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8217 - val_loss: 0.3507 - val_accuracy: 0.8450\n",
            "Epoch 702/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3805 - accuracy: 0.8277 - val_loss: 0.3506 - val_accuracy: 0.8455\n",
            "Epoch 703/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3879 - accuracy: 0.8243 - val_loss: 0.3509 - val_accuracy: 0.8460\n",
            "Epoch 704/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3852 - accuracy: 0.8233 - val_loss: 0.3507 - val_accuracy: 0.8470\n",
            "Epoch 705/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3877 - accuracy: 0.8240 - val_loss: 0.3509 - val_accuracy: 0.8460\n",
            "Epoch 706/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8223 - val_loss: 0.3506 - val_accuracy: 0.8445\n",
            "Epoch 707/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8237 - val_loss: 0.3507 - val_accuracy: 0.8455\n",
            "Epoch 708/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8203 - val_loss: 0.3506 - val_accuracy: 0.8435\n",
            "Epoch 709/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8227 - val_loss: 0.3505 - val_accuracy: 0.8450\n",
            "Epoch 710/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.8310 - val_loss: 0.3504 - val_accuracy: 0.8460\n",
            "Epoch 711/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3873 - accuracy: 0.8273 - val_loss: 0.3506 - val_accuracy: 0.8460\n",
            "Epoch 712/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8177 - val_loss: 0.3506 - val_accuracy: 0.8465\n",
            "Epoch 713/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3876 - accuracy: 0.8257 - val_loss: 0.3507 - val_accuracy: 0.8455\n",
            "Epoch 714/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8233 - val_loss: 0.3510 - val_accuracy: 0.8455\n",
            "Epoch 715/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3831 - accuracy: 0.8267 - val_loss: 0.3507 - val_accuracy: 0.8465\n",
            "Epoch 716/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3777 - accuracy: 0.8273 - val_loss: 0.3509 - val_accuracy: 0.8470\n",
            "Epoch 717/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8203 - val_loss: 0.3510 - val_accuracy: 0.8455\n",
            "Epoch 718/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8217 - val_loss: 0.3510 - val_accuracy: 0.8445\n",
            "Epoch 719/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3894 - accuracy: 0.8230 - val_loss: 0.3507 - val_accuracy: 0.8465\n",
            "Epoch 720/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3820 - accuracy: 0.8267 - val_loss: 0.3508 - val_accuracy: 0.8465\n",
            "Epoch 721/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3818 - accuracy: 0.8240 - val_loss: 0.3506 - val_accuracy: 0.8460\n",
            "Epoch 722/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8347 - val_loss: 0.3505 - val_accuracy: 0.8440\n",
            "Epoch 723/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8203 - val_loss: 0.3504 - val_accuracy: 0.8460\n",
            "Epoch 724/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8187 - val_loss: 0.3505 - val_accuracy: 0.8465\n",
            "Epoch 725/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.8250 - val_loss: 0.3507 - val_accuracy: 0.8470\n",
            "Epoch 726/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8180 - val_loss: 0.3510 - val_accuracy: 0.8475\n",
            "Epoch 727/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8217 - val_loss: 0.3509 - val_accuracy: 0.8475\n",
            "Epoch 728/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3879 - accuracy: 0.8227 - val_loss: 0.3506 - val_accuracy: 0.8470\n",
            "Epoch 729/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8263 - val_loss: 0.3506 - val_accuracy: 0.8445\n",
            "Epoch 730/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.8293 - val_loss: 0.3507 - val_accuracy: 0.8440\n",
            "Epoch 731/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.8240 - val_loss: 0.3504 - val_accuracy: 0.8460\n",
            "Epoch 732/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8200 - val_loss: 0.3504 - val_accuracy: 0.8455\n",
            "Epoch 733/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.8237 - val_loss: 0.3507 - val_accuracy: 0.8435\n",
            "Epoch 734/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8213 - val_loss: 0.3506 - val_accuracy: 0.8450\n",
            "Epoch 735/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.8253 - val_loss: 0.3505 - val_accuracy: 0.8450\n",
            "Epoch 736/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8217 - val_loss: 0.3504 - val_accuracy: 0.8455\n",
            "Epoch 737/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8300 - val_loss: 0.3506 - val_accuracy: 0.8460\n",
            "Epoch 738/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3935 - accuracy: 0.8173 - val_loss: 0.3510 - val_accuracy: 0.8460\n",
            "Epoch 739/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.8223 - val_loss: 0.3510 - val_accuracy: 0.8465\n",
            "Epoch 740/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8350 - val_loss: 0.3506 - val_accuracy: 0.8475\n",
            "Epoch 741/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8227 - val_loss: 0.3509 - val_accuracy: 0.8475\n",
            "Epoch 742/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8200 - val_loss: 0.3505 - val_accuracy: 0.8465\n",
            "Epoch 743/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.8280 - val_loss: 0.3503 - val_accuracy: 0.8470\n",
            "Epoch 744/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3826 - accuracy: 0.8287 - val_loss: 0.3500 - val_accuracy: 0.8445\n",
            "Epoch 745/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3874 - accuracy: 0.8310 - val_loss: 0.3500 - val_accuracy: 0.8440\n",
            "Epoch 746/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8207 - val_loss: 0.3506 - val_accuracy: 0.8455\n",
            "Epoch 747/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3900 - accuracy: 0.8240 - val_loss: 0.3503 - val_accuracy: 0.8455\n",
            "Epoch 748/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3870 - accuracy: 0.8223 - val_loss: 0.3505 - val_accuracy: 0.8455\n",
            "Epoch 749/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.8323 - val_loss: 0.3508 - val_accuracy: 0.8465\n",
            "Epoch 750/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3830 - accuracy: 0.8190 - val_loss: 0.3505 - val_accuracy: 0.8465\n",
            "Epoch 751/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3934 - accuracy: 0.8187 - val_loss: 0.3504 - val_accuracy: 0.8465\n",
            "Epoch 752/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3839 - accuracy: 0.8273 - val_loss: 0.3505 - val_accuracy: 0.8460\n",
            "Epoch 753/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3842 - accuracy: 0.8280 - val_loss: 0.3506 - val_accuracy: 0.8450\n",
            "Epoch 754/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3904 - accuracy: 0.8213 - val_loss: 0.3505 - val_accuracy: 0.8460\n",
            "Epoch 755/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3893 - accuracy: 0.8247 - val_loss: 0.3503 - val_accuracy: 0.8450\n",
            "Epoch 756/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3849 - accuracy: 0.8263 - val_loss: 0.3500 - val_accuracy: 0.8460\n",
            "Epoch 757/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3874 - accuracy: 0.8237 - val_loss: 0.3503 - val_accuracy: 0.8460\n",
            "Epoch 758/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3901 - accuracy: 0.8233 - val_loss: 0.3505 - val_accuracy: 0.8455\n",
            "Epoch 759/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3778 - accuracy: 0.8300 - val_loss: 0.3506 - val_accuracy: 0.8470\n",
            "Epoch 760/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3872 - accuracy: 0.8200 - val_loss: 0.3503 - val_accuracy: 0.8470\n",
            "Epoch 761/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3780 - accuracy: 0.8253 - val_loss: 0.3502 - val_accuracy: 0.8480\n",
            "Epoch 762/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8277 - val_loss: 0.3501 - val_accuracy: 0.8470\n",
            "Epoch 763/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3844 - accuracy: 0.8287 - val_loss: 0.3503 - val_accuracy: 0.8455\n",
            "Epoch 764/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3768 - accuracy: 0.8330 - val_loss: 0.3503 - val_accuracy: 0.8450\n",
            "Epoch 765/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3803 - accuracy: 0.8253 - val_loss: 0.3503 - val_accuracy: 0.8465\n",
            "Epoch 766/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3842 - accuracy: 0.8317 - val_loss: 0.3505 - val_accuracy: 0.8465\n",
            "Epoch 767/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3832 - accuracy: 0.8293 - val_loss: 0.3505 - val_accuracy: 0.8475\n",
            "Epoch 768/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3815 - accuracy: 0.8253 - val_loss: 0.3503 - val_accuracy: 0.8455\n",
            "Epoch 769/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3858 - accuracy: 0.8263 - val_loss: 0.3501 - val_accuracy: 0.8455\n",
            "Epoch 770/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8243 - val_loss: 0.3504 - val_accuracy: 0.8445\n",
            "Epoch 771/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3775 - accuracy: 0.8307 - val_loss: 0.3504 - val_accuracy: 0.8450\n",
            "Epoch 772/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8237 - val_loss: 0.3501 - val_accuracy: 0.8445\n",
            "Epoch 773/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.8247 - val_loss: 0.3501 - val_accuracy: 0.8440\n",
            "Epoch 774/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.8310 - val_loss: 0.3502 - val_accuracy: 0.8455\n",
            "Epoch 775/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3867 - accuracy: 0.8200 - val_loss: 0.3503 - val_accuracy: 0.8475\n",
            "Epoch 776/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8273 - val_loss: 0.3500 - val_accuracy: 0.8465\n",
            "Epoch 777/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.8250 - val_loss: 0.3500 - val_accuracy: 0.8470\n",
            "Epoch 778/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.8293 - val_loss: 0.3498 - val_accuracy: 0.8440\n",
            "Epoch 779/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3873 - accuracy: 0.8167 - val_loss: 0.3500 - val_accuracy: 0.8430\n",
            "Epoch 780/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.8287 - val_loss: 0.3501 - val_accuracy: 0.8435\n",
            "Epoch 781/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.8167 - val_loss: 0.3502 - val_accuracy: 0.8455\n",
            "Epoch 782/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3805 - accuracy: 0.8343 - val_loss: 0.3503 - val_accuracy: 0.8440\n",
            "Epoch 783/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8280 - val_loss: 0.3501 - val_accuracy: 0.8445\n",
            "Epoch 784/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8240 - val_loss: 0.3503 - val_accuracy: 0.8460\n",
            "Epoch 785/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3872 - accuracy: 0.8277 - val_loss: 0.3501 - val_accuracy: 0.8460\n",
            "Epoch 786/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.8313 - val_loss: 0.3502 - val_accuracy: 0.8460\n",
            "Epoch 787/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3831 - accuracy: 0.8250 - val_loss: 0.3507 - val_accuracy: 0.8445\n",
            "Epoch 788/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.8250 - val_loss: 0.3502 - val_accuracy: 0.8465\n",
            "Epoch 789/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.8223 - val_loss: 0.3498 - val_accuracy: 0.8465\n",
            "Epoch 790/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3892 - accuracy: 0.8270 - val_loss: 0.3500 - val_accuracy: 0.8445\n",
            "Epoch 791/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8320 - val_loss: 0.3504 - val_accuracy: 0.8430\n",
            "Epoch 792/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8220 - val_loss: 0.3502 - val_accuracy: 0.8435\n",
            "Epoch 793/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3823 - accuracy: 0.8180 - val_loss: 0.3500 - val_accuracy: 0.8445\n",
            "Epoch 794/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.8247 - val_loss: 0.3497 - val_accuracy: 0.8465\n",
            "Epoch 795/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.8253 - val_loss: 0.3500 - val_accuracy: 0.8445\n",
            "Epoch 796/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3828 - accuracy: 0.8233 - val_loss: 0.3499 - val_accuracy: 0.8430\n",
            "Epoch 797/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8247 - val_loss: 0.3497 - val_accuracy: 0.8455\n",
            "Epoch 798/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8247 - val_loss: 0.3500 - val_accuracy: 0.8455\n",
            "Epoch 799/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.8230 - val_loss: 0.3499 - val_accuracy: 0.8440\n",
            "Epoch 800/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8313 - val_loss: 0.3501 - val_accuracy: 0.8440\n",
            "Epoch 801/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8267 - val_loss: 0.3502 - val_accuracy: 0.8440\n",
            "Epoch 802/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3859 - accuracy: 0.8253 - val_loss: 0.3499 - val_accuracy: 0.8465\n",
            "Epoch 803/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8340 - val_loss: 0.3497 - val_accuracy: 0.8450\n",
            "Epoch 804/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3845 - accuracy: 0.8213 - val_loss: 0.3499 - val_accuracy: 0.8460\n",
            "Epoch 805/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8293 - val_loss: 0.3499 - val_accuracy: 0.8460\n",
            "Epoch 806/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8160 - val_loss: 0.3498 - val_accuracy: 0.8465\n",
            "Epoch 807/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8307 - val_loss: 0.3497 - val_accuracy: 0.8470\n",
            "Epoch 808/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3872 - accuracy: 0.8247 - val_loss: 0.3496 - val_accuracy: 0.8440\n",
            "Epoch 809/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8250 - val_loss: 0.3500 - val_accuracy: 0.8435\n",
            "Epoch 810/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8227 - val_loss: 0.3498 - val_accuracy: 0.8435\n",
            "Epoch 811/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8227 - val_loss: 0.3497 - val_accuracy: 0.8445\n",
            "Epoch 812/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8240 - val_loss: 0.3500 - val_accuracy: 0.8450\n",
            "Epoch 813/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8293 - val_loss: 0.3504 - val_accuracy: 0.8475\n",
            "Epoch 814/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3919 - accuracy: 0.8213 - val_loss: 0.3503 - val_accuracy: 0.8455\n",
            "Epoch 815/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8307 - val_loss: 0.3498 - val_accuracy: 0.8450\n",
            "Epoch 816/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.8330 - val_loss: 0.3498 - val_accuracy: 0.8440\n",
            "Epoch 817/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8260 - val_loss: 0.3500 - val_accuracy: 0.8465\n",
            "Epoch 818/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3898 - accuracy: 0.8247 - val_loss: 0.3500 - val_accuracy: 0.8465\n",
            "Epoch 819/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.8280 - val_loss: 0.3499 - val_accuracy: 0.8445\n",
            "Epoch 820/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3825 - accuracy: 0.8280 - val_loss: 0.3496 - val_accuracy: 0.8440\n",
            "Epoch 821/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3818 - accuracy: 0.8257 - val_loss: 0.3496 - val_accuracy: 0.8430\n",
            "Epoch 822/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8303 - val_loss: 0.3499 - val_accuracy: 0.8445\n",
            "Epoch 823/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3859 - accuracy: 0.8220 - val_loss: 0.3500 - val_accuracy: 0.8445\n",
            "Epoch 824/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3851 - accuracy: 0.8230 - val_loss: 0.3502 - val_accuracy: 0.8465\n",
            "Epoch 825/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8290 - val_loss: 0.3501 - val_accuracy: 0.8465\n",
            "Epoch 826/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3861 - accuracy: 0.8250 - val_loss: 0.3495 - val_accuracy: 0.8455\n",
            "Epoch 827/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3858 - accuracy: 0.8243 - val_loss: 0.3494 - val_accuracy: 0.8455\n",
            "Epoch 828/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3813 - accuracy: 0.8260 - val_loss: 0.3501 - val_accuracy: 0.8460\n",
            "Epoch 829/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8237 - val_loss: 0.3501 - val_accuracy: 0.8440\n",
            "Epoch 830/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8277 - val_loss: 0.3497 - val_accuracy: 0.8455\n",
            "Epoch 831/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3893 - accuracy: 0.8267 - val_loss: 0.3495 - val_accuracy: 0.8455\n",
            "Epoch 832/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3830 - accuracy: 0.8287 - val_loss: 0.3495 - val_accuracy: 0.8470\n",
            "Epoch 833/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8230 - val_loss: 0.3498 - val_accuracy: 0.8435\n",
            "Epoch 834/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3868 - accuracy: 0.8250 - val_loss: 0.3498 - val_accuracy: 0.8440\n",
            "Epoch 835/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.8247 - val_loss: 0.3497 - val_accuracy: 0.8440\n",
            "Epoch 836/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.8287 - val_loss: 0.3498 - val_accuracy: 0.8445\n",
            "Epoch 837/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3852 - accuracy: 0.8247 - val_loss: 0.3500 - val_accuracy: 0.8445\n",
            "Epoch 838/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.8297 - val_loss: 0.3503 - val_accuracy: 0.8440\n",
            "Epoch 839/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.8263 - val_loss: 0.3497 - val_accuracy: 0.8460\n",
            "Epoch 840/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3783 - accuracy: 0.8353 - val_loss: 0.3494 - val_accuracy: 0.8465\n",
            "Epoch 841/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.8313 - val_loss: 0.3495 - val_accuracy: 0.8460\n",
            "Epoch 842/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8263 - val_loss: 0.3496 - val_accuracy: 0.8465\n",
            "Epoch 843/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8307 - val_loss: 0.3498 - val_accuracy: 0.8450\n",
            "Epoch 844/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3806 - accuracy: 0.8260 - val_loss: 0.3500 - val_accuracy: 0.8440\n",
            "Epoch 845/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8247 - val_loss: 0.3499 - val_accuracy: 0.8455\n",
            "Epoch 846/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.8217 - val_loss: 0.3501 - val_accuracy: 0.8455\n",
            "Epoch 847/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3837 - accuracy: 0.8220 - val_loss: 0.3501 - val_accuracy: 0.8470\n",
            "Epoch 848/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3871 - accuracy: 0.8253 - val_loss: 0.3500 - val_accuracy: 0.8465\n",
            "Epoch 849/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3866 - accuracy: 0.8240 - val_loss: 0.3498 - val_accuracy: 0.8450\n",
            "Epoch 850/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3854 - accuracy: 0.8243 - val_loss: 0.3498 - val_accuracy: 0.8440\n",
            "Epoch 851/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3821 - accuracy: 0.8330 - val_loss: 0.3499 - val_accuracy: 0.8465\n",
            "Epoch 852/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.8307 - val_loss: 0.3498 - val_accuracy: 0.8460\n",
            "Epoch 853/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8257 - val_loss: 0.3501 - val_accuracy: 0.8450\n",
            "Epoch 854/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.8337 - val_loss: 0.3498 - val_accuracy: 0.8455\n",
            "Epoch 855/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8327 - val_loss: 0.3495 - val_accuracy: 0.8455\n",
            "Epoch 856/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8207 - val_loss: 0.3495 - val_accuracy: 0.8460\n",
            "Epoch 857/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3872 - accuracy: 0.8230 - val_loss: 0.3500 - val_accuracy: 0.8445\n",
            "Epoch 858/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8203 - val_loss: 0.3498 - val_accuracy: 0.8440\n",
            "Epoch 859/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3822 - accuracy: 0.8320 - val_loss: 0.3494 - val_accuracy: 0.8455\n",
            "Epoch 860/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.8273 - val_loss: 0.3497 - val_accuracy: 0.8460\n",
            "Epoch 861/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.8263 - val_loss: 0.3494 - val_accuracy: 0.8435\n",
            "Epoch 862/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3828 - accuracy: 0.8267 - val_loss: 0.3494 - val_accuracy: 0.8455\n",
            "Epoch 863/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3812 - accuracy: 0.8247 - val_loss: 0.3496 - val_accuracy: 0.8455\n",
            "Epoch 864/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.8293 - val_loss: 0.3497 - val_accuracy: 0.8470\n",
            "Epoch 865/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3814 - accuracy: 0.8253 - val_loss: 0.3495 - val_accuracy: 0.8470\n",
            "Epoch 866/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.8213 - val_loss: 0.3494 - val_accuracy: 0.8470\n",
            "Epoch 867/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.8237 - val_loss: 0.3497 - val_accuracy: 0.8470\n",
            "Epoch 868/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3871 - accuracy: 0.8230 - val_loss: 0.3495 - val_accuracy: 0.8455\n",
            "Epoch 869/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8293 - val_loss: 0.3496 - val_accuracy: 0.8470\n",
            "Epoch 870/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3875 - accuracy: 0.8243 - val_loss: 0.3497 - val_accuracy: 0.8470\n",
            "Epoch 871/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3816 - accuracy: 0.8330 - val_loss: 0.3497 - val_accuracy: 0.8460\n",
            "Epoch 872/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3833 - accuracy: 0.8220 - val_loss: 0.3494 - val_accuracy: 0.8460\n",
            "Epoch 873/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8290 - val_loss: 0.3492 - val_accuracy: 0.8450\n",
            "Epoch 874/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.8197 - val_loss: 0.3490 - val_accuracy: 0.8435\n",
            "Epoch 875/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.8193 - val_loss: 0.3494 - val_accuracy: 0.8440\n",
            "Epoch 876/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3841 - accuracy: 0.8287 - val_loss: 0.3495 - val_accuracy: 0.8445\n",
            "Epoch 877/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8300 - val_loss: 0.3495 - val_accuracy: 0.8440\n",
            "Epoch 878/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8237 - val_loss: 0.3496 - val_accuracy: 0.8460\n",
            "Epoch 879/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3830 - accuracy: 0.8303 - val_loss: 0.3494 - val_accuracy: 0.8465\n",
            "Epoch 880/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.8260 - val_loss: 0.3494 - val_accuracy: 0.8460\n",
            "Epoch 881/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3769 - accuracy: 0.8320 - val_loss: 0.3492 - val_accuracy: 0.8445\n",
            "Epoch 882/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3867 - accuracy: 0.8290 - val_loss: 0.3492 - val_accuracy: 0.8445\n",
            "Epoch 883/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3840 - accuracy: 0.8253 - val_loss: 0.3493 - val_accuracy: 0.8440\n",
            "Epoch 884/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3854 - accuracy: 0.8270 - val_loss: 0.3495 - val_accuracy: 0.8450\n",
            "Epoch 885/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.8253 - val_loss: 0.3494 - val_accuracy: 0.8455\n",
            "Epoch 886/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3825 - accuracy: 0.8300 - val_loss: 0.3493 - val_accuracy: 0.8475\n",
            "Epoch 887/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3842 - accuracy: 0.8287 - val_loss: 0.3492 - val_accuracy: 0.8450\n",
            "Epoch 888/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.8317 - val_loss: 0.3494 - val_accuracy: 0.8455\n",
            "Epoch 889/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3772 - accuracy: 0.8260 - val_loss: 0.3494 - val_accuracy: 0.8450\n",
            "Epoch 890/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8240 - val_loss: 0.3495 - val_accuracy: 0.8465\n",
            "Epoch 891/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.8310 - val_loss: 0.3495 - val_accuracy: 0.8465\n",
            "Epoch 892/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8293 - val_loss: 0.3495 - val_accuracy: 0.8465\n",
            "Epoch 893/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3776 - accuracy: 0.8283 - val_loss: 0.3498 - val_accuracy: 0.8465\n",
            "Epoch 894/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.8280 - val_loss: 0.3497 - val_accuracy: 0.8440\n",
            "Epoch 895/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3813 - accuracy: 0.8223 - val_loss: 0.3494 - val_accuracy: 0.8460\n",
            "Epoch 896/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3814 - accuracy: 0.8337 - val_loss: 0.3495 - val_accuracy: 0.8450\n",
            "Epoch 897/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.8273 - val_loss: 0.3497 - val_accuracy: 0.8475\n",
            "Epoch 898/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3831 - accuracy: 0.8247 - val_loss: 0.3496 - val_accuracy: 0.8465\n",
            "Epoch 899/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.8237 - val_loss: 0.3494 - val_accuracy: 0.8455\n",
            "Epoch 900/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.8260 - val_loss: 0.3496 - val_accuracy: 0.8455\n",
            "Epoch 901/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8210 - val_loss: 0.3494 - val_accuracy: 0.8445\n",
            "Epoch 902/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.8280 - val_loss: 0.3491 - val_accuracy: 0.8445\n",
            "Epoch 903/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3898 - accuracy: 0.8203 - val_loss: 0.3491 - val_accuracy: 0.8450\n",
            "Epoch 904/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3871 - accuracy: 0.8240 - val_loss: 0.3493 - val_accuracy: 0.8450\n",
            "Epoch 905/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3815 - accuracy: 0.8293 - val_loss: 0.3493 - val_accuracy: 0.8460\n",
            "Epoch 906/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.8240 - val_loss: 0.3493 - val_accuracy: 0.8465\n",
            "Epoch 907/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8230 - val_loss: 0.3494 - val_accuracy: 0.8470\n",
            "Epoch 908/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3843 - accuracy: 0.8253 - val_loss: 0.3493 - val_accuracy: 0.8450\n",
            "Epoch 909/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3873 - accuracy: 0.8217 - val_loss: 0.3492 - val_accuracy: 0.8445\n",
            "Epoch 910/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3793 - accuracy: 0.8280 - val_loss: 0.3488 - val_accuracy: 0.8445\n",
            "Epoch 911/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3824 - accuracy: 0.8280 - val_loss: 0.3488 - val_accuracy: 0.8435\n",
            "Epoch 912/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3861 - accuracy: 0.8237 - val_loss: 0.3492 - val_accuracy: 0.8450\n",
            "Epoch 913/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3809 - accuracy: 0.8327 - val_loss: 0.3491 - val_accuracy: 0.8450\n",
            "Epoch 914/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3912 - accuracy: 0.8240 - val_loss: 0.3491 - val_accuracy: 0.8445\n",
            "Epoch 915/2000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.3808 - accuracy: 0.8287 - val_loss: 0.3490 - val_accuracy: 0.8435\n",
            "Epoch 916/2000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3791 - accuracy: 0.8260 - val_loss: 0.3491 - val_accuracy: 0.8450\n",
            "Epoch 917/2000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.3853 - accuracy: 0.8303 - val_loss: 0.3491 - val_accuracy: 0.8465\n",
            "Epoch 918/2000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3770 - accuracy: 0.8340 - val_loss: 0.3492 - val_accuracy: 0.8465\n",
            "Epoch 919/2000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3806 - accuracy: 0.8330 - val_loss: 0.3489 - val_accuracy: 0.8450\n",
            "Epoch 920/2000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.3817 - accuracy: 0.8243 - val_loss: 0.3491 - val_accuracy: 0.8475\n",
            "Epoch 921/2000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3826 - accuracy: 0.8273 - val_loss: 0.3494 - val_accuracy: 0.8470\n",
            "Epoch 922/2000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.3814 - accuracy: 0.8280 - val_loss: 0.3492 - val_accuracy: 0.8470\n",
            "Epoch 923/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3764 - accuracy: 0.8303 - val_loss: 0.3492 - val_accuracy: 0.8470\n",
            "Epoch 924/2000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.3830 - accuracy: 0.8287 - val_loss: 0.3489 - val_accuracy: 0.8455\n",
            "Epoch 925/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3810 - accuracy: 0.8227 - val_loss: 0.3491 - val_accuracy: 0.8470\n",
            "Epoch 926/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3881 - accuracy: 0.8263 - val_loss: 0.3491 - val_accuracy: 0.8475\n",
            "Epoch 927/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3783 - accuracy: 0.8297 - val_loss: 0.3492 - val_accuracy: 0.8475\n",
            "Epoch 928/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3840 - accuracy: 0.8287 - val_loss: 0.3490 - val_accuracy: 0.8465\n",
            "Epoch 929/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3822 - accuracy: 0.8200 - val_loss: 0.3489 - val_accuracy: 0.8460\n",
            "Epoch 930/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3776 - accuracy: 0.8330 - val_loss: 0.3489 - val_accuracy: 0.8465\n",
            "Epoch 931/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3747 - accuracy: 0.8287 - val_loss: 0.3490 - val_accuracy: 0.8460\n",
            "Epoch 932/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3836 - accuracy: 0.8260 - val_loss: 0.3491 - val_accuracy: 0.8460\n",
            "Epoch 933/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.8223 - val_loss: 0.3493 - val_accuracy: 0.8470\n",
            "Epoch 934/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3780 - accuracy: 0.8303 - val_loss: 0.3490 - val_accuracy: 0.8445\n",
            "Epoch 935/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8177 - val_loss: 0.3490 - val_accuracy: 0.8450\n",
            "Epoch 936/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8273 - val_loss: 0.3489 - val_accuracy: 0.8450\n",
            "Epoch 937/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.8313 - val_loss: 0.3488 - val_accuracy: 0.8445\n",
            "Epoch 938/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3851 - accuracy: 0.8263 - val_loss: 0.3489 - val_accuracy: 0.8460\n",
            "Epoch 939/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3839 - accuracy: 0.8267 - val_loss: 0.3492 - val_accuracy: 0.8480\n",
            "Epoch 940/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3840 - accuracy: 0.8243 - val_loss: 0.3491 - val_accuracy: 0.8470\n",
            "Epoch 941/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8263 - val_loss: 0.3492 - val_accuracy: 0.8475\n",
            "Epoch 942/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3794 - accuracy: 0.8277 - val_loss: 0.3492 - val_accuracy: 0.8465\n",
            "Epoch 943/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3795 - accuracy: 0.8293 - val_loss: 0.3490 - val_accuracy: 0.8455\n",
            "Epoch 944/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8313 - val_loss: 0.3491 - val_accuracy: 0.8440\n",
            "Epoch 945/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8267 - val_loss: 0.3492 - val_accuracy: 0.8460\n",
            "Epoch 946/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.8217 - val_loss: 0.3493 - val_accuracy: 0.8465\n",
            "Epoch 947/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3876 - accuracy: 0.8227 - val_loss: 0.3491 - val_accuracy: 0.8475\n",
            "Epoch 948/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8323 - val_loss: 0.3489 - val_accuracy: 0.8450\n",
            "Epoch 949/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8287 - val_loss: 0.3485 - val_accuracy: 0.8445\n",
            "Epoch 950/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3791 - accuracy: 0.8283 - val_loss: 0.3490 - val_accuracy: 0.8435\n",
            "Epoch 951/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8310 - val_loss: 0.3494 - val_accuracy: 0.8460\n",
            "Epoch 952/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.8263 - val_loss: 0.3489 - val_accuracy: 0.8460\n",
            "Epoch 953/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3783 - accuracy: 0.8320 - val_loss: 0.3489 - val_accuracy: 0.8450\n",
            "Epoch 954/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3813 - accuracy: 0.8357 - val_loss: 0.3490 - val_accuracy: 0.8460\n",
            "Epoch 955/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3825 - accuracy: 0.8250 - val_loss: 0.3486 - val_accuracy: 0.8460\n",
            "Epoch 956/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8363 - val_loss: 0.3488 - val_accuracy: 0.8445\n",
            "Epoch 957/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3871 - accuracy: 0.8237 - val_loss: 0.3488 - val_accuracy: 0.8460\n",
            "Epoch 958/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3837 - accuracy: 0.8223 - val_loss: 0.3487 - val_accuracy: 0.8465\n",
            "Epoch 959/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3836 - accuracy: 0.8277 - val_loss: 0.3490 - val_accuracy: 0.8465\n",
            "Epoch 960/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.8257 - val_loss: 0.3494 - val_accuracy: 0.8460\n",
            "Epoch 961/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.8273 - val_loss: 0.3491 - val_accuracy: 0.8480\n",
            "Epoch 962/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3817 - accuracy: 0.8343 - val_loss: 0.3488 - val_accuracy: 0.8460\n",
            "Epoch 963/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.8317 - val_loss: 0.3488 - val_accuracy: 0.8465\n",
            "Epoch 964/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8357 - val_loss: 0.3489 - val_accuracy: 0.8465\n",
            "Epoch 965/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.8300 - val_loss: 0.3489 - val_accuracy: 0.8450\n",
            "Epoch 966/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.8303 - val_loss: 0.3487 - val_accuracy: 0.8450\n",
            "Epoch 967/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.8310 - val_loss: 0.3491 - val_accuracy: 0.8455\n",
            "Epoch 968/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3889 - accuracy: 0.8313 - val_loss: 0.3489 - val_accuracy: 0.8455\n",
            "Epoch 969/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3811 - accuracy: 0.8270 - val_loss: 0.3491 - val_accuracy: 0.8460\n",
            "Epoch 970/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.8287 - val_loss: 0.3493 - val_accuracy: 0.8465\n",
            "Epoch 971/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3876 - accuracy: 0.8260 - val_loss: 0.3495 - val_accuracy: 0.8465\n",
            "Epoch 972/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3839 - accuracy: 0.8270 - val_loss: 0.3493 - val_accuracy: 0.8465\n",
            "Epoch 973/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8293 - val_loss: 0.3486 - val_accuracy: 0.8445\n",
            "Epoch 974/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3811 - accuracy: 0.8267 - val_loss: 0.3486 - val_accuracy: 0.8445\n",
            "Epoch 975/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3766 - accuracy: 0.8337 - val_loss: 0.3487 - val_accuracy: 0.8460\n",
            "Epoch 976/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8327 - val_loss: 0.3488 - val_accuracy: 0.8465\n",
            "Epoch 977/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.8247 - val_loss: 0.3486 - val_accuracy: 0.8460\n",
            "Epoch 978/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3835 - accuracy: 0.8257 - val_loss: 0.3486 - val_accuracy: 0.8450\n",
            "Epoch 979/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.8260 - val_loss: 0.3487 - val_accuracy: 0.8450\n",
            "Epoch 980/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3750 - accuracy: 0.8270 - val_loss: 0.3486 - val_accuracy: 0.8455\n",
            "Epoch 981/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8307 - val_loss: 0.3485 - val_accuracy: 0.8465\n",
            "Epoch 982/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3901 - accuracy: 0.8203 - val_loss: 0.3490 - val_accuracy: 0.8465\n",
            "Epoch 983/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3828 - accuracy: 0.8230 - val_loss: 0.3493 - val_accuracy: 0.8450\n",
            "Epoch 984/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3773 - accuracy: 0.8350 - val_loss: 0.3492 - val_accuracy: 0.8460\n",
            "Epoch 985/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3800 - accuracy: 0.8280 - val_loss: 0.3488 - val_accuracy: 0.8435\n",
            "Epoch 986/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.8217 - val_loss: 0.3493 - val_accuracy: 0.8460\n",
            "Epoch 987/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8290 - val_loss: 0.3492 - val_accuracy: 0.8470\n",
            "Epoch 988/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3792 - accuracy: 0.8287 - val_loss: 0.3489 - val_accuracy: 0.8455\n",
            "Epoch 989/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8310 - val_loss: 0.3492 - val_accuracy: 0.8485\n",
            "Epoch 990/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8300 - val_loss: 0.3493 - val_accuracy: 0.8475\n",
            "Epoch 991/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3830 - accuracy: 0.8257 - val_loss: 0.3488 - val_accuracy: 0.8470\n",
            "Epoch 992/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3868 - accuracy: 0.8257 - val_loss: 0.3487 - val_accuracy: 0.8455\n",
            "Epoch 993/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3850 - accuracy: 0.8253 - val_loss: 0.3487 - val_accuracy: 0.8455\n",
            "Epoch 994/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3829 - accuracy: 0.8240 - val_loss: 0.3487 - val_accuracy: 0.8460\n",
            "Epoch 995/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3802 - accuracy: 0.8333 - val_loss: 0.3486 - val_accuracy: 0.8455\n",
            "Epoch 996/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3838 - accuracy: 0.8283 - val_loss: 0.3485 - val_accuracy: 0.8425\n",
            "Epoch 997/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8250 - val_loss: 0.3483 - val_accuracy: 0.8430\n",
            "Epoch 998/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3832 - accuracy: 0.8267 - val_loss: 0.3484 - val_accuracy: 0.8425\n",
            "Epoch 999/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.8300 - val_loss: 0.3485 - val_accuracy: 0.8445\n",
            "Epoch 1000/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3826 - accuracy: 0.8290 - val_loss: 0.3488 - val_accuracy: 0.8455\n",
            "Epoch 1001/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3827 - accuracy: 0.8277 - val_loss: 0.3487 - val_accuracy: 0.8460\n",
            "Epoch 1002/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8273 - val_loss: 0.3488 - val_accuracy: 0.8470\n",
            "Epoch 1003/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3804 - accuracy: 0.8267 - val_loss: 0.3489 - val_accuracy: 0.8460\n",
            "Epoch 1004/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8313 - val_loss: 0.3486 - val_accuracy: 0.8450\n",
            "Epoch 1005/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.8287 - val_loss: 0.3487 - val_accuracy: 0.8465\n",
            "Epoch 1006/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.8213 - val_loss: 0.3491 - val_accuracy: 0.8475\n",
            "Epoch 1007/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.8300 - val_loss: 0.3495 - val_accuracy: 0.8465\n",
            "Epoch 1008/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8217 - val_loss: 0.3493 - val_accuracy: 0.8460\n",
            "Epoch 1009/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.8273 - val_loss: 0.3491 - val_accuracy: 0.8465\n",
            "Epoch 1010/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.8313 - val_loss: 0.3486 - val_accuracy: 0.8450\n",
            "Epoch 1011/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3832 - accuracy: 0.8270 - val_loss: 0.3488 - val_accuracy: 0.8455\n",
            "Epoch 1012/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.8217 - val_loss: 0.3489 - val_accuracy: 0.8480\n",
            "Epoch 1013/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3775 - accuracy: 0.8307 - val_loss: 0.3487 - val_accuracy: 0.8465\n",
            "Epoch 1014/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.8297 - val_loss: 0.3489 - val_accuracy: 0.8465\n",
            "Epoch 1015/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8263 - val_loss: 0.3492 - val_accuracy: 0.8470\n",
            "Epoch 1016/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3841 - accuracy: 0.8250 - val_loss: 0.3490 - val_accuracy: 0.8465\n",
            "Epoch 1017/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3764 - accuracy: 0.8313 - val_loss: 0.3483 - val_accuracy: 0.8450\n",
            "Epoch 1018/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3871 - accuracy: 0.8237 - val_loss: 0.3484 - val_accuracy: 0.8445\n",
            "Epoch 1019/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.8263 - val_loss: 0.3490 - val_accuracy: 0.8445\n",
            "Epoch 1020/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3806 - accuracy: 0.8310 - val_loss: 0.3486 - val_accuracy: 0.8450\n",
            "Epoch 1021/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3827 - accuracy: 0.8303 - val_loss: 0.3487 - val_accuracy: 0.8465\n",
            "Epoch 1022/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3806 - accuracy: 0.8247 - val_loss: 0.3485 - val_accuracy: 0.8465\n",
            "Epoch 1023/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3763 - accuracy: 0.8347 - val_loss: 0.3486 - val_accuracy: 0.8480\n",
            "Epoch 1024/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3856 - accuracy: 0.8263 - val_loss: 0.3490 - val_accuracy: 0.8470\n",
            "Epoch 1025/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3810 - accuracy: 0.8280 - val_loss: 0.3491 - val_accuracy: 0.8470\n",
            "Epoch 1026/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3793 - accuracy: 0.8343 - val_loss: 0.3490 - val_accuracy: 0.8465\n",
            "Epoch 1027/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3881 - accuracy: 0.8207 - val_loss: 0.3486 - val_accuracy: 0.8460\n",
            "Epoch 1028/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.8340 - val_loss: 0.3488 - val_accuracy: 0.8465\n",
            "Epoch 1029/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.8293 - val_loss: 0.3489 - val_accuracy: 0.8465\n",
            "Epoch 1030/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.8273 - val_loss: 0.3488 - val_accuracy: 0.8470\n",
            "Epoch 1031/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3820 - accuracy: 0.8317 - val_loss: 0.3489 - val_accuracy: 0.8475\n",
            "Epoch 1032/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8297 - val_loss: 0.3491 - val_accuracy: 0.8450\n",
            "Epoch 1033/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3806 - accuracy: 0.8267 - val_loss: 0.3487 - val_accuracy: 0.8450\n",
            "Epoch 1034/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8347 - val_loss: 0.3486 - val_accuracy: 0.8465\n",
            "Epoch 1035/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3842 - accuracy: 0.8250 - val_loss: 0.3483 - val_accuracy: 0.8470\n",
            "Epoch 1036/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3785 - accuracy: 0.8283 - val_loss: 0.3485 - val_accuracy: 0.8465\n",
            "Epoch 1037/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3857 - accuracy: 0.8303 - val_loss: 0.3486 - val_accuracy: 0.8455\n",
            "Epoch 1038/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3785 - accuracy: 0.8277 - val_loss: 0.3486 - val_accuracy: 0.8455\n",
            "Epoch 1039/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3823 - accuracy: 0.8280 - val_loss: 0.3489 - val_accuracy: 0.8450\n",
            "Epoch 1040/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3820 - accuracy: 0.8350 - val_loss: 0.3488 - val_accuracy: 0.8470\n",
            "Epoch 1041/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3790 - accuracy: 0.8280 - val_loss: 0.3488 - val_accuracy: 0.8475\n",
            "Epoch 1042/2000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.3789 - accuracy: 0.8293 - val_loss: 0.3488 - val_accuracy: 0.8470\n",
            "Epoch 1043/2000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.3858 - accuracy: 0.8233 - val_loss: 0.3486 - val_accuracy: 0.8460\n",
            "Epoch 1044/2000\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.3818 - accuracy: 0.8303 - val_loss: 0.3486 - val_accuracy: 0.8480\n",
            "Epoch 1045/2000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3822 - accuracy: 0.8297 - val_loss: 0.3483 - val_accuracy: 0.8470\n",
            "Epoch 1046/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3786 - accuracy: 0.8303 - val_loss: 0.3485 - val_accuracy: 0.8480\n",
            "Epoch 1047/2000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3882 - accuracy: 0.8263 - val_loss: 0.3486 - val_accuracy: 0.8460\n",
            "Epoch 1048/2000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3846 - accuracy: 0.8300 - val_loss: 0.3487 - val_accuracy: 0.8465\n",
            "Epoch 1049/2000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3828 - accuracy: 0.8257 - val_loss: 0.3488 - val_accuracy: 0.8470\n",
            "Epoch 1050/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3801 - accuracy: 0.8287 - val_loss: 0.3490 - val_accuracy: 0.8475\n",
            "Epoch 1051/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3816 - accuracy: 0.8267 - val_loss: 0.3489 - val_accuracy: 0.8470\n",
            "Epoch 1052/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3784 - accuracy: 0.8273 - val_loss: 0.3489 - val_accuracy: 0.8470\n",
            "Epoch 1053/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3817 - accuracy: 0.8287 - val_loss: 0.3486 - val_accuracy: 0.8445\n",
            "Epoch 1054/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3810 - accuracy: 0.8270 - val_loss: 0.3486 - val_accuracy: 0.8460\n",
            "Epoch 1055/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3796 - accuracy: 0.8297 - val_loss: 0.3490 - val_accuracy: 0.8475\n",
            "Epoch 1056/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3800 - accuracy: 0.8297 - val_loss: 0.3489 - val_accuracy: 0.8490\n",
            "Epoch 1057/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3867 - accuracy: 0.8137 - val_loss: 0.3489 - val_accuracy: 0.8465\n",
            "Epoch 1058/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3732 - accuracy: 0.8370 - val_loss: 0.3490 - val_accuracy: 0.8485\n",
            "Epoch 1059/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.8243 - val_loss: 0.3494 - val_accuracy: 0.8490\n",
            "Epoch 1060/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8287 - val_loss: 0.3489 - val_accuracy: 0.8465\n",
            "Epoch 1061/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.8283 - val_loss: 0.3487 - val_accuracy: 0.8470\n",
            "Epoch 1062/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.8260 - val_loss: 0.3489 - val_accuracy: 0.8460\n",
            "Epoch 1063/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3835 - accuracy: 0.8257 - val_loss: 0.3487 - val_accuracy: 0.8455\n",
            "Epoch 1064/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3832 - accuracy: 0.8220 - val_loss: 0.3490 - val_accuracy: 0.8460\n",
            "Epoch 1065/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8300 - val_loss: 0.3488 - val_accuracy: 0.8455\n",
            "Epoch 1066/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.8270 - val_loss: 0.3485 - val_accuracy: 0.8460\n",
            "Epoch 1067/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.8293 - val_loss: 0.3485 - val_accuracy: 0.8475\n",
            "Epoch 1068/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.8353 - val_loss: 0.3486 - val_accuracy: 0.8470\n",
            "Epoch 1069/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.8287 - val_loss: 0.3485 - val_accuracy: 0.8465\n",
            "Epoch 1070/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8340 - val_loss: 0.3484 - val_accuracy: 0.8460\n",
            "Epoch 1071/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8350 - val_loss: 0.3486 - val_accuracy: 0.8450\n",
            "Epoch 1072/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8260 - val_loss: 0.3486 - val_accuracy: 0.8440\n",
            "Epoch 1073/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3803 - accuracy: 0.8310 - val_loss: 0.3486 - val_accuracy: 0.8460\n",
            "Epoch 1074/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.8277 - val_loss: 0.3487 - val_accuracy: 0.8450\n",
            "Epoch 1075/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3836 - accuracy: 0.8340 - val_loss: 0.3490 - val_accuracy: 0.8460\n",
            "Epoch 1076/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8253 - val_loss: 0.3491 - val_accuracy: 0.8470\n",
            "Epoch 1077/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3823 - accuracy: 0.8203 - val_loss: 0.3489 - val_accuracy: 0.8465\n",
            "Epoch 1078/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8247 - val_loss: 0.3487 - val_accuracy: 0.8465\n",
            "Epoch 1079/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3826 - accuracy: 0.8317 - val_loss: 0.3488 - val_accuracy: 0.8485\n",
            "Epoch 1080/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8380 - val_loss: 0.3487 - val_accuracy: 0.8450\n",
            "Epoch 1081/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.8270 - val_loss: 0.3488 - val_accuracy: 0.8465\n",
            "Epoch 1082/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3785 - accuracy: 0.8293 - val_loss: 0.3486 - val_accuracy: 0.8455\n",
            "Epoch 1083/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8267 - val_loss: 0.3486 - val_accuracy: 0.8445\n",
            "Epoch 1084/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.8300 - val_loss: 0.3488 - val_accuracy: 0.8440\n",
            "Epoch 1085/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3829 - accuracy: 0.8303 - val_loss: 0.3489 - val_accuracy: 0.8475\n",
            "Epoch 1086/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.8277 - val_loss: 0.3489 - val_accuracy: 0.8460\n",
            "Epoch 1087/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8300 - val_loss: 0.3489 - val_accuracy: 0.8475\n",
            "Epoch 1088/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.8253 - val_loss: 0.3488 - val_accuracy: 0.8475\n",
            "Epoch 1089/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8267 - val_loss: 0.3488 - val_accuracy: 0.8475\n",
            "Epoch 1090/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8297 - val_loss: 0.3487 - val_accuracy: 0.8460\n",
            "Epoch 1091/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8300 - val_loss: 0.3487 - val_accuracy: 0.8440\n",
            "Epoch 1092/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.8273 - val_loss: 0.3488 - val_accuracy: 0.8465\n",
            "Epoch 1093/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.8197 - val_loss: 0.3489 - val_accuracy: 0.8460\n",
            "Epoch 1094/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.8243 - val_loss: 0.3487 - val_accuracy: 0.8460\n",
            "Epoch 1095/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8320 - val_loss: 0.3485 - val_accuracy: 0.8445\n",
            "Epoch 1096/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3809 - accuracy: 0.8303 - val_loss: 0.3487 - val_accuracy: 0.8445\n",
            "Epoch 1097/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.8277 - val_loss: 0.3490 - val_accuracy: 0.8470\n",
            "Epoch 1098/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3832 - accuracy: 0.8267 - val_loss: 0.3488 - val_accuracy: 0.8445\n",
            "Epoch 1099/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3755 - accuracy: 0.8270 - val_loss: 0.3486 - val_accuracy: 0.8450\n",
            "Epoch 1100/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3755 - accuracy: 0.8337 - val_loss: 0.3490 - val_accuracy: 0.8450\n",
            "Epoch 1101/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3780 - accuracy: 0.8343 - val_loss: 0.3488 - val_accuracy: 0.8455\n",
            "Epoch 1102/2000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3781 - accuracy: 0.8273 - val_loss: 0.3488 - val_accuracy: 0.8450\n",
            "Epoch 1103/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3827 - accuracy: 0.8270 - val_loss: 0.3489 - val_accuracy: 0.8455\n",
            "Epoch 1104/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3742 - accuracy: 0.8340 - val_loss: 0.3490 - val_accuracy: 0.8480\n",
            "Epoch 1105/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3724 - accuracy: 0.8247 - val_loss: 0.3488 - val_accuracy: 0.8455\n",
            "Epoch 1106/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3864 - accuracy: 0.8267 - val_loss: 0.3487 - val_accuracy: 0.8445\n",
            "Epoch 1107/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3846 - accuracy: 0.8273 - val_loss: 0.3489 - val_accuracy: 0.8450\n",
            "Epoch 1108/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3747 - accuracy: 0.8300 - val_loss: 0.3488 - val_accuracy: 0.8450\n",
            "Epoch 1109/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3782 - accuracy: 0.8280 - val_loss: 0.3489 - val_accuracy: 0.8460\n",
            "Epoch 1110/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3788 - accuracy: 0.8297 - val_loss: 0.3485 - val_accuracy: 0.8450\n",
            "Epoch 1111/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3767 - accuracy: 0.8353 - val_loss: 0.3487 - val_accuracy: 0.8465\n",
            "Epoch 1112/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.8303 - val_loss: 0.3488 - val_accuracy: 0.8475\n",
            "Epoch 1113/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3798 - accuracy: 0.8247 - val_loss: 0.3489 - val_accuracy: 0.8475\n",
            "Epoch 1114/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3901 - accuracy: 0.8240 - val_loss: 0.3487 - val_accuracy: 0.8470\n",
            "Epoch 1115/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.8253 - val_loss: 0.3485 - val_accuracy: 0.8460\n",
            "Epoch 1116/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8353 - val_loss: 0.3484 - val_accuracy: 0.8440\n",
            "Epoch 1117/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3830 - accuracy: 0.8263 - val_loss: 0.3484 - val_accuracy: 0.8445\n",
            "Epoch 1118/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.8247 - val_loss: 0.3484 - val_accuracy: 0.8445\n",
            "Epoch 1119/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3788 - accuracy: 0.8310 - val_loss: 0.3486 - val_accuracy: 0.8460\n",
            "Epoch 1120/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.8293 - val_loss: 0.3488 - val_accuracy: 0.8470\n",
            "Epoch 1121/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3842 - accuracy: 0.8257 - val_loss: 0.3486 - val_accuracy: 0.8450\n",
            "Epoch 1122/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3763 - accuracy: 0.8287 - val_loss: 0.3487 - val_accuracy: 0.8470\n",
            "Epoch 1123/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3757 - accuracy: 0.8330 - val_loss: 0.3489 - val_accuracy: 0.8485\n",
            "Epoch 1124/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.8297 - val_loss: 0.3485 - val_accuracy: 0.8475\n",
            "Epoch 1125/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8317 - val_loss: 0.3483 - val_accuracy: 0.8450\n",
            "Epoch 1126/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8303 - val_loss: 0.3486 - val_accuracy: 0.8465\n",
            "Epoch 1127/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.8290 - val_loss: 0.3488 - val_accuracy: 0.8460\n",
            "Epoch 1128/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.8250 - val_loss: 0.3488 - val_accuracy: 0.8460\n",
            "Epoch 1129/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3834 - accuracy: 0.8277 - val_loss: 0.3487 - val_accuracy: 0.8475\n",
            "Epoch 1130/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3804 - accuracy: 0.8237 - val_loss: 0.3484 - val_accuracy: 0.8470\n",
            "Epoch 1131/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8287 - val_loss: 0.3487 - val_accuracy: 0.8475\n",
            "Epoch 1132/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.8307 - val_loss: 0.3487 - val_accuracy: 0.8450\n",
            "Epoch 1133/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3826 - accuracy: 0.8270 - val_loss: 0.3488 - val_accuracy: 0.8450\n",
            "Epoch 1134/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3761 - accuracy: 0.8297 - val_loss: 0.3486 - val_accuracy: 0.8450\n",
            "Epoch 1135/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8317 - val_loss: 0.3487 - val_accuracy: 0.8460\n",
            "Epoch 1136/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8323 - val_loss: 0.3488 - val_accuracy: 0.8470\n",
            "Epoch 1137/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3715 - accuracy: 0.8240 - val_loss: 0.3487 - val_accuracy: 0.8450\n",
            "Epoch 1138/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8230 - val_loss: 0.3486 - val_accuracy: 0.8450\n",
            "Epoch 1139/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3782 - accuracy: 0.8220 - val_loss: 0.3484 - val_accuracy: 0.8460\n",
            "Epoch 1140/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.8273 - val_loss: 0.3485 - val_accuracy: 0.8455\n",
            "Epoch 1141/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8323 - val_loss: 0.3485 - val_accuracy: 0.8460\n",
            "Epoch 1142/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3846 - accuracy: 0.8223 - val_loss: 0.3486 - val_accuracy: 0.8455\n",
            "Epoch 1143/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.8287 - val_loss: 0.3487 - val_accuracy: 0.8470\n",
            "Epoch 1144/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8230 - val_loss: 0.3491 - val_accuracy: 0.8470\n",
            "Epoch 1145/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8260 - val_loss: 0.3489 - val_accuracy: 0.8465\n",
            "Epoch 1146/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8263 - val_loss: 0.3487 - val_accuracy: 0.8470\n",
            "Epoch 1147/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3802 - accuracy: 0.8277 - val_loss: 0.3489 - val_accuracy: 0.8465\n",
            "Epoch 1148/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3782 - accuracy: 0.8277 - val_loss: 0.3489 - val_accuracy: 0.8470\n",
            "Epoch 1149/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.8260 - val_loss: 0.3488 - val_accuracy: 0.8460\n",
            "Epoch 1150/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3775 - accuracy: 0.8293 - val_loss: 0.3489 - val_accuracy: 0.8450\n",
            "Epoch 1151/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.8293 - val_loss: 0.3487 - val_accuracy: 0.8450\n",
            "Epoch 1152/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3840 - accuracy: 0.8280 - val_loss: 0.3490 - val_accuracy: 0.8470\n",
            "Epoch 1153/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.8307 - val_loss: 0.3488 - val_accuracy: 0.8470\n",
            "Epoch 1154/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3753 - accuracy: 0.8257 - val_loss: 0.3485 - val_accuracy: 0.8480\n",
            "Epoch 1155/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3811 - accuracy: 0.8260 - val_loss: 0.3484 - val_accuracy: 0.8450\n",
            "Epoch 1156/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3778 - accuracy: 0.8293 - val_loss: 0.3490 - val_accuracy: 0.8480\n",
            "Epoch 1157/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8260 - val_loss: 0.3492 - val_accuracy: 0.8465\n",
            "Epoch 1158/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.8270 - val_loss: 0.3486 - val_accuracy: 0.8440\n",
            "Epoch 1159/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.8180 - val_loss: 0.3487 - val_accuracy: 0.8450\n",
            "Epoch 1160/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3762 - accuracy: 0.8293 - val_loss: 0.3487 - val_accuracy: 0.8460\n",
            "Epoch 1161/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.8317 - val_loss: 0.3489 - val_accuracy: 0.8470\n",
            "Epoch 1162/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.8350 - val_loss: 0.3492 - val_accuracy: 0.8455\n",
            "Epoch 1163/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.8333 - val_loss: 0.3489 - val_accuracy: 0.8465\n",
            "Epoch 1164/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8307 - val_loss: 0.3488 - val_accuracy: 0.8455\n",
            "Epoch 1165/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3714 - accuracy: 0.8390 - val_loss: 0.3487 - val_accuracy: 0.8450\n",
            "Epoch 1166/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8347 - val_loss: 0.3486 - val_accuracy: 0.8445\n",
            "Epoch 1167/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3798 - accuracy: 0.8310 - val_loss: 0.3486 - val_accuracy: 0.8455\n",
            "Epoch 1168/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3788 - accuracy: 0.8343 - val_loss: 0.3486 - val_accuracy: 0.8465\n",
            "Epoch 1169/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.8277 - val_loss: 0.3486 - val_accuracy: 0.8470\n",
            "Epoch 1170/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.8273 - val_loss: 0.3488 - val_accuracy: 0.8475\n",
            "Epoch 1171/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8243 - val_loss: 0.3486 - val_accuracy: 0.8470\n",
            "Epoch 1172/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.8287 - val_loss: 0.3487 - val_accuracy: 0.8450\n",
            "Epoch 1173/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.8317 - val_loss: 0.3486 - val_accuracy: 0.8480\n",
            "Epoch 1174/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3813 - accuracy: 0.8290 - val_loss: 0.3488 - val_accuracy: 0.8470\n",
            "Epoch 1175/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.8303 - val_loss: 0.3493 - val_accuracy: 0.8460\n",
            "Epoch 1176/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8357 - val_loss: 0.3493 - val_accuracy: 0.8450\n",
            "Epoch 1177/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.8300 - val_loss: 0.3489 - val_accuracy: 0.8460\n",
            "Epoch 1178/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3761 - accuracy: 0.8297 - val_loss: 0.3485 - val_accuracy: 0.8460\n",
            "Epoch 1179/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3780 - accuracy: 0.8287 - val_loss: 0.3483 - val_accuracy: 0.8455\n",
            "Epoch 1180/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3779 - accuracy: 0.8280 - val_loss: 0.3482 - val_accuracy: 0.8450\n",
            "Epoch 1181/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3789 - accuracy: 0.8267 - val_loss: 0.3483 - val_accuracy: 0.8450\n",
            "Epoch 1182/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3817 - accuracy: 0.8263 - val_loss: 0.3487 - val_accuracy: 0.8475\n",
            "Epoch 1183/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3823 - accuracy: 0.8293 - val_loss: 0.3486 - val_accuracy: 0.8465\n",
            "Epoch 1184/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3865 - accuracy: 0.8273 - val_loss: 0.3488 - val_accuracy: 0.8455\n",
            "Epoch 1185/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3824 - accuracy: 0.8320 - val_loss: 0.3488 - val_accuracy: 0.8460\n",
            "Epoch 1186/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3830 - accuracy: 0.8323 - val_loss: 0.3487 - val_accuracy: 0.8460\n",
            "Epoch 1187/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3808 - accuracy: 0.8233 - val_loss: 0.3482 - val_accuracy: 0.8445\n",
            "Epoch 1188/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3805 - accuracy: 0.8327 - val_loss: 0.3485 - val_accuracy: 0.8460\n",
            "Epoch 1189/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3767 - accuracy: 0.8303 - val_loss: 0.3486 - val_accuracy: 0.8475\n",
            "Epoch 1190/2000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3811 - accuracy: 0.8313 - val_loss: 0.3483 - val_accuracy: 0.8450\n",
            "Epoch 1191/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3859 - accuracy: 0.8217 - val_loss: 0.3485 - val_accuracy: 0.8460\n",
            "Epoch 1192/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3749 - accuracy: 0.8353 - val_loss: 0.3485 - val_accuracy: 0.8445\n",
            "Epoch 1193/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3753 - accuracy: 0.8307 - val_loss: 0.3486 - val_accuracy: 0.8475\n",
            "Epoch 1194/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3769 - accuracy: 0.8333 - val_loss: 0.3483 - val_accuracy: 0.8460\n",
            "Epoch 1195/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8313 - val_loss: 0.3485 - val_accuracy: 0.8455\n",
            "Epoch 1196/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3730 - accuracy: 0.8273 - val_loss: 0.3489 - val_accuracy: 0.8480\n",
            "Epoch 1197/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3744 - accuracy: 0.8297 - val_loss: 0.3487 - val_accuracy: 0.8475\n",
            "Epoch 1198/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3776 - accuracy: 0.8287 - val_loss: 0.3487 - val_accuracy: 0.8475\n",
            "Epoch 1199/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3774 - accuracy: 0.8320 - val_loss: 0.3487 - val_accuracy: 0.8470\n",
            "Epoch 1200/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3821 - accuracy: 0.8247 - val_loss: 0.3487 - val_accuracy: 0.8465\n",
            "Epoch 1201/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3778 - accuracy: 0.8287 - val_loss: 0.3486 - val_accuracy: 0.8470\n",
            "Epoch 1202/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3755 - accuracy: 0.8287 - val_loss: 0.3483 - val_accuracy: 0.8455\n",
            "Epoch 1203/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3794 - accuracy: 0.8257 - val_loss: 0.3482 - val_accuracy: 0.8460\n",
            "Epoch 1204/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3742 - accuracy: 0.8313 - val_loss: 0.3485 - val_accuracy: 0.8485\n",
            "Epoch 1205/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3747 - accuracy: 0.8343 - val_loss: 0.3485 - val_accuracy: 0.8450\n",
            "Epoch 1206/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8283 - val_loss: 0.3484 - val_accuracy: 0.8460\n",
            "Epoch 1207/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8297 - val_loss: 0.3488 - val_accuracy: 0.8480\n",
            "Epoch 1208/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8270 - val_loss: 0.3484 - val_accuracy: 0.8475\n",
            "Epoch 1209/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3830 - accuracy: 0.8243 - val_loss: 0.3487 - val_accuracy: 0.8485\n",
            "Epoch 1210/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3801 - accuracy: 0.8300 - val_loss: 0.3487 - val_accuracy: 0.8480\n",
            "Epoch 1211/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3737 - accuracy: 0.8340 - val_loss: 0.3485 - val_accuracy: 0.8470\n",
            "Epoch 1212/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.8283 - val_loss: 0.3486 - val_accuracy: 0.8460\n",
            "Epoch 1213/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.8273 - val_loss: 0.3483 - val_accuracy: 0.8465\n",
            "Epoch 1214/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3799 - accuracy: 0.8317 - val_loss: 0.3483 - val_accuracy: 0.8445\n",
            "Epoch 1215/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.8327 - val_loss: 0.3486 - val_accuracy: 0.8450\n",
            "Epoch 1216/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3791 - accuracy: 0.8313 - val_loss: 0.3486 - val_accuracy: 0.8465\n",
            "Epoch 1217/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8293 - val_loss: 0.3484 - val_accuracy: 0.8455\n",
            "Epoch 1218/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3815 - accuracy: 0.8267 - val_loss: 0.3487 - val_accuracy: 0.8490\n",
            "Epoch 1219/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.8327 - val_loss: 0.3485 - val_accuracy: 0.8465\n",
            "Epoch 1220/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3830 - accuracy: 0.8270 - val_loss: 0.3485 - val_accuracy: 0.8445\n",
            "Epoch 1221/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8317 - val_loss: 0.3488 - val_accuracy: 0.8460\n",
            "Epoch 1222/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3802 - accuracy: 0.8257 - val_loss: 0.3489 - val_accuracy: 0.8475\n",
            "Epoch 1223/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3724 - accuracy: 0.8320 - val_loss: 0.3485 - val_accuracy: 0.8475\n",
            "Epoch 1224/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8303 - val_loss: 0.3482 - val_accuracy: 0.8455\n",
            "Epoch 1225/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3778 - accuracy: 0.8283 - val_loss: 0.3485 - val_accuracy: 0.8455\n",
            "Epoch 1226/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8267 - val_loss: 0.3485 - val_accuracy: 0.8455\n",
            "Epoch 1227/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3816 - accuracy: 0.8297 - val_loss: 0.3483 - val_accuracy: 0.8450\n",
            "Epoch 1228/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8247 - val_loss: 0.3486 - val_accuracy: 0.8480\n",
            "Epoch 1229/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.8267 - val_loss: 0.3482 - val_accuracy: 0.8460\n",
            "Epoch 1230/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8283 - val_loss: 0.3480 - val_accuracy: 0.8460\n",
            "Epoch 1231/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8343 - val_loss: 0.3480 - val_accuracy: 0.8465\n",
            "Epoch 1232/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3789 - accuracy: 0.8280 - val_loss: 0.3482 - val_accuracy: 0.8470\n",
            "Epoch 1233/2000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3802 - accuracy: 0.8260 - val_loss: 0.3486 - val_accuracy: 0.8480\n",
            "Epoch 1234/2000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3791 - accuracy: 0.8273 - val_loss: 0.3485 - val_accuracy: 0.8460\n",
            "Epoch 1235/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8257 - val_loss: 0.3486 - val_accuracy: 0.8480\n",
            "Epoch 1236/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3785 - accuracy: 0.8320 - val_loss: 0.3484 - val_accuracy: 0.8460\n",
            "Epoch 1237/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8347 - val_loss: 0.3487 - val_accuracy: 0.8455\n",
            "Epoch 1238/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.8347 - val_loss: 0.3490 - val_accuracy: 0.8475\n",
            "Epoch 1239/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3771 - accuracy: 0.8340 - val_loss: 0.3488 - val_accuracy: 0.8470\n",
            "Epoch 1240/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.8283 - val_loss: 0.3486 - val_accuracy: 0.8485\n",
            "Epoch 1241/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.8307 - val_loss: 0.3482 - val_accuracy: 0.8480\n",
            "Epoch 1242/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8300 - val_loss: 0.3486 - val_accuracy: 0.8480\n",
            "Epoch 1243/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8317 - val_loss: 0.3484 - val_accuracy: 0.8460\n",
            "Epoch 1244/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8310 - val_loss: 0.3488 - val_accuracy: 0.8465\n",
            "Epoch 1245/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.8310 - val_loss: 0.3488 - val_accuracy: 0.8475\n",
            "Epoch 1246/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.8283 - val_loss: 0.3485 - val_accuracy: 0.8485\n",
            "Epoch 1247/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8267 - val_loss: 0.3483 - val_accuracy: 0.8465\n",
            "Epoch 1248/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3867 - accuracy: 0.8233 - val_loss: 0.3482 - val_accuracy: 0.8465\n",
            "Epoch 1249/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.8210 - val_loss: 0.3486 - val_accuracy: 0.8455\n",
            "Epoch 1250/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3722 - accuracy: 0.8403 - val_loss: 0.3485 - val_accuracy: 0.8475\n",
            "Epoch 1251/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3857 - accuracy: 0.8300 - val_loss: 0.3486 - val_accuracy: 0.8465\n",
            "Epoch 1252/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.8353 - val_loss: 0.3485 - val_accuracy: 0.8480\n",
            "Epoch 1253/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.8323 - val_loss: 0.3488 - val_accuracy: 0.8485\n",
            "Epoch 1254/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.8297 - val_loss: 0.3485 - val_accuracy: 0.8460\n",
            "Epoch 1255/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8240 - val_loss: 0.3483 - val_accuracy: 0.8455\n",
            "Epoch 1256/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.8273 - val_loss: 0.3482 - val_accuracy: 0.8450\n",
            "Epoch 1257/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.8350 - val_loss: 0.3484 - val_accuracy: 0.8455\n",
            "Epoch 1258/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.8327 - val_loss: 0.3484 - val_accuracy: 0.8460\n",
            "Epoch 1259/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3773 - accuracy: 0.8330 - val_loss: 0.3485 - val_accuracy: 0.8455\n",
            "Epoch 1260/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8317 - val_loss: 0.3486 - val_accuracy: 0.8455\n",
            "Epoch 1261/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3835 - accuracy: 0.8273 - val_loss: 0.3489 - val_accuracy: 0.8465\n",
            "Epoch 1262/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.8340 - val_loss: 0.3493 - val_accuracy: 0.8460\n",
            "Epoch 1263/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.8253 - val_loss: 0.3487 - val_accuracy: 0.8470\n",
            "Epoch 1264/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.8253 - val_loss: 0.3485 - val_accuracy: 0.8460\n",
            "Epoch 1265/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.8327 - val_loss: 0.3486 - val_accuracy: 0.8465\n",
            "Epoch 1266/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.8307 - val_loss: 0.3487 - val_accuracy: 0.8465\n",
            "Epoch 1267/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8327 - val_loss: 0.3490 - val_accuracy: 0.8465\n",
            "Epoch 1268/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8293 - val_loss: 0.3489 - val_accuracy: 0.8470\n",
            "Epoch 1269/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.8287 - val_loss: 0.3488 - val_accuracy: 0.8470\n",
            "Epoch 1270/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3843 - accuracy: 0.8247 - val_loss: 0.3487 - val_accuracy: 0.8470\n",
            "Epoch 1271/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3785 - accuracy: 0.8320 - val_loss: 0.3488 - val_accuracy: 0.8475\n",
            "Epoch 1272/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3727 - accuracy: 0.8343 - val_loss: 0.3488 - val_accuracy: 0.8475\n",
            "Epoch 1273/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3751 - accuracy: 0.8390 - val_loss: 0.3489 - val_accuracy: 0.8470\n",
            "Epoch 1274/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3770 - accuracy: 0.8323 - val_loss: 0.3490 - val_accuracy: 0.8460\n",
            "Epoch 1275/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3794 - accuracy: 0.8313 - val_loss: 0.3488 - val_accuracy: 0.8460\n",
            "Epoch 1276/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3800 - accuracy: 0.8283 - val_loss: 0.3486 - val_accuracy: 0.8460\n",
            "Epoch 1277/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3780 - accuracy: 0.8213 - val_loss: 0.3487 - val_accuracy: 0.8470\n",
            "Epoch 1278/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8297 - val_loss: 0.3485 - val_accuracy: 0.8480\n",
            "Epoch 1279/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3778 - accuracy: 0.8293 - val_loss: 0.3488 - val_accuracy: 0.8465\n",
            "Epoch 1280/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.8293 - val_loss: 0.3487 - val_accuracy: 0.8475\n",
            "Epoch 1281/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3791 - accuracy: 0.8260 - val_loss: 0.3487 - val_accuracy: 0.8480\n",
            "Epoch 1282/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3790 - accuracy: 0.8247 - val_loss: 0.3488 - val_accuracy: 0.8470\n",
            "Epoch 1283/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3750 - accuracy: 0.8340 - val_loss: 0.3484 - val_accuracy: 0.8470\n",
            "Epoch 1284/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3832 - accuracy: 0.8257 - val_loss: 0.3480 - val_accuracy: 0.8465\n",
            "Epoch 1285/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.8360 - val_loss: 0.3481 - val_accuracy: 0.8475\n",
            "Epoch 1286/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3787 - accuracy: 0.8277 - val_loss: 0.3482 - val_accuracy: 0.8475\n",
            "Epoch 1287/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3840 - accuracy: 0.8233 - val_loss: 0.3485 - val_accuracy: 0.8470\n",
            "Epoch 1288/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3745 - accuracy: 0.8327 - val_loss: 0.3484 - val_accuracy: 0.8475\n",
            "Epoch 1289/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8287 - val_loss: 0.3484 - val_accuracy: 0.8460\n",
            "Epoch 1290/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3791 - accuracy: 0.8280 - val_loss: 0.3483 - val_accuracy: 0.8470\n",
            "Epoch 1291/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3755 - accuracy: 0.8273 - val_loss: 0.3483 - val_accuracy: 0.8470\n",
            "Epoch 1292/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3865 - accuracy: 0.8277 - val_loss: 0.3484 - val_accuracy: 0.8460\n",
            "Epoch 1293/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3837 - accuracy: 0.8237 - val_loss: 0.3482 - val_accuracy: 0.8460\n",
            "Epoch 1294/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3784 - accuracy: 0.8270 - val_loss: 0.3480 - val_accuracy: 0.8460\n",
            "Epoch 1295/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3744 - accuracy: 0.8310 - val_loss: 0.3481 - val_accuracy: 0.8475\n",
            "Epoch 1296/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3736 - accuracy: 0.8347 - val_loss: 0.3483 - val_accuracy: 0.8475\n",
            "Epoch 1297/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3873 - accuracy: 0.8203 - val_loss: 0.3484 - val_accuracy: 0.8470\n",
            "Epoch 1298/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3859 - accuracy: 0.8263 - val_loss: 0.3486 - val_accuracy: 0.8470\n",
            "Epoch 1299/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3812 - accuracy: 0.8267 - val_loss: 0.3487 - val_accuracy: 0.8475\n",
            "Epoch 1300/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3848 - accuracy: 0.8317 - val_loss: 0.3486 - val_accuracy: 0.8475\n",
            "Epoch 1301/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3798 - accuracy: 0.8263 - val_loss: 0.3485 - val_accuracy: 0.8475\n",
            "Epoch 1302/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3810 - accuracy: 0.8293 - val_loss: 0.3485 - val_accuracy: 0.8470\n",
            "Epoch 1303/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3795 - accuracy: 0.8327 - val_loss: 0.3487 - val_accuracy: 0.8460\n",
            "Epoch 1304/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3715 - accuracy: 0.8337 - val_loss: 0.3486 - val_accuracy: 0.8470\n",
            "Epoch 1305/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3763 - accuracy: 0.8337 - val_loss: 0.3483 - val_accuracy: 0.8465\n",
            "Epoch 1306/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3812 - accuracy: 0.8327 - val_loss: 0.3482 - val_accuracy: 0.8470\n",
            "Epoch 1307/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3801 - accuracy: 0.8230 - val_loss: 0.3481 - val_accuracy: 0.8475\n",
            "Epoch 1308/2000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3779 - accuracy: 0.8350 - val_loss: 0.3481 - val_accuracy: 0.8480\n",
            "Epoch 1309/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3758 - accuracy: 0.8340 - val_loss: 0.3482 - val_accuracy: 0.8470\n",
            "Epoch 1310/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3701 - accuracy: 0.8340 - val_loss: 0.3483 - val_accuracy: 0.8470\n",
            "Epoch 1311/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3751 - accuracy: 0.8340 - val_loss: 0.3484 - val_accuracy: 0.8475\n",
            "Epoch 1312/2000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3744 - accuracy: 0.8333 - val_loss: 0.3484 - val_accuracy: 0.8475\n",
            "Epoch 1313/2000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.3862 - accuracy: 0.8240 - val_loss: 0.3487 - val_accuracy: 0.8475\n",
            "Epoch 1314/2000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3832 - accuracy: 0.8320 - val_loss: 0.3485 - val_accuracy: 0.8475\n",
            "Epoch 1315/2000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.3798 - accuracy: 0.8293 - val_loss: 0.3482 - val_accuracy: 0.8480\n",
            "Epoch 1316/2000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3815 - accuracy: 0.8347 - val_loss: 0.3484 - val_accuracy: 0.8470\n",
            "Epoch 1317/2000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3755 - accuracy: 0.8340 - val_loss: 0.3482 - val_accuracy: 0.8475\n",
            "Epoch 1318/2000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3752 - accuracy: 0.8307 - val_loss: 0.3483 - val_accuracy: 0.8470\n",
            "Epoch 1319/2000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3794 - accuracy: 0.8303 - val_loss: 0.3481 - val_accuracy: 0.8465\n",
            "Epoch 1320/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3714 - accuracy: 0.8350 - val_loss: 0.3480 - val_accuracy: 0.8460\n",
            "Epoch 1321/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3813 - accuracy: 0.8273 - val_loss: 0.3481 - val_accuracy: 0.8470\n",
            "Epoch 1322/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3815 - accuracy: 0.8290 - val_loss: 0.3484 - val_accuracy: 0.8480\n",
            "Epoch 1323/2000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3752 - accuracy: 0.8320 - val_loss: 0.3482 - val_accuracy: 0.8480\n",
            "Epoch 1324/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3838 - accuracy: 0.8280 - val_loss: 0.3483 - val_accuracy: 0.8485\n",
            "Epoch 1325/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3827 - accuracy: 0.8280 - val_loss: 0.3483 - val_accuracy: 0.8480\n",
            "Epoch 1326/2000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3782 - accuracy: 0.8260 - val_loss: 0.3486 - val_accuracy: 0.8475\n",
            "Epoch 1327/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3732 - accuracy: 0.8327 - val_loss: 0.3486 - val_accuracy: 0.8475\n",
            "Epoch 1328/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.8283 - val_loss: 0.3484 - val_accuracy: 0.8450\n",
            "Epoch 1329/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3789 - accuracy: 0.8317 - val_loss: 0.3482 - val_accuracy: 0.8455\n",
            "Epoch 1330/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3811 - accuracy: 0.8303 - val_loss: 0.3483 - val_accuracy: 0.8460\n",
            "Epoch 1331/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3792 - accuracy: 0.8297 - val_loss: 0.3484 - val_accuracy: 0.8475\n",
            "Epoch 1332/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3774 - accuracy: 0.8300 - val_loss: 0.3482 - val_accuracy: 0.8470\n",
            "Epoch 1333/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3750 - accuracy: 0.8320 - val_loss: 0.3484 - val_accuracy: 0.8470\n",
            "Epoch 1334/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3776 - accuracy: 0.8337 - val_loss: 0.3485 - val_accuracy: 0.8460\n",
            "Epoch 1335/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.8250 - val_loss: 0.3483 - val_accuracy: 0.8470\n",
            "Epoch 1336/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3779 - accuracy: 0.8293 - val_loss: 0.3481 - val_accuracy: 0.8470\n",
            "Epoch 1337/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3812 - accuracy: 0.8273 - val_loss: 0.3481 - val_accuracy: 0.8460\n",
            "Epoch 1338/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3831 - accuracy: 0.8320 - val_loss: 0.3481 - val_accuracy: 0.8470\n",
            "Epoch 1339/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3882 - accuracy: 0.8260 - val_loss: 0.3479 - val_accuracy: 0.8480\n",
            "Epoch 1340/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3703 - accuracy: 0.8347 - val_loss: 0.3482 - val_accuracy: 0.8475\n",
            "Epoch 1341/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8287 - val_loss: 0.3486 - val_accuracy: 0.8470\n",
            "Epoch 1342/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3808 - accuracy: 0.8333 - val_loss: 0.3486 - val_accuracy: 0.8455\n",
            "Epoch 1343/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3783 - accuracy: 0.8353 - val_loss: 0.3485 - val_accuracy: 0.8460\n",
            "Epoch 1344/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3771 - accuracy: 0.8307 - val_loss: 0.3483 - val_accuracy: 0.8465\n",
            "Epoch 1345/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3746 - accuracy: 0.8327 - val_loss: 0.3485 - val_accuracy: 0.8475\n",
            "Epoch 1346/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3735 - accuracy: 0.8227 - val_loss: 0.3483 - val_accuracy: 0.8490\n",
            "Epoch 1347/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3768 - accuracy: 0.8263 - val_loss: 0.3481 - val_accuracy: 0.8450\n",
            "Epoch 1348/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.8330 - val_loss: 0.3482 - val_accuracy: 0.8460\n",
            "Epoch 1349/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8210 - val_loss: 0.3483 - val_accuracy: 0.8465\n",
            "Epoch 1350/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3694 - accuracy: 0.8380 - val_loss: 0.3484 - val_accuracy: 0.8470\n",
            "Epoch 1351/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3803 - accuracy: 0.8290 - val_loss: 0.3482 - val_accuracy: 0.8470\n",
            "Epoch 1352/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3807 - accuracy: 0.8293 - val_loss: 0.3485 - val_accuracy: 0.8475\n",
            "Epoch 1353/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3836 - accuracy: 0.8273 - val_loss: 0.3479 - val_accuracy: 0.8470\n",
            "Epoch 1354/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3769 - accuracy: 0.8297 - val_loss: 0.3481 - val_accuracy: 0.8470\n",
            "Epoch 1355/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3785 - accuracy: 0.8333 - val_loss: 0.3482 - val_accuracy: 0.8470\n",
            "Epoch 1356/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8257 - val_loss: 0.3481 - val_accuracy: 0.8485\n",
            "Epoch 1357/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3839 - accuracy: 0.8230 - val_loss: 0.3482 - val_accuracy: 0.8480\n",
            "Epoch 1358/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3813 - accuracy: 0.8287 - val_loss: 0.3485 - val_accuracy: 0.8470\n",
            "Epoch 1359/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8360 - val_loss: 0.3483 - val_accuracy: 0.8470\n",
            "Epoch 1360/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8253 - val_loss: 0.3485 - val_accuracy: 0.8465\n",
            "Epoch 1361/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.8353 - val_loss: 0.3481 - val_accuracy: 0.8470\n",
            "Epoch 1362/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8273 - val_loss: 0.3480 - val_accuracy: 0.8460\n",
            "Epoch 1363/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3764 - accuracy: 0.8337 - val_loss: 0.3481 - val_accuracy: 0.8460\n",
            "Epoch 1364/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3801 - accuracy: 0.8290 - val_loss: 0.3478 - val_accuracy: 0.8470\n",
            "Epoch 1365/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3759 - accuracy: 0.8267 - val_loss: 0.3478 - val_accuracy: 0.8475\n",
            "Epoch 1366/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.8247 - val_loss: 0.3479 - val_accuracy: 0.8495\n",
            "Epoch 1367/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3804 - accuracy: 0.8287 - val_loss: 0.3482 - val_accuracy: 0.8480\n",
            "Epoch 1368/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8317 - val_loss: 0.3485 - val_accuracy: 0.8475\n",
            "Epoch 1369/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.8353 - val_loss: 0.3488 - val_accuracy: 0.8460\n",
            "Epoch 1370/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8280 - val_loss: 0.3486 - val_accuracy: 0.8465\n",
            "Epoch 1371/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.8247 - val_loss: 0.3483 - val_accuracy: 0.8460\n",
            "Epoch 1372/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.8287 - val_loss: 0.3484 - val_accuracy: 0.8475\n",
            "Epoch 1373/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8303 - val_loss: 0.3484 - val_accuracy: 0.8470\n",
            "Epoch 1374/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.8290 - val_loss: 0.3480 - val_accuracy: 0.8475\n",
            "Epoch 1375/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.8293 - val_loss: 0.3479 - val_accuracy: 0.8465\n",
            "Epoch 1376/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.8253 - val_loss: 0.3480 - val_accuracy: 0.8460\n",
            "Epoch 1377/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3738 - accuracy: 0.8300 - val_loss: 0.3485 - val_accuracy: 0.8460\n",
            "Epoch 1378/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8290 - val_loss: 0.3483 - val_accuracy: 0.8470\n",
            "Epoch 1379/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8367 - val_loss: 0.3481 - val_accuracy: 0.8480\n",
            "Epoch 1380/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3757 - accuracy: 0.8307 - val_loss: 0.3481 - val_accuracy: 0.8480\n",
            "Epoch 1381/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3739 - accuracy: 0.8340 - val_loss: 0.3481 - val_accuracy: 0.8480\n",
            "Epoch 1382/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3695 - accuracy: 0.8453 - val_loss: 0.3481 - val_accuracy: 0.8480\n",
            "Epoch 1383/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3761 - accuracy: 0.8290 - val_loss: 0.3479 - val_accuracy: 0.8465\n",
            "Epoch 1384/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.8337 - val_loss: 0.3479 - val_accuracy: 0.8480\n",
            "Epoch 1385/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3700 - accuracy: 0.8330 - val_loss: 0.3480 - val_accuracy: 0.8465\n",
            "Epoch 1386/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3757 - accuracy: 0.8300 - val_loss: 0.3480 - val_accuracy: 0.8465\n",
            "Epoch 1387/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.8290 - val_loss: 0.3479 - val_accuracy: 0.8485\n",
            "Epoch 1388/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8277 - val_loss: 0.3480 - val_accuracy: 0.8480\n",
            "Epoch 1389/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3818 - accuracy: 0.8247 - val_loss: 0.3477 - val_accuracy: 0.8485\n",
            "Epoch 1390/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.8280 - val_loss: 0.3477 - val_accuracy: 0.8485\n",
            "Epoch 1391/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3706 - accuracy: 0.8370 - val_loss: 0.3481 - val_accuracy: 0.8495\n",
            "Epoch 1392/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.8307 - val_loss: 0.3483 - val_accuracy: 0.8475\n",
            "Epoch 1393/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3782 - accuracy: 0.8323 - val_loss: 0.3482 - val_accuracy: 0.8495\n",
            "Epoch 1394/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.8270 - val_loss: 0.3480 - val_accuracy: 0.8475\n",
            "Epoch 1395/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8253 - val_loss: 0.3480 - val_accuracy: 0.8465\n",
            "Epoch 1396/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3808 - accuracy: 0.8247 - val_loss: 0.3481 - val_accuracy: 0.8475\n",
            "Epoch 1397/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3762 - accuracy: 0.8317 - val_loss: 0.3483 - val_accuracy: 0.8450\n",
            "Epoch 1398/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3744 - accuracy: 0.8337 - val_loss: 0.3479 - val_accuracy: 0.8480\n",
            "Epoch 1399/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3835 - accuracy: 0.8330 - val_loss: 0.3478 - val_accuracy: 0.8480\n",
            "Epoch 1400/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3795 - accuracy: 0.8337 - val_loss: 0.3479 - val_accuracy: 0.8480\n",
            "Epoch 1401/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3745 - accuracy: 0.8340 - val_loss: 0.3476 - val_accuracy: 0.8480\n",
            "Epoch 1402/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8290 - val_loss: 0.3475 - val_accuracy: 0.8480\n",
            "Epoch 1403/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.8303 - val_loss: 0.3475 - val_accuracy: 0.8475\n",
            "Epoch 1404/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8307 - val_loss: 0.3478 - val_accuracy: 0.8495\n",
            "Epoch 1405/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3767 - accuracy: 0.8313 - val_loss: 0.3482 - val_accuracy: 0.8475\n",
            "Epoch 1406/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3776 - accuracy: 0.8333 - val_loss: 0.3481 - val_accuracy: 0.8475\n",
            "Epoch 1407/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3825 - accuracy: 0.8267 - val_loss: 0.3479 - val_accuracy: 0.8465\n",
            "Epoch 1408/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3818 - accuracy: 0.8307 - val_loss: 0.3479 - val_accuracy: 0.8485\n",
            "Epoch 1409/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3808 - accuracy: 0.8247 - val_loss: 0.3479 - val_accuracy: 0.8490\n",
            "Epoch 1410/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3800 - accuracy: 0.8293 - val_loss: 0.3479 - val_accuracy: 0.8480\n",
            "Epoch 1411/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3753 - accuracy: 0.8327 - val_loss: 0.3478 - val_accuracy: 0.8470\n",
            "Epoch 1412/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.8327 - val_loss: 0.3481 - val_accuracy: 0.8475\n",
            "Epoch 1413/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.8240 - val_loss: 0.3481 - val_accuracy: 0.8480\n",
            "Epoch 1414/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3745 - accuracy: 0.8323 - val_loss: 0.3481 - val_accuracy: 0.8475\n",
            "Epoch 1415/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3800 - accuracy: 0.8257 - val_loss: 0.3482 - val_accuracy: 0.8475\n",
            "Epoch 1416/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3819 - accuracy: 0.8343 - val_loss: 0.3483 - val_accuracy: 0.8485\n",
            "Epoch 1417/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3730 - accuracy: 0.8330 - val_loss: 0.3484 - val_accuracy: 0.8485\n",
            "Epoch 1418/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3810 - accuracy: 0.8260 - val_loss: 0.3482 - val_accuracy: 0.8485\n",
            "Epoch 1419/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3757 - accuracy: 0.8260 - val_loss: 0.3482 - val_accuracy: 0.8460\n",
            "Epoch 1420/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3760 - accuracy: 0.8323 - val_loss: 0.3484 - val_accuracy: 0.8465\n",
            "Epoch 1421/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3769 - accuracy: 0.8357 - val_loss: 0.3483 - val_accuracy: 0.8475\n",
            "Epoch 1422/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3742 - accuracy: 0.8340 - val_loss: 0.3481 - val_accuracy: 0.8480\n",
            "Epoch 1423/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.8343 - val_loss: 0.3481 - val_accuracy: 0.8475\n",
            "Epoch 1424/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.8263 - val_loss: 0.3481 - val_accuracy: 0.8490\n",
            "Epoch 1425/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3736 - accuracy: 0.8297 - val_loss: 0.3481 - val_accuracy: 0.8460\n",
            "Epoch 1426/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.8280 - val_loss: 0.3479 - val_accuracy: 0.8480\n",
            "Epoch 1427/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3871 - accuracy: 0.8220 - val_loss: 0.3481 - val_accuracy: 0.8485\n",
            "Epoch 1428/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3826 - accuracy: 0.8313 - val_loss: 0.3482 - val_accuracy: 0.8480\n",
            "Epoch 1429/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3813 - accuracy: 0.8300 - val_loss: 0.3484 - val_accuracy: 0.8470\n",
            "Epoch 1430/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8270 - val_loss: 0.3481 - val_accuracy: 0.8490\n",
            "Epoch 1431/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.8297 - val_loss: 0.3483 - val_accuracy: 0.8485\n",
            "Epoch 1432/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.8287 - val_loss: 0.3485 - val_accuracy: 0.8480\n",
            "Epoch 1433/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3811 - accuracy: 0.8300 - val_loss: 0.3485 - val_accuracy: 0.8475\n",
            "Epoch 1434/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8290 - val_loss: 0.3484 - val_accuracy: 0.8480\n",
            "Epoch 1435/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.8233 - val_loss: 0.3482 - val_accuracy: 0.8455\n",
            "Epoch 1436/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3768 - accuracy: 0.8310 - val_loss: 0.3480 - val_accuracy: 0.8455\n",
            "Epoch 1437/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8273 - val_loss: 0.3482 - val_accuracy: 0.8455\n",
            "Epoch 1438/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8323 - val_loss: 0.3483 - val_accuracy: 0.8470\n",
            "Epoch 1439/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3756 - accuracy: 0.8413 - val_loss: 0.3482 - val_accuracy: 0.8465\n",
            "Epoch 1440/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8277 - val_loss: 0.3483 - val_accuracy: 0.8480\n",
            "Epoch 1441/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3785 - accuracy: 0.8343 - val_loss: 0.3485 - val_accuracy: 0.8470\n",
            "Epoch 1442/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3788 - accuracy: 0.8270 - val_loss: 0.3483 - val_accuracy: 0.8465\n",
            "Epoch 1443/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3841 - accuracy: 0.8303 - val_loss: 0.3481 - val_accuracy: 0.8470\n",
            "Epoch 1444/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3745 - accuracy: 0.8333 - val_loss: 0.3483 - val_accuracy: 0.8475\n",
            "Epoch 1445/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3762 - accuracy: 0.8323 - val_loss: 0.3483 - val_accuracy: 0.8465\n",
            "Epoch 1446/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3774 - accuracy: 0.8257 - val_loss: 0.3486 - val_accuracy: 0.8475\n",
            "Epoch 1447/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3823 - accuracy: 0.8247 - val_loss: 0.3485 - val_accuracy: 0.8475\n",
            "Epoch 1448/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3816 - accuracy: 0.8253 - val_loss: 0.3485 - val_accuracy: 0.8460\n",
            "Epoch 1449/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.8323 - val_loss: 0.3484 - val_accuracy: 0.8475\n",
            "Epoch 1450/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3830 - accuracy: 0.8367 - val_loss: 0.3484 - val_accuracy: 0.8480\n",
            "Epoch 1451/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.8307 - val_loss: 0.3481 - val_accuracy: 0.8470\n",
            "Epoch 1452/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8390 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
            "Epoch 1453/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3748 - accuracy: 0.8297 - val_loss: 0.3479 - val_accuracy: 0.8475\n",
            "Epoch 1454/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3782 - accuracy: 0.8330 - val_loss: 0.3477 - val_accuracy: 0.8460\n",
            "Epoch 1455/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3722 - accuracy: 0.8360 - val_loss: 0.3478 - val_accuracy: 0.8460\n",
            "Epoch 1456/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3846 - accuracy: 0.8270 - val_loss: 0.3484 - val_accuracy: 0.8455\n",
            "Epoch 1457/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3757 - accuracy: 0.8337 - val_loss: 0.3483 - val_accuracy: 0.8460\n",
            "Epoch 1458/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.8257 - val_loss: 0.3482 - val_accuracy: 0.8460\n",
            "Epoch 1459/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8347 - val_loss: 0.3483 - val_accuracy: 0.8485\n",
            "Epoch 1460/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3775 - accuracy: 0.8320 - val_loss: 0.3485 - val_accuracy: 0.8480\n",
            "Epoch 1461/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3840 - accuracy: 0.8280 - val_loss: 0.3482 - val_accuracy: 0.8475\n",
            "Epoch 1462/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3743 - accuracy: 0.8273 - val_loss: 0.3482 - val_accuracy: 0.8465\n",
            "Epoch 1463/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3789 - accuracy: 0.8287 - val_loss: 0.3483 - val_accuracy: 0.8455\n",
            "Epoch 1464/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3829 - accuracy: 0.8273 - val_loss: 0.3481 - val_accuracy: 0.8485\n",
            "Epoch 1465/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3777 - accuracy: 0.8317 - val_loss: 0.3483 - val_accuracy: 0.8480\n",
            "Epoch 1466/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3784 - accuracy: 0.8260 - val_loss: 0.3482 - val_accuracy: 0.8465\n",
            "Epoch 1467/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.8273 - val_loss: 0.3479 - val_accuracy: 0.8455\n",
            "Epoch 1468/2000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3743 - accuracy: 0.8307 - val_loss: 0.3479 - val_accuracy: 0.8455\n",
            "Epoch 1469/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3782 - accuracy: 0.8350 - val_loss: 0.3483 - val_accuracy: 0.8470\n",
            "Epoch 1470/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3787 - accuracy: 0.8307 - val_loss: 0.3481 - val_accuracy: 0.8470\n",
            "Epoch 1471/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3787 - accuracy: 0.8290 - val_loss: 0.3481 - val_accuracy: 0.8475\n",
            "Epoch 1472/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3808 - accuracy: 0.8273 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
            "Epoch 1473/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3706 - accuracy: 0.8297 - val_loss: 0.3477 - val_accuracy: 0.8460\n",
            "Epoch 1474/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3795 - accuracy: 0.8233 - val_loss: 0.3480 - val_accuracy: 0.8470\n",
            "Epoch 1475/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8390 - val_loss: 0.3485 - val_accuracy: 0.8465\n",
            "Epoch 1476/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3752 - accuracy: 0.8377 - val_loss: 0.3483 - val_accuracy: 0.8475\n",
            "Epoch 1477/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3744 - accuracy: 0.8367 - val_loss: 0.3482 - val_accuracy: 0.8470\n",
            "Epoch 1478/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3816 - accuracy: 0.8280 - val_loss: 0.3483 - val_accuracy: 0.8475\n",
            "Epoch 1479/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3830 - accuracy: 0.8297 - val_loss: 0.3482 - val_accuracy: 0.8470\n",
            "Epoch 1480/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3804 - accuracy: 0.8277 - val_loss: 0.3483 - val_accuracy: 0.8475\n",
            "Epoch 1481/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3831 - accuracy: 0.8293 - val_loss: 0.3482 - val_accuracy: 0.8475\n",
            "Epoch 1482/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3794 - accuracy: 0.8263 - val_loss: 0.3481 - val_accuracy: 0.8470\n",
            "Epoch 1483/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3795 - accuracy: 0.8233 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
            "Epoch 1484/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3826 - accuracy: 0.8300 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
            "Epoch 1485/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3782 - accuracy: 0.8363 - val_loss: 0.3480 - val_accuracy: 0.8460\n",
            "Epoch 1486/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3846 - accuracy: 0.8257 - val_loss: 0.3483 - val_accuracy: 0.8470\n",
            "Epoch 1487/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3806 - accuracy: 0.8307 - val_loss: 0.3486 - val_accuracy: 0.8450\n",
            "Epoch 1488/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3746 - accuracy: 0.8280 - val_loss: 0.3483 - val_accuracy: 0.8485\n",
            "Epoch 1489/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3824 - accuracy: 0.8260 - val_loss: 0.3484 - val_accuracy: 0.8480\n",
            "Epoch 1490/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3764 - accuracy: 0.8297 - val_loss: 0.3484 - val_accuracy: 0.8475\n",
            "Epoch 1491/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3791 - accuracy: 0.8253 - val_loss: 0.3485 - val_accuracy: 0.8470\n",
            "Epoch 1492/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8290 - val_loss: 0.3480 - val_accuracy: 0.8470\n",
            "Epoch 1493/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3758 - accuracy: 0.8330 - val_loss: 0.3478 - val_accuracy: 0.8480\n",
            "Epoch 1494/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3763 - accuracy: 0.8290 - val_loss: 0.3479 - val_accuracy: 0.8470\n",
            "Epoch 1495/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3795 - accuracy: 0.8263 - val_loss: 0.3479 - val_accuracy: 0.8480\n",
            "Epoch 1496/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.8317 - val_loss: 0.3484 - val_accuracy: 0.8485\n",
            "Epoch 1497/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3824 - accuracy: 0.8317 - val_loss: 0.3483 - val_accuracy: 0.8480\n",
            "Epoch 1498/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8317 - val_loss: 0.3481 - val_accuracy: 0.8480\n",
            "Epoch 1499/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3758 - accuracy: 0.8300 - val_loss: 0.3476 - val_accuracy: 0.8475\n",
            "Epoch 1500/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3769 - accuracy: 0.8287 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1501/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3757 - accuracy: 0.8313 - val_loss: 0.3482 - val_accuracy: 0.8465\n",
            "Epoch 1502/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8280 - val_loss: 0.3480 - val_accuracy: 0.8480\n",
            "Epoch 1503/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.8293 - val_loss: 0.3480 - val_accuracy: 0.8485\n",
            "Epoch 1504/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.8267 - val_loss: 0.3480 - val_accuracy: 0.8480\n",
            "Epoch 1505/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3772 - accuracy: 0.8273 - val_loss: 0.3477 - val_accuracy: 0.8490\n",
            "Epoch 1506/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8287 - val_loss: 0.3478 - val_accuracy: 0.8475\n",
            "Epoch 1507/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3766 - accuracy: 0.8340 - val_loss: 0.3481 - val_accuracy: 0.8465\n",
            "Epoch 1508/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.8357 - val_loss: 0.3479 - val_accuracy: 0.8470\n",
            "Epoch 1509/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3800 - accuracy: 0.8257 - val_loss: 0.3478 - val_accuracy: 0.8475\n",
            "Epoch 1510/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3765 - accuracy: 0.8323 - val_loss: 0.3480 - val_accuracy: 0.8480\n",
            "Epoch 1511/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3785 - accuracy: 0.8317 - val_loss: 0.3480 - val_accuracy: 0.8470\n",
            "Epoch 1512/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3837 - accuracy: 0.8240 - val_loss: 0.3479 - val_accuracy: 0.8465\n",
            "Epoch 1513/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3751 - accuracy: 0.8260 - val_loss: 0.3480 - val_accuracy: 0.8475\n",
            "Epoch 1514/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3766 - accuracy: 0.8280 - val_loss: 0.3481 - val_accuracy: 0.8480\n",
            "Epoch 1515/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.8363 - val_loss: 0.3480 - val_accuracy: 0.8485\n",
            "Epoch 1516/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3770 - accuracy: 0.8327 - val_loss: 0.3477 - val_accuracy: 0.8480\n",
            "Epoch 1517/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3727 - accuracy: 0.8330 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1518/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3689 - accuracy: 0.8313 - val_loss: 0.3478 - val_accuracy: 0.8455\n",
            "Epoch 1519/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8300 - val_loss: 0.3480 - val_accuracy: 0.8460\n",
            "Epoch 1520/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3777 - accuracy: 0.8293 - val_loss: 0.3482 - val_accuracy: 0.8465\n",
            "Epoch 1521/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3775 - accuracy: 0.8330 - val_loss: 0.3482 - val_accuracy: 0.8485\n",
            "Epoch 1522/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8347 - val_loss: 0.3483 - val_accuracy: 0.8485\n",
            "Epoch 1523/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3789 - accuracy: 0.8230 - val_loss: 0.3480 - val_accuracy: 0.8470\n",
            "Epoch 1524/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8340 - val_loss: 0.3478 - val_accuracy: 0.8455\n",
            "Epoch 1525/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.8280 - val_loss: 0.3478 - val_accuracy: 0.8480\n",
            "Epoch 1526/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3762 - accuracy: 0.8373 - val_loss: 0.3480 - val_accuracy: 0.8475\n",
            "Epoch 1527/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.8280 - val_loss: 0.3479 - val_accuracy: 0.8465\n",
            "Epoch 1528/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.8340 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1529/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3798 - accuracy: 0.8333 - val_loss: 0.3478 - val_accuracy: 0.8465\n",
            "Epoch 1530/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3743 - accuracy: 0.8303 - val_loss: 0.3481 - val_accuracy: 0.8480\n",
            "Epoch 1531/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.8333 - val_loss: 0.3481 - val_accuracy: 0.8490\n",
            "Epoch 1532/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3766 - accuracy: 0.8287 - val_loss: 0.3480 - val_accuracy: 0.8475\n",
            "Epoch 1533/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3733 - accuracy: 0.8320 - val_loss: 0.3481 - val_accuracy: 0.8480\n",
            "Epoch 1534/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3799 - accuracy: 0.8313 - val_loss: 0.3480 - val_accuracy: 0.8485\n",
            "Epoch 1535/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3678 - accuracy: 0.8363 - val_loss: 0.3482 - val_accuracy: 0.8475\n",
            "Epoch 1536/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3759 - accuracy: 0.8297 - val_loss: 0.3484 - val_accuracy: 0.8465\n",
            "Epoch 1537/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3776 - accuracy: 0.8260 - val_loss: 0.3485 - val_accuracy: 0.8455\n",
            "Epoch 1538/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8343 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
            "Epoch 1539/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3756 - accuracy: 0.8303 - val_loss: 0.3479 - val_accuracy: 0.8470\n",
            "Epoch 1540/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3818 - accuracy: 0.8287 - val_loss: 0.3480 - val_accuracy: 0.8475\n",
            "Epoch 1541/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3744 - accuracy: 0.8330 - val_loss: 0.3478 - val_accuracy: 0.8480\n",
            "Epoch 1542/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.8313 - val_loss: 0.3482 - val_accuracy: 0.8485\n",
            "Epoch 1543/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3778 - accuracy: 0.8303 - val_loss: 0.3480 - val_accuracy: 0.8465\n",
            "Epoch 1544/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8277 - val_loss: 0.3479 - val_accuracy: 0.8485\n",
            "Epoch 1545/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.8257 - val_loss: 0.3477 - val_accuracy: 0.8485\n",
            "Epoch 1546/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3780 - accuracy: 0.8297 - val_loss: 0.3475 - val_accuracy: 0.8480\n",
            "Epoch 1547/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.8330 - val_loss: 0.3476 - val_accuracy: 0.8480\n",
            "Epoch 1548/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.8300 - val_loss: 0.3475 - val_accuracy: 0.8485\n",
            "Epoch 1549/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.8280 - val_loss: 0.3474 - val_accuracy: 0.8485\n",
            "Epoch 1550/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3789 - accuracy: 0.8297 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1551/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3738 - accuracy: 0.8287 - val_loss: 0.3481 - val_accuracy: 0.8460\n",
            "Epoch 1552/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3764 - accuracy: 0.8313 - val_loss: 0.3481 - val_accuracy: 0.8460\n",
            "Epoch 1553/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3767 - accuracy: 0.8303 - val_loss: 0.3480 - val_accuracy: 0.8460\n",
            "Epoch 1554/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8320 - val_loss: 0.3480 - val_accuracy: 0.8480\n",
            "Epoch 1555/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.8273 - val_loss: 0.3479 - val_accuracy: 0.8455\n",
            "Epoch 1556/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.8253 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1557/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.8323 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1558/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3834 - accuracy: 0.8243 - val_loss: 0.3475 - val_accuracy: 0.8475\n",
            "Epoch 1559/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3812 - accuracy: 0.8343 - val_loss: 0.3474 - val_accuracy: 0.8480\n",
            "Epoch 1560/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8387 - val_loss: 0.3475 - val_accuracy: 0.8475\n",
            "Epoch 1561/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.8310 - val_loss: 0.3479 - val_accuracy: 0.8470\n",
            "Epoch 1562/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3707 - accuracy: 0.8323 - val_loss: 0.3478 - val_accuracy: 0.8475\n",
            "Epoch 1563/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8260 - val_loss: 0.3481 - val_accuracy: 0.8470\n",
            "Epoch 1564/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8307 - val_loss: 0.3480 - val_accuracy: 0.8485\n",
            "Epoch 1565/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8270 - val_loss: 0.3478 - val_accuracy: 0.8480\n",
            "Epoch 1566/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3795 - accuracy: 0.8230 - val_loss: 0.3480 - val_accuracy: 0.8470\n",
            "Epoch 1567/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3742 - accuracy: 0.8303 - val_loss: 0.3480 - val_accuracy: 0.8485\n",
            "Epoch 1568/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3772 - accuracy: 0.8323 - val_loss: 0.3481 - val_accuracy: 0.8470\n",
            "Epoch 1569/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3793 - accuracy: 0.8320 - val_loss: 0.3481 - val_accuracy: 0.8450\n",
            "Epoch 1570/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3782 - accuracy: 0.8287 - val_loss: 0.3481 - val_accuracy: 0.8465\n",
            "Epoch 1571/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3722 - accuracy: 0.8333 - val_loss: 0.3479 - val_accuracy: 0.8470\n",
            "Epoch 1572/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.8237 - val_loss: 0.3480 - val_accuracy: 0.8465\n",
            "Epoch 1573/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3739 - accuracy: 0.8320 - val_loss: 0.3480 - val_accuracy: 0.8485\n",
            "Epoch 1574/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3790 - accuracy: 0.8303 - val_loss: 0.3481 - val_accuracy: 0.8475\n",
            "Epoch 1575/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3806 - accuracy: 0.8297 - val_loss: 0.3480 - val_accuracy: 0.8455\n",
            "Epoch 1576/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3888 - accuracy: 0.8233 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
            "Epoch 1577/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8297 - val_loss: 0.3482 - val_accuracy: 0.8475\n",
            "Epoch 1578/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3791 - accuracy: 0.8287 - val_loss: 0.3481 - val_accuracy: 0.8470\n",
            "Epoch 1579/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3768 - accuracy: 0.8353 - val_loss: 0.3480 - val_accuracy: 0.8475\n",
            "Epoch 1580/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3728 - accuracy: 0.8347 - val_loss: 0.3482 - val_accuracy: 0.8470\n",
            "Epoch 1581/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3733 - accuracy: 0.8340 - val_loss: 0.3480 - val_accuracy: 0.8485\n",
            "Epoch 1582/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8323 - val_loss: 0.3477 - val_accuracy: 0.8490\n",
            "Epoch 1583/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.8233 - val_loss: 0.3477 - val_accuracy: 0.8480\n",
            "Epoch 1584/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.8360 - val_loss: 0.3478 - val_accuracy: 0.8470\n",
            "Epoch 1585/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8370 - val_loss: 0.3480 - val_accuracy: 0.8460\n",
            "Epoch 1586/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8343 - val_loss: 0.3476 - val_accuracy: 0.8475\n",
            "Epoch 1587/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3749 - accuracy: 0.8357 - val_loss: 0.3478 - val_accuracy: 0.8460\n",
            "Epoch 1588/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3762 - accuracy: 0.8310 - val_loss: 0.3475 - val_accuracy: 0.8460\n",
            "Epoch 1589/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3798 - accuracy: 0.8267 - val_loss: 0.3479 - val_accuracy: 0.8470\n",
            "Epoch 1590/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3730 - accuracy: 0.8333 - val_loss: 0.3478 - val_accuracy: 0.8460\n",
            "Epoch 1591/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3765 - accuracy: 0.8353 - val_loss: 0.3477 - val_accuracy: 0.8455\n",
            "Epoch 1592/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3773 - accuracy: 0.8320 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
            "Epoch 1593/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.8250 - val_loss: 0.3478 - val_accuracy: 0.8460\n",
            "Epoch 1594/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3747 - accuracy: 0.8243 - val_loss: 0.3480 - val_accuracy: 0.8465\n",
            "Epoch 1595/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3768 - accuracy: 0.8297 - val_loss: 0.3480 - val_accuracy: 0.8435\n",
            "Epoch 1596/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.8227 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1597/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8287 - val_loss: 0.3479 - val_accuracy: 0.8470\n",
            "Epoch 1598/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3726 - accuracy: 0.8350 - val_loss: 0.3480 - val_accuracy: 0.8460\n",
            "Epoch 1599/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8317 - val_loss: 0.3477 - val_accuracy: 0.8465\n",
            "Epoch 1600/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3789 - accuracy: 0.8300 - val_loss: 0.3478 - val_accuracy: 0.8480\n",
            "Epoch 1601/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8287 - val_loss: 0.3478 - val_accuracy: 0.8460\n",
            "Epoch 1602/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3750 - accuracy: 0.8310 - val_loss: 0.3478 - val_accuracy: 0.8475\n",
            "Epoch 1603/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8400 - val_loss: 0.3480 - val_accuracy: 0.8460\n",
            "Epoch 1604/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3749 - accuracy: 0.8307 - val_loss: 0.3479 - val_accuracy: 0.8470\n",
            "Epoch 1605/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3811 - accuracy: 0.8303 - val_loss: 0.3479 - val_accuracy: 0.8480\n",
            "Epoch 1606/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3761 - accuracy: 0.8267 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
            "Epoch 1607/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3764 - accuracy: 0.8327 - val_loss: 0.3475 - val_accuracy: 0.8470\n",
            "Epoch 1608/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3795 - accuracy: 0.8300 - val_loss: 0.3477 - val_accuracy: 0.8460\n",
            "Epoch 1609/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3791 - accuracy: 0.8273 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1610/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3816 - accuracy: 0.8287 - val_loss: 0.3480 - val_accuracy: 0.8460\n",
            "Epoch 1611/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3740 - accuracy: 0.8297 - val_loss: 0.3480 - val_accuracy: 0.8460\n",
            "Epoch 1612/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3797 - accuracy: 0.8303 - val_loss: 0.3480 - val_accuracy: 0.8475\n",
            "Epoch 1613/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3731 - accuracy: 0.8303 - val_loss: 0.3477 - val_accuracy: 0.8465\n",
            "Epoch 1614/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8337 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
            "Epoch 1615/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3765 - accuracy: 0.8320 - val_loss: 0.3478 - val_accuracy: 0.8480\n",
            "Epoch 1616/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.8367 - val_loss: 0.3475 - val_accuracy: 0.8475\n",
            "Epoch 1617/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3739 - accuracy: 0.8343 - val_loss: 0.3476 - val_accuracy: 0.8470\n",
            "Epoch 1618/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3752 - accuracy: 0.8297 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1619/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3845 - accuracy: 0.8273 - val_loss: 0.3478 - val_accuracy: 0.8480\n",
            "Epoch 1620/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3798 - accuracy: 0.8350 - val_loss: 0.3477 - val_accuracy: 0.8490\n",
            "Epoch 1621/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3729 - accuracy: 0.8313 - val_loss: 0.3476 - val_accuracy: 0.8470\n",
            "Epoch 1622/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3769 - accuracy: 0.8277 - val_loss: 0.3480 - val_accuracy: 0.8475\n",
            "Epoch 1623/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3750 - accuracy: 0.8360 - val_loss: 0.3480 - val_accuracy: 0.8475\n",
            "Epoch 1624/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3784 - accuracy: 0.8303 - val_loss: 0.3483 - val_accuracy: 0.8475\n",
            "Epoch 1625/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3735 - accuracy: 0.8340 - val_loss: 0.3480 - val_accuracy: 0.8475\n",
            "Epoch 1626/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3812 - accuracy: 0.8307 - val_loss: 0.3480 - val_accuracy: 0.8465\n",
            "Epoch 1627/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3777 - accuracy: 0.8267 - val_loss: 0.3477 - val_accuracy: 0.8480\n",
            "Epoch 1628/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3774 - accuracy: 0.8303 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1629/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3779 - accuracy: 0.8277 - val_loss: 0.3479 - val_accuracy: 0.8490\n",
            "Epoch 1630/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3772 - accuracy: 0.8307 - val_loss: 0.3480 - val_accuracy: 0.8495\n",
            "Epoch 1631/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3813 - accuracy: 0.8270 - val_loss: 0.3480 - val_accuracy: 0.8460\n",
            "Epoch 1632/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3771 - accuracy: 0.8307 - val_loss: 0.3477 - val_accuracy: 0.8465\n",
            "Epoch 1633/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3727 - accuracy: 0.8350 - val_loss: 0.3480 - val_accuracy: 0.8485\n",
            "Epoch 1634/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3771 - accuracy: 0.8250 - val_loss: 0.3478 - val_accuracy: 0.8470\n",
            "Epoch 1635/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3794 - accuracy: 0.8250 - val_loss: 0.3477 - val_accuracy: 0.8480\n",
            "Epoch 1636/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3741 - accuracy: 0.8277 - val_loss: 0.3480 - val_accuracy: 0.8480\n",
            "Epoch 1637/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3783 - accuracy: 0.8297 - val_loss: 0.3478 - val_accuracy: 0.8470\n",
            "Epoch 1638/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3835 - accuracy: 0.8260 - val_loss: 0.3481 - val_accuracy: 0.8485\n",
            "Epoch 1639/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3803 - accuracy: 0.8280 - val_loss: 0.3479 - val_accuracy: 0.8475\n",
            "Epoch 1640/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3782 - accuracy: 0.8293 - val_loss: 0.3476 - val_accuracy: 0.8485\n",
            "Epoch 1641/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3772 - accuracy: 0.8267 - val_loss: 0.3475 - val_accuracy: 0.8470\n",
            "Epoch 1642/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8277 - val_loss: 0.3476 - val_accuracy: 0.8470\n",
            "Epoch 1643/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8273 - val_loss: 0.3478 - val_accuracy: 0.8460\n",
            "Epoch 1644/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3736 - accuracy: 0.8330 - val_loss: 0.3482 - val_accuracy: 0.8470\n",
            "Epoch 1645/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8287 - val_loss: 0.3480 - val_accuracy: 0.8450\n",
            "Epoch 1646/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.8307 - val_loss: 0.3479 - val_accuracy: 0.8470\n",
            "Epoch 1647/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3804 - accuracy: 0.8267 - val_loss: 0.3480 - val_accuracy: 0.8470\n",
            "Epoch 1648/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3768 - accuracy: 0.8263 - val_loss: 0.3483 - val_accuracy: 0.8475\n",
            "Epoch 1649/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8380 - val_loss: 0.3483 - val_accuracy: 0.8475\n",
            "Epoch 1650/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.8337 - val_loss: 0.3480 - val_accuracy: 0.8470\n",
            "Epoch 1651/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.8327 - val_loss: 0.3480 - val_accuracy: 0.8455\n",
            "Epoch 1652/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3839 - accuracy: 0.8263 - val_loss: 0.3481 - val_accuracy: 0.8470\n",
            "Epoch 1653/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8323 - val_loss: 0.3479 - val_accuracy: 0.8475\n",
            "Epoch 1654/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.8310 - val_loss: 0.3478 - val_accuracy: 0.8475\n",
            "Epoch 1655/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3786 - accuracy: 0.8280 - val_loss: 0.3480 - val_accuracy: 0.8460\n",
            "Epoch 1656/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3713 - accuracy: 0.8333 - val_loss: 0.3478 - val_accuracy: 0.8475\n",
            "Epoch 1657/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3801 - accuracy: 0.8307 - val_loss: 0.3481 - val_accuracy: 0.8485\n",
            "Epoch 1658/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3806 - accuracy: 0.8303 - val_loss: 0.3479 - val_accuracy: 0.8470\n",
            "Epoch 1659/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8297 - val_loss: 0.3480 - val_accuracy: 0.8475\n",
            "Epoch 1660/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3781 - accuracy: 0.8243 - val_loss: 0.3479 - val_accuracy: 0.8475\n",
            "Epoch 1661/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3737 - accuracy: 0.8327 - val_loss: 0.3481 - val_accuracy: 0.8465\n",
            "Epoch 1662/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3724 - accuracy: 0.8327 - val_loss: 0.3479 - val_accuracy: 0.8480\n",
            "Epoch 1663/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3708 - accuracy: 0.8390 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
            "Epoch 1664/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3788 - accuracy: 0.8267 - val_loss: 0.3479 - val_accuracy: 0.8455\n",
            "Epoch 1665/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.8307 - val_loss: 0.3481 - val_accuracy: 0.8445\n",
            "Epoch 1666/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3748 - accuracy: 0.8283 - val_loss: 0.3479 - val_accuracy: 0.8465\n",
            "Epoch 1667/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3743 - accuracy: 0.8310 - val_loss: 0.3481 - val_accuracy: 0.8480\n",
            "Epoch 1668/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3784 - accuracy: 0.8393 - val_loss: 0.3481 - val_accuracy: 0.8470\n",
            "Epoch 1669/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8353 - val_loss: 0.3481 - val_accuracy: 0.8465\n",
            "Epoch 1670/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3729 - accuracy: 0.8310 - val_loss: 0.3479 - val_accuracy: 0.8465\n",
            "Epoch 1671/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3805 - accuracy: 0.8333 - val_loss: 0.3476 - val_accuracy: 0.8465\n",
            "Epoch 1672/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3735 - accuracy: 0.8370 - val_loss: 0.3479 - val_accuracy: 0.8465\n",
            "Epoch 1673/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3789 - accuracy: 0.8287 - val_loss: 0.3479 - val_accuracy: 0.8465\n",
            "Epoch 1674/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3788 - accuracy: 0.8280 - val_loss: 0.3480 - val_accuracy: 0.8485\n",
            "Epoch 1675/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8293 - val_loss: 0.3482 - val_accuracy: 0.8465\n",
            "Epoch 1676/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3748 - accuracy: 0.8320 - val_loss: 0.3478 - val_accuracy: 0.8470\n",
            "Epoch 1677/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3785 - accuracy: 0.8307 - val_loss: 0.3478 - val_accuracy: 0.8465\n",
            "Epoch 1678/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8343 - val_loss: 0.3478 - val_accuracy: 0.8465\n",
            "Epoch 1679/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3818 - accuracy: 0.8310 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1680/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3798 - accuracy: 0.8303 - val_loss: 0.3476 - val_accuracy: 0.8470\n",
            "Epoch 1681/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3792 - accuracy: 0.8323 - val_loss: 0.3476 - val_accuracy: 0.8465\n",
            "Epoch 1682/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8317 - val_loss: 0.3477 - val_accuracy: 0.8485\n",
            "Epoch 1683/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.8323 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1684/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3817 - accuracy: 0.8263 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1685/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3745 - accuracy: 0.8367 - val_loss: 0.3477 - val_accuracy: 0.8480\n",
            "Epoch 1686/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3801 - accuracy: 0.8337 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1687/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.8277 - val_loss: 0.3478 - val_accuracy: 0.8480\n",
            "Epoch 1688/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3798 - accuracy: 0.8237 - val_loss: 0.3480 - val_accuracy: 0.8485\n",
            "Epoch 1689/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8263 - val_loss: 0.3480 - val_accuracy: 0.8470\n",
            "Epoch 1690/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3825 - accuracy: 0.8237 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
            "Epoch 1691/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3801 - accuracy: 0.8253 - val_loss: 0.3475 - val_accuracy: 0.8470\n",
            "Epoch 1692/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3818 - accuracy: 0.8280 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
            "Epoch 1693/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8303 - val_loss: 0.3478 - val_accuracy: 0.8460\n",
            "Epoch 1694/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.8370 - val_loss: 0.3476 - val_accuracy: 0.8475\n",
            "Epoch 1695/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3795 - accuracy: 0.8320 - val_loss: 0.3478 - val_accuracy: 0.8475\n",
            "Epoch 1696/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.8320 - val_loss: 0.3479 - val_accuracy: 0.8465\n",
            "Epoch 1697/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3710 - accuracy: 0.8390 - val_loss: 0.3477 - val_accuracy: 0.8465\n",
            "Epoch 1698/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3825 - accuracy: 0.8337 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1699/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3744 - accuracy: 0.8290 - val_loss: 0.3480 - val_accuracy: 0.8470\n",
            "Epoch 1700/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3674 - accuracy: 0.8360 - val_loss: 0.3481 - val_accuracy: 0.8490\n",
            "Epoch 1701/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3804 - accuracy: 0.8280 - val_loss: 0.3480 - val_accuracy: 0.8460\n",
            "Epoch 1702/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3744 - accuracy: 0.8330 - val_loss: 0.3481 - val_accuracy: 0.8460\n",
            "Epoch 1703/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3758 - accuracy: 0.8333 - val_loss: 0.3481 - val_accuracy: 0.8445\n",
            "Epoch 1704/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3764 - accuracy: 0.8303 - val_loss: 0.3480 - val_accuracy: 0.8460\n",
            "Epoch 1705/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3777 - accuracy: 0.8293 - val_loss: 0.3484 - val_accuracy: 0.8465\n",
            "Epoch 1706/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3778 - accuracy: 0.8367 - val_loss: 0.3483 - val_accuracy: 0.8475\n",
            "Epoch 1707/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8320 - val_loss: 0.3482 - val_accuracy: 0.8475\n",
            "Epoch 1708/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8303 - val_loss: 0.3478 - val_accuracy: 0.8485\n",
            "Epoch 1709/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.8293 - val_loss: 0.3476 - val_accuracy: 0.8475\n",
            "Epoch 1710/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3707 - accuracy: 0.8353 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
            "Epoch 1711/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3805 - accuracy: 0.8277 - val_loss: 0.3478 - val_accuracy: 0.8470\n",
            "Epoch 1712/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8337 - val_loss: 0.3477 - val_accuracy: 0.8485\n",
            "Epoch 1713/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3767 - accuracy: 0.8317 - val_loss: 0.3473 - val_accuracy: 0.8470\n",
            "Epoch 1714/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3784 - accuracy: 0.8310 - val_loss: 0.3474 - val_accuracy: 0.8475\n",
            "Epoch 1715/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8327 - val_loss: 0.3473 - val_accuracy: 0.8470\n",
            "Epoch 1716/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.8270 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
            "Epoch 1717/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3747 - accuracy: 0.8310 - val_loss: 0.3475 - val_accuracy: 0.8465\n",
            "Epoch 1718/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.8253 - val_loss: 0.3477 - val_accuracy: 0.8465\n",
            "Epoch 1719/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3778 - accuracy: 0.8357 - val_loss: 0.3476 - val_accuracy: 0.8455\n",
            "Epoch 1720/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3778 - accuracy: 0.8280 - val_loss: 0.3477 - val_accuracy: 0.8465\n",
            "Epoch 1721/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8290 - val_loss: 0.3479 - val_accuracy: 0.8465\n",
            "Epoch 1722/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3799 - accuracy: 0.8337 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1723/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3758 - accuracy: 0.8323 - val_loss: 0.3477 - val_accuracy: 0.8485\n",
            "Epoch 1724/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3745 - accuracy: 0.8327 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1725/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3746 - accuracy: 0.8343 - val_loss: 0.3476 - val_accuracy: 0.8475\n",
            "Epoch 1726/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3735 - accuracy: 0.8373 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1727/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3797 - accuracy: 0.8283 - val_loss: 0.3479 - val_accuracy: 0.8475\n",
            "Epoch 1728/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3781 - accuracy: 0.8267 - val_loss: 0.3478 - val_accuracy: 0.8450\n",
            "Epoch 1729/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8337 - val_loss: 0.3480 - val_accuracy: 0.8455\n",
            "Epoch 1730/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8320 - val_loss: 0.3481 - val_accuracy: 0.8475\n",
            "Epoch 1731/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8337 - val_loss: 0.3478 - val_accuracy: 0.8470\n",
            "Epoch 1732/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8293 - val_loss: 0.3481 - val_accuracy: 0.8465\n",
            "Epoch 1733/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3745 - accuracy: 0.8323 - val_loss: 0.3480 - val_accuracy: 0.8470\n",
            "Epoch 1734/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3781 - accuracy: 0.8370 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1735/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.8280 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1736/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8253 - val_loss: 0.3479 - val_accuracy: 0.8465\n",
            "Epoch 1737/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3782 - accuracy: 0.8330 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
            "Epoch 1738/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3758 - accuracy: 0.8327 - val_loss: 0.3474 - val_accuracy: 0.8465\n",
            "Epoch 1739/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.8260 - val_loss: 0.3477 - val_accuracy: 0.8460\n",
            "Epoch 1740/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3810 - accuracy: 0.8287 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1741/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8267 - val_loss: 0.3478 - val_accuracy: 0.8475\n",
            "Epoch 1742/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3742 - accuracy: 0.8370 - val_loss: 0.3478 - val_accuracy: 0.8445\n",
            "Epoch 1743/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3772 - accuracy: 0.8323 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1744/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3805 - accuracy: 0.8307 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
            "Epoch 1745/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3843 - accuracy: 0.8247 - val_loss: 0.3478 - val_accuracy: 0.8475\n",
            "Epoch 1746/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3713 - accuracy: 0.8403 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1747/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3794 - accuracy: 0.8320 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1748/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8283 - val_loss: 0.3474 - val_accuracy: 0.8480\n",
            "Epoch 1749/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3753 - accuracy: 0.8367 - val_loss: 0.3477 - val_accuracy: 0.8485\n",
            "Epoch 1750/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3804 - accuracy: 0.8240 - val_loss: 0.3478 - val_accuracy: 0.8465\n",
            "Epoch 1751/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3773 - accuracy: 0.8287 - val_loss: 0.3478 - val_accuracy: 0.8475\n",
            "Epoch 1752/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3799 - accuracy: 0.8260 - val_loss: 0.3476 - val_accuracy: 0.8480\n",
            "Epoch 1753/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3771 - accuracy: 0.8307 - val_loss: 0.3479 - val_accuracy: 0.8475\n",
            "Epoch 1754/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3730 - accuracy: 0.8337 - val_loss: 0.3479 - val_accuracy: 0.8475\n",
            "Epoch 1755/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3751 - accuracy: 0.8330 - val_loss: 0.3475 - val_accuracy: 0.8480\n",
            "Epoch 1756/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3812 - accuracy: 0.8263 - val_loss: 0.3473 - val_accuracy: 0.8475\n",
            "Epoch 1757/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3747 - accuracy: 0.8280 - val_loss: 0.3476 - val_accuracy: 0.8470\n",
            "Epoch 1758/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3768 - accuracy: 0.8340 - val_loss: 0.3475 - val_accuracy: 0.8485\n",
            "Epoch 1759/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3779 - accuracy: 0.8300 - val_loss: 0.3478 - val_accuracy: 0.8480\n",
            "Epoch 1760/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3756 - accuracy: 0.8307 - val_loss: 0.3474 - val_accuracy: 0.8465\n",
            "Epoch 1761/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3765 - accuracy: 0.8330 - val_loss: 0.3477 - val_accuracy: 0.8480\n",
            "Epoch 1762/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8347 - val_loss: 0.3479 - val_accuracy: 0.8485\n",
            "Epoch 1763/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3828 - accuracy: 0.8280 - val_loss: 0.3481 - val_accuracy: 0.8460\n",
            "Epoch 1764/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3739 - accuracy: 0.8367 - val_loss: 0.3481 - val_accuracy: 0.8465\n",
            "Epoch 1765/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3740 - accuracy: 0.8330 - val_loss: 0.3479 - val_accuracy: 0.8480\n",
            "Epoch 1766/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3792 - accuracy: 0.8347 - val_loss: 0.3479 - val_accuracy: 0.8485\n",
            "Epoch 1767/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3712 - accuracy: 0.8353 - val_loss: 0.3478 - val_accuracy: 0.8480\n",
            "Epoch 1768/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3765 - accuracy: 0.8263 - val_loss: 0.3478 - val_accuracy: 0.8470\n",
            "Epoch 1769/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3743 - accuracy: 0.8350 - val_loss: 0.3478 - val_accuracy: 0.8470\n",
            "Epoch 1770/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3793 - accuracy: 0.8287 - val_loss: 0.3479 - val_accuracy: 0.8455\n",
            "Epoch 1771/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3765 - accuracy: 0.8370 - val_loss: 0.3480 - val_accuracy: 0.8455\n",
            "Epoch 1772/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3831 - accuracy: 0.8303 - val_loss: 0.3479 - val_accuracy: 0.8475\n",
            "Epoch 1773/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3718 - accuracy: 0.8290 - val_loss: 0.3478 - val_accuracy: 0.8475\n",
            "Epoch 1774/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8327 - val_loss: 0.3475 - val_accuracy: 0.8485\n",
            "Epoch 1775/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3751 - accuracy: 0.8360 - val_loss: 0.3476 - val_accuracy: 0.8470\n",
            "Epoch 1776/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3808 - accuracy: 0.8317 - val_loss: 0.3474 - val_accuracy: 0.8460\n",
            "Epoch 1777/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3724 - accuracy: 0.8397 - val_loss: 0.3473 - val_accuracy: 0.8475\n",
            "Epoch 1778/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3799 - accuracy: 0.8287 - val_loss: 0.3475 - val_accuracy: 0.8455\n",
            "Epoch 1779/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3819 - accuracy: 0.8273 - val_loss: 0.3478 - val_accuracy: 0.8485\n",
            "Epoch 1780/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3791 - accuracy: 0.8253 - val_loss: 0.3478 - val_accuracy: 0.8470\n",
            "Epoch 1781/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3819 - accuracy: 0.8297 - val_loss: 0.3478 - val_accuracy: 0.8460\n",
            "Epoch 1782/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3781 - accuracy: 0.8300 - val_loss: 0.3480 - val_accuracy: 0.8455\n",
            "Epoch 1783/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3715 - accuracy: 0.8347 - val_loss: 0.3477 - val_accuracy: 0.8465\n",
            "Epoch 1784/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8303 - val_loss: 0.3476 - val_accuracy: 0.8455\n",
            "Epoch 1785/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3791 - accuracy: 0.8317 - val_loss: 0.3477 - val_accuracy: 0.8450\n",
            "Epoch 1786/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3779 - accuracy: 0.8293 - val_loss: 0.3475 - val_accuracy: 0.8470\n",
            "Epoch 1787/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.8267 - val_loss: 0.3478 - val_accuracy: 0.8490\n",
            "Epoch 1788/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8293 - val_loss: 0.3476 - val_accuracy: 0.8485\n",
            "Epoch 1789/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3783 - accuracy: 0.8263 - val_loss: 0.3475 - val_accuracy: 0.8470\n",
            "Epoch 1790/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8270 - val_loss: 0.3476 - val_accuracy: 0.8465\n",
            "Epoch 1791/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3768 - accuracy: 0.8330 - val_loss: 0.3474 - val_accuracy: 0.8480\n",
            "Epoch 1792/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3815 - accuracy: 0.8283 - val_loss: 0.3476 - val_accuracy: 0.8450\n",
            "Epoch 1793/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8303 - val_loss: 0.3476 - val_accuracy: 0.8475\n",
            "Epoch 1794/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8300 - val_loss: 0.3475 - val_accuracy: 0.8480\n",
            "Epoch 1795/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8353 - val_loss: 0.3474 - val_accuracy: 0.8465\n",
            "Epoch 1796/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.8253 - val_loss: 0.3475 - val_accuracy: 0.8455\n",
            "Epoch 1797/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3755 - accuracy: 0.8310 - val_loss: 0.3476 - val_accuracy: 0.8450\n",
            "Epoch 1798/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3787 - accuracy: 0.8300 - val_loss: 0.3478 - val_accuracy: 0.8460\n",
            "Epoch 1799/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.8280 - val_loss: 0.3477 - val_accuracy: 0.8465\n",
            "Epoch 1800/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.8327 - val_loss: 0.3476 - val_accuracy: 0.8455\n",
            "Epoch 1801/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3791 - accuracy: 0.8347 - val_loss: 0.3477 - val_accuracy: 0.8460\n",
            "Epoch 1802/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3804 - accuracy: 0.8347 - val_loss: 0.3477 - val_accuracy: 0.8450\n",
            "Epoch 1803/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3791 - accuracy: 0.8300 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
            "Epoch 1804/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8320 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1805/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3737 - accuracy: 0.8353 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1806/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8350 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1807/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8310 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
            "Epoch 1808/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3839 - accuracy: 0.8213 - val_loss: 0.3475 - val_accuracy: 0.8470\n",
            "Epoch 1809/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3738 - accuracy: 0.8343 - val_loss: 0.3474 - val_accuracy: 0.8460\n",
            "Epoch 1810/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3752 - accuracy: 0.8350 - val_loss: 0.3474 - val_accuracy: 0.8475\n",
            "Epoch 1811/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.8270 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1812/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3782 - accuracy: 0.8263 - val_loss: 0.3476 - val_accuracy: 0.8475\n",
            "Epoch 1813/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8373 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1814/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3767 - accuracy: 0.8270 - val_loss: 0.3480 - val_accuracy: 0.8485\n",
            "Epoch 1815/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3798 - accuracy: 0.8240 - val_loss: 0.3478 - val_accuracy: 0.8490\n",
            "Epoch 1816/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3752 - accuracy: 0.8333 - val_loss: 0.3479 - val_accuracy: 0.8480\n",
            "Epoch 1817/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8320 - val_loss: 0.3479 - val_accuracy: 0.8480\n",
            "Epoch 1818/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.8337 - val_loss: 0.3478 - val_accuracy: 0.8465\n",
            "Epoch 1819/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3763 - accuracy: 0.8327 - val_loss: 0.3476 - val_accuracy: 0.8465\n",
            "Epoch 1820/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8277 - val_loss: 0.3476 - val_accuracy: 0.8465\n",
            "Epoch 1821/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8313 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
            "Epoch 1822/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.8293 - val_loss: 0.3479 - val_accuracy: 0.8475\n",
            "Epoch 1823/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8333 - val_loss: 0.3478 - val_accuracy: 0.8460\n",
            "Epoch 1824/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3761 - accuracy: 0.8307 - val_loss: 0.3480 - val_accuracy: 0.8480\n",
            "Epoch 1825/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3762 - accuracy: 0.8303 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
            "Epoch 1826/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3695 - accuracy: 0.8353 - val_loss: 0.3477 - val_accuracy: 0.8455\n",
            "Epoch 1827/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.8303 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1828/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3757 - accuracy: 0.8327 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1829/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3803 - accuracy: 0.8283 - val_loss: 0.3475 - val_accuracy: 0.8470\n",
            "Epoch 1830/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3835 - accuracy: 0.8283 - val_loss: 0.3477 - val_accuracy: 0.8465\n",
            "Epoch 1831/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.8333 - val_loss: 0.3478 - val_accuracy: 0.8470\n",
            "Epoch 1832/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3743 - accuracy: 0.8300 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
            "Epoch 1833/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3698 - accuracy: 0.8360 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1834/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8357 - val_loss: 0.3475 - val_accuracy: 0.8470\n",
            "Epoch 1835/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3730 - accuracy: 0.8347 - val_loss: 0.3475 - val_accuracy: 0.8475\n",
            "Epoch 1836/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.8277 - val_loss: 0.3476 - val_accuracy: 0.8485\n",
            "Epoch 1837/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8340 - val_loss: 0.3476 - val_accuracy: 0.8480\n",
            "Epoch 1838/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3723 - accuracy: 0.8333 - val_loss: 0.3476 - val_accuracy: 0.8475\n",
            "Epoch 1839/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8323 - val_loss: 0.3476 - val_accuracy: 0.8475\n",
            "Epoch 1840/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8310 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1841/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3771 - accuracy: 0.8287 - val_loss: 0.3478 - val_accuracy: 0.8470\n",
            "Epoch 1842/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8390 - val_loss: 0.3478 - val_accuracy: 0.8480\n",
            "Epoch 1843/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3720 - accuracy: 0.8347 - val_loss: 0.3479 - val_accuracy: 0.8475\n",
            "Epoch 1844/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.8343 - val_loss: 0.3481 - val_accuracy: 0.8460\n",
            "Epoch 1845/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3841 - accuracy: 0.8240 - val_loss: 0.3476 - val_accuracy: 0.8470\n",
            "Epoch 1846/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3831 - accuracy: 0.8240 - val_loss: 0.3473 - val_accuracy: 0.8475\n",
            "Epoch 1847/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3730 - accuracy: 0.8337 - val_loss: 0.3476 - val_accuracy: 0.8475\n",
            "Epoch 1848/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8250 - val_loss: 0.3478 - val_accuracy: 0.8455\n",
            "Epoch 1849/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3802 - accuracy: 0.8323 - val_loss: 0.3473 - val_accuracy: 0.8470\n",
            "Epoch 1850/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3742 - accuracy: 0.8317 - val_loss: 0.3476 - val_accuracy: 0.8470\n",
            "Epoch 1851/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8323 - val_loss: 0.3474 - val_accuracy: 0.8455\n",
            "Epoch 1852/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3757 - accuracy: 0.8363 - val_loss: 0.3475 - val_accuracy: 0.8475\n",
            "Epoch 1853/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3741 - accuracy: 0.8360 - val_loss: 0.3474 - val_accuracy: 0.8475\n",
            "Epoch 1854/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.8330 - val_loss: 0.3474 - val_accuracy: 0.8475\n",
            "Epoch 1855/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.8263 - val_loss: 0.3473 - val_accuracy: 0.8460\n",
            "Epoch 1856/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8273 - val_loss: 0.3475 - val_accuracy: 0.8475\n",
            "Epoch 1857/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3724 - accuracy: 0.8310 - val_loss: 0.3475 - val_accuracy: 0.8465\n",
            "Epoch 1858/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.8350 - val_loss: 0.3475 - val_accuracy: 0.8470\n",
            "Epoch 1859/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3806 - accuracy: 0.8280 - val_loss: 0.3476 - val_accuracy: 0.8470\n",
            "Epoch 1860/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3789 - accuracy: 0.8290 - val_loss: 0.3474 - val_accuracy: 0.8465\n",
            "Epoch 1861/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8253 - val_loss: 0.3474 - val_accuracy: 0.8460\n",
            "Epoch 1862/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.8323 - val_loss: 0.3475 - val_accuracy: 0.8470\n",
            "Epoch 1863/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3737 - accuracy: 0.8370 - val_loss: 0.3477 - val_accuracy: 0.8485\n",
            "Epoch 1864/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8350 - val_loss: 0.3477 - val_accuracy: 0.8485\n",
            "Epoch 1865/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8327 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1866/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3786 - accuracy: 0.8310 - val_loss: 0.3476 - val_accuracy: 0.8445\n",
            "Epoch 1867/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.8310 - val_loss: 0.3474 - val_accuracy: 0.8465\n",
            "Epoch 1868/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3790 - accuracy: 0.8327 - val_loss: 0.3476 - val_accuracy: 0.8470\n",
            "Epoch 1869/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8307 - val_loss: 0.3476 - val_accuracy: 0.8485\n",
            "Epoch 1870/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3728 - accuracy: 0.8337 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1871/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8290 - val_loss: 0.3474 - val_accuracy: 0.8460\n",
            "Epoch 1872/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3749 - accuracy: 0.8310 - val_loss: 0.3473 - val_accuracy: 0.8455\n",
            "Epoch 1873/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3773 - accuracy: 0.8363 - val_loss: 0.3472 - val_accuracy: 0.8475\n",
            "Epoch 1874/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3774 - accuracy: 0.8320 - val_loss: 0.3476 - val_accuracy: 0.8485\n",
            "Epoch 1875/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8273 - val_loss: 0.3476 - val_accuracy: 0.8470\n",
            "Epoch 1876/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.8290 - val_loss: 0.3476 - val_accuracy: 0.8445\n",
            "Epoch 1877/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.8297 - val_loss: 0.3476 - val_accuracy: 0.8445\n",
            "Epoch 1878/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3802 - accuracy: 0.8307 - val_loss: 0.3474 - val_accuracy: 0.8455\n",
            "Epoch 1879/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3729 - accuracy: 0.8307 - val_loss: 0.3476 - val_accuracy: 0.8465\n",
            "Epoch 1880/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3710 - accuracy: 0.8320 - val_loss: 0.3475 - val_accuracy: 0.8485\n",
            "Epoch 1881/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8273 - val_loss: 0.3477 - val_accuracy: 0.8465\n",
            "Epoch 1882/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.8313 - val_loss: 0.3479 - val_accuracy: 0.8465\n",
            "Epoch 1883/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8327 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
            "Epoch 1884/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3801 - accuracy: 0.8317 - val_loss: 0.3477 - val_accuracy: 0.8465\n",
            "Epoch 1885/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8320 - val_loss: 0.3477 - val_accuracy: 0.8450\n",
            "Epoch 1886/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8270 - val_loss: 0.3478 - val_accuracy: 0.8450\n",
            "Epoch 1887/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3782 - accuracy: 0.8310 - val_loss: 0.3477 - val_accuracy: 0.8480\n",
            "Epoch 1888/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.8300 - val_loss: 0.3475 - val_accuracy: 0.8450\n",
            "Epoch 1889/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.8267 - val_loss: 0.3475 - val_accuracy: 0.8475\n",
            "Epoch 1890/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3718 - accuracy: 0.8357 - val_loss: 0.3475 - val_accuracy: 0.8460\n",
            "Epoch 1891/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.8273 - val_loss: 0.3478 - val_accuracy: 0.8465\n",
            "Epoch 1892/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3740 - accuracy: 0.8310 - val_loss: 0.3476 - val_accuracy: 0.8465\n",
            "Epoch 1893/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3764 - accuracy: 0.8327 - val_loss: 0.3476 - val_accuracy: 0.8475\n",
            "Epoch 1894/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3771 - accuracy: 0.8293 - val_loss: 0.3474 - val_accuracy: 0.8480\n",
            "Epoch 1895/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3791 - accuracy: 0.8293 - val_loss: 0.3474 - val_accuracy: 0.8465\n",
            "Epoch 1896/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3776 - accuracy: 0.8340 - val_loss: 0.3475 - val_accuracy: 0.8470\n",
            "Epoch 1897/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3773 - accuracy: 0.8283 - val_loss: 0.3474 - val_accuracy: 0.8470\n",
            "Epoch 1898/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3728 - accuracy: 0.8287 - val_loss: 0.3473 - val_accuracy: 0.8460\n",
            "Epoch 1899/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.8340 - val_loss: 0.3473 - val_accuracy: 0.8450\n",
            "Epoch 1900/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.8277 - val_loss: 0.3475 - val_accuracy: 0.8470\n",
            "Epoch 1901/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3802 - accuracy: 0.8283 - val_loss: 0.3474 - val_accuracy: 0.8475\n",
            "Epoch 1902/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3785 - accuracy: 0.8287 - val_loss: 0.3475 - val_accuracy: 0.8465\n",
            "Epoch 1903/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3784 - accuracy: 0.8337 - val_loss: 0.3477 - val_accuracy: 0.8465\n",
            "Epoch 1904/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3815 - accuracy: 0.8250 - val_loss: 0.3476 - val_accuracy: 0.8455\n",
            "Epoch 1905/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3800 - accuracy: 0.8263 - val_loss: 0.3476 - val_accuracy: 0.8465\n",
            "Epoch 1906/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3744 - accuracy: 0.8263 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
            "Epoch 1907/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3777 - accuracy: 0.8297 - val_loss: 0.3477 - val_accuracy: 0.8445\n",
            "Epoch 1908/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3809 - accuracy: 0.8290 - val_loss: 0.3479 - val_accuracy: 0.8450\n",
            "Epoch 1909/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.8243 - val_loss: 0.3479 - val_accuracy: 0.8455\n",
            "Epoch 1910/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3751 - accuracy: 0.8323 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
            "Epoch 1911/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3857 - accuracy: 0.8223 - val_loss: 0.3476 - val_accuracy: 0.8470\n",
            "Epoch 1912/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3758 - accuracy: 0.8283 - val_loss: 0.3475 - val_accuracy: 0.8460\n",
            "Epoch 1913/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3714 - accuracy: 0.8313 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
            "Epoch 1914/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3781 - accuracy: 0.8247 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1915/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3756 - accuracy: 0.8303 - val_loss: 0.3478 - val_accuracy: 0.8465\n",
            "Epoch 1916/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3790 - accuracy: 0.8277 - val_loss: 0.3479 - val_accuracy: 0.8475\n",
            "Epoch 1917/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.8297 - val_loss: 0.3478 - val_accuracy: 0.8465\n",
            "Epoch 1918/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3717 - accuracy: 0.8373 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
            "Epoch 1919/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3797 - accuracy: 0.8263 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1920/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3833 - accuracy: 0.8280 - val_loss: 0.3477 - val_accuracy: 0.8480\n",
            "Epoch 1921/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3815 - accuracy: 0.8313 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1922/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3812 - accuracy: 0.8267 - val_loss: 0.3479 - val_accuracy: 0.8455\n",
            "Epoch 1923/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.8287 - val_loss: 0.3481 - val_accuracy: 0.8430\n",
            "Epoch 1924/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8310 - val_loss: 0.3478 - val_accuracy: 0.8460\n",
            "Epoch 1925/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3743 - accuracy: 0.8340 - val_loss: 0.3475 - val_accuracy: 0.8460\n",
            "Epoch 1926/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8400 - val_loss: 0.3477 - val_accuracy: 0.8460\n",
            "Epoch 1927/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3674 - accuracy: 0.8367 - val_loss: 0.3479 - val_accuracy: 0.8465\n",
            "Epoch 1928/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8307 - val_loss: 0.3477 - val_accuracy: 0.8460\n",
            "Epoch 1929/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3671 - accuracy: 0.8293 - val_loss: 0.3475 - val_accuracy: 0.8455\n",
            "Epoch 1930/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3678 - accuracy: 0.8317 - val_loss: 0.3475 - val_accuracy: 0.8460\n",
            "Epoch 1931/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3801 - accuracy: 0.8280 - val_loss: 0.3478 - val_accuracy: 0.8465\n",
            "Epoch 1932/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3690 - accuracy: 0.8343 - val_loss: 0.3477 - val_accuracy: 0.8455\n",
            "Epoch 1933/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3743 - accuracy: 0.8300 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
            "Epoch 1934/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8267 - val_loss: 0.3475 - val_accuracy: 0.8445\n",
            "Epoch 1935/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3767 - accuracy: 0.8290 - val_loss: 0.3476 - val_accuracy: 0.8450\n",
            "Epoch 1936/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8353 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
            "Epoch 1937/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.8280 - val_loss: 0.3475 - val_accuracy: 0.8470\n",
            "Epoch 1938/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3706 - accuracy: 0.8330 - val_loss: 0.3477 - val_accuracy: 0.8475\n",
            "Epoch 1939/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3800 - accuracy: 0.8300 - val_loss: 0.3479 - val_accuracy: 0.8475\n",
            "Epoch 1940/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.8293 - val_loss: 0.3476 - val_accuracy: 0.8475\n",
            "Epoch 1941/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.8343 - val_loss: 0.3477 - val_accuracy: 0.8455\n",
            "Epoch 1942/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3769 - accuracy: 0.8313 - val_loss: 0.3478 - val_accuracy: 0.8455\n",
            "Epoch 1943/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8327 - val_loss: 0.3475 - val_accuracy: 0.8465\n",
            "Epoch 1944/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.8233 - val_loss: 0.3475 - val_accuracy: 0.8475\n",
            "Epoch 1945/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3774 - accuracy: 0.8297 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1946/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3802 - accuracy: 0.8317 - val_loss: 0.3481 - val_accuracy: 0.8465\n",
            "Epoch 1947/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3843 - accuracy: 0.8287 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
            "Epoch 1948/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8330 - val_loss: 0.3476 - val_accuracy: 0.8465\n",
            "Epoch 1949/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8340 - val_loss: 0.3475 - val_accuracy: 0.8440\n",
            "Epoch 1950/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8363 - val_loss: 0.3473 - val_accuracy: 0.8470\n",
            "Epoch 1951/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3734 - accuracy: 0.8317 - val_loss: 0.3473 - val_accuracy: 0.8470\n",
            "Epoch 1952/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8320 - val_loss: 0.3473 - val_accuracy: 0.8465\n",
            "Epoch 1953/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8307 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
            "Epoch 1954/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3740 - accuracy: 0.8323 - val_loss: 0.3480 - val_accuracy: 0.8460\n",
            "Epoch 1955/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8280 - val_loss: 0.3477 - val_accuracy: 0.8455\n",
            "Epoch 1956/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8340 - val_loss: 0.3478 - val_accuracy: 0.8460\n",
            "Epoch 1957/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3768 - accuracy: 0.8303 - val_loss: 0.3480 - val_accuracy: 0.8445\n",
            "Epoch 1958/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.8250 - val_loss: 0.3483 - val_accuracy: 0.8445\n",
            "Epoch 1959/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8323 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1960/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3755 - accuracy: 0.8287 - val_loss: 0.3478 - val_accuracy: 0.8465\n",
            "Epoch 1961/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.8300 - val_loss: 0.3478 - val_accuracy: 0.8460\n",
            "Epoch 1962/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8317 - val_loss: 0.3476 - val_accuracy: 0.8465\n",
            "Epoch 1963/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8323 - val_loss: 0.3474 - val_accuracy: 0.8480\n",
            "Epoch 1964/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8210 - val_loss: 0.3475 - val_accuracy: 0.8480\n",
            "Epoch 1965/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8303 - val_loss: 0.3480 - val_accuracy: 0.8480\n",
            "Epoch 1966/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3731 - accuracy: 0.8343 - val_loss: 0.3477 - val_accuracy: 0.8460\n",
            "Epoch 1967/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3722 - accuracy: 0.8317 - val_loss: 0.3475 - val_accuracy: 0.8470\n",
            "Epoch 1968/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8330 - val_loss: 0.3474 - val_accuracy: 0.8455\n",
            "Epoch 1969/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8263 - val_loss: 0.3473 - val_accuracy: 0.8450\n",
            "Epoch 1970/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8333 - val_loss: 0.3474 - val_accuracy: 0.8470\n",
            "Epoch 1971/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.8323 - val_loss: 0.3477 - val_accuracy: 0.8455\n",
            "Epoch 1972/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3831 - accuracy: 0.8257 - val_loss: 0.3478 - val_accuracy: 0.8465\n",
            "Epoch 1973/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8380 - val_loss: 0.3477 - val_accuracy: 0.8470\n",
            "Epoch 1974/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8313 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
            "Epoch 1975/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3751 - accuracy: 0.8343 - val_loss: 0.3480 - val_accuracy: 0.8455\n",
            "Epoch 1976/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3755 - accuracy: 0.8347 - val_loss: 0.3480 - val_accuracy: 0.8455\n",
            "Epoch 1977/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3752 - accuracy: 0.8337 - val_loss: 0.3478 - val_accuracy: 0.8470\n",
            "Epoch 1978/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8370 - val_loss: 0.3478 - val_accuracy: 0.8460\n",
            "Epoch 1979/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.8313 - val_loss: 0.3479 - val_accuracy: 0.8460\n",
            "Epoch 1980/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3735 - accuracy: 0.8323 - val_loss: 0.3481 - val_accuracy: 0.8460\n",
            "Epoch 1981/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3794 - accuracy: 0.8307 - val_loss: 0.3481 - val_accuracy: 0.8460\n",
            "Epoch 1982/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3774 - accuracy: 0.8313 - val_loss: 0.3478 - val_accuracy: 0.8465\n",
            "Epoch 1983/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3756 - accuracy: 0.8290 - val_loss: 0.3476 - val_accuracy: 0.8455\n",
            "Epoch 1984/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8313 - val_loss: 0.3475 - val_accuracy: 0.8450\n",
            "Epoch 1985/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3745 - accuracy: 0.8313 - val_loss: 0.3475 - val_accuracy: 0.8455\n",
            "Epoch 1986/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3722 - accuracy: 0.8357 - val_loss: 0.3475 - val_accuracy: 0.8460\n",
            "Epoch 1987/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3763 - accuracy: 0.8337 - val_loss: 0.3474 - val_accuracy: 0.8460\n",
            "Epoch 1988/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3819 - accuracy: 0.8283 - val_loss: 0.3477 - val_accuracy: 0.8450\n",
            "Epoch 1989/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3750 - accuracy: 0.8320 - val_loss: 0.3474 - val_accuracy: 0.8440\n",
            "Epoch 1990/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8310 - val_loss: 0.3478 - val_accuracy: 0.8460\n",
            "Epoch 1991/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3747 - accuracy: 0.8290 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
            "Epoch 1992/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8253 - val_loss: 0.3478 - val_accuracy: 0.8465\n",
            "Epoch 1993/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8310 - val_loss: 0.3482 - val_accuracy: 0.8445\n",
            "Epoch 1994/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3753 - accuracy: 0.8260 - val_loss: 0.3480 - val_accuracy: 0.8465\n",
            "Epoch 1995/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3770 - accuracy: 0.8303 - val_loss: 0.3480 - val_accuracy: 0.8455\n",
            "Epoch 1996/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3886 - accuracy: 0.8263 - val_loss: 0.3481 - val_accuracy: 0.8450\n",
            "Epoch 1997/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8293 - val_loss: 0.3480 - val_accuracy: 0.8470\n",
            "Epoch 1998/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3694 - accuracy: 0.8370 - val_loss: 0.3478 - val_accuracy: 0.8445\n",
            "Epoch 1999/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3762 - accuracy: 0.8317 - val_loss: 0.3478 - val_accuracy: 0.8455\n",
            "Epoch 2000/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3800 - accuracy: 0.8293 - val_loss: 0.3478 - val_accuracy: 0.8470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Loss"
      ],
      "metadata": {
        "id": "CqIILuSC4UkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = go.Scatter(y=his.history['loss'],\n",
        "                    mode=\"lines\",\n",
        "                    line=dict(\n",
        "                        width=2,\n",
        "                        color='blue'),\n",
        "                        name=\"loss\"\n",
        "                   )\n",
        "h2 = go.Scatter(y=his.history['val_loss'],\n",
        "                    mode=\"lines\",\n",
        "                    line=dict(\n",
        "                        width=2,\n",
        "                        color='red'),\n",
        "                        name=\"val_loss\"\n",
        "                   )\n",
        "\n",
        "data = [h1,h2]\n",
        "layout1 = go.Layout(title='Loss',\n",
        "                   xaxis=dict(title='epochs'),\n",
        "                   yaxis=dict(title=''))\n",
        "fig1 = go.Figure(data = data, layout=layout1)\n",
        "plotly.offline.iplot(fig1)"
      ],
      "metadata": {
        "id": "HoA9srg04Vp-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "add9ba0c-7091-4dec-a870-af6da3b5cddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"b8132e6c-7043-450d-861f-ed521b86502e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b8132e6c-7043-450d-861f-ed521b86502e\")) {                    Plotly.newPlot(                        \"b8132e6c-7043-450d-861f-ed521b86502e\",                        [{\"line\":{\"color\":\"blue\",\"width\":2},\"mode\":\"lines\",\"name\":\"loss\",\"y\":[0.7355189323425293,0.7214465141296387,0.7022424936294556,0.6982419490814209,0.6948774456977844,0.6831111907958984,0.6819565892219543,0.6764553785324097,0.6720706224441528,0.6676276326179504,0.6644225120544434,0.6636517643928528,0.6593940258026123,0.6528941988945007,0.6524242162704468,0.6502023935317993,0.6437194347381592,0.6428540349006653,0.6389721035957336,0.6376029253005981,0.6322422027587891,0.6319383382797241,0.6295207738876343,0.6299408674240112,0.6216124296188354,0.623478353023529,0.6169548034667969,0.6197528839111328,0.6110802292823792,0.608184814453125,0.6083153486251831,0.608542263507843,0.6031948924064636,0.6017447710037231,0.591685950756073,0.6011317372322083,0.6010746955871582,0.589435338973999,0.5917396545410156,0.585594117641449,0.583331823348999,0.5820373296737671,0.5828981399536133,0.5794899463653564,0.5790619850158691,0.5695461630821228,0.5741961002349854,0.5720738768577576,0.5682186484336853,0.5671014189720154,0.566282331943512,0.5664907097816467,0.5601568818092346,0.5610294938087463,0.5562989711761475,0.5539222955703735,0.5586115121841431,0.5557613372802734,0.550443708896637,0.5461550951004028,0.5501124858856201,0.5430935025215149,0.5512874126434326,0.5476909279823303,0.5418060421943665,0.5443568825721741,0.5384936332702637,0.5388116836547852,0.5410133600234985,0.5272371768951416,0.5376124978065491,0.5321378707885742,0.5384073257446289,0.5294845104217529,0.5307091474533081,0.5253987908363342,0.5239338278770447,0.5258579850196838,0.5194034576416016,0.518727719783783,0.5143802762031555,0.5243757963180542,0.5198079347610474,0.5174350142478943,0.5127596259117126,0.5176995992660522,0.5181534290313721,0.5135239362716675,0.5114250779151917,0.5132671594619751,0.518471896648407,0.5189839005470276,0.506022572517395,0.5094785094261169,0.515311062335968,0.5056647062301636,0.509275496006012,0.5037645101547241,0.5070873498916626,0.4993411898612976,0.5041131377220154,0.5010490417480469,0.4965084493160248,0.4987885057926178,0.4947241544723511,0.4952624440193176,0.4997638463973999,0.49655166268348694,0.48731356859207153,0.5073539018630981,0.49865445494651794,0.49312567710876465,0.4928980767726898,0.4800827205181122,0.4965740144252777,0.49134305119514465,0.4862670600414276,0.4873479902744293,0.484325647354126,0.4842830300331116,0.48690950870513916,0.48292219638824463,0.4756234884262085,0.4891916811466217,0.48334431648254395,0.48441556096076965,0.48508983850479126,0.48561760783195496,0.47498539090156555,0.47669827938079834,0.48696228861808777,0.4739513695240021,0.48001936078071594,0.47805628180503845,0.46770179271698,0.47358280420303345,0.4845452606678009,0.4755629897117615,0.47098827362060547,0.4703713655471802,0.46998998522758484,0.47482502460479736,0.4699934124946594,0.47353070974349976,0.4680262804031372,0.46876201033592224,0.46956485509872437,0.46130046248435974,0.46517813205718994,0.46385523676872253,0.47088325023651123,0.4642930030822754,0.4675934314727783,0.4648253619670868,0.46592092514038086,0.4647331237792969,0.46665483713150024,0.4595089256763458,0.46311482787132263,0.45652535557746887,0.4492514729499817,0.4568324685096741,0.4508533477783203,0.45847705006599426,0.46159765124320984,0.44903644919395447,0.451754629611969,0.4553176164627075,0.4606079161167145,0.450950026512146,0.45749202370643616,0.45685794949531555,0.4507775902748108,0.45360490679740906,0.45302361249923706,0.4532356858253479,0.45097437500953674,0.4452832043170929,0.4490276277065277,0.4451903998851776,0.45025452971458435,0.45013585686683655,0.4573453664779663,0.4447464644908905,0.4394609034061432,0.44083285331726074,0.44969630241394043,0.4434179663658142,0.45050573348999023,0.4461134374141693,0.4484761655330658,0.44922706484794617,0.453023761510849,0.44108080863952637,0.43863895535469055,0.4460204541683197,0.4427071213722229,0.44356077909469604,0.43950480222702026,0.4382479786872864,0.4376819133758545,0.4334256947040558,0.4432046711444855,0.447557657957077,0.4324505925178528,0.43371039628982544,0.4431208372116089,0.42683324217796326,0.436196893453598,0.4419502019882202,0.4355506896972656,0.4364386796951294,0.4434088468551636,0.44066160917282104,0.4355736970901489,0.4387827515602112,0.4332791864871979,0.43552669882774353,0.43476253747940063,0.4356837272644043,0.4319831430912018,0.433472216129303,0.42894285917282104,0.43604081869125366,0.4289678931236267,0.4301324784755707,0.4366188049316406,0.4207279086112976,0.4286014437675476,0.42574334144592285,0.4306850731372833,0.4212827980518341,0.4238004684448242,0.42731723189353943,0.43128952383995056,0.43068620562553406,0.4318282902240753,0.42689529061317444,0.4252125322818756,0.42662179470062256,0.42869833111763,0.4240270256996155,0.42826107144355774,0.42967015504837036,0.42475324869155884,0.4225177764892578,0.43324294686317444,0.4221700429916382,0.4222296476364136,0.42647042870521545,0.43006637692451477,0.4178747534751892,0.4296739399433136,0.42336148023605347,0.418172150850296,0.42340192198753357,0.420718789100647,0.42506253719329834,0.421499103307724,0.41831859946250916,0.41085901856422424,0.4288861155509949,0.41928747296333313,0.4230862557888031,0.4186376929283142,0.42650580406188965,0.4220799505710602,0.41283154487609863,0.4214550256729126,0.4169086813926697,0.412019819021225,0.4222659170627594,0.4222119450569153,0.420104444026947,0.4160515069961548,0.41788533329963684,0.4137709438800812,0.41567277908325195,0.4191855192184448,0.42051419615745544,0.421499103307724,0.41099780797958374,0.41289013624191284,0.4126109480857849,0.41340917348861694,0.41727742552757263,0.41235172748565674,0.41441643238067627,0.4106377065181732,0.41687750816345215,0.410917192697525,0.41901203989982605,0.40991881489753723,0.41903698444366455,0.4078601896762848,0.4189566373825073,0.4206005334854126,0.417397141456604,0.4076358675956726,0.4093274474143982,0.4072568714618683,0.4061334729194641,0.4137609899044037,0.40687263011932373,0.4084435999393463,0.41776424646377563,0.40872135758399963,0.4133281111717224,0.41166773438453674,0.41516122221946716,0.4145289659500122,0.4071776568889618,0.4028720557689667,0.415985107421875,0.4068925678730011,0.4130772650241852,0.40240782499313354,0.4126880168914795,0.4083268940448761,0.4156686067581177,0.41184931993484497,0.41122305393218994,0.40760478377342224,0.4104655385017395,0.41128939390182495,0.40262606739997864,0.4195080101490021,0.40960773825645447,0.4048374891281128,0.41357937455177307,0.4070207476615906,0.4086875021457672,0.4114808440208435,0.397746741771698,0.40266478061676025,0.40460485219955444,0.40992918610572815,0.4103453457355499,0.4145531952381134,0.41477373242378235,0.4106414318084717,0.4055826961994171,0.4109576344490051,0.4096739888191223,0.4124085307121277,0.4117792844772339,0.4071038067340851,0.4003254771232605,0.40976110100746155,0.39803919196128845,0.3968006670475006,0.3968014419078827,0.4011901319026947,0.4156840741634369,0.4076260030269623,0.40901777148246765,0.40375667810440063,0.41258031129837036,0.39893949031829834,0.4061889350414276,0.39943376183509827,0.4007030725479126,0.3979543447494507,0.4127826690673828,0.4033997356891632,0.40244510769844055,0.4049068093299866,0.408547580242157,0.4042799472808838,0.4037548303604126,0.4065518379211426,0.4121340215206146,0.4067096412181854,0.4012274146080017,0.39569082856178284,0.40690600872039795,0.4098226726055145,0.40839383006095886,0.3990537226200104,0.40718480944633484,0.39804500341415405,0.39945748448371887,0.40707501769065857,0.4022475481033325,0.3971276879310608,0.39785054326057434,0.4035186767578125,0.4059500992298126,0.39981287717819214,0.4024765193462372,0.3942932188510895,0.39571431279182434,0.40764108300209045,0.40434542298316956,0.406259149312973,0.4046654999256134,0.4000336229801178,0.4024656116962433,0.4049445390701294,0.39550793170928955,0.3989969491958618,0.3950084149837494,0.3921230137348175,0.39306527376174927,0.3957844376564026,0.39391854405403137,0.3978058695793152,0.3989352285861969,0.4039294719696045,0.40195903182029724,0.40028077363967896,0.40144795179367065,0.389169842004776,0.4004457890987396,0.39607617259025574,0.4087062180042267,0.3962474763393402,0.3963637351989746,0.39542654156684875,0.4007315933704376,0.4001844525337219,0.3986016809940338,0.3981243968009949,0.4030223488807678,0.4069911241531372,0.40378907322883606,0.4037698209285736,0.4022845923900604,0.4002649784088135,0.40266352891921997,0.39031895995140076,0.397316038608551,0.39268457889556885,0.3945610225200653,0.39711737632751465,0.3956727385520935,0.4090281128883362,0.3956144154071808,0.4029091000556946,0.3996623158454895,0.3992916941642761,0.3983067572116852,0.3953057825565338,0.3928515613079071,0.3940841555595398,0.3989792466163635,0.39660418033599854,0.395711749792099,0.402626633644104,0.39842215180397034,0.39164620637893677,0.39481016993522644,0.389606237411499,0.39102989435195923,0.3947324752807617,0.3999979794025421,0.39166584610939026,0.40089234709739685,0.39920467138290405,0.39038729667663574,0.3927239179611206,0.3991478681564331,0.3951317071914673,0.39807039499282837,0.39074841141700745,0.38964900374412537,0.3988253176212311,0.4001813232898712,0.40260639786720276,0.4002876281738281,0.4013320803642273,0.39396804571151733,0.3921794891357422,0.402494341135025,0.3945188820362091,0.3986141085624695,0.3865863084793091,0.39234092831611633,0.40318676829338074,0.3897213935852051,0.40231505036354065,0.4051132798194885,0.40405741333961487,0.39590808749198914,0.39432084560394287,0.39506009221076965,0.38813769817352295,0.4008956253528595,0.3927503526210785,0.3987395465373993,0.39367496967315674,0.39163875579833984,0.40019872784614563,0.39182227849960327,0.40085217356681824,0.40074804425239563,0.3913041651248932,0.3927098512649536,0.3998110890388489,0.38761645555496216,0.39618903398513794,0.3952115774154663,0.3842790126800537,0.396607905626297,0.38698849081993103,0.39464861154556274,0.39172622561454773,0.39598047733306885,0.3927095830440521,0.39213570952415466,0.39645907282829285,0.3936123549938202,0.38338372111320496,0.3891170620918274,0.38996630907058716,0.3946114182472229,0.39221271872520447,0.393080472946167,0.38396281003952026,0.3928118348121643,0.3960837423801422,0.38985180854797363,0.3954542577266693,0.3913863003253937,0.391385942697525,0.3897864520549774,0.3906487226486206,0.38549962639808655,0.3976867198944092,0.38908854126930237,0.3935210108757019,0.3905412554740906,0.3980138301849365,0.39658740162849426,0.39161819219589233,0.3952743709087372,0.39738428592681885,0.388324499130249,0.39184513688087463,0.39381828904151917,0.39662763476371765,0.3938486874103546,0.39645126461982727,0.3997764587402344,0.3869362473487854,0.38973042368888855,0.38829827308654785,0.3866424262523651,0.3881013095378876,0.39243343472480774,0.38018858432769775,0.3946366012096405,0.394182950258255,0.3841685652732849,0.3886522352695465,0.3932358920574188,0.3873867988586426,0.3945349454879761,0.3884093761444092,0.38665518164634705,0.3982522487640381,0.3885765075683594,0.38330069184303284,0.3863995671272278,0.38803425431251526,0.39472082257270813,0.3922693133354187,0.3973483741283417,0.3886089622974396,0.38597002625465393,0.3976266384124756,0.3917456567287445,0.38298070430755615,0.39078062772750854,0.39348217844963074,0.39104992151260376,0.3868272304534912,0.3920435309410095,0.3885846734046936,0.39257392287254333,0.3902169167995453,0.3924318850040436,0.3847862482070923,0.39222297072410583,0.3870255649089813,0.39330506324768066,0.3910161852836609,0.39299044013023376,0.3869214653968811,0.39663630723953247,0.39806798100471497,0.38817331194877625,0.38267573714256287,0.3947277367115021,0.38828226923942566,0.39753180742263794,0.3843362629413605,0.3856751024723053,0.39142337441444397,0.38933679461479187,0.3869471848011017,0.3884725272655487,0.39667317271232605,0.3843849301338196,0.386361300945282,0.3893408179283142,0.39212140440940857,0.3897547721862793,0.37668344378471375,0.39031800627708435,0.3943522274494171,0.39116373658180237,0.38758915662765503,0.3915312886238098,0.38710010051727295,0.38849443197250366,0.3869074285030365,0.3918633759021759,0.39834073185920715,0.39044371247291565,0.3856995105743408,0.39234253764152527,0.3843685984611511,0.38974177837371826,0.3873812258243561,0.3970637917518616,0.39104118943214417,0.39136770367622375,0.38054776191711426,0.38364583253860474,0.38564082980155945,0.3883477747440338,0.39170584082603455,0.3821645975112915,0.3908673822879791,0.3886425495147705,0.3880923390388489,0.38403597474098206,0.39714041352272034,0.38792866468429565,0.3776145875453949,0.3823626637458801,0.3907347023487091,0.38782986998558044,0.39318615198135376,0.3913215398788452,0.390231192111969,0.3907429277896881,0.39582133293151855,0.39177969098091125,0.3888493776321411,0.3867613971233368,0.3859579265117645,0.3879017233848572,0.3958609104156494,0.38678911328315735,0.3908572494983673,0.39748087525367737,0.38562342524528503,0.3837723731994629,0.3941445052623749,0.38629698753356934,0.3836311399936676,0.3985244929790497,0.3898508846759796,0.38198885321617126,0.38193610310554504,0.3807695209980011,0.3886697590351105,0.3890232741832733,0.38912978768348694,0.38813862204551697,0.38533368706703186,0.3930973410606384,0.3869175612926483,0.3878529965877533,0.38354483246803284,0.3841002881526947,0.3910650312900543,0.3954876661300659,0.3839048743247986,0.3885382115840912,0.38691458106040955,0.38681477308273315,0.38942447304725647,0.3808923065662384,0.3859805762767792,0.393632173538208,0.39664289355278015,0.38193535804748535,0.3904857635498047,0.39464348554611206,0.38065430521965027,0.3943469226360321,0.38347890973091125,0.39156556129455566,0.38590723276138306,0.39257290959358215,0.38725546002388,0.3859653174877167,0.38914233446121216,0.38048404455184937,0.3879111409187317,0.38517794013023376,0.38774779438972473,0.38748812675476074,0.3870435357093811,0.3887186348438263,0.38776037096977234,0.38452842831611633,0.38726770877838135,0.3918023407459259,0.3876287341117859,0.3834764361381531,0.3831425905227661,0.3776765465736389,0.3803783059120178,0.388400137424469,0.3894094228744507,0.38199254870414734,0.381818026304245,0.3846340477466583,0.39483439922332764,0.3919457495212555,0.3837451636791229,0.39330801367759705,0.38915103673934937,0.38786637783050537,0.3913431465625763,0.38414710760116577,0.3844471573829651,0.3895421624183655,0.3916909992694855,0.3929808437824249,0.38297319412231445,0.38583728671073914,0.3795263171195984,0.3935352861881256,0.3829213082790375,0.3773882985115051,0.39071786403656006,0.38874495029449463,0.3841326832771301,0.382576048374176,0.3873833417892456,0.39632341265678406,0.3900068402290344,0.3870226740837097,0.38051432371139526,0.38295674324035645,0.3933756649494171,0.38392743468284607,0.3842206597328186,0.390423059463501,0.3892723023891449,0.38490375876426697,0.3874299228191376,0.39010652899742126,0.37781041860580444,0.3871869742870331,0.37801408767700195,0.39171552658081055,0.3844010829925537,0.376789391040802,0.38029149174690247,0.3841557502746582,0.3832171559333801,0.3814576268196106,0.38579678535461426,0.3923737704753876,0.3774743676185608,0.3889833986759186,0.3842705190181732,0.37910059094429016,0.38666731119155884,0.3821175992488861,0.38545727729797363,0.3819403052330017,0.38725268840789795,0.3852880001068115,0.3862442076206207,0.3805471956729889,0.38651156425476074,0.38132134079933167,0.3872224986553192,0.38420453667640686,0.38308003544807434,0.38553276658058167,0.3824295699596405,0.3891541063785553,0.37394067645072937,0.387627512216568,0.38226422667503357,0.3850782513618469,0.38437825441360474,0.3828049302101135,0.3887852430343628,0.39051079750061035,0.39205509424209595,0.37861010432243347,0.3867434859275818,0.3858548700809479,0.38206946849823,0.3844744563102722,0.3798384964466095,0.38172078132629395,0.37549009919166565,0.3872205913066864,0.38901111483573914,0.389461874961853,0.3873874843120575,0.3869745135307312,0.38001856207847595,0.39192667603492737,0.38644078373908997,0.3815629184246063,0.38806867599487305,0.3897799849510193,0.3775855600833893,0.3824986517429352,0.3817552924156189,0.38334596157073975,0.38587260246276855,0.38509851694107056,0.3862258195877075,0.3861047029495239,0.38577160239219666,0.38127392530441284,0.3855644166469574,0.3842182755470276,0.38934144377708435,0.38301700353622437,0.3866213262081146,0.3868080973625183,0.3820030987262726,0.3788794279098511,0.38519105315208435,0.3828277885913849,0.382388174533844,0.3783385157585144,0.3811204731464386,0.38969096541404724,0.3878152668476105,0.38063108921051025,0.38334688544273376,0.38620230555534363,0.38374069333076477,0.38714319467544556,0.3866303563117981,0.385438472032547,0.3821338713169098,0.3843923807144165,0.37832364439964294,0.37644198536872864,0.37741658091545105,0.39114850759506226,0.3872193992137909,0.3874896764755249,0.3821815252304077,0.3852095901966095,0.3806690275669098,0.38281962275505066,0.3811846375465393,0.381411612033844,0.3813900947570801,0.3872097134590149,0.38430771231651306,0.38711658120155334,0.38006022572517395,0.38754063844680786,0.3816045820713043,0.38333454728126526,0.37465518712997437,0.3833490312099457,0.3880181908607483,0.38411930203437805,0.38696736097335815,0.38476866483688354,0.38295361399650574,0.3846183717250824,0.37694868445396423,0.38670504093170166,0.3840317726135254,0.38544490933418274,0.3847024440765381,0.3825201094150543,0.3841826915740967,0.3816109597682953,0.37718665599823,0.3851555287837982,0.3811248242855072,0.38225680589675903,0.37756314873695374,0.380656361579895,0.38133886456489563,0.3814488649368286,0.3836037516593933,0.38310131430625916,0.37970736622810364,0.3944406807422638,0.38702818751335144,0.3856869339942932,0.3897722065448761,0.38707849383354187,0.3814513683319092,0.3808635175228119,0.3882754445075989,0.38432347774505615,0.38728708028793335,0.37928083539009094,0.3824242651462555,0.38613131642341614,0.3808573782444,0.3911930322647095,0.38075923919677734,0.3791481852531433,0.38526177406311035,0.37698790431022644,0.38057202100753784,0.3817366659641266,0.3826368451118469,0.3814357817173004,0.376403272151947,0.38301968574523926,0.3809618055820465,0.3881351351737976,0.37826284766197205,0.38401085138320923,0.38215047121047974,0.37756362557411194,0.37472569942474365,0.3836025893688202,0.38447892665863037,0.37799572944641113,0.3855706751346588,0.3782774806022644,0.38033321499824524,0.3851225674152374,0.38387957215309143,0.3839811086654663,0.38352808356285095,0.3793594241142273,0.3794530928134918,0.3805691599845886,0.38352853059768677,0.3828903138637543,0.3875930607318878,0.3804016411304474,0.3847582936286926,0.37909162044525146,0.38003677129745483,0.3792639672756195,0.37832772731781006,0.3813413381576538,0.382526695728302,0.3816821277141571,0.38705700635910034,0.38371703028678894,0.38356831669807434,0.38087308406829834,0.38069242238998413,0.3817088305950165,0.37970906496047974,0.3804120719432831,0.3802829682826996,0.3753361701965332,0.3846668303012848,0.388943076133728,0.3810673952102661,0.38512974977493286,0.38759487867355347,0.38386300206184387,0.37691259384155273,0.3811480402946472,0.3765697777271271,0.3746599853038788,0.3786681592464447,0.38352665305137634,0.3824805021286011,0.3749935030937195,0.3775375187397003,0.39007568359375,0.38277745246887207,0.37725481390953064,0.37997332215309143,0.3862879276275635,0.3761643171310425,0.37923306226730347,0.37485408782958984,0.3791448175907135,0.3829541504383087,0.3868270814418793,0.38496163487434387,0.38294902443885803,0.3801511228084564,0.38381704688072205,0.3812980055809021,0.3831656575202942,0.3818855881690979,0.3826223909854889,0.382739782333374,0.37775570154190063,0.3803632855415344,0.37669748067855835,0.3769848346710205,0.3840576708316803,0.3801814317703247,0.38779202103614807,0.3792763352394104,0.37750664353370667,0.3832032382488251,0.3820045590400696,0.377451092004776,0.3845488727092743,0.3820616900920868,0.3841298818588257,0.3764420449733734,0.38705724477767944,0.3809644877910614,0.38059908151626587,0.3827476501464844,0.38055744767189026,0.3762901723384857,0.38563472032546997,0.3810443878173828,0.3792599141597748,0.3880576491355896,0.3807236850261688,0.37956058979034424,0.384409099817276,0.3820069134235382,0.3798182010650635,0.380555659532547,0.37271565198898315,0.3841882348060608,0.37851154804229736,0.38570356369018555,0.3785085082054138,0.38228633999824524,0.3820061981678009,0.37897440791130066,0.37890127301216125,0.38578715920448303,0.3817882835865021,0.38224250078201294,0.37863701581954956,0.38824114203453064,0.38463684916496277,0.3828396499156952,0.38007184863090515,0.38159728050231934,0.3783773183822632,0.3817172944545746,0.3810029625892639,0.3795698583126068,0.37996557354927063,0.3866858184337616,0.373180627822876,0.3818662166595459,0.3746359050273895,0.38237816095352173,0.3862338960170746,0.3835289776325226,0.38321995735168457,0.37880080938339233,0.386381596326828,0.38275179266929626,0.375413179397583,0.3809027373790741,0.38173210620880127,0.3820800483226776,0.3822270631790161,0.3803040087223053,0.37704408168792725,0.38359886407852173,0.3869158923625946,0.3822590410709381,0.3852364122867584,0.38256505131721497,0.3758167624473572,0.378936231136322,0.37852975726127625,0.38090091943740845,0.3791234493255615,0.3828781247138977,0.3772069215774536,0.38021281361579895,0.37986451387405396,0.38016772270202637,0.3807831108570099,0.3748053014278412,0.38436195254325867,0.38152623176574707,0.38288331031799316,0.3746442496776581,0.3809451758861542,0.3843629062175751,0.3832429051399231,0.3755350410938263,0.3755159080028534,0.37803852558135986,0.37806054949760437,0.3826512396335602,0.3741832375526428,0.37242281436920166,0.38635385036468506,0.3846222758293152,0.3746800124645233,0.3781796097755432,0.3787657916545868,0.37665894627571106,0.3845871686935425,0.37980496883392334,0.3900701403617859,0.3789439797401428,0.374176949262619,0.38304105401039124,0.38189801573753357,0.37882372736930847,0.38527151942253113,0.3841876685619354,0.3763188421726227,0.3757424056529999,0.38074934482574463,0.3770853579044342,0.3799593150615692,0.38277918100357056,0.38034936785697937,0.3833996653556824,0.3804156184196472,0.38219332695007324,0.37895238399505615,0.38258203864097595,0.3760967254638672,0.3755877614021301,0.37721651792526245,0.3714527189731598,0.3822009563446045,0.37822428345680237,0.38225460052490234,0.3758159875869751,0.384552538394928,0.3799425959587097,0.3884751498699188,0.3777667284011841,0.3808385133743286,0.3801723122596741,0.37816935777664185,0.38368284702301025,0.3774537742137909,0.3798748254776001,0.38395944237709045,0.37891361117362976,0.37532860040664673,0.38114306330680847,0.37779393792152405,0.3792051076889038,0.3793443739414215,0.38618379831314087,0.37623417377471924,0.3849864900112152,0.3790087401866913,0.3788639307022095,0.3820911943912506,0.37142255902290344,0.3741847276687622,0.37977591156959534,0.37882331013679504,0.38714346289634705,0.3795701563358307,0.38347890973091125,0.38192617893218994,0.38422146439552307,0.38130608201026917,0.3802039325237274,0.3765382468700409,0.3786851763725281,0.3760693371295929,0.3780313730239868,0.3779016435146332,0.3788546919822693,0.38169729709625244,0.3822704255580902,0.3865169584751129,0.3823606073856354,0.3830462098121643,0.38075077533721924,0.3805088400840759,0.37674659490585327,0.38112854957580566,0.38587915897369385,0.37493669986724854,0.3752797842025757,0.37694042921066284,0.3821164667606354,0.37303048372268677,0.374402791261673,0.3775561451911926,0.37739098072052,0.3820677399635315,0.37780264019966125,0.3754749894142151,0.37936750054359436,0.37418872117996216,0.3747156858444214,0.3798392415046692,0.3746587634086609,0.3747138977050781,0.3829646706581116,0.38010358810424805,0.37368953227996826,0.37769603729248047,0.3753669857978821,0.3799133002758026,0.3824668824672699,0.3790724277496338,0.37826114892959595,0.3814986050128937,0.3771582841873169,0.3830222189426422,0.3823161721229553,0.3801921010017395,0.3723801374435425,0.38059988617897034,0.37783917784690857,0.3726440966129303,0.38162508606910706,0.3880963921546936,0.38120409846305847,0.3693190813064575,0.37259870767593384,0.378853976726532,0.38020938634872437,0.37905949354171753,0.37950465083122253,0.37854263186454773,0.37578150629997253,0.3791328966617584,0.3770790994167328,0.3771805465221405,0.38028669357299805,0.3772106468677521,0.38354039192199707,0.3790585994720459,0.3771823048591614,0.3831116557121277,0.3788433372974396,0.3866729736328125,0.3805233836174011,0.37218937277793884,0.38566675782203674,0.37569189071655273,0.37872302532196045,0.38276731967926025,0.38564905524253845,0.3786603510379791,0.37596777081489563,0.3796009421348572,0.37732917070388794,0.3777965009212494,0.38352227210998535,0.37971729040145874,0.38066205382347107,0.3841263949871063,0.37816447019577026,0.3818722665309906,0.3728773891925812,0.3748956322669983,0.38090404868125916,0.3843439519405365,0.37847980856895447,0.37266215682029724,0.37506017088890076,0.3770432472229004,0.3794308304786682,0.38002580404281616,0.37800851464271545,0.3823036253452301,0.3777589499950409,0.37544041872024536,0.37908345460891724,0.3790259063243866,0.3750090003013611,0.3831534683704376,0.3811652958393097,0.3786581754684448,0.383952796459198,0.3744558095932007,0.37620386481285095,0.37912020087242126,0.3754797875881195,0.3865172564983368,0.38369685411453247,0.37837231159210205,0.3744201362133026,0.37357789278030396,0.38726118206977844,0.38590070605278015,0.38121336698532104,0.38478022813796997,0.37978917360305786,0.3810104429721832,0.3795364499092102,0.3715238571166992,0.37626492977142334,0.381233811378479,0.3801121115684509,0.3778902292251587,0.3757842481136322,0.37010055780410767,0.3751315772533417,0.37444597482681274,0.3861728608608246,0.3832467794418335,0.3797683119773865,0.3814629316329956,0.37551409006118774,0.3751562535762787,0.3794252574443817,0.37138909101486206,0.38134071230888367,0.3815077841281891,0.3751670718193054,0.3837835192680359,0.3826889991760254,0.37820783257484436,0.3731565475463867,0.37702688574790955,0.3789095878601074,0.38109707832336426,0.379162073135376,0.37736591696739197,0.37496477365493774,0.3776305317878723,0.3790336847305298,0.3778909146785736,0.38123807311058044,0.38309329748153687,0.3881603181362152,0.3702792227268219,0.3729879558086395,0.3807692527770996,0.37830850481987,0.37711384892463684,0.3746229112148285,0.37348473072052,0.37675386667251587,0.3777156472206116,0.37647321820259094,0.3694062829017639,0.38028135895729065,0.3806808590888977,0.38356152176856995,0.37692996859550476,0.37853243947029114,0.3765069842338562,0.38385266065597534,0.3812600374221802,0.3746525049209595,0.3805958330631256,0.3742574155330658,0.38166093826293945,0.37641575932502747,0.3800581991672516,0.37591031193733215,0.38438040018081665,0.38044679164886475,0.3778301477432251,0.37319499254226685,0.37617647647857666,0.3789525628089905,0.37855270504951477,0.38024935126304626,0.3787260353565216,0.3793390393257141,0.37815454602241516,0.37383463978767395,0.3760719299316406,0.3725608289241791,0.3756781816482544,0.3738805651664734,0.3694515824317932,0.37614861130714417,0.37568333745002747,0.3699614405632019,0.37572386860847473,0.38460400700569153,0.3766069710254669,0.3818206787109375,0.38425692915916443,0.3706134855747223,0.3775274157524109,0.378156453371048,0.3823813498020172,0.3800196051597595,0.38077548146247864,0.37622886896133423,0.3743966817855835,0.3835179805755615,0.3794783651828766,0.37448981404304504,0.38044652342796326,0.37873339653015137,0.3773384988307953,0.37667199969291687,0.3776092529296875,0.38251805305480957,0.38175418972969055,0.3808470070362091,0.3799595534801483,0.3753395080566406,0.38158631324768066,0.38420015573501587,0.37448975443840027,0.38003480434417725,0.38191208243370056,0.37298843264579773,0.38098442554473877,0.37568679451942444,0.3760121762752533,0.37693294882774353,0.3742404282093048,0.3769727349281311,0.37960222363471985,0.373586505651474,0.3769652843475342,0.3871019780635834,0.38263288140296936,0.38134172558784485,0.3816763162612915,0.3786562979221344,0.3798603415489197,0.3811265826225281,0.37368932366371155,0.38237878680229187,0.3768376111984253,0.3821438252925873,0.3757750689983368,0.3755626678466797,0.3763321042060852,0.378510981798172,0.3788241446018219,0.38413578271865845,0.3745152950286865,0.37621042132377625,0.3774070739746094,0.38232433795928955,0.38156092166900635,0.3754417300224304,0.3830268979072571,0.37542858719825745,0.37251585721969604,0.3747927248477936,0.3781803846359253,0.3722212314605713,0.38457104563713074,0.3757098913192749,0.37866055965423584,0.3822254538536072,0.3775143325328827,0.3840380907058716,0.37429019808769226,0.37886467576026917,0.3828962445259094,0.3776962459087372,0.37844258546829224,0.37963244318962097,0.3742704391479492,0.3781841993331909,0.3787486255168915,0.3786817193031311,0.3807753622531891,0.370574951171875,0.37945356965065,0.3701464831829071,0.3752405643463135,0.3744311034679413,0.38156548142433167,0.3830200135707855,0.3803838789463043,0.3830830752849579,0.37942448258399963,0.37954485416412354,0.38260355591773987,0.37823233008384705,0.3846222460269928,0.3805572986602783,0.37456727027893066,0.382355660200119,0.37644514441490173,0.3790561258792877,0.3740784823894501,0.3757668137550354,0.37629643082618713,0.3795243203639984,0.38155439496040344,0.3823799192905426,0.3729936480522156,0.3757569193840027,0.37688952684402466,0.3756893277168274,0.37378230690956116,0.3787316083908081,0.37600404024124146,0.377201646566391,0.3788052499294281,0.3766131103038788,0.37521785497665405,0.3799826204776764,0.37650737166404724,0.37853187322616577,0.38372188806533813,0.3750559985637665,0.3765759766101837,0.37890884280204773,0.3769603371620178,0.37272611260414124,0.36888203024864197,0.377122163772583,0.37771737575531006,0.3775055706501007,0.3754737973213196,0.3789266347885132,0.37667903304100037,0.3850039839744568,0.37619689106941223,0.3764204978942871,0.37644678354263306,0.3797847628593445,0.37428298592567444,0.37326547503471375,0.37661752104759216,0.3732677400112152,0.3798879384994507,0.3678421974182129,0.3758656680583954,0.3776428699493408,0.37716108560562134,0.3755614459514618,0.38175830245018005,0.3744499087333679,0.3711110055446625,0.3778325915336609,0.37258976697921753,0.3787476420402527,0.37798169255256653,0.3710607886314392,0.3830569386482239,0.37931808829307556,0.3788532614707947,0.3738026022911072,0.37636837363243103,0.37673184275627136,0.37060046195983887,0.37934282422065735,0.37991830706596375,0.37537187337875366,0.3833695948123932,0.38123950362205505,0.3720523416996002,0.3813830018043518,0.3707077205181122,0.3808738887310028,0.3773764669895172,0.38522565364837646,0.37951791286468506,0.37424975633621216,0.3772132992744446,0.37933260202407837,0.3782010078430176,0.372215211391449,0.381439208984375,0.3739473521709442,0.3789532780647278,0.38057199120521545,0.3888394236564636,0.3766753375530243,0.37912848591804504,0.3768469989299774,0.37275204062461853,0.3732510507106781,0.3760114312171936,0.38161852955818176,0.3769521117210388,0.37370458245277405,0.37512800097465515,0.3748651444911957,0.37623393535614014,0.3798188865184784,0.37297168374061584,0.37645938992500305,0.3773132264614105,0.38439416885375977,0.3747265636920929,0.37675172090530396,0.381634920835495,0.3805963397026062,0.37258458137512207,0.3798224627971649,0.37892475724220276,0.3747098445892334,0.37504491209983826,0.36785924434661865,0.37494441866874695,0.3811289072036743,0.3760766088962555,0.3763754069805145,0.37945860624313354,0.3791283071041107,0.3816308081150055,0.3740048110485077,0.3797430694103241,0.37308627367019653,0.3712370991706848,0.3765333294868469,0.3752489387989044,0.37385571002960205,0.375165730714798,0.3845134377479553,0.3798282742500305,0.3729035258293152,0.3768680691719055,0.3749682307243347,0.3784113824367523,0.37347888946533203,0.38123494386672974,0.3776979148387909,0.3773873746395111,0.3778955042362213,0.37718936800956726,0.38129040598869324,0.37713953852653503,0.37270575761795044,0.3771182894706726,0.37938910722732544,0.3741307258605957,0.3782852292060852,0.38353803753852844,0.38031840324401855,0.37821125984191895,0.3772207796573639,0.3795437514781952,0.37707608938217163,0.37355533242225647,0.3762446343898773,0.3845110237598419,0.38043034076690674,0.3767932653427124,0.3730769455432892,0.3754482865333557,0.37965473532676697,0.38386282324790955,0.36993083357810974,0.37962377071380615,0.3786103129386902,0.3713078498840332,0.3801253139972687,0.3806297183036804,0.372022420167923,0.3780703842639923,0.37369996309280396,0.3723945617675781,0.3708418011665344,0.37876710295677185,0.38329020142555237,0.37482866644859314,0.3742678165435791,0.37840893864631653,0.3761098086833954,0.3728853762149811,0.38047558069229126,0.37345537543296814,0.3789019286632538,0.3788236081600189,0.3770560026168823,0.3748117685317993,0.3784535229206085,0.3754708766937256,0.38177457451820374,0.3798193335533142,0.37919241189956665,0.3748663067817688,0.38069531321525574,0.38168230652809143,0.37453246116638184,0.3800700306892395,0.37962061166763306,0.3797614276409149,0.3775343894958496,0.3824707865715027,0.38010555505752563,0.38181033730506897,0.37485361099243164,0.37603816390037537,0.3794904053211212,0.3825889825820923,0.3709588944911957,0.38253048062324524,0.3744213879108429,0.36742374300956726,0.38040998578071594,0.374409019947052,0.3758426606655121,0.3764461576938629,0.3777024745941162,0.377811998128891,0.37351009249687195,0.37012800574302673,0.37765127420425415,0.37065035104751587,0.3805122971534729,0.374879390001297,0.37670788168907166,0.37836754322052,0.3791007399559021,0.3769950866699219,0.3747478723526001,0.38050585985183716,0.37777552008628845,0.377785861492157,0.3790740966796875,0.37993016839027405,0.3758050799369812,0.3744972050189972,0.37464213371276855,0.3734976053237915,0.37969428300857544,0.37810635566711426,0.3742407262325287,0.37723246216773987,0.3730451166629791,0.37652796506881714,0.3744846284389496,0.37806257605552673,0.37927791476249695,0.38001683354377747,0.3781639039516449,0.37576431035995483,0.38260358572006226,0.3809526264667511,0.3822898864746094,0.37419939041137695,0.3771841526031494,0.3805299401283264,0.38426318764686584,0.3712882995605469,0.3793826997280121,0.37882769107818604,0.3753409683704376,0.3803618550300598,0.37726661562919617,0.37993675470352173,0.3771215081214905,0.37304016947746277,0.37511327862739563,0.3812476694583893,0.37468093633651733,0.3768039047718048,0.37789681553840637,0.3755788207054138,0.37653422355651855,0.37266016006469727,0.38281548023223877,0.37392449378967285,0.37400105595588684,0.37921056151390076,0.37115344405174255,0.3765198886394501,0.3742629289627075,0.379332035779953,0.3765186369419098,0.3830703794956207,0.37176844477653503,0.3770027756690979,0.3750839829444885,0.3807515799999237,0.3724117577075958,0.37987199425697327,0.38192689418792725,0.3790513873100281,0.3819109797477722,0.3780975639820099,0.371466726064682,0.3754255771636963,0.3790697157382965,0.37789013981819153,0.3811807334423065,0.3792048692703247,0.3782627284526825,0.3759295642375946,0.37677982449531555,0.3815065622329712,0.3749498426914215,0.3792499601840973,0.37605786323547363,0.3796328604221344,0.3754899203777313,0.3787356913089752,0.37544316053390503,0.3783954679965973,0.37912848591804504,0.3803505003452301,0.3791455626487732,0.3753509819507599,0.37374499440193176,0.37170788645744324,0.37699809670448303,0.3838847279548645,0.37381136417388916,0.3752479553222656,0.3786388337612152,0.3782137930393219,0.37180256843566895,0.3766731321811676,0.3798007071018219,0.37515851855278015,0.3801553249359131,0.3782064914703369,0.37625768780708313,0.3817231059074402,0.37492892146110535,0.3757120370864868,0.37650614976882935,0.3760601282119751,0.37620246410369873,0.3694979250431061,0.37873995304107666,0.37565192580223083,0.3803426921367645,0.3835482895374298,0.3764062523841858,0.37433841824531555,0.36978602409362793,0.3720618188381195,0.3730326294898987,0.37957990169525146,0.37264177203178406,0.3723181486129761,0.3725906312465668,0.37550118565559387,0.37706348299980164,0.3728726804256439,0.3720352351665497,0.37566861510276794,0.3841140866279602,0.3831087648868561,0.37299543619155884,0.3788411319255829,0.38023754954338074,0.3742395043373108,0.38009724020957947,0.3756575584411621,0.37412765622138977,0.3742690086364746,0.37958866357803345,0.38770100474357605,0.3724100887775421,0.38073238730430603,0.38058245182037354,0.37893691658973694,0.3812984228134155,0.3774506747722626,0.3736560344696045,0.3706377446651459,0.37440893054008484,0.37859565019607544,0.38098692893981934,0.3789903521537781,0.3750075399875641,0.37284916639328003,0.3773024082183838,0.3749200403690338,0.3772844970226288,0.37739819288253784,0.3765946328639984,0.3814478814601898,0.3789291977882385,0.3802223801612854,0.37285444140434265,0.3710445463657379,0.374664306640625,0.3792918622493744,0.37690412998199463,0.38007494807243347,0.37876224517822266,0.38210222125053406,0.3781982958316803,0.3770182430744171,0.3785513639450073,0.371783971786499,0.3754037618637085,0.37396040558815,0.37636327743530273,0.3771188259124756,0.37906599044799805,0.37757739424705505,0.37733325362205505,0.3727833926677704,0.37524572014808655,0.3771885633468628,0.3801772892475128,0.37845295667648315,0.37839436531066895,0.3815339207649231,0.3800491392612457,0.3744383454322815,0.37769007682800293,0.3808783292770386,0.3771713972091675,0.3751162588596344,0.3856751322746277,0.375828355550766,0.3714347183704376,0.37809890508651733,0.3755698502063751,0.3789864480495453,0.37871304154396057,0.37166687846183777,0.37970495223999023,0.3832893371582031,0.3814678490161896,0.38122057914733887,0.3775325119495392,0.3676038086414337,0.3742780387401581,0.37212634086608887,0.3674129545688629,0.3760509788990021,0.36708003282546997,0.3678412139415741,0.380095511674881,0.36900460720062256,0.37431323528289795,0.3806232810020447,0.3767356276512146,0.37145307660102844,0.3760341703891754,0.3706480860710144,0.38001859188079834,0.38089820742607117,0.37529897689819336,0.37691470980644226,0.37743324041366577,0.38518086075782776,0.37742188572883606,0.38020867109298706,0.384318083524704,0.3740869462490082,0.3791125416755676,0.37307626008987427,0.3734157681465149,0.3702557682991028,0.37621042132377625,0.37403300404548645,0.37700405716896057,0.3750339448451996,0.37679967284202576,0.3787049949169159,0.37654349207878113,0.3755240738391876,0.37639522552490234,0.3744434118270874,0.37628036737442017,0.37552034854888916,0.376991331577301,0.3730853796005249,0.37218862771987915,0.3695780336856842,0.3848077058792114,0.37631916999816895,0.3806847631931305,0.38309359550476074,0.3749866187572479,0.3801628351211548,0.37506818771362305,0.3755088746547699,0.37519538402557373,0.3755629360675812,0.38072603940963745,0.373485267162323,0.3793720006942749,0.37737366557121277,0.3756342828273773,0.3746679723262787,0.3745352029800415,0.3722352981567383,0.3763420283794403,0.38185811042785645,0.37497401237487793,0.37612003087997437,0.3746941387653351,0.3771609961986542,0.3749586045742035,0.37527990341186523,0.3770308494567871,0.3886197507381439,0.3762972354888916,0.3693760931491852,0.37623506784439087,0.3800196051597595],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\",\"width\":2},\"mode\":\"lines\",\"name\":\"val_loss\",\"y\":[0.6975100636482239,0.6851710677146912,0.679698646068573,0.6751272082328796,0.6724069714546204,0.6691359877586365,0.6655128598213196,0.6618401408195496,0.6582676768302917,0.6552018523216248,0.652106761932373,0.6496390104293823,0.6459118723869324,0.6428444981575012,0.6401666402816772,0.6377844214439392,0.634856104850769,0.6318260431289673,0.6295441389083862,0.6281771063804626,0.6240819692611694,0.6204963326454163,0.6183294653892517,0.6165300607681274,0.6131453514099121,0.6101080775260925,0.6078505516052246,0.605048418045044,0.6016556620597839,0.5990004539489746,0.5967178344726562,0.5937232375144958,0.5911224484443665,0.5881026387214661,0.5855263471603394,0.5831332206726074,0.580946147441864,0.578779935836792,0.5769520401954651,0.5732372999191284,0.5702976584434509,0.5690101981163025,0.5654987692832947,0.5631598830223083,0.5609970092773438,0.5586356520652771,0.555523693561554,0.5526492595672607,0.5510874390602112,0.5491453409194946,0.5466100573539734,0.5438846349716187,0.5413962006568909,0.5393860936164856,0.537036657333374,0.5347422361373901,0.5326511859893799,0.5301207304000854,0.5274783372879028,0.5255120992660522,0.5235443115234375,0.5208278894424438,0.5191822052001953,0.5174632668495178,0.5151568055152893,0.5128766298294067,0.511152982711792,0.5096922516822815,0.5074909925460815,0.5064136981964111,0.5043013691902161,0.5029988884925842,0.5005744695663452,0.49902617931365967,0.4973994195461273,0.49581199884414673,0.4936182498931885,0.4921887218952179,0.4906194508075714,0.4893295466899872,0.48689979314804077,0.486135333776474,0.4845028221607208,0.48320502042770386,0.48194000124931335,0.47981736063957214,0.4790017008781433,0.4771801233291626,0.4758896231651306,0.47503331303596497,0.4732879102230072,0.4724349081516266,0.47127631306648254,0.46960362792015076,0.46845296025276184,0.46759212017059326,0.46669310331344604,0.4653516709804535,0.4643669128417969,0.4632972478866577,0.46224266290664673,0.46061837673187256,0.4593251049518585,0.45829689502716064,0.457388699054718,0.4561959207057953,0.45493361353874207,0.45415112376213074,0.4533243179321289,0.4523847997188568,0.45150652527809143,0.45050251483917236,0.44960886240005493,0.4480947256088257,0.44761431217193604,0.44723814725875854,0.4453727602958679,0.4442235827445984,0.443197637796402,0.4426765441894531,0.44179096817970276,0.4410479962825775,0.4400058686733246,0.43892475962638855,0.43849071860313416,0.43762773275375366,0.43696898221969604,0.4359615743160248,0.4354318678379059,0.4344235360622406,0.43437182903289795,0.4334184527397156,0.4325513541698456,0.43180468678474426,0.43091297149658203,0.4301292300224304,0.4295773506164551,0.42902788519859314,0.42786580324172974,0.42701733112335205,0.42625516653060913,0.42561474442481995,0.42536643147468567,0.4244232773780823,0.4238393008708954,0.42319199442863464,0.4225503206253052,0.4219876229763031,0.4211301803588867,0.4207702577114105,0.4199061095714569,0.41930368542671204,0.4183747470378876,0.41752758622169495,0.41702747344970703,0.41652050614356995,0.4160955250263214,0.4152938425540924,0.41485005617141724,0.41452398896217346,0.41360780596733093,0.41297680139541626,0.41263294219970703,0.41187015175819397,0.4108618497848511,0.410340279340744,0.40955501794815063,0.40952232480049133,0.40910640358924866,0.40818193554878235,0.4075833857059479,0.40677610039711,0.40642377734184265,0.4061332046985626,0.4057987928390503,0.4051344394683838,0.40456661581993103,0.4036006033420563,0.40337875485420227,0.40294885635375977,0.4027763605117798,0.40220823884010315,0.4016478359699249,0.4008462131023407,0.4005137085914612,0.4002843201160431,0.3995056450366974,0.39895838499069214,0.3984508216381073,0.39837315678596497,0.39817047119140625,0.397796094417572,0.39717933535575867,0.39725878834724426,0.39654138684272766,0.39645859599113464,0.395816832780838,0.39527571201324463,0.39481067657470703,0.39435678720474243,0.39445146918296814,0.39389410614967346,0.39309170842170715,0.3929991126060486,0.39304348826408386,0.3919408619403839,0.3917786777019501,0.391424298286438,0.3910268545150757,0.3911692500114441,0.3904823660850525,0.3901141881942749,0.389795184135437,0.38954484462738037,0.38906654715538025,0.3884483277797699,0.3885456919670105,0.38831812143325806,0.38786375522613525,0.38736480474472046,0.3869338929653168,0.3867914378643036,0.38625484704971313,0.3861022889614105,0.38596782088279724,0.3857070803642273,0.3850938081741333,0.3849947452545166,0.3846780061721802,0.3841945230960846,0.38398632407188416,0.3837553858757019,0.38344666361808777,0.382953941822052,0.3824925422668457,0.38209667801856995,0.38185766339302063,0.38163232803344727,0.3814782500267029,0.3812311887741089,0.38107526302337646,0.38102513551712036,0.38064146041870117,0.38007739186286926,0.38039061427116394,0.37969309091567993,0.379111647605896,0.37911880016326904,0.37901103496551514,0.3789631128311157,0.3787245750427246,0.37883079051971436,0.3781907856464386,0.3782908618450165,0.3777971565723419,0.3775734007358551,0.37707293033599854,0.37707239389419556,0.3768271803855896,0.37668606638908386,0.3766576945781708,0.37654781341552734,0.3759896159172058,0.3758370578289032,0.3753759562969208,0.37538474798202515,0.37517598271369934,0.3749464750289917,0.37444159388542175,0.3744868040084839,0.3740416169166565,0.3737095296382904,0.3737014830112457,0.3741222023963928,0.3735443651676178,0.3734554946422577,0.3733428716659546,0.3730459213256836,0.3728053867816925,0.3726823627948761,0.37259918451309204,0.37238094210624695,0.3725167512893677,0.37210407853126526,0.37156441807746887,0.37123799324035645,0.3712080717086792,0.37167155742645264,0.3715027868747711,0.37108132243156433,0.3707341253757477,0.37070003151893616,0.3706006705760956,0.3703705072402954,0.37030261754989624,0.36981409788131714,0.3698241412639618,0.36978641152381897,0.36926451325416565,0.369096964597702,0.36923012137413025,0.3695155084133148,0.3695870339870453,0.3691916763782501,0.3690425455570221,0.3685571849346161,0.3682750463485718,0.3681103587150574,0.36834368109703064,0.3681752383708954,0.3678082227706909,0.36732780933380127,0.3673366904258728,0.36758989095687866,0.36715278029441833,0.3674052357673645,0.36736035346984863,0.36668434739112854,0.366318017244339,0.3665071725845337,0.36645039916038513,0.3663923442363739,0.36635392904281616,0.3658069670200348,0.3659566342830658,0.36584988236427307,0.36622002720832825,0.3654668927192688,0.36544784903526306,0.36541691422462463,0.36503171920776367,0.3648776113986969,0.364706814289093,0.3645075559616089,0.36471816897392273,0.36468639969825745,0.36462199687957764,0.36432570219039917,0.3642074167728424,0.36403077840805054,0.3642408847808838,0.36376795172691345,0.3636362552642822,0.3635654151439667,0.36337441205978394,0.36350512504577637,0.3635617792606354,0.36348941922187805,0.36336103081703186,0.3636384904384613,0.36339643597602844,0.362665593624115,0.3624916970729828,0.3626404404640198,0.3625529706478119,0.36265647411346436,0.36253997683525085,0.3627749979496002,0.3624345064163208,0.3622787594795227,0.3623620271682739,0.3623236417770386,0.3620438873767853,0.36185336112976074,0.36169466376304626,0.3617989718914032,0.36161261796951294,0.3613691031932831,0.3611701726913452,0.3612842857837677,0.3610615134239197,0.3609940707683563,0.3610566258430481,0.36074110865592957,0.3609890639781952,0.361043781042099,0.36118701100349426,0.3604826331138611,0.36035993695259094,0.3602246046066284,0.360420823097229,0.360408216714859,0.36031562089920044,0.36009952425956726,0.3599122166633606,0.3600847125053406,0.35978925228118896,0.35947808623313904,0.3592725694179535,0.3593349754810333,0.3593122065067291,0.35963869094848633,0.3598417639732361,0.35959362983703613,0.35931363701820374,0.35903388261795044,0.359188437461853,0.35892754793167114,0.3588107228279114,0.35867393016815186,0.35881391167640686,0.35858914256095886,0.35857442021369934,0.35861456394195557,0.35860028862953186,0.35867583751678467,0.3581319749355316,0.35837507247924805,0.3580189347267151,0.35810184478759766,0.35808852314949036,0.3579850196838379,0.35804083943367004,0.3580555021762848,0.3578464686870575,0.3577914237976074,0.3579389452934265,0.35835903882980347,0.35780927538871765,0.357974648475647,0.35809195041656494,0.3577793538570404,0.35783007740974426,0.3574844300746918,0.35762518644332886,0.35768336057662964,0.35740551352500916,0.35743722319602966,0.3573926091194153,0.3574330508708954,0.3574058711528778,0.3574570417404175,0.3570617139339447,0.35717999935150146,0.35717451572418213,0.35706669092178345,0.35721075534820557,0.3572089374065399,0.35694918036460876,0.3568669259548187,0.35707759857177734,0.3571613132953644,0.3570406436920166,0.35717305541038513,0.356902152299881,0.3567023277282715,0.3568263649940491,0.35684826970100403,0.35677269101142883,0.3569547235965729,0.3566380441188812,0.356458842754364,0.3562367558479309,0.3564129173755646,0.356270432472229,0.3564848303794861,0.3564128577709198,0.3563421964645386,0.356454074382782,0.3564371168613434,0.3565811514854431,0.35636797547340393,0.3560694456100464,0.35594800114631653,0.3562772274017334,0.35638654232025146,0.3561546504497528,0.35597681999206543,0.35592854022979736,0.3560095727443695,0.35615208745002747,0.3560880720615387,0.3559424579143524,0.3557792603969574,0.3558140993118286,0.355808287858963,0.35573074221611023,0.3558887541294098,0.3555045425891876,0.35564276576042175,0.3559320569038391,0.3562985360622406,0.3559485971927643,0.35586902499198914,0.35604578256607056,0.3559728264808655,0.3557159900665283,0.3556968569755554,0.35554084181785583,0.35575971007347107,0.3554914593696594,0.3551979660987854,0.35513874888420105,0.3551568388938904,0.3550722599029541,0.3550862669944763,0.35541608929634094,0.3551885485649109,0.35490357875823975,0.3552325665950775,0.35525357723236084,0.3548515737056732,0.35472217202186584,0.3547232151031494,0.354829341173172,0.3549981117248535,0.35481393337249756,0.35467371344566345,0.35436663031578064,0.3545580506324768,0.3545900881290436,0.35483452677726746,0.35481777787208557,0.3546728193759918,0.3545092046260834,0.35439401865005493,0.3545171022415161,0.35459381341934204,0.35446637868881226,0.3544708788394928,0.3545317053794861,0.3543010652065277,0.3540552258491516,0.354007750749588,0.3540940582752228,0.35394757986068726,0.35385119915008545,0.3537740707397461,0.3537115454673767,0.3537781536579132,0.35350146889686584,0.35367128252983093,0.35394686460494995,0.3535063564777374,0.3534197509288788,0.3536534011363983,0.3534088134765625,0.353420227766037,0.3532046973705292,0.3533293902873993,0.35350680351257324,0.3534729778766632,0.35343483090400696,0.3531876802444458,0.3531615138053894,0.3529628813266754,0.3530777096748352,0.35303637385368347,0.35298052430152893,0.3531680405139923,0.35315531492233276,0.35324394702911377,0.35344067215919495,0.3532385230064392,0.3530465066432953,0.3526414632797241,0.35272088646888733,0.3531297743320465,0.35297197103500366,0.3528909385204315,0.35283151268959045,0.35325902700424194,0.3525903522968292,0.3525456488132477,0.35246923565864563,0.35248690843582153,0.3527441918849945,0.35306015610694885,0.3526524305343628,0.3523951470851898,0.3525232672691345,0.352414608001709,0.352237343788147,0.35235852003097534,0.35265034437179565,0.35256293416023254,0.35251063108444214,0.3524906635284424,0.35255900025367737,0.35233673453330994,0.35254719853401184,0.35273271799087524,0.352532297372818,0.35222887992858887,0.3521929383277893,0.35211989283561707,0.3526352643966675,0.3526361882686615,0.352483332157135,0.35241419076919556,0.3520626127719879,0.3519621789455414,0.3523961901664734,0.35257869958877563,0.35226550698280334,0.352712482213974,0.3525505065917969,0.3520781993865967,0.35212579369544983,0.35218244791030884,0.3520282208919525,0.35178613662719727,0.3520696461200714,0.3520755469799042,0.35216349363327026,0.35195446014404297,0.3516853451728821,0.35168108344078064,0.35191619396209717,0.3520088493824005,0.3519824147224426,0.3520534336566925,0.3518625497817993,0.35231900215148926,0.3523079454898834,0.3521633744239807,0.35185736417770386,0.3516635298728943,0.3517082929611206,0.3515174090862274,0.35150954127311707,0.35159820318222046,0.35183194279670715,0.3517068922519684,0.3519456684589386,0.3520452678203583,0.3517753779888153,0.35159751772880554,0.35165318846702576,0.35168445110321045,0.3517608642578125,0.3517029285430908,0.35170218348503113,0.351733922958374,0.3517165780067444,0.35155364871025085,0.3517615497112274,0.3515051305294037,0.3517250418663025,0.35171210765838623,0.35164764523506165,0.3515070378780365,0.3512803912162781,0.3517296016216278,0.3516026437282562,0.3513718247413635,0.3513627350330353,0.3512684106826782,0.35117486119270325,0.3512057363986969,0.35127711296081543,0.3514727056026459,0.3511016368865967,0.3509715497493744,0.35089820623397827,0.3509787321090698,0.3508056700229645,0.3511693775653839,0.3510704040527344,0.3512648642063141,0.35125306248664856,0.35113251209259033,0.35101035237312317,0.3510272800922394,0.35129958391189575,0.3514949679374695,0.35128775238990784,0.3514218032360077,0.35104766488075256,0.35115620493888855,0.3511609435081482,0.35114580392837524,0.35113972425460815,0.35099107027053833,0.351100891828537,0.3512445092201233,0.3511110544204712,0.35106295347213745,0.3511452078819275,0.35098177194595337,0.35114336013793945,0.35131603479385376,0.3510976731777191,0.3511020541191101,0.35097160935401917,0.35092541575431824,0.3508714437484741,0.3511226177215576,0.351047158241272,0.3511863648891449,0.35119497776031494,0.35110336542129517,0.3506152927875519,0.35045120120048523,0.3506649136543274,0.35070666670799255,0.350700706243515,0.350729376077652,0.35065972805023193,0.3504941463470459,0.3506515920162201,0.350551962852478,0.35089221596717834,0.35065239667892456,0.35091158747673035,0.3506479561328888,0.35070765018463135,0.35061129927635193,0.35047897696495056,0.3504401743412018,0.3505809009075165,0.35063162446022034,0.35067084431648254,0.3510381281375885,0.3506787419319153,0.35086238384246826,0.35103246569633484,0.3510144352912903,0.35074582695961,0.35075825452804565,0.3506000339984894,0.35046619176864624,0.3503578305244446,0.3505120873451233,0.3506655991077423,0.35095444321632385,0.35093021392822266,0.35064658522605896,0.3506198227405548,0.35065048933029175,0.3503611981868744,0.3503741919994354,0.3506660759449005,0.35064697265625,0.35046130418777466,0.35044974088668823,0.35061436891555786,0.3509509563446045,0.3509984612464905,0.35055679082870483,0.35090717673301697,0.3504994213581085,0.3502718508243561,0.35001879930496216,0.3499595522880554,0.3506452143192291,0.3503350019454956,0.3505469262599945,0.350769579410553,0.3504716753959656,0.3504076600074768,0.3505401313304901,0.35057592391967773,0.3505125045776367,0.35027968883514404,0.34996020793914795,0.3503323197364807,0.3505198359489441,0.35057196021080017,0.3502638041973114,0.3502194285392761,0.35005998611450195,0.3503187596797943,0.3502953350543976,0.35033494234085083,0.350486695766449,0.35049039125442505,0.35027584433555603,0.35006359219551086,0.3503822982311249,0.3504391312599182,0.3500550389289856,0.35005542635917664,0.35020744800567627,0.35034263134002686,0.3500385880470276,0.3500308096408844,0.349763959646225,0.3500264883041382,0.3500950336456299,0.3501763641834259,0.35027337074279785,0.35013166069984436,0.3503023087978363,0.35014843940734863,0.35022714734077454,0.3506793677806854,0.3501647114753723,0.34979602694511414,0.34999823570251465,0.35041648149490356,0.35016965866088867,0.3499896824359894,0.3496783375740051,0.34998375177383423,0.34994927048683167,0.3497282862663269,0.34997478127479553,0.349922776222229,0.35007530450820923,0.3502348065376282,0.3499177098274231,0.3496607840061188,0.34991687536239624,0.3498691916465759,0.34984904527664185,0.3497384190559387,0.34964025020599365,0.3499890863895416,0.3498038947582245,0.349704772233963,0.3499803841114044,0.3503502905368805,0.3503299653530121,0.34978747367858887,0.3498062193393707,0.34996703267097473,0.3499630093574524,0.3498927354812622,0.3495885729789734,0.34962818026542664,0.3498731553554535,0.3499557375907898,0.3502180576324463,0.3500712215900421,0.34950000047683716,0.34944644570350647,0.3500750660896301,0.3500649333000183,0.3497193455696106,0.34946200251579285,0.3494608402252197,0.34979331493377686,0.3498445749282837,0.3497171401977539,0.3497665524482727,0.3499947488307953,0.350286066532135,0.34970471262931824,0.3494148254394531,0.34953853487968445,0.3495989143848419,0.34983518719673157,0.34995850920677185,0.349857360124588,0.35006919503211975,0.35005950927734375,0.3499729037284851,0.34976911544799805,0.34975382685661316,0.3498513698577881,0.34976696968078613,0.35013076663017273,0.34982672333717346,0.34949395060539246,0.3494906723499298,0.3500434458255768,0.349801242351532,0.3493974208831787,0.3496587574481964,0.3493519127368927,0.34944283962249756,0.3495660722255707,0.34973594546318054,0.3494935929775238,0.3493802845478058,0.3496919572353363,0.3494638204574585,0.3495534658432007,0.34966346621513367,0.34969255328178406,0.3494347631931305,0.34915587306022644,0.3490445613861084,0.3493693172931671,0.3495173454284668,0.34945476055145264,0.3496367931365967,0.34944602847099304,0.34935247898101807,0.3492160439491272,0.3491881787776947,0.34930089116096497,0.3494882583618164,0.3494105935096741,0.3493143916130066,0.34916576743125916,0.3493928015232086,0.3494272530078888,0.34953510761260986,0.3495345413684845,0.3494771718978882,0.34976139664649963,0.349651575088501,0.3494376838207245,0.349548876285553,0.34966525435447693,0.3495793342590332,0.34938573837280273,0.3495776653289795,0.3493835926055908,0.34907689690589905,0.3491115868091583,0.3492565453052521,0.34932971000671387,0.349276602268219,0.34940022230148315,0.3492986261844635,0.34917253255844116,0.34875407814979553,0.3488222658634186,0.34916165471076965,0.3491040766239166,0.3491494059562683,0.34904998540878296,0.3491148352622986,0.3491494059562683,0.349202960729599,0.3488970100879669,0.34908032417297363,0.34936463832855225,0.34917545318603516,0.34915924072265625,0.34891489148139954,0.34910255670547485,0.34913957118988037,0.349152147769928,0.3490208685398102,0.34892040491104126,0.3488524854183197,0.34895211458206177,0.3491164743900299,0.34930047392845154,0.3490043878555298,0.3489840626716614,0.34892815351486206,0.3488466739654541,0.3489207327365875,0.349223256111145,0.3491232991218567,0.34924018383026123,0.34924763441085815,0.3490171432495117,0.34910479187965393,0.3492490351200104,0.3492535352706909,0.34913748502731323,0.34891918301582336,0.3485429584980011,0.34901162981987,0.3493667542934418,0.3488732576370239,0.3489226996898651,0.3489561080932617,0.3485706150531769,0.34878402948379517,0.3488467037677765,0.3487374484539032,0.34899452328681946,0.34936338663101196,0.3491385281085968,0.3487950563430786,0.34882715344429016,0.3489147424697876,0.3488578796386719,0.3486512005329132,0.3490615487098694,0.3488748073577881,0.3491459786891937,0.34929659962654114,0.34954360127449036,0.34925147891044617,0.3486168384552002,0.34855619072914124,0.34865689277648926,0.3487735390663147,0.3486379384994507,0.3485877811908722,0.34868955612182617,0.34861481189727783,0.34854400157928467,0.3490465581417084,0.3492630124092102,0.3492209315299988,0.34876036643981934,0.34929344058036804,0.3491520583629608,0.3488786518573761,0.3491817116737366,0.3492750823497772,0.3487911522388458,0.34866899251937866,0.34874898195266724,0.34866660833358765,0.34863293170928955,0.34854790568351746,0.3482975959777832,0.3484000563621521,0.3484993875026703,0.3487637937068939,0.34865644574165344,0.34878623485565186,0.34888944029808044,0.3485819101333618,0.3486630618572235,0.3491264283657074,0.34952783584594727,0.3492679297924042,0.34906211495399475,0.3485957086086273,0.348750501871109,0.3489138185977936,0.3487001359462738,0.34889230132102966,0.3491954505443573,0.3489547371864319,0.34830954670906067,0.3484129011631012,0.34903883934020996,0.3486078381538391,0.3486758768558502,0.3484944999217987,0.34863024950027466,0.3489605784416199,0.34911245107650757,0.3490259349346161,0.3485751450061798,0.34877514839172363,0.34886953234672546,0.3488228917121887,0.3489205241203308,0.34905022382736206,0.3486519157886505,0.34862422943115234,0.3483482301235199,0.34847015142440796,0.34855130314826965,0.3486020267009735,0.3488718271255493,0.3488387167453766,0.3488417863845825,0.34877532720565796,0.3485795259475708,0.34856387972831726,0.34825190901756287,0.34854039549827576,0.34860777854919434,0.3486911654472351,0.34877005219459534,0.34895721077919006,0.34885093569755554,0.34886911511421204,0.34859099984169006,0.3486363887786865,0.34897828102111816,0.34891968965530396,0.3489155173301697,0.348960280418396,0.34935781359672546,0.34893280267715454,0.3486787974834442,0.3488539457321167,0.3487027883529663,0.3489933907985687,0.34881699085235596,0.3485203683376312,0.34848102927207947,0.34855034947395325,0.3484634459018707,0.3484279215335846,0.34861984848976135,0.3486384153366089,0.3485923707485199,0.3487071394920349,0.348979115486145,0.3491062521934509,0.3488779366016388,0.34868282079696655,0.3487708866596222,0.34867238998413086,0.34884974360466003,0.3485562205314636,0.3485708236694336,0.34878334403038025,0.34891360998153687,0.34891277551651,0.34891536831855774,0.34877562522888184,0.3487812578678131,0.3486784100532532,0.34866827726364136,0.3487832546234131,0.3488960266113281,0.3487464487552643,0.34854304790496826,0.34868282079696655,0.34895622730255127,0.34877216815948486,0.34857261180877686,0.34901824593544006,0.3487858474254608,0.34879952669143677,0.3488522469997406,0.3489563465118408,0.3488098084926605,0.3486599624156952,0.3488609790802002,0.34882548451423645,0.3489404618740082,0.34853053092956543,0.34870144724845886,0.34882158041000366,0.34888124465942383,0.3487108051776886,0.3485476076602936,0.34836339950561523,0.34844866394996643,0.34844955801963806,0.3486407995223999,0.34884756803512573,0.3486187756061554,0.3487258851528168,0.3489367961883545,0.34853798151016235,0.34830036759376526,0.3485698997974396,0.34880104660987854,0.34881559014320374,0.348659873008728,0.3483645021915436,0.3486648499965668,0.34873029589653015,0.34883299469947815,0.34857022762298584,0.3486834764480591,0.3487881124019623,0.34869474172592163,0.3485710620880127,0.34840717911720276,0.3485344648361206,0.34854087233543396,0.3486388921737671,0.3487355411052704,0.34907957911491394,0.34894558787345886,0.34872522950172424,0.34894511103630066,0.3489008843898773,0.34877508878707886,0.3488963544368744,0.34865424036979675,0.3489559292793274,0.3487854599952698,0.3484923243522644,0.3484334647655487,0.3489936888217926,0.3492273688316345,0.3486229479312897,0.3486781120300293,0.3487498462200165,0.34894874691963196,0.3492210805416107,0.3489287197589874,0.34877362847328186,0.3487315773963928,0.3486175537109375,0.34859034419059753,0.348646342754364,0.3486311435699463,0.3487522304058075,0.3486497700214386,0.34874460101127625,0.3485640287399292,0.3487710952758789,0.34928277134895325,0.3493342697620392,0.34894388914108276,0.3484518826007843,0.34826913475990295,0.3482075035572052,0.3482661247253418,0.348664253950119,0.3486109673976898,0.34882402420043945,0.3488357663154602,0.34869512915611267,0.34824490547180176,0.3484847843647003,0.348579466342926,0.34834831953048706,0.34850412607192993,0.3484562635421753,0.34856775403022766,0.34827160835266113,0.34845516085624695,0.34888115525245667,0.3487429618835449,0.3486672341823578,0.34868142008781433,0.3487167954444885,0.3485919237136841,0.348287433385849,0.3482082188129425,0.34851813316345215,0.3484869599342346,0.3484296202659607,0.3487999141216278,0.34841808676719666,0.3486587107181549,0.3487231433391571,0.34854134917259216,0.34860819578170776,0.34830233454704285,0.34831151366233826,0.34864479303359985,0.34857288002967834,0.34839218854904175,0.34865984320640564,0.3484807014465332,0.34853246808052063,0.34883594512939453,0.34892651438713074,0.34852534532546997,0.34819719195365906,0.34848102927207947,0.3485119640827179,0.34828710556030273,0.3485707640647888,0.34817999601364136,0.3480425477027893,0.3480297029018402,0.3481657803058624,0.34856748580932617,0.348511278629303,0.3485819399356842,0.34842535853385925,0.3486536145210266,0.34899792075157166,0.34879156947135925,0.34857606887817383,0.3482470214366913,0.3485662639141083,0.3484155237674713,0.34881752729415894,0.3488442301750183,0.34848347306251526,0.3482504189014435,0.3482016623020172,0.3486380875110626,0.34854453802108765,0.34856978058815,0.34854358434677124,0.34877851605415344,0.34849056601524353,0.3482615649700165,0.34815144538879395,0.34843921661376953,0.3483833074569702,0.3484888970851898,0.348564088344574,0.348918080329895,0.34930869936943054,0.34868013858795166,0.348479300737381,0.34857964515686035,0.34873148798942566,0.3489561080932617,0.3488900065422058,0.34881091117858887,0.34868818521499634,0.3487708270549774,0.3487517833709717,0.3488861918449402,0.34899529814720154,0.34882569313049316,0.3486483693122864,0.3486538231372833,0.3484862148761749,0.34883731603622437,0.3487037420272827,0.34871888160705566,0.3487890362739563,0.3484213352203369,0.3479935824871063,0.3481094539165497,0.3481959104537964,0.34848734736442566,0.3484051525592804,0.34838107228279114,0.34827935695648193,0.3483056128025055,0.34835681319236755,0.3481765687465668,0.34799760580062866,0.3481428027153015,0.34826138615608215,0.34841713309288025,0.3485676944255829,0.3487304747104645,0.348564475774765,0.348528653383255,0.3485028147697449,0.3486843705177307,0.3485979437828064,0.34831172227859497,0.3481690287590027,0.34814953804016113,0.3481288254261017,0.3482475280761719,0.3482798635959625,0.3483741581439972,0.3484055995941162,0.34868189692497253,0.3484976887702942,0.34821346402168274,0.348354697227478,0.3482016324996948,0.34832271933555603,0.3481192886829376,0.3479781448841095,0.3480795919895172,0.34835851192474365,0.34823620319366455,0.34831535816192627,0.3482908308506012,0.3485695421695709,0.3485543727874756,0.34839335083961487,0.3481979966163635,0.3483242988586426,0.3483944237232208,0.34822696447372437,0.3484240174293518,0.34845399856567383,0.3482663631439209,0.3481298089027405,0.3480621874332428,0.3480618894100189,0.34787073731422424,0.34819573163986206,0.3485831320285797,0.34858211874961853,0.34852325916290283,0.34830161929130554,0.3484683632850647,0.34833917021751404,0.34805789589881897,0.34821179509162903,0.348278284072876,0.34836533665657043,0.3482045829296112,0.3485388159751892,0.3479433059692383,0.3481304943561554,0.34815728664398193,0.34812822937965393,0.3482334315776825,0.3484632670879364,0.34826433658599854,0.34851881861686707,0.34813058376312256,0.34801316261291504,0.34810298681259155,0.3477688729763031,0.3478126525878906,0.3478664457798004,0.3482351005077362,0.34846028685569763,0.3488442599773407,0.3485982418060303,0.34831687808036804,0.34838172793388367,0.34841999411582947,0.34800612926483154,0.34791186451911926,0.34799909591674805,0.34845080971717834,0.34829583764076233,0.34813350439071655,0.3481369614601135,0.3481143116950989,0.3481268882751465,0.3478546142578125,0.34791886806488037,0.34802693128585815,0.3479638397693634,0.34792283177375793,0.3479669988155365,0.34769493341445923,0.34769394993782043,0.3480835556983948,0.34832584857940674,0.3481684625148773,0.34802865982055664,0.34795892238616943,0.3480510115623474,0.3482981026172638,0.3479361832141876,0.34779760241508484,0.3478565514087677,0.34760767221450806,0.34750133752822876,0.3475496470928192,0.34784916043281555,0.3481944501399994,0.3480527698993683,0.34793734550476074,0.3478793203830719,0.3479278087615967,0.347894549369812,0.3478321433067322,0.34807825088500977,0.3481060266494751,0.34814441204071045,0.3482085168361664,0.3483179807662964,0.34843963384628296,0.34815624356269836,0.3481728732585907,0.34840190410614014,0.3483416438102722,0.3481080234050751,0.3481452763080597,0.34810927510261536,0.34812307357788086,0.3479360044002533,0.34810757637023926,0.3482080399990082,0.3484078049659729,0.34806910157203674,0.3483039140701294,0.34845417737960815,0.3484746217727661,0.3484322428703308,0.348163366317749,0.34797486662864685,0.34816259145736694,0.34827902913093567,0.34821614623069763,0.3483400046825409,0.34849536418914795,0.34834957122802734,0.3481147289276123,0.34827032685279846,0.34830161929130554,0.3485812246799469,0.34851911664009094,0.34851089119911194,0.3483511805534363,0.3484441339969635,0.34809374809265137,0.3479260802268982,0.34792375564575195,0.34771808981895447,0.3477688133716583,0.34836116433143616,0.3482857942581177,0.34823077917099,0.3482814133167267,0.34854230284690857,0.34821268916130066,0.348222941160202,0.34826409816741943,0.3481453061103821,0.34826529026031494,0.3482142984867096,0.3479424715042114,0.34792953729629517,0.34827637672424316,0.34805217385292053,0.3481002151966095,0.3478558361530304,0.34774094820022583,0.34796780347824097,0.3485143184661865,0.3483125567436218,0.34816521406173706,0.3482854962348938,0.3481808304786682,0.3482702076435089,0.3482440710067749,0.34812605381011963,0.3478850722312927,0.34791845083236694,0.3479808568954468,0.34826338291168213,0.3486155867576599,0.3483070731163025,0.3484353721141815,0.34838414192199707,0.34850621223449707,0.34797903895378113,0.3478343188762665,0.34789586067199707,0.3479478657245636,0.3484463691711426,0.3482828736305237,0.34806618094444275,0.34757256507873535,0.34769555926322937,0.34819793701171875,0.3480328917503357,0.34803032875061035,0.34796836972236633,0.3476983904838562,0.3477955162525177,0.3481002748012543,0.3478989899158478,0.3478178083896637,0.3480089604854584,0.3479801118373871,0.34788239002227783,0.34800979495048523,0.3480846583843231,0.34801244735717773,0.34773436188697815,0.3476680517196655,0.3477584719657898,0.3479515612125397,0.3481752872467041,0.3481951057910919,0.3483368158340454,0.347989559173584,0.3477659523487091,0.34781935811042786,0.348042756319046,0.3478758633136749,0.3476867377758026,0.3477608561515808,0.3480643332004547,0.34806564450263977,0.3480120897293091,0.3481402099132538,0.34796905517578125,0.3481554687023163,0.34836578369140625,0.3485006093978882,0.3479221761226654,0.3479037880897522,0.34803926944732666,0.3478342294692993,0.34822386503219604,0.3480052351951599,0.34791287779808044,0.34772929549217224,0.3474523723125458,0.34764471650123596,0.34754082560539246,0.3473975360393524,0.34768375754356384,0.3480672538280487,0.3481310307979584,0.34797921776771545,0.3479643166065216,0.34788548946380615,0.3476867973804474,0.34765625,0.34753844141960144,0.34741368889808655,0.34746673703193665,0.3478654623031616,0.3477814793586731,0.3481241464614868,0.34804269671440125,0.34783512353897095,0.34803506731987,0.34798645973205566,0.34814563393592834,0.3481471836566925,0.34807872772216797,0.34793585538864136,0.3479776084423065,0.3479909598827362,0.3480875790119171,0.3479572534561157,0.34787750244140625,0.34822502732276917,0.34806403517723083,0.3480358421802521,0.3481624126434326,0.3480006754398346,0.3477473258972168,0.34768059849739075,0.3477882742881775,0.3480091691017151,0.34760743379592896,0.34777331352233887,0.3474835455417633,0.3479389250278473,0.3477712869644165,0.3477233946323395,0.3476254940032959,0.34782469272613525,0.3480183482170105,0.34797635674476624,0.3477000296115875,0.34789344668388367,0.34800875186920166,0.3476620018482208,0.3477531671524048,0.34783631563186646,0.34778890013694763,0.34800058603286743,0.3478721082210541,0.3478762209415436,0.3476453423500061,0.3475273549556732,0.34774693846702576,0.3476945459842682,0.34800392389297485,0.3480260968208313,0.3479958176612854,0.3477482795715332,0.34788259863853455,0.3477994501590729,0.34747400879859924,0.3476410210132599,0.3477248549461365,0.3477934002876282,0.34768199920654297,0.34762078523635864,0.3480110168457031,0.34796392917633057,0.34833985567092896,0.34804925322532654,0.34796270728111267,0.3476978540420532,0.3477226495742798,0.3478999733924866,0.3479975759983063,0.34804126620292664,0.3477325439453125,0.34798306226730347,0.34781232476234436,0.3477371037006378,0.3479579985141754,0.34784460067749023,0.3480689227581024,0.3479025959968567,0.347639262676239,0.3474782109260559,0.3476483225822449,0.34783121943473816,0.3482038974761963,0.34798726439476013,0.34791457653045654,0.3480166494846344,0.34831276535987854,0.3483176529407501,0.34795573353767395,0.3479999005794525,0.34810933470726013,0.3478752076625824,0.3478301167488098,0.34800076484680176,0.3477960526943207,0.3481479585170746,0.3479287922382355,0.347953736782074,0.3479168117046356,0.3480550944805145,0.3478560745716095,0.3476252555847168,0.3479337692260742,0.3481047749519348,0.34790822863578796,0.34812307357788086,0.34812721610069275,0.3481062352657318,0.3478587865829468,0.34761306643486023,0.3479457199573517,0.3479425609111786,0.34800341725349426,0.3482102155685425,0.3477805256843567,0.34778767824172974,0.34777629375457764,0.3477485179901123,0.3476314842700958,0.3475879430770874,0.34773629903793335,0.3477189540863037,0.347690612077713,0.3477357029914856,0.3476548194885254,0.3477643132209778,0.3480358421802521,0.3480305075645447,0.3479471504688263,0.34749338030815125,0.34757447242736816,0.3477577567100525,0.3476440906524658,0.3478050231933594,0.34789028763771057,0.3476984202861786,0.34774595499038696,0.34795328974723816,0.3480534553527832,0.34796130657196045,0.34809714555740356,0.3480657637119293,0.3480031490325928,0.348365843296051,0.34829503297805786,0.34815800189971924,0.34783077239990234,0.3476478159427643,0.34787285327911377,0.34781256318092346,0.3476565480232239,0.3472539186477661,0.3474186956882477,0.347285658121109,0.34758177399635315,0.34751835465431213,0.347676157951355,0.34758052229881287,0.34766560792922974,0.3478517532348633,0.34774917364120483,0.34766829013824463,0.34769341349601746,0.3476273715496063,0.34771254658699036,0.34788262844085693,0.34783676266670227,0.3479631245136261,0.3480605483055115,0.34778258204460144,0.34811779856681824,0.34796303510665894,0.3477330803871155,0.3477208614349365,0.3479042649269104,0.34764403104782104,0.3474409878253937,0.34766119718551636,0.34772998094558716,0.34779444336891174,0.3478200435638428,0.34769850969314575,0.34762701392173767,0.34775310754776,0.3476741909980774,0.34765806794166565,0.34743714332580566,0.3476763367652893,0.347799688577652,0.34777432680130005,0.3476373851299286,0.34788787364959717,0.34794265031814575,0.34746965765953064,0.3473312258720398,0.34759002923965454,0.347463995218277,0.3477551341056824,0.3474493622779846,0.3476688861846924,0.34791308641433716,0.34807008504867554,0.34811556339263916,0.3479260802268982,0.3478811979293823,0.3477708399295807,0.3477557897567749,0.3478277623653412,0.347856342792511,0.3479590117931366,0.3478747010231018,0.34779810905456543,0.34749293327331543,0.3476216495037079,0.34744080901145935,0.3473362922668457,0.3474554419517517,0.3477535545825958,0.3478241562843323,0.3478327691555023,0.34795185923576355,0.3477283716201782,0.34760698676109314,0.3477143347263336,0.3475019633769989,0.34778085350990295,0.3476351797580719,0.3475423753261566,0.3475654423236847,0.3473576307296753,0.3476337194442749,0.3475978374481201,0.3475341796875,0.3473966121673584,0.34754252433776855,0.3476223647594452,0.34778037667274475,0.3476931154727936,0.3475511968135834,0.3476717174053192,0.3476947546005249,0.3475857377052307,0.3477279245853424,0.3476724326610565,0.34768402576446533,0.3476051092147827,0.3475213050842285,0.34736818075180054,0.347412645816803,0.3476501405239105,0.3476293981075287,0.3477485477924347,0.34798821806907654,0.3478158712387085,0.3479211628437042,0.34788209199905396,0.34776219725608826,0.34760650992393494,0.34764012694358826,0.3478618264198303,0.3478565812110901,0.3477587401866913,0.3480224013328552,0.3478946387767792,0.3477246165275574,0.347651869058609,0.34774014353752136,0.34750697016716003,0.3477487564086914,0.347777783870697,0.34785959124565125,0.3477281928062439,0.347459614276886,0.34748581051826477,0.3476320207118988,0.3476359248161316,0.3475603759288788,0.34763970971107483,0.34771865606307983,0.34780389070510864,0.3477936387062073,0.3478977680206299,0.3481128513813019,0.34758418798446655,0.34733909368515015,0.34762299060821533,0.3477507531642914,0.3473193645477295,0.347639799118042,0.34739357233047485,0.3474789559841156,0.34743860363960266,0.3474104106426239,0.34728795289993286,0.347548246383667,0.34750983119010925,0.3474768102169037,0.34759777784347534,0.34737053513526917,0.3473535180091858,0.34753137826919556,0.34770575165748596,0.347651869058609,0.34770333766937256,0.3475688397884369,0.34742218255996704,0.3476323187351227,0.3476296365261078,0.34774652123451233,0.34739935398101807,0.34732574224472046,0.3472071588039398,0.3476294279098511,0.34758153557777405,0.3475867211818695,0.34764203429222107,0.34744736552238464,0.34761539101600647,0.34753599762916565,0.34773266315460205,0.34792360663414,0.3478609621524811,0.34769243001937866,0.3476622700691223,0.347802072763443,0.34767603874206543,0.34749728441238403,0.347476601600647,0.3475455343723297,0.34779056906700134,0.34762683510780334,0.3476344645023346,0.3473697304725647,0.34743815660476685,0.3475313186645508,0.34737861156463623,0.3472920060157776,0.3472732901573181,0.3474794030189514,0.3473888635635376,0.3474724590778351,0.347655713558197,0.34762123227119446,0.3475964069366455,0.34758591651916504,0.3477354943752289,0.3478546738624573,0.3478563725948334,0.34785977005958557,0.3475775718688965,0.3474660813808441,0.34759873151779175,0.34773993492126465,0.347772479057312,0.3479207456111908,0.3478490114212036,0.3479090929031372,0.3477156460285187,0.34771794080734253,0.34769922494888306,0.34787848591804504,0.34807342290878296,0.34783080220222473,0.34746208786964417,0.3477053940296173,0.34793326258659363,0.3476732075214386,0.34749653935432434,0.3474768102169037,0.34781506657600403,0.3476797938346863,0.3475765585899353,0.3475273549556732,0.34757646918296814,0.34758538007736206,0.3474756181240082,0.3476806879043579,0.3479107618331909,0.3475847542285919,0.34770625829696655,0.3477969169616699,0.347479909658432,0.34752923250198364,0.3477119207382202,0.34807059168815613,0.3479230999946594,0.3475952744483948,0.3474525213241577,0.34727349877357483,0.34725725650787354,0.3472868800163269,0.3476047217845917,0.34796661138534546,0.3476862609386444,0.3477860391139984,0.3479881286621094,0.34828728437423706,0.3477233350276947,0.3478381335735321,0.34780964255332947,0.34756433963775635,0.34739065170288086,0.34749510884284973,0.3479878008365631,0.3477177619934082,0.34748563170433044,0.34739676117897034,0.34729650616645813,0.3474481999874115,0.3477177619934082,0.3478497862815857,0.34769928455352783,0.34793993830680847,0.3480498492717743,0.34795472025871277,0.34784841537475586,0.3477816879749298,0.3478507101535797,0.3481132984161377,0.3480580449104309,0.34778693318367004,0.34760406613349915,0.34751495718955994,0.3475368618965149,0.34747350215911865,0.3473902940750122,0.34765011072158813,0.34740665555000305,0.34776610136032104,0.34764835238456726,0.3477652072906494,0.34819793701171875,0.34798663854599,0.34804150462150574,0.34808552265167236,0.3479613959789276,0.3477931320667267,0.347845196723938,0.34784847497940063],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Loss\"},\"xaxis\":{\"title\":{\"text\":\"epochs\"}},\"yaxis\":{\"title\":{\"text\":\"\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b8132e6c-7043-450d-861f-ed521b86502e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Accuracy"
      ],
      "metadata": {
        "id": "IjmstyIP4Wxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = go.Scatter(y=his.history['accuracy'],\n",
        "                    mode=\"lines\", line=dict(\n",
        "                    width=2,\n",
        "                    color='blue'),\n",
        "                    name=\"acc\"\n",
        "                   )\n",
        "h2 = go.Scatter(y=his.history['val_accuracy'],\n",
        "                    mode=\"lines\", line=dict(\n",
        "                    width=2,\n",
        "                    color='red'),\n",
        "                    name=\"val_acc\"\n",
        "                   )\n",
        "\n",
        "data = [h1,h2]\n",
        "layout1 = go.Layout(title='Accuracy',\n",
        "                   xaxis=dict(title='epochs'),\n",
        "                   yaxis=dict(title=''))\n",
        "fig1 = go.Figure(data = data, layout=layout1)\n",
        "plotly.offline.iplot(fig1)"
      ],
      "metadata": {
        "id": "kNbpM6nI4XyP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "e674351d-3efc-4ff6-e2f2-2ce415d1890a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"a66de6f9-bfcf-4254-ae90-b2b6eb2462c1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a66de6f9-bfcf-4254-ae90-b2b6eb2462c1\")) {                    Plotly.newPlot(                        \"a66de6f9-bfcf-4254-ae90-b2b6eb2462c1\",                        [{\"line\":{\"color\":\"blue\",\"width\":2},\"mode\":\"lines\",\"name\":\"acc\",\"y\":[0.4970000088214874,0.4976666569709778,0.5173333287239075,0.5176666378974915,0.528333306312561,0.543666660785675,0.5523333549499512,0.5573333501815796,0.5703333616256714,0.5860000252723694,0.578000009059906,0.5929999947547913,0.6113333106040955,0.6169999837875366,0.609000027179718,0.612666666507721,0.652999997138977,0.6393333077430725,0.6439999938011169,0.6513333320617676,0.6646666526794434,0.6626666784286499,0.6629999876022339,0.6523333191871643,0.6893333196640015,0.6890000104904175,0.7016666531562805,0.7039999961853027,0.706333339214325,0.7086666822433472,0.7016666531562805,0.7086666822433472,0.7173333168029785,0.7166666388511658,0.7296666502952576,0.7176666855812073,0.7123333215713501,0.7323333621025085,0.7273333072662354,0.7400000095367432,0.7386666536331177,0.7379999756813049,0.7356666922569275,0.7473333477973938,0.7316666841506958,0.746999979019165,0.7356666922569275,0.737666666507721,0.7493333220481873,0.7396666407585144,0.7493333220481873,0.7433333396911621,0.7473333477973938,0.7423333525657654,0.7536666393280029,0.762333333492279,0.7513333559036255,0.7480000257492065,0.7526666522026062,0.753000020980835,0.7480000257492065,0.7590000033378601,0.7323333621025085,0.7486666440963745,0.7513333559036255,0.7509999871253967,0.7513333559036255,0.7486666440963745,0.7493333220481873,0.762666642665863,0.753333330154419,0.7586666941642761,0.7406666874885559,0.7620000243186951,0.7599999904632568,0.7573333382606506,0.7676666378974915,0.7526666522026062,0.7703333497047424,0.7696666717529297,0.7603333592414856,0.7573333382606506,0.765999972820282,0.7723333239555359,0.7596666812896729,0.768666684627533,0.7603333592414856,0.7603333592414856,0.765666663646698,0.7613333463668823,0.7563333511352539,0.7580000162124634,0.7586666941642761,0.7646666765213013,0.7590000033378601,0.7616666555404663,0.7689999938011169,0.7666666507720947,0.7616666555404663,0.7743333578109741,0.7590000033378601,0.7649999856948853,0.7873333096504211,0.7666666507720947,0.7739999890327454,0.7706666588783264,0.7706666588783264,0.7696666717529297,0.7836666703224182,0.7710000276565552,0.7720000147819519,0.7680000066757202,0.7773333191871643,0.7799999713897705,0.7726666927337646,0.7836666703224182,0.7806666493415833,0.7766666412353516,0.7799999713897705,0.7756666541099548,0.7823333144187927,0.7839999794960022,0.7886666655540466,0.7689999938011169,0.7753333449363708,0.778333306312561,0.7806666493415833,0.7739999890327454,0.7900000214576721,0.7756666541099548,0.7773333191871643,0.7820000052452087,0.777999997138977,0.7756666541099548,0.7879999876022339,0.7883333563804626,0.7743333578109741,0.7816666960716248,0.7893333435058594,0.7820000052452087,0.7866666913032532,0.7770000100135803,0.7883333563804626,0.7760000228881836,0.7883333563804626,0.7910000085830688,0.7816666960716248,0.7906666398048401,0.7879999876022339,0.7896666526794434,0.7873333096504211,0.7910000085830688,0.7876666784286499,0.7860000133514404,0.7853333353996277,0.7876666784286499,0.7893333435058594,0.7873333096504211,0.7940000295639038,0.7893333435058594,0.7979999780654907,0.7929999828338623,0.7889999747276306,0.7903333306312561,0.7916666865348816,0.79666668176651,0.7976666688919067,0.79666668176651,0.7870000004768372,0.7986666560173035,0.7870000004768372,0.7900000214576721,0.7940000295639038,0.7940000295639038,0.7983333468437195,0.7900000214576721,0.7983333468437195,0.7906666398048401,0.7940000295639038,0.796999990940094,0.7993333339691162,0.7943333387374878,0.7833333611488342,0.7963333129882812,0.8080000281333923,0.7983333468437195,0.7946666479110718,0.7976666688919067,0.7896666526794434,0.7976666688919067,0.7893333435058594,0.7950000166893005,0.7910000085830688,0.800000011920929,0.7979999780654907,0.7866666913032532,0.7956666946411133,0.7906666398048401,0.800000011920929,0.8009999990463257,0.8013333082199097,0.8023333549499512,0.793666660785675,0.7860000133514404,0.8050000071525574,0.8013333082199097,0.7906666398048401,0.8073333501815796,0.7993333339691162,0.7950000166893005,0.8029999732971191,0.8026666641235352,0.7943333387374878,0.8019999861717224,0.8046666383743286,0.7946666479110718,0.796999990940094,0.8040000200271606,0.8046666383743286,0.7979999780654907,0.8013333082199097,0.8036666512489319,0.8053333163261414,0.7979999780654907,0.8073333501815796,0.8080000281333923,0.7996666431427002,0.812666654586792,0.8063333630561829,0.7956666946411133,0.8056666851043701,0.8106666803359985,0.8119999766349792,0.8006666898727417,0.8050000071525574,0.8033333420753479,0.8003333210945129,0.8106666803359985,0.8059999942779541,0.8109999895095825,0.8040000200271606,0.8076666593551636,0.8033333420753479,0.8019999861717224,0.809333324432373,0.8033333420753479,0.8036666512489319,0.8090000152587891,0.8116666674613953,0.8086666464805603,0.8066666722297668,0.8153333067893982,0.8040000200271606,0.8096666932106018,0.8086666464805603,0.8006666898727417,0.8066666722297668,0.8063333630561829,0.815666675567627,0.8046666383743286,0.8146666884422302,0.7993333339691162,0.812333345413208,0.8043333292007446,0.8140000104904175,0.79666668176651,0.8040000200271606,0.8166666626930237,0.8096666932106018,0.8109999895095825,0.8109999895095825,0.8090000152587891,0.8003333210945129,0.8080000281333923,0.8063333630561829,0.812666654586792,0.8169999718666077,0.8083333373069763,0.8066666722297668,0.8053333163261414,0.8069999814033508,0.8133333325386047,0.8153333067893982,0.8136666417121887,0.8163333535194397,0.8050000071525574,0.8140000104904175,0.8180000185966492,0.8163333535194397,0.8073333501815796,0.8186666369438171,0.8090000152587891,0.8159999847412109,0.8069999814033508,0.8193333148956299,0.8086666464805603,0.8090000152587891,0.8083333373069763,0.8176666498184204,0.8176666498184204,0.8196666836738586,0.8196666836738586,0.8130000233650208,0.8140000104904175,0.8149999976158142,0.8133333325386047,0.8133333325386047,0.8109999895095825,0.8083333373069763,0.809333324432373,0.812333345413208,0.8146666884422302,0.8206666707992554,0.8116666674613953,0.8100000023841858,0.809333324432373,0.8213333487510681,0.8113333582878113,0.809333324432373,0.8076666593551636,0.8090000152587891,0.812666654586792,0.8143333196640015,0.8166666626930237,0.8130000233650208,0.8130000233650208,0.8059999942779541,0.8136666417121887,0.8106666803359985,0.8073333501815796,0.8159999847412109,0.8240000009536743,0.8143333196640015,0.8206666707992554,0.8143333196640015,0.8119999766349792,0.8100000023841858,0.8080000281333923,0.8103333115577698,0.8086666464805603,0.812333345413208,0.8169999718666077,0.8159999847412109,0.8146666884422302,0.8103333115577698,0.8206666707992554,0.8116666674613953,0.8263333439826965,0.8116666674613953,0.8196666836738586,0.8193333148956299,0.8206666707992554,0.8166666626930237,0.8109999895095825,0.8146666884422302,0.8149999976158142,0.8240000009536743,0.8173333406448364,0.8163333535194397,0.8153333067893982,0.8173333406448364,0.8180000185966492,0.8246666789054871,0.8073333501815796,0.8163333535194397,0.8193333148956299,0.8133333325386047,0.8103333115577698,0.8196666836738586,0.8146666884422302,0.8136666417121887,0.8083333373069763,0.812333345413208,0.8183333277702332,0.8190000057220459,0.8136666417121887,0.8096666932106018,0.8159999847412109,0.8180000185966492,0.8130000233650208,0.8163333535194397,0.8186666369438171,0.812666654586792,0.812666654586792,0.8193333148956299,0.8226666450500488,0.8109999895095825,0.8106666803359985,0.8180000185966492,0.8180000185966492,0.8240000009536743,0.8216666579246521,0.8080000281333923,0.812333345413208,0.8083333373069763,0.8113333582878113,0.8199999928474426,0.8180000185966492,0.8140000104904175,0.8203333616256714,0.8149999976158142,0.8266666531562805,0.8186666369438171,0.8180000185966492,0.8306666612625122,0.8273333311080933,0.8106666803359985,0.8166666626930237,0.8103333115577698,0.8236666917800903,0.8063333630561829,0.8176666498184204,0.8190000057220459,0.8146666884422302,0.8100000023841858,0.8103333115577698,0.8293333053588867,0.8209999799728394,0.8253333568572998,0.8209999799728394,0.8083333373069763,0.812333345413208,0.8153333067893982,0.8119999766349792,0.8083333373069763,0.8153333067893982,0.8173333406448364,0.8163333535194397,0.8169999718666077,0.8163333535194397,0.8230000138282776,0.8153333067893982,0.8236666917800903,0.8233333230018616,0.8183333277702332,0.828000009059906,0.8136666417121887,0.8203333616256714,0.8133333325386047,0.8140000104904175,0.8149999976158142,0.8186666369438171,0.8166666626930237,0.8233333230018616,0.8233333230018616,0.8183333277702332,0.8193333148956299,0.8163333535194397,0.815666675567627,0.8216666579246521,0.824999988079071,0.8176666498184204,0.828000009059906,0.8259999752044678,0.8176666498184204,0.8146666884422302,0.8209999799728394,0.8116666674613953,0.8146666884422302,0.8223333358764648,0.8209999799728394,0.8180000185966492,0.8180000185966492,0.8180000185966492,0.8199999928474426,0.8193333148956299,0.8169999718666077,0.8183333277702332,0.8159999847412109,0.8146666884422302,0.8183333277702332,0.8183333277702332,0.8186666369438171,0.8130000233650208,0.8186666369438171,0.8146666884422302,0.82833331823349,0.8180000185966492,0.8276666402816772,0.8286666870117188,0.8133333325386047,0.812666654586792,0.8149999976158142,0.8209999799728394,0.8190000057220459,0.8203333616256714,0.8230000138282776,0.815666675567627,0.8213333487510681,0.8190000057220459,0.8209999799728394,0.8186666369438171,0.8196666836738586,0.8236666917800903,0.8193333148956299,0.8213333487510681,0.8196666836738586,0.8243333101272583,0.815666675567627,0.8230000138282776,0.8183333277702332,0.8213333487510681,0.8196666836738586,0.8169999718666077,0.8240000009536743,0.8169999718666077,0.8196666836738586,0.8130000233650208,0.8190000057220459,0.8259999752044678,0.8240000009536743,0.8236666917800903,0.8270000219345093,0.8256666660308838,0.8199999928474426,0.8216666579246521,0.8276666402816772,0.8193333148956299,0.8320000171661377,0.8243333101272583,0.8199999928474426,0.828000009059906,0.8256666660308838,0.8186666369438171,0.8209999799728394,0.8186666369438171,0.8199999928474426,0.8246666789054871,0.8183333277702332,0.8309999704360962,0.8196666836738586,0.8220000267028809,0.8243333101272583,0.8203333616256714,0.8190000057220459,0.8226666450500488,0.8216666579246521,0.8233333230018616,0.8169999718666077,0.8199999928474426,0.8203333616256714,0.8256666660308838,0.8209999799728394,0.8186666369438171,0.8259999752044678,0.8213333487510681,0.8206666707992554,0.8186666369438171,0.8263333439826965,0.8270000219345093,0.8286666870117188,0.8203333616256714,0.8209999799728394,0.8289999961853027,0.8230000138282776,0.8216666579246521,0.8289999961853027,0.8153333067893982,0.8243333101272583,0.8286666870117188,0.8109999895095825,0.8203333616256714,0.8276666402816772,0.8226666450500488,0.8243333101272583,0.8233333230018616,0.8240000009536743,0.8183333277702332,0.8243333101272583,0.8230000138282776,0.8226666450500488,0.8203333616256714,0.8273333311080933,0.8246666789054871,0.8216666579246521,0.8216666579246521,0.8299999833106995,0.8276666402816772,0.8236666917800903,0.8236666917800903,0.8213333487510681,0.8209999799728394,0.8293333053588867,0.8243333101272583,0.8236666917800903,0.8233333230018616,0.8206666707992554,0.8193333148956299,0.824999988079071,0.8149999976158142,0.8149999976158142,0.8183333277702332,0.831333339214325,0.8196666836738586,0.8233333230018616,0.8180000185966492,0.8293333053588867,0.8256666660308838,0.8199999928474426,0.8220000267028809,0.8276666402816772,0.8233333230018616,0.824999988079071,0.8276666402816772,0.8323333263397217,0.8273333311080933,0.8263333439826965,0.8256666660308838,0.831333339214325,0.8259999752044678,0.8216666579246521,0.8216666579246521,0.8199999928474426,0.8263333439826965,0.8233333230018616,0.8209999799728394,0.8223333358764648,0.82833331823349,0.8116666674613953,0.8276666402816772,0.8203333616256714,0.8203333616256714,0.8273333311080933,0.8230000138282776,0.8226666450500488,0.8253333568572998,0.8223333358764648,0.8213333487510681,0.8253333568572998,0.8299999833106995,0.8240000009536743,0.8213333487510681,0.8236666917800903,0.8259999752044678,0.8240000009536743,0.8153333067893982,0.8209999799728394,0.8230000138282776,0.8209999799728394,0.8253333568572998,0.831333339214325,0.8306666612625122,0.8199999928474426,0.8223333358764648,0.8199999928474426,0.8169999718666077,0.8286666870117188,0.8216666579246521,0.8190000057220459,0.8223333358764648,0.824999988079071,0.8256666660308838,0.8253333568572998,0.8256666660308838,0.8226666450500488,0.8230000138282776,0.8259999752044678,0.8173333406448364,0.8230000138282776,0.8309999704360962,0.8159999847412109,0.82833331823349,0.8246666789054871,0.8213333487510681,0.8240000009536743,0.8299999833106995,0.8316666483879089,0.8309999704360962,0.8243333101272583,0.8216666579246521,0.8216666579246521,0.8220000267028809,0.8196666836738586,0.8199999928474426,0.8220000267028809,0.8259999752044678,0.8289999961853027,0.8263333439826965,0.8206666707992554,0.8246666789054871,0.8296666741371155,0.8163333535194397,0.8226666450500488,0.8246666789054871,0.8240000009536743,0.8276666402816772,0.8240000009536743,0.8193333148956299,0.8146666884422302,0.8236666917800903,0.815666675567627,0.82833331823349,0.8273333311080933,0.8190000057220459,0.8236666917800903,0.8199999928474426,0.8259999752044678,0.8259999752044678,0.8276666402816772,0.82833331823349,0.8216666579246521,0.8276666402816772,0.8243333101272583,0.8233333230018616,0.8240000009536743,0.8223333358764648,0.8236666917800903,0.8203333616256714,0.8226666450500488,0.8309999704360962,0.8273333311080933,0.8176666498184204,0.8256666660308838,0.8233333230018616,0.8266666531562805,0.8273333311080933,0.8203333616256714,0.8216666579246521,0.8230000138282776,0.8266666531562805,0.8240000009536743,0.8346666693687439,0.8203333616256714,0.8186666369438171,0.824999988079071,0.8180000185966492,0.8216666579246521,0.8226666450500488,0.8263333439826965,0.8293333053588867,0.8240000009536743,0.8199999928474426,0.8236666917800903,0.8213333487510681,0.8253333568572998,0.8216666579246521,0.8299999833106995,0.8173333406448364,0.8223333358764648,0.8349999785423279,0.8226666450500488,0.8199999928474426,0.828000009059906,0.8286666870117188,0.8309999704360962,0.8206666707992554,0.8240000009536743,0.8223333358764648,0.8323333263397217,0.8190000057220459,0.8186666369438171,0.8273333311080933,0.828000009059906,0.8213333487510681,0.8246666789054871,0.8263333439826965,0.8236666917800903,0.8233333230018616,0.8299999833106995,0.8199999928474426,0.8253333568572998,0.8276666402816772,0.8286666870117188,0.8330000042915344,0.8253333568572998,0.8316666483879089,0.8293333053588867,0.8253333568572998,0.8263333439826965,0.8243333101272583,0.8306666612625122,0.8236666917800903,0.8246666789054871,0.8309999704360962,0.8199999928474426,0.8273333311080933,0.824999988079071,0.8293333053588867,0.8166666626930237,0.8286666870117188,0.8166666626930237,0.8343333601951599,0.828000009059906,0.8240000009536743,0.8276666402816772,0.831333339214325,0.824999988079071,0.824999988079071,0.8223333358764648,0.8270000219345093,0.8320000171661377,0.8220000267028809,0.8180000185966492,0.8246666789054871,0.8253333568572998,0.8233333230018616,0.8246666789054871,0.8246666789054871,0.8230000138282776,0.831333339214325,0.8266666531562805,0.8253333568572998,0.8339999914169312,0.8213333487510681,0.8293333053588867,0.8159999847412109,0.8306666612625122,0.8246666789054871,0.824999988079071,0.8226666450500488,0.8226666450500488,0.8240000009536743,0.8293333053588867,0.8213333487510681,0.8306666612625122,0.8330000042915344,0.8259999752044678,0.8246666789054871,0.828000009059906,0.828000009059906,0.8256666660308838,0.8303333520889282,0.8220000267028809,0.8230000138282776,0.8289999961853027,0.824999988079071,0.8243333101272583,0.8259999752044678,0.8236666917800903,0.8276666402816772,0.8266666531562805,0.8286666870117188,0.8230000138282776,0.824999988079071,0.8246666789054871,0.8286666870117188,0.8246666789054871,0.8296666741371155,0.8263333439826965,0.8353333473205566,0.831333339214325,0.8263333439826965,0.8306666612625122,0.8259999752044678,0.8246666789054871,0.8216666579246521,0.8220000267028809,0.8253333568572998,0.8240000009536743,0.8243333101272583,0.8330000042915344,0.8306666612625122,0.8256666660308838,0.8336666822433472,0.8326666951179504,0.8206666707992554,0.8230000138282776,0.8203333616256714,0.8320000171661377,0.8273333311080933,0.8263333439826965,0.8266666531562805,0.8246666789054871,0.8293333053588867,0.8253333568572998,0.8213333487510681,0.8236666917800903,0.8230000138282776,0.8293333053588867,0.8243333101272583,0.8330000042915344,0.8220000267028809,0.8289999961853027,0.8196666836738586,0.8193333148956299,0.8286666870117188,0.8299999833106995,0.8236666917800903,0.8303333520889282,0.8259999752044678,0.8320000171661377,0.8289999961853027,0.8253333568572998,0.8270000219345093,0.8253333568572998,0.8299999833106995,0.8286666870117188,0.8316666483879089,0.8259999752044678,0.8240000009536743,0.8309999704360962,0.8293333053588867,0.82833331823349,0.828000009059906,0.8223333358764648,0.8336666822433472,0.8273333311080933,0.8246666789054871,0.8236666917800903,0.8259999752044678,0.8209999799728394,0.828000009059906,0.8203333616256714,0.8240000009536743,0.8293333053588867,0.8240000009536743,0.8230000138282776,0.8253333568572998,0.8216666579246521,0.828000009059906,0.828000009059906,0.8236666917800903,0.8326666951179504,0.8240000009536743,0.8286666870117188,0.8259999752044678,0.8303333520889282,0.8339999914169312,0.8330000042915344,0.8243333101272583,0.8273333311080933,0.828000009059906,0.8303333520889282,0.8286666870117188,0.8226666450500488,0.8263333439826965,0.8296666741371155,0.8286666870117188,0.8199999928474426,0.8330000042915344,0.8286666870117188,0.8259999752044678,0.8223333358764648,0.8303333520889282,0.8176666498184204,0.8273333311080933,0.831333339214325,0.8263333439826965,0.8266666531562805,0.8243333101272583,0.8263333439826965,0.8276666402816772,0.8293333053588867,0.831333339214325,0.8266666531562805,0.8216666579246521,0.8226666450500488,0.8323333263397217,0.8286666870117188,0.82833331823349,0.8309999704360962,0.8263333439826965,0.8320000171661377,0.8356666564941406,0.824999988079071,0.8363333344459534,0.8236666917800903,0.8223333358764648,0.8276666402816772,0.8256666660308838,0.8273333311080933,0.8343333601951599,0.8316666483879089,0.8356666564941406,0.8299999833106995,0.8303333520889282,0.8309999704360962,0.831333339214325,0.8270000219345093,0.8286666870117188,0.8259999752044678,0.8270000219345093,0.8293333053588867,0.8266666531562805,0.8336666822433472,0.8326666951179504,0.8246666789054871,0.8256666660308838,0.8259999752044678,0.8270000219345093,0.8306666612625122,0.8203333616256714,0.8230000138282776,0.8349999785423279,0.828000009059906,0.8216666579246521,0.8289999961853027,0.8286666870117188,0.8309999704360962,0.8299999833106995,0.8256666660308838,0.8256666660308838,0.8253333568572998,0.8240000009536743,0.8333333134651184,0.82833331823349,0.824999988079071,0.8266666531562805,0.8299999833106995,0.8289999961853027,0.8276666402816772,0.8273333311080933,0.8266666531562805,0.831333339214325,0.8286666870117188,0.8213333487510681,0.8299999833106995,0.8216666579246521,0.8273333311080933,0.831333339214325,0.8270000219345093,0.8216666579246521,0.8306666612625122,0.8296666741371155,0.8263333439826965,0.824999988079071,0.831333339214325,0.8236666917800903,0.8263333439826965,0.8309999704360962,0.8303333520889282,0.8246666789054871,0.8346666693687439,0.8263333439826965,0.828000009059906,0.8343333601951599,0.8206666707992554,0.8339999914169312,0.8293333053588867,0.8273333311080933,0.8316666483879089,0.8296666741371155,0.8266666531562805,0.8346666693687439,0.824999988079071,0.82833331823349,0.8303333520889282,0.8276666402816772,0.828000009059906,0.8349999785423279,0.828000009059906,0.8293333053588867,0.8233333230018616,0.8303333520889282,0.8296666741371155,0.8303333520889282,0.8263333439826965,0.8299999833106995,0.8256666660308838,0.8286666870117188,0.8266666531562805,0.8273333311080933,0.8286666870117188,0.8270000219345093,0.8296666741371155,0.8296666741371155,0.8136666417121887,0.8370000123977661,0.8243333101272583,0.8286666870117188,0.82833331823349,0.8259999752044678,0.8256666660308838,0.8220000267028809,0.8299999833106995,0.8270000219345093,0.8293333053588867,0.8353333473205566,0.8286666870117188,0.8339999914169312,0.8349999785423279,0.8259999752044678,0.8309999704360962,0.8276666402816772,0.8339999914169312,0.8253333568572998,0.8203333616256714,0.8246666789054871,0.8316666483879089,0.8379999995231628,0.8270000219345093,0.8293333053588867,0.8266666531562805,0.8299999833106995,0.8303333520889282,0.8276666402816772,0.8299999833106995,0.8253333568572998,0.8266666531562805,0.8296666741371155,0.8299999833106995,0.8273333311080933,0.8196666836738586,0.8243333101272583,0.8320000171661377,0.8303333520889282,0.8276666402816772,0.8266666531562805,0.8270000219345093,0.8336666822433472,0.8343333601951599,0.8273333311080933,0.8270000219345093,0.8339999914169312,0.8246666789054871,0.8266666531562805,0.8273333311080933,0.8299999833106995,0.828000009059906,0.8296666741371155,0.8353333473205566,0.8303333520889282,0.8246666789054871,0.8240000009536743,0.8253333568572998,0.8353333473205566,0.8263333439826965,0.8246666789054871,0.8309999704360962,0.8293333053588867,0.8256666660308838,0.8286666870117188,0.8330000042915344,0.8296666741371155,0.8316666483879089,0.8303333520889282,0.8289999961853027,0.824999988079071,0.8276666402816772,0.8236666917800903,0.8286666870117188,0.8306666612625122,0.8270000219345093,0.8296666741371155,0.8316666483879089,0.8323333263397217,0.8240000009536743,0.8230000138282776,0.8220000267028809,0.8273333311080933,0.8323333263397217,0.8223333358764648,0.8286666870117188,0.8230000138282776,0.8259999752044678,0.8263333439826965,0.8276666402816772,0.8276666402816772,0.8259999752044678,0.8293333053588867,0.8293333053588867,0.828000009059906,0.8306666612625122,0.8256666660308838,0.8259999752044678,0.8293333053588867,0.8259999752044678,0.8270000219345093,0.8180000185966492,0.8293333053588867,0.8316666483879089,0.8349999785423279,0.8333333134651184,0.8306666612625122,0.8389999866485596,0.8346666693687439,0.8309999704360962,0.8343333601951599,0.8276666402816772,0.8273333311080933,0.8243333101272583,0.8286666870117188,0.8316666483879089,0.8289999961853027,0.8303333520889282,0.8356666564941406,0.8299999833106995,0.8296666741371155,0.8286666870117188,0.828000009059906,0.8266666531562805,0.8263333439826965,0.8293333053588867,0.8273333311080933,0.8320000171661377,0.8323333263397217,0.8233333230018616,0.8326666951179504,0.8303333520889282,0.831333339214325,0.8216666579246521,0.8353333473205566,0.8306666612625122,0.8333333134651184,0.831333339214325,0.8273333311080933,0.8296666741371155,0.8286666870117188,0.8320000171661377,0.8246666789054871,0.8286666870117188,0.8286666870117188,0.8256666660308838,0.831333339214325,0.8343333601951599,0.82833331823349,0.8296666741371155,0.8270000219345093,0.8243333101272583,0.8299999833106995,0.8339999914169312,0.82833331823349,0.8273333311080933,0.8316666483879089,0.8326666951179504,0.831333339214325,0.8293333053588867,0.8266666531562805,0.8326666951179504,0.8270000219345093,0.8316666483879089,0.8256666660308838,0.8320000171661377,0.8303333520889282,0.82833331823349,0.8266666531562805,0.8296666741371155,0.8246666789054871,0.8266666531562805,0.82833331823349,0.8343333601951599,0.828000009059906,0.8259999752044678,0.8273333311080933,0.8256666660308838,0.8320000171661377,0.8346666693687439,0.8346666693687439,0.8339999914169312,0.82833331823349,0.8306666612625122,0.8299999833106995,0.8316666483879089,0.8309999704360962,0.8309999704360962,0.82833331823349,0.8266666531562805,0.8233333230018616,0.8209999799728394,0.8403333425521851,0.8299999833106995,0.8353333473205566,0.8323333263397217,0.8296666741371155,0.8240000009536743,0.8273333311080933,0.8349999785423279,0.8326666951179504,0.8330000042915344,0.8316666483879089,0.8273333311080933,0.8339999914169312,0.8253333568572998,0.8253333568572998,0.8326666951179504,0.8306666612625122,0.8326666951179504,0.8293333053588867,0.8286666870117188,0.8246666789054871,0.8320000171661377,0.8343333601951599,0.8389999866485596,0.8323333263397217,0.831333339214325,0.82833331823349,0.8213333487510681,0.8296666741371155,0.8293333053588867,0.8293333053588867,0.8259999752044678,0.8246666789054871,0.8339999914169312,0.8256666660308838,0.8360000252723694,0.8276666402816772,0.8233333230018616,0.8326666951179504,0.8286666870117188,0.828000009059906,0.8273333311080933,0.8276666402816772,0.8236666917800903,0.8270000219345093,0.8309999704360962,0.8346666693687439,0.8203333616256714,0.8263333439826965,0.8266666531562805,0.8316666483879089,0.8263333439826965,0.8293333053588867,0.8326666951179504,0.8336666822433472,0.8336666822433472,0.8326666951179504,0.8230000138282776,0.8349999785423279,0.8339999914169312,0.8339999914169312,0.8339999914169312,0.8333333134651184,0.8240000009536743,0.8320000171661377,0.8293333053588867,0.8346666693687439,0.8339999914169312,0.8306666612625122,0.8303333520889282,0.8349999785423279,0.8273333311080933,0.8289999961853027,0.8320000171661377,0.828000009059906,0.828000009059906,0.8259999752044678,0.8326666951179504,0.82833331823349,0.8316666483879089,0.8303333520889282,0.8296666741371155,0.8299999833106995,0.8320000171661377,0.8336666822433472,0.824999988079071,0.8293333053588867,0.8273333311080933,0.8320000171661377,0.8259999752044678,0.8346666693687439,0.8286666870117188,0.8333333134651184,0.8353333473205566,0.8306666612625122,0.8326666951179504,0.8226666450500488,0.8263333439826965,0.8330000042915344,0.8209999799728394,0.8379999995231628,0.8289999961853027,0.8293333053588867,0.8273333311080933,0.8296666741371155,0.8333333134651184,0.8256666660308838,0.8230000138282776,0.8286666870117188,0.8360000252723694,0.8253333568572998,0.8353333473205566,0.8273333311080933,0.8336666822433472,0.8289999961853027,0.8266666531562805,0.8246666789054871,0.8286666870117188,0.8316666483879089,0.8353333473205566,0.828000009059906,0.8246666789054871,0.8286666870117188,0.8303333520889282,0.8289999961853027,0.8293333053588867,0.8253333568572998,0.8299999833106995,0.8289999961853027,0.8366666436195374,0.8306666612625122,0.8339999914169312,0.8453333377838135,0.8289999961853027,0.8336666822433472,0.8330000042915344,0.8299999833106995,0.8289999961853027,0.8276666402816772,0.8246666789054871,0.828000009059906,0.8370000123977661,0.8306666612625122,0.8323333263397217,0.8270000219345093,0.8253333568572998,0.8246666789054871,0.8316666483879089,0.8336666822433472,0.8330000042915344,0.8336666822433472,0.8339999914169312,0.8289999961853027,0.8303333520889282,0.8306666612625122,0.831333339214325,0.8333333134651184,0.8266666531562805,0.8306666612625122,0.8246666789054871,0.8293333053588867,0.8326666951179504,0.8326666951179504,0.8240000009536743,0.8323333263397217,0.8256666660308838,0.8343333601951599,0.8330000042915344,0.8259999752044678,0.8259999752044678,0.8323333263397217,0.8356666564941406,0.8339999914169312,0.8343333601951599,0.8263333439826965,0.8296666741371155,0.828000009059906,0.8220000267028809,0.831333339214325,0.8299999833106995,0.8270000219345093,0.8296666741371155,0.8286666870117188,0.8299999833106995,0.8289999961853027,0.8233333230018616,0.8309999704360962,0.8273333311080933,0.8323333263397217,0.8413333296775818,0.8276666402816772,0.8343333601951599,0.8270000219345093,0.8303333520889282,0.8333333134651184,0.8323333263397217,0.8256666660308838,0.8246666789054871,0.8253333568572998,0.8323333263397217,0.8366666436195374,0.8306666612625122,0.8389999866485596,0.8296666741371155,0.8330000042915344,0.8360000252723694,0.8270000219345093,0.8336666822433472,0.8256666660308838,0.8346666693687439,0.8320000171661377,0.828000009059906,0.8273333311080933,0.8286666870117188,0.8273333311080933,0.8316666483879089,0.8259999752044678,0.8273333311080933,0.8306666612625122,0.8349999785423279,0.8306666612625122,0.8289999961853027,0.8273333311080933,0.8296666741371155,0.8233333230018616,0.8389999866485596,0.8376666903495789,0.8366666436195374,0.828000009059906,0.8296666741371155,0.8276666402816772,0.8293333053588867,0.8263333439826965,0.8233333230018616,0.8299999833106995,0.8363333344459534,0.8256666660308838,0.8306666612625122,0.828000009059906,0.8259999752044678,0.8296666741371155,0.8253333568572998,0.8289999961853027,0.8330000042915344,0.8289999961853027,0.8263333439826965,0.8316666483879089,0.8316666483879089,0.8316666483879089,0.8299999833106995,0.8286666870117188,0.831333339214325,0.828000009059906,0.8293333053588867,0.8266666531562805,0.8273333311080933,0.8286666870117188,0.8339999914169312,0.8356666564941406,0.8256666660308838,0.8323333263397217,0.8316666483879089,0.8240000009536743,0.8259999752044678,0.828000009059906,0.8363333344459534,0.8326666951179504,0.8330000042915344,0.831333339214325,0.8299999833106995,0.8293333053588867,0.8330000042915344,0.8346666693687439,0.8230000138282776,0.8339999914169312,0.828000009059906,0.8373333215713501,0.828000009059906,0.8339999914169312,0.8333333134651184,0.8303333520889282,0.8333333134651184,0.8286666870117188,0.8320000171661377,0.831333339214325,0.8363333344459534,0.8296666741371155,0.8259999752044678,0.8343333601951599,0.8303333520889282,0.8286666870117188,0.8330000042915344,0.831333339214325,0.8303333520889282,0.8276666402816772,0.8256666660308838,0.8296666741371155,0.8330000042915344,0.8299999833106995,0.828000009059906,0.8296666741371155,0.8286666870117188,0.831333339214325,0.8303333520889282,0.8320000171661377,0.8273333311080933,0.8253333568572998,0.8323333263397217,0.8243333101272583,0.8343333601951599,0.8386666774749756,0.8309999704360962,0.8323333263397217,0.8259999752044678,0.8306666612625122,0.8270000219345093,0.8230000138282776,0.8303333520889282,0.8323333263397217,0.8320000171661377,0.8286666870117188,0.8333333134651184,0.8236666917800903,0.8320000171661377,0.8303333520889282,0.8296666741371155,0.8233333230018616,0.8296666741371155,0.8286666870117188,0.8353333473205566,0.8346666693687439,0.8339999914169312,0.8323333263397217,0.8233333230018616,0.8360000252723694,0.8370000123977661,0.8343333601951599,0.8356666564941406,0.8309999704360962,0.8266666531562805,0.8333333134651184,0.8353333473205566,0.8320000171661377,0.824999988079071,0.8243333101272583,0.8296666741371155,0.8226666450500488,0.8286666870117188,0.8349999785423279,0.8316666483879089,0.8299999833106995,0.8286666870117188,0.8309999704360962,0.8399999737739563,0.8306666612625122,0.8303333520889282,0.8266666531562805,0.8326666951179504,0.8299999833106995,0.8273333311080933,0.8286666870117188,0.8296666741371155,0.8303333520889282,0.8303333520889282,0.8336666822433472,0.8320000171661377,0.8366666436195374,0.8343333601951599,0.8296666741371155,0.8273333311080933,0.8349999785423279,0.831333339214325,0.8276666402816772,0.8360000252723694,0.8303333520889282,0.8339999914169312,0.8306666612625122,0.8266666531562805,0.8303333520889282,0.8276666402816772,0.8306666612625122,0.8270000219345093,0.8306666612625122,0.8349999785423279,0.824999988079071,0.824999988079071,0.8276666402816772,0.8296666741371155,0.8259999752044678,0.828000009059906,0.8293333053588867,0.8266666531562805,0.8276666402816772,0.8273333311080933,0.8330000042915344,0.8286666870117188,0.8306666612625122,0.8266666531562805,0.8263333439826965,0.8379999995231628,0.8336666822433472,0.8326666951179504,0.8263333439826965,0.8323333263397217,0.8309999704360962,0.828000009059906,0.8333333134651184,0.8306666612625122,0.8303333520889282,0.8296666741371155,0.8243333101272583,0.8326666951179504,0.8326666951179504,0.8389999866485596,0.8266666531562805,0.8306666612625122,0.82833331823349,0.8309999704360962,0.8393333554267883,0.8353333473205566,0.8309999704360962,0.8333333134651184,0.8370000123977661,0.8286666870117188,0.828000009059906,0.8293333053588867,0.8320000171661377,0.8306666612625122,0.8343333601951599,0.8309999704360962,0.8303333520889282,0.8323333263397217,0.8316666483879089,0.8323333263397217,0.8263333439826965,0.8366666436195374,0.8336666822433472,0.8276666402816772,0.8236666917800903,0.8263333439826965,0.8236666917800903,0.8253333568572998,0.828000009059906,0.8303333520889282,0.8370000123977661,0.8320000171661377,0.8320000171661377,0.8389999866485596,0.8336666822433472,0.8289999961853027,0.8360000252723694,0.828000009059906,0.8330000042915344,0.8333333134651184,0.8303333520889282,0.8293333053588867,0.8366666436195374,0.8320000171661377,0.8303333520889282,0.8293333053588867,0.8353333473205566,0.8276666402816772,0.8336666822433472,0.8316666483879089,0.8309999704360962,0.8326666951179504,0.8270000219345093,0.8309999704360962,0.8253333568572998,0.8356666564941406,0.828000009059906,0.8289999961853027,0.8336666822433472,0.8323333263397217,0.8326666951179504,0.8343333601951599,0.8373333215713501,0.82833331823349,0.8266666531562805,0.8336666822433472,0.8320000171661377,0.8336666822433472,0.8293333053588867,0.8323333263397217,0.8370000123977661,0.828000009059906,0.8253333568572998,0.8330000042915344,0.8326666951179504,0.8259999752044678,0.8286666870117188,0.8266666531562805,0.8370000123977661,0.8323333263397217,0.8306666612625122,0.8246666789054871,0.8403333425521851,0.8320000171661377,0.82833331823349,0.8366666436195374,0.8240000009536743,0.8286666870117188,0.8259999752044678,0.8306666612625122,0.8336666822433472,0.8330000042915344,0.8263333439826965,0.828000009059906,0.8339999914169312,0.8299999833106995,0.8306666612625122,0.8330000042915344,0.8346666693687439,0.828000009059906,0.8366666436195374,0.8330000042915344,0.8346666693687439,0.8353333473205566,0.8263333439826965,0.8349999785423279,0.8286666870117188,0.8370000123977661,0.8303333520889282,0.8289999961853027,0.8326666951179504,0.8360000252723694,0.8316666483879089,0.8396666646003723,0.8286666870117188,0.8273333311080933,0.8253333568572998,0.8296666741371155,0.8299999833106995,0.8346666693687439,0.8303333520889282,0.8316666483879089,0.8293333053588867,0.8266666531562805,0.8293333053588867,0.8263333439826965,0.8270000219345093,0.8330000042915344,0.82833331823349,0.8303333520889282,0.8299999833106995,0.8353333473205566,0.8253333568572998,0.8309999704360962,0.8299999833106995,0.828000009059906,0.8326666951179504,0.8346666693687439,0.8346666693687439,0.8299999833106995,0.8320000171661377,0.8353333473205566,0.8349999785423279,0.8309999704360962,0.8213333487510681,0.8343333601951599,0.8349999785423279,0.8270000219345093,0.8263333439826965,0.8373333215713501,0.8270000219345093,0.8240000009536743,0.8333333134651184,0.8320000171661377,0.8336666822433472,0.8326666951179504,0.8276666402816772,0.831333339214325,0.8293333053588867,0.8333333134651184,0.8306666612625122,0.8303333520889282,0.8353333473205566,0.8303333520889282,0.8326666951179504,0.82833331823349,0.82833331823349,0.8333333134651184,0.8299999833106995,0.8360000252723694,0.8356666564941406,0.8346666693687439,0.8276666402816772,0.8339999914169312,0.8333333134651184,0.8323333263397217,0.8309999704360962,0.8286666870117188,0.8389999866485596,0.8346666693687439,0.8343333601951599,0.8240000009536743,0.8240000009536743,0.8336666822433472,0.824999988079071,0.8323333263397217,0.8316666483879089,0.8323333263397217,0.8363333344459534,0.8360000252723694,0.8330000042915344,0.8263333439826965,0.8273333311080933,0.8309999704360962,0.8349999785423279,0.828000009059906,0.8289999961853027,0.8253333568572998,0.8323333263397217,0.8370000123977661,0.8349999785423279,0.8326666951179504,0.8309999704360962,0.8309999704360962,0.8326666951179504,0.8306666612625122,0.8336666822433472,0.8289999961853027,0.8309999704360962,0.8363333344459534,0.8320000171661377,0.8273333311080933,0.8289999961853027,0.8296666741371155,0.8306666612625122,0.8306666612625122,0.8320000171661377,0.8273333311080933,0.831333339214325,0.8326666951179504,0.8316666483879089,0.8320000171661377,0.8270000219345093,0.8309999704360962,0.8299999833106995,0.8266666531562805,0.8356666564941406,0.8273333311080933,0.8309999704360962,0.8326666951179504,0.8293333053588867,0.8293333053588867,0.8339999914169312,0.82833331823349,0.8286666870117188,0.8339999914169312,0.8276666402816772,0.82833331823349,0.8286666870117188,0.8336666822433472,0.824999988079071,0.8263333439826965,0.8263333439826965,0.8296666741371155,0.8289999961853027,0.8243333101272583,0.8323333263397217,0.8223333358764648,0.82833331823349,0.831333339214325,0.8246666789054871,0.8303333520889282,0.8276666402816772,0.8296666741371155,0.8373333215713501,0.8263333439826965,0.828000009059906,0.831333339214325,0.8266666531562805,0.8286666870117188,0.8309999704360962,0.8339999914169312,0.8399999737739563,0.8366666436195374,0.8306666612625122,0.8293333053588867,0.8316666483879089,0.828000009059906,0.8343333601951599,0.8299999833106995,0.8266666531562805,0.8289999961853027,0.8353333473205566,0.828000009059906,0.8330000042915344,0.8299999833106995,0.8293333053588867,0.8343333601951599,0.831333339214325,0.8326666951179504,0.8233333230018616,0.8296666741371155,0.8316666483879089,0.8286666870117188,0.8330000042915344,0.8339999914169312,0.8363333344459534,0.8316666483879089,0.8320000171661377,0.8306666612625122,0.8323333263397217,0.828000009059906,0.8339999914169312,0.8303333520889282,0.824999988079071,0.8323333263397217,0.8286666870117188,0.8299999833106995,0.8316666483879089,0.8323333263397217,0.8209999799728394,0.8303333520889282,0.8343333601951599,0.8316666483879089,0.8330000042915344,0.8263333439826965,0.8333333134651184,0.8323333263397217,0.8256666660308838,0.8379999995231628,0.831333339214325,0.8343333601951599,0.8346666693687439,0.8336666822433472,0.8370000123977661,0.831333339214325,0.8323333263397217,0.8306666612625122,0.831333339214325,0.8289999961853027,0.831333339214325,0.831333339214325,0.8356666564941406,0.8336666822433472,0.82833331823349,0.8320000171661377,0.8309999704360962,0.8289999961853027,0.8253333568572998,0.8309999704360962,0.8259999752044678,0.8303333520889282,0.8263333439826965,0.8293333053588867,0.8370000123977661,0.8316666483879089,0.8293333053588867],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\",\"width\":2},\"mode\":\"lines\",\"name\":\"val_acc\",\"y\":[0.5139999985694885,0.534500002861023,0.5394999980926514,0.5440000295639038,0.5164999961853027,0.5450000166893005,0.5895000100135803,0.5619999766349792,0.5759999752044678,0.6554999947547913,0.593500018119812,0.6784999966621399,0.6535000205039978,0.699999988079071,0.6650000214576721,0.6995000243186951,0.7200000286102295,0.699999988079071,0.7515000104904175,0.7174999713897705,0.7275000214576721,0.7724999785423279,0.7609999775886536,0.7310000061988831,0.8069999814033508,0.7609999775886536,0.7689999938011169,0.8029999732971191,0.7674999833106995,0.8015000224113464,0.7854999899864197,0.8105000257492065,0.8029999732971191,0.8034999966621399,0.8065000176429749,0.8029999732971191,0.8069999814033508,0.8199999928474426,0.8169999718666077,0.8105000257492065,0.8115000128746033,0.8130000233650208,0.8215000033378601,0.8174999952316284,0.8195000290870667,0.8234999775886536,0.8220000267028809,0.8240000009536743,0.8230000138282776,0.8245000243186951,0.828499972820282,0.8309999704360962,0.8270000219345093,0.8299999833106995,0.8314999938011169,0.8320000171661377,0.8305000066757202,0.8339999914169312,0.8339999914169312,0.824999988079071,0.8370000123977661,0.8339999914169312,0.8209999799728394,0.8370000123977661,0.8379999995231628,0.8299999833106995,0.8335000276565552,0.8379999995231628,0.8295000195503235,0.8395000100135803,0.8379999995231628,0.8395000100135803,0.8370000123977661,0.8324999809265137,0.8309999704360962,0.8410000205039978,0.8355000019073486,0.8339999914169312,0.8399999737739563,0.8424999713897705,0.8339999914169312,0.8399999737739563,0.8420000076293945,0.843500018119812,0.8445000052452087,0.8374999761581421,0.8445000052452087,0.8389999866485596,0.843999981880188,0.8414999842643738,0.8399999737739563,0.8385000228881836,0.8429999947547913,0.8410000205039978,0.8424999713897705,0.8399999737739563,0.847000002861023,0.8414999842643738,0.8410000205039978,0.843500018119812,0.8389999866485596,0.8454999923706055,0.8429999947547913,0.8420000076293945,0.8464999794960022,0.8454999923706055,0.8429999947547913,0.8450000286102295,0.8475000262260437,0.8454999923706055,0.8450000286102295,0.8445000052452087,0.8475000262260437,0.8429999947547913,0.843999981880188,0.847000002861023,0.8450000286102295,0.843999981880188,0.843999981880188,0.843500018119812,0.8420000076293945,0.8424999713897705,0.8424999713897705,0.843500018119812,0.843999981880188,0.8424999713897705,0.843999981880188,0.843999981880188,0.8420000076293945,0.8429999947547913,0.8429999947547913,0.843500018119812,0.8454999923706055,0.8454999923706055,0.843999981880188,0.8424999713897705,0.8429999947547913,0.843999981880188,0.8445000052452087,0.843999981880188,0.843500018119812,0.8420000076293945,0.8420000076293945,0.8429999947547913,0.8429999947547913,0.8420000076293945,0.8414999842643738,0.8464999794960022,0.8424999713897705,0.843500018119812,0.8420000076293945,0.8464999794960022,0.8429999947547913,0.8429999947547913,0.8429999947547913,0.8429999947547913,0.8454999923706055,0.8429999947547913,0.8424999713897705,0.843500018119812,0.843500018119812,0.8414999842643738,0.8424999713897705,0.843999981880188,0.8445000052452087,0.8454999923706055,0.843500018119812,0.843999981880188,0.8429999947547913,0.8424999713897705,0.8420000076293945,0.8424999713897705,0.843500018119812,0.8429999947547913,0.8445000052452087,0.843999981880188,0.8450000286102295,0.8420000076293945,0.843500018119812,0.8445000052452087,0.8454999923706055,0.8460000157356262,0.8450000286102295,0.8429999947547913,0.8410000205039978,0.8450000286102295,0.8414999842643738,0.8414999842643738,0.8454999923706055,0.8450000286102295,0.8450000286102295,0.843999981880188,0.8429999947547913,0.8460000157356262,0.8429999947547913,0.843500018119812,0.8479999899864197,0.847000002861023,0.8424999713897705,0.8429999947547913,0.8454999923706055,0.8464999794960022,0.8454999923706055,0.8450000286102295,0.8454999923706055,0.843999981880188,0.8460000157356262,0.8454999923706055,0.847000002861023,0.8450000286102295,0.8460000157356262,0.8475000262260437,0.8475000262260437,0.8460000157356262,0.8479999899864197,0.8454999923706055,0.847000002861023,0.8479999899864197,0.847000002861023,0.8460000157356262,0.8450000286102295,0.8464999794960022,0.8475000262260437,0.8485000133514404,0.847000002861023,0.8485000133514404,0.8475000262260437,0.8450000286102295,0.8460000157356262,0.8460000157356262,0.847000002861023,0.8475000262260437,0.8479999899864197,0.8460000157356262,0.847000002861023,0.8489999771118164,0.8479999899864197,0.8485000133514404,0.847000002861023,0.8475000262260437,0.8479999899864197,0.8479999899864197,0.847000002861023,0.8475000262260437,0.8479999899864197,0.8479999899864197,0.847000002861023,0.8485000133514404,0.8464999794960022,0.847000002861023,0.8479999899864197,0.8464999794960022,0.8464999794960022,0.847000002861023,0.8485000133514404,0.8485000133514404,0.8464999794960022,0.8460000157356262,0.8464999794960022,0.8454999923706055,0.8479999899864197,0.8475000262260437,0.8479999899864197,0.847000002861023,0.8479999899864197,0.8479999899864197,0.8464999794960022,0.8464999794960022,0.8460000157356262,0.8454999923706055,0.8454999923706055,0.8454999923706055,0.8479999899864197,0.847000002861023,0.8475000262260437,0.8479999899864197,0.8485000133514404,0.8460000157356262,0.8450000286102295,0.8454999923706055,0.8464999794960022,0.8464999794960022,0.8454999923706055,0.8460000157356262,0.8464999794960022,0.8460000157356262,0.8445000052452087,0.8450000286102295,0.847000002861023,0.8475000262260437,0.8485000133514404,0.8464999794960022,0.8454999923706055,0.843999981880188,0.843999981880188,0.8464999794960022,0.8464999794960022,0.8460000157356262,0.8450000286102295,0.8450000286102295,0.8450000286102295,0.8429999947547913,0.8454999923706055,0.8460000157356262,0.8429999947547913,0.8454999923706055,0.8450000286102295,0.8464999794960022,0.8454999923706055,0.8414999842643738,0.8460000157356262,0.847000002861023,0.8445000052452087,0.8429999947547913,0.8445000052452087,0.843999981880188,0.8420000076293945,0.8454999923706055,0.8454999923706055,0.843999981880188,0.8420000076293945,0.8450000286102295,0.8424999713897705,0.8454999923706055,0.8454999923706055,0.8454999923706055,0.8424999713897705,0.843999981880188,0.8445000052452087,0.843999981880188,0.8475000262260437,0.8464999794960022,0.8454999923706055,0.8460000157356262,0.8454999923706055,0.8450000286102295,0.843999981880188,0.843999981880188,0.8464999794960022,0.8460000157356262,0.8424999713897705,0.843999981880188,0.8485000133514404,0.8464999794960022,0.8454999923706055,0.8445000052452087,0.843999981880188,0.8464999794960022,0.8454999923706055,0.8424999713897705,0.8429999947547913,0.8450000286102295,0.8460000157356262,0.8460000157356262,0.8445000052452087,0.8429999947547913,0.8424999713897705,0.843999981880188,0.8454999923706055,0.843500018119812,0.843999981880188,0.8460000157356262,0.8450000286102295,0.843999981880188,0.8450000286102295,0.8460000157356262,0.8450000286102295,0.843999981880188,0.8464999794960022,0.843999981880188,0.8454999923706055,0.8464999794960022,0.843500018119812,0.8454999923706055,0.8460000157356262,0.8450000286102295,0.843500018119812,0.843999981880188,0.847000002861023,0.8454999923706055,0.8429999947547913,0.8450000286102295,0.8429999947547913,0.8445000052452087,0.843500018119812,0.8450000286102295,0.843999981880188,0.843999981880188,0.8460000157356262,0.8450000286102295,0.8450000286102295,0.8424999713897705,0.843500018119812,0.8424999713897705,0.8424999713897705,0.843999981880188,0.843500018119812,0.8445000052452087,0.843500018119812,0.8454999923706055,0.8445000052452087,0.8454999923706055,0.8445000052452087,0.8420000076293945,0.843500018119812,0.8429999947547913,0.843999981880188,0.843999981880188,0.843500018119812,0.843999981880188,0.843500018119812,0.843999981880188,0.843999981880188,0.8445000052452087,0.8445000052452087,0.8445000052452087,0.843999981880188,0.8460000157356262,0.8454999923706055,0.8460000157356262,0.8450000286102295,0.8445000052452087,0.8454999923706055,0.8475000262260437,0.8445000052452087,0.843500018119812,0.8445000052452087,0.8445000052452087,0.8454999923706055,0.8429999947547913,0.843500018119812,0.8445000052452087,0.843999981880188,0.8454999923706055,0.8454999923706055,0.8450000286102295,0.8460000157356262,0.8460000157356262,0.8460000157356262,0.8460000157356262,0.8420000076293945,0.8450000286102295,0.8450000286102295,0.8464999794960022,0.8450000286102295,0.843500018119812,0.8454999923706055,0.8429999947547913,0.8445000052452087,0.8445000052452087,0.8424999713897705,0.843500018119812,0.843999981880188,0.843999981880188,0.8450000286102295,0.8450000286102295,0.843500018119812,0.843500018119812,0.843500018119812,0.843500018119812,0.8450000286102295,0.843999981880188,0.843500018119812,0.8445000052452087,0.843999981880188,0.8450000286102295,0.8445000052452087,0.843999981880188,0.8424999713897705,0.8429999947547913,0.843999981880188,0.8445000052452087,0.843500018119812,0.8445000052452087,0.8450000286102295,0.8450000286102295,0.8450000286102295,0.8460000157356262,0.8454999923706055,0.8450000286102295,0.8460000157356262,0.8450000286102295,0.8445000052452087,0.8450000286102295,0.843500018119812,0.8420000076293945,0.8420000076293945,0.843500018119812,0.8450000286102295,0.8454999923706055,0.8450000286102295,0.843500018119812,0.8475000262260437,0.8454999923706055,0.8450000286102295,0.8450000286102295,0.8454999923706055,0.8445000052452087,0.8464999794960022,0.843500018119812,0.8454999923706055,0.8445000052452087,0.8424999713897705,0.8454999923706055,0.8454999923706055,0.8450000286102295,0.8450000286102295,0.8445000052452087,0.8450000286102295,0.8454999923706055,0.8464999794960022,0.847000002861023,0.8445000052452087,0.8460000157356262,0.8450000286102295,0.8445000052452087,0.8420000076293945,0.840499997138977,0.8445000052452087,0.8464999794960022,0.847000002861023,0.8445000052452087,0.8454999923706055,0.8450000286102295,0.843999981880188,0.8454999923706055,0.8479999899864197,0.8454999923706055,0.8460000157356262,0.8424999713897705,0.8424999713897705,0.8420000076293945,0.843999981880188,0.8450000286102295,0.8445000052452087,0.8445000052452087,0.8450000286102295,0.843500018119812,0.8460000157356262,0.847000002861023,0.8454999923706055,0.8445000052452087,0.8454999923706055,0.843999981880188,0.8429999947547913,0.8489999771118164,0.8454999923706055,0.8424999713897705,0.8445000052452087,0.8454999923706055,0.843999981880188,0.8450000286102295,0.8450000286102295,0.8460000157356262,0.8454999923706055,0.843500018119812,0.8429999947547913,0.8460000157356262,0.8445000052452087,0.8454999923706055,0.8454999923706055,0.8429999947547913,0.8445000052452087,0.8460000157356262,0.8464999794960022,0.8454999923706055,0.8445000052452087,0.843500018119812,0.8429999947547913,0.843999981880188,0.843999981880188,0.8450000286102295,0.843999981880188,0.8450000286102295,0.8454999923706055,0.8454999923706055,0.8454999923706055,0.8460000157356262,0.8450000286102295,0.8464999794960022,0.8460000157356262,0.8454999923706055,0.843500018119812,0.8445000052452087,0.8450000286102295,0.8464999794960022,0.8454999923706055,0.8445000052452087,0.8445000052452087,0.8464999794960022,0.8429999947547913,0.847000002861023,0.8450000286102295,0.8429999947547913,0.8445000052452087,0.8454999923706055,0.8445000052452087,0.8460000157356262,0.8460000157356262,0.8445000052452087,0.8450000286102295,0.8464999794960022,0.8445000052452087,0.8454999923706055,0.8479999899864197,0.8460000157356262,0.8445000052452087,0.8454999923706055,0.8464999794960022,0.8445000052452087,0.8454999923706055,0.8475000262260437,0.8460000157356262,0.8445000052452087,0.843999981880188,0.843999981880188,0.8464999794960022,0.8454999923706055,0.8454999923706055,0.847000002861023,0.847000002861023,0.8445000052452087,0.843999981880188,0.847000002861023,0.847000002861023,0.8460000157356262,0.8454999923706055,0.8464999794960022,0.843999981880188,0.847000002861023,0.8479999899864197,0.8479999899864197,0.8464999794960022,0.8475000262260437,0.847000002861023,0.8485000133514404,0.8450000286102295,0.8464999794960022,0.8460000157356262,0.8464999794960022,0.8464999794960022,0.847000002861023,0.8475000262260437,0.843999981880188,0.8450000286102295,0.8460000157356262,0.8450000286102295,0.8475000262260437,0.8464999794960022,0.8450000286102295,0.8445000052452087,0.8450000286102295,0.847000002861023,0.847000002861023,0.8464999794960022,0.8475000262260437,0.8445000052452087,0.847000002861023,0.8454999923706055,0.8450000286102295,0.8464999794960022,0.843999981880188,0.8454999923706055,0.8475000262260437,0.8475000262260437,0.8460000157356262,0.8479999899864197,0.8464999794960022,0.847000002861023,0.8464999794960022,0.8460000157356262,0.8464999794960022,0.843999981880188,0.8445000052452087,0.8445000052452087,0.8454999923706055,0.8460000157356262,0.8454999923706055,0.8450000286102295,0.8460000157356262,0.8464999794960022,0.843999981880188,0.8445000052452087,0.8460000157356262,0.8445000052452087,0.8450000286102295,0.8460000157356262,0.8460000157356262,0.8460000157356262,0.8445000052452087,0.8445000052452087,0.8464999794960022,0.8450000286102295,0.8460000157356262,0.8454999923706055,0.8464999794960022,0.8460000157356262,0.8454999923706055,0.8464999794960022,0.8450000286102295,0.8450000286102295,0.8454999923706055,0.8460000157356262,0.847000002861023,0.8460000157356262,0.8445000052452087,0.8454999923706055,0.843500018119812,0.8450000286102295,0.8460000157356262,0.8460000157356262,0.8464999794960022,0.8454999923706055,0.8454999923706055,0.8464999794960022,0.847000002861023,0.8454999923706055,0.8445000052452087,0.8464999794960022,0.8464999794960022,0.8460000157356262,0.843999981880188,0.8460000157356262,0.8464999794960022,0.847000002861023,0.8475000262260437,0.8475000262260437,0.847000002861023,0.8445000052452087,0.843999981880188,0.8460000157356262,0.8454999923706055,0.843500018119812,0.8450000286102295,0.8450000286102295,0.8454999923706055,0.8460000157356262,0.8460000157356262,0.8464999794960022,0.8475000262260437,0.8475000262260437,0.8464999794960022,0.847000002861023,0.8445000052452087,0.843999981880188,0.8454999923706055,0.8454999923706055,0.8454999923706055,0.8464999794960022,0.8464999794960022,0.8464999794960022,0.8460000157356262,0.8450000286102295,0.8460000157356262,0.8450000286102295,0.8460000157356262,0.8460000157356262,0.8454999923706055,0.847000002861023,0.847000002861023,0.8479999899864197,0.847000002861023,0.8454999923706055,0.8450000286102295,0.8464999794960022,0.8464999794960022,0.8475000262260437,0.8454999923706055,0.8454999923706055,0.8445000052452087,0.8450000286102295,0.8445000052452087,0.843999981880188,0.8454999923706055,0.8475000262260437,0.8464999794960022,0.847000002861023,0.843999981880188,0.8429999947547913,0.843500018119812,0.8454999923706055,0.843999981880188,0.8445000052452087,0.8460000157356262,0.8460000157356262,0.8460000157356262,0.8445000052452087,0.8464999794960022,0.8464999794960022,0.8445000052452087,0.8429999947547913,0.843500018119812,0.8445000052452087,0.8464999794960022,0.8445000052452087,0.8429999947547913,0.8454999923706055,0.8454999923706055,0.843999981880188,0.843999981880188,0.843999981880188,0.8464999794960022,0.8450000286102295,0.8460000157356262,0.8460000157356262,0.8464999794960022,0.847000002861023,0.843999981880188,0.843500018119812,0.843500018119812,0.8445000052452087,0.8450000286102295,0.8475000262260437,0.8454999923706055,0.8450000286102295,0.843999981880188,0.8464999794960022,0.8464999794960022,0.8445000052452087,0.843999981880188,0.8429999947547913,0.8445000052452087,0.8445000052452087,0.8464999794960022,0.8464999794960022,0.8454999923706055,0.8454999923706055,0.8460000157356262,0.843999981880188,0.8454999923706055,0.8454999923706055,0.847000002861023,0.843500018119812,0.843999981880188,0.843999981880188,0.8445000052452087,0.8445000052452087,0.843999981880188,0.8460000157356262,0.8464999794960022,0.8460000157356262,0.8464999794960022,0.8450000286102295,0.843999981880188,0.8454999923706055,0.8454999923706055,0.847000002861023,0.8464999794960022,0.8450000286102295,0.843999981880188,0.8464999794960022,0.8460000157356262,0.8450000286102295,0.8454999923706055,0.8454999923706055,0.8460000157356262,0.8445000052452087,0.843999981880188,0.8454999923706055,0.8460000157356262,0.843500018119812,0.8454999923706055,0.8454999923706055,0.847000002861023,0.847000002861023,0.847000002861023,0.847000002861023,0.8454999923706055,0.847000002861023,0.847000002861023,0.8460000157356262,0.8460000157356262,0.8450000286102295,0.843500018119812,0.843999981880188,0.8445000052452087,0.843999981880188,0.8460000157356262,0.8464999794960022,0.8460000157356262,0.8445000052452087,0.8445000052452087,0.843999981880188,0.8450000286102295,0.8454999923706055,0.8475000262260437,0.8450000286102295,0.8454999923706055,0.8450000286102295,0.8464999794960022,0.8464999794960022,0.8464999794960022,0.8464999794960022,0.843999981880188,0.8460000157356262,0.8450000286102295,0.8475000262260437,0.8464999794960022,0.8454999923706055,0.8454999923706055,0.8445000052452087,0.8445000052452087,0.8450000286102295,0.8450000286102295,0.8460000157356262,0.8464999794960022,0.847000002861023,0.8450000286102295,0.8445000052452087,0.8445000052452087,0.843500018119812,0.8450000286102295,0.8450000286102295,0.8445000052452087,0.843500018119812,0.8450000286102295,0.8464999794960022,0.8464999794960022,0.8450000286102295,0.8475000262260437,0.847000002861023,0.847000002861023,0.847000002861023,0.8454999923706055,0.847000002861023,0.8475000262260437,0.8475000262260437,0.8464999794960022,0.8460000157356262,0.8464999794960022,0.8460000157356262,0.8460000157356262,0.847000002861023,0.8445000052452087,0.8450000286102295,0.8450000286102295,0.8445000052452087,0.8460000157356262,0.8479999899864197,0.847000002861023,0.8475000262260437,0.8464999794960022,0.8454999923706055,0.843999981880188,0.8460000157356262,0.8464999794960022,0.8475000262260437,0.8450000286102295,0.8445000052452087,0.843500018119812,0.8460000157356262,0.8460000157356262,0.8450000286102295,0.8460000157356262,0.8460000157356262,0.8445000052452087,0.8460000157356262,0.8464999794960022,0.8464999794960022,0.8460000157356262,0.8479999899864197,0.8460000157356262,0.8464999794960022,0.8464999794960022,0.8450000286102295,0.8450000286102295,0.8454999923706055,0.8454999923706055,0.8460000157356262,0.8464999794960022,0.8464999794960022,0.8464999794960022,0.8445000052452087,0.8445000052452087,0.8460000157356262,0.8464999794960022,0.8460000157356262,0.8450000286102295,0.8450000286102295,0.8454999923706055,0.8464999794960022,0.8464999794960022,0.8450000286102295,0.8460000157356262,0.843500018119812,0.8460000157356262,0.847000002861023,0.8454999923706055,0.8485000133514404,0.8475000262260437,0.847000002861023,0.8454999923706055,0.8454999923706055,0.8460000157356262,0.8454999923706055,0.8424999713897705,0.8429999947547913,0.8424999713897705,0.8445000052452087,0.8454999923706055,0.8460000157356262,0.847000002861023,0.8460000157356262,0.8450000286102295,0.8464999794960022,0.8475000262260437,0.8464999794960022,0.8460000157356262,0.8464999794960022,0.8450000286102295,0.8454999923706055,0.8479999899864197,0.8464999794960022,0.8464999794960022,0.847000002861023,0.8464999794960022,0.8450000286102295,0.8445000052452087,0.8445000052452087,0.8450000286102295,0.8464999794960022,0.8464999794960022,0.8479999899864197,0.847000002861023,0.847000002861023,0.8464999794960022,0.8460000157356262,0.8464999794960022,0.8464999794960022,0.847000002861023,0.8475000262260437,0.8450000286102295,0.8450000286102295,0.8464999794960022,0.847000002861023,0.8464999794960022,0.8454999923706055,0.8454999923706055,0.8450000286102295,0.847000002861023,0.8475000262260437,0.847000002861023,0.8460000157356262,0.8479999899864197,0.847000002861023,0.8479999899864197,0.8460000157356262,0.8464999794960022,0.847000002861023,0.8475000262260437,0.847000002861023,0.847000002861023,0.8445000052452087,0.8460000157356262,0.8475000262260437,0.8489999771118164,0.8464999794960022,0.8485000133514404,0.8489999771118164,0.8464999794960022,0.847000002861023,0.8460000157356262,0.8454999923706055,0.8460000157356262,0.8454999923706055,0.8460000157356262,0.8475000262260437,0.847000002861023,0.8464999794960022,0.8460000157356262,0.8450000286102295,0.843999981880188,0.8460000157356262,0.8450000286102295,0.8460000157356262,0.847000002861023,0.8464999794960022,0.8464999794960022,0.8485000133514404,0.8450000286102295,0.8464999794960022,0.8454999923706055,0.8445000052452087,0.843999981880188,0.8475000262260437,0.8460000157356262,0.8475000262260437,0.8475000262260437,0.8475000262260437,0.8460000157356262,0.843999981880188,0.8464999794960022,0.8460000157356262,0.8460000157356262,0.8445000052452087,0.8445000052452087,0.847000002861023,0.8445000052452087,0.8450000286102295,0.8450000286102295,0.8454999923706055,0.8450000286102295,0.8454999923706055,0.8479999899864197,0.8454999923706055,0.8445000052452087,0.8450000286102295,0.8450000286102295,0.8460000157356262,0.8450000286102295,0.8464999794960022,0.8475000262260437,0.8475000262260437,0.847000002861023,0.8460000157356262,0.843999981880188,0.8445000052452087,0.8445000052452087,0.8460000157356262,0.847000002861023,0.8450000286102295,0.847000002861023,0.8485000133514404,0.8475000262260437,0.8450000286102295,0.8464999794960022,0.8460000157356262,0.8460000157356262,0.8475000262260437,0.847000002861023,0.8475000262260437,0.8450000286102295,0.8450000286102295,0.8450000286102295,0.8460000157356262,0.847000002861023,0.8450000286102295,0.8450000286102295,0.8460000157356262,0.8454999923706055,0.8460000157356262,0.8454999923706055,0.847000002861023,0.847000002861023,0.8464999794960022,0.847000002861023,0.8464999794960022,0.847000002861023,0.8460000157356262,0.8450000286102295,0.8450000286102295,0.847000002861023,0.847000002861023,0.8479999899864197,0.8450000286102295,0.8479999899864197,0.8464999794960022,0.843999981880188,0.8450000286102295,0.8460000157356262,0.847000002861023,0.8454999923706055,0.8464999794960022,0.8454999923706055,0.8450000286102295,0.8445000052452087,0.8454999923706055,0.8464999794960022,0.847000002861023,0.8475000262260437,0.847000002861023,0.8450000286102295,0.8479999899864197,0.847000002861023,0.8460000157356262,0.8450000286102295,0.8460000157356262,0.8460000157356262,0.8454999923706055,0.8450000286102295,0.8450000286102295,0.8475000262260437,0.8464999794960022,0.8454999923706055,0.8460000157356262,0.8460000157356262,0.8445000052452087,0.8460000157356262,0.8475000262260437,0.8450000286102295,0.8460000157356262,0.8445000052452087,0.8475000262260437,0.8460000157356262,0.8454999923706055,0.8479999899864197,0.8475000262260437,0.8475000262260437,0.847000002861023,0.8464999794960022,0.847000002861023,0.8454999923706055,0.8460000157356262,0.8485000133514404,0.8450000286102295,0.8460000157356262,0.8479999899864197,0.8475000262260437,0.8485000133514404,0.8479999899864197,0.847000002861023,0.8460000157356262,0.8464999794960022,0.8445000052452087,0.8450000286102295,0.8464999794960022,0.8454999923706055,0.8489999771118164,0.8464999794960022,0.8445000052452087,0.8460000157356262,0.8475000262260437,0.8475000262260437,0.8454999923706055,0.8454999923706055,0.8454999923706055,0.8450000286102295,0.8479999899864197,0.8460000157356262,0.8460000157356262,0.8464999794960022,0.847000002861023,0.8479999899864197,0.8460000157356262,0.8479999899864197,0.8460000157356262,0.8454999923706055,0.8475000262260437,0.847000002861023,0.8485000133514404,0.8479999899864197,0.8479999899864197,0.8460000157356262,0.8464999794960022,0.8475000262260437,0.8485000133514404,0.8464999794960022,0.8464999794960022,0.8454999923706055,0.8475000262260437,0.8464999794960022,0.8479999899864197,0.8485000133514404,0.8460000157356262,0.8454999923706055,0.8450000286102295,0.8454999923706055,0.8460000157356262,0.8454999923706055,0.8454999923706055,0.8464999794960022,0.8460000157356262,0.847000002861023,0.8460000157356262,0.8464999794960022,0.8464999794960022,0.8464999794960022,0.847000002861023,0.847000002861023,0.847000002861023,0.8475000262260437,0.8475000262260437,0.847000002861023,0.8460000157356262,0.8460000157356262,0.8460000157356262,0.847000002861023,0.8479999899864197,0.8464999794960022,0.8475000262260437,0.8479999899864197,0.847000002861023,0.847000002861023,0.8464999794960022,0.8475000262260437,0.8475000262260437,0.847000002861023,0.8475000262260437,0.8460000157356262,0.847000002861023,0.847000002861023,0.8460000157356262,0.8460000157356262,0.8460000157356262,0.8475000262260437,0.8475000262260437,0.847000002861023,0.847000002861023,0.8475000262260437,0.8475000262260437,0.8475000262260437,0.847000002861023,0.8460000157356262,0.847000002861023,0.8464999794960022,0.847000002861023,0.8475000262260437,0.8479999899864197,0.847000002861023,0.847000002861023,0.8475000262260437,0.8475000262260437,0.8475000262260437,0.8475000262260437,0.8479999899864197,0.847000002861023,0.8475000262260437,0.847000002861023,0.8464999794960022,0.8460000157356262,0.847000002861023,0.8479999899864197,0.8479999899864197,0.8485000133514404,0.8479999899864197,0.8475000262260437,0.8475000262260437,0.8450000286102295,0.8454999923706055,0.8460000157356262,0.8475000262260437,0.847000002861023,0.847000002861023,0.8460000157356262,0.847000002861023,0.847000002861023,0.8460000157356262,0.847000002861023,0.8479999899864197,0.8475000262260437,0.847000002861023,0.8454999923706055,0.8460000157356262,0.8464999794960022,0.8475000262260437,0.8489999771118164,0.8450000286102295,0.8460000157356262,0.8464999794960022,0.847000002861023,0.847000002861023,0.8475000262260437,0.847000002861023,0.847000002861023,0.847000002861023,0.8485000133514404,0.8479999899864197,0.847000002861023,0.847000002861023,0.8464999794960022,0.847000002861023,0.8460000157356262,0.8460000157356262,0.847000002861023,0.8475000262260437,0.8495000004768372,0.8479999899864197,0.8475000262260437,0.8460000157356262,0.8464999794960022,0.8460000157356262,0.8475000262260437,0.847000002861023,0.8475000262260437,0.8464999794960022,0.8460000157356262,0.8460000157356262,0.847000002861023,0.8479999899864197,0.8479999899864197,0.8479999899864197,0.8479999899864197,0.8464999794960022,0.8479999899864197,0.8464999794960022,0.8464999794960022,0.8485000133514404,0.8479999899864197,0.8485000133514404,0.8485000133514404,0.8495000004768372,0.8475000262260437,0.8495000004768372,0.8475000262260437,0.8464999794960022,0.8475000262260437,0.8450000286102295,0.8479999899864197,0.8479999899864197,0.8479999899864197,0.8479999899864197,0.8479999899864197,0.8475000262260437,0.8495000004768372,0.8475000262260437,0.8475000262260437,0.8464999794960022,0.8485000133514404,0.8489999771118164,0.8479999899864197,0.847000002861023,0.8475000262260437,0.8479999899864197,0.8475000262260437,0.8475000262260437,0.8485000133514404,0.8485000133514404,0.8485000133514404,0.8460000157356262,0.8464999794960022,0.8475000262260437,0.8479999899864197,0.8475000262260437,0.8489999771118164,0.8460000157356262,0.8479999899864197,0.8485000133514404,0.8479999899864197,0.847000002861023,0.8489999771118164,0.8485000133514404,0.8479999899864197,0.8475000262260437,0.8479999899864197,0.8454999923706055,0.8454999923706055,0.8454999923706055,0.847000002861023,0.8464999794960022,0.8479999899864197,0.847000002861023,0.8464999794960022,0.847000002861023,0.8475000262260437,0.8464999794960022,0.8475000262260437,0.8475000262260437,0.8460000157356262,0.8475000262260437,0.8479999899864197,0.847000002861023,0.8460000157356262,0.8475000262260437,0.8460000157356262,0.8460000157356262,0.8454999923706055,0.8460000157356262,0.8460000157356262,0.8485000133514404,0.8479999899864197,0.8475000262260437,0.8464999794960022,0.8454999923706055,0.8485000133514404,0.8479999899864197,0.8464999794960022,0.8454999923706055,0.8454999923706055,0.847000002861023,0.847000002861023,0.8475000262260437,0.8460000157356262,0.8460000157356262,0.847000002861023,0.8464999794960022,0.8475000262260437,0.847000002861023,0.8475000262260437,0.847000002861023,0.8475000262260437,0.8475000262260437,0.847000002861023,0.8460000157356262,0.8460000157356262,0.8460000157356262,0.847000002861023,0.8450000286102295,0.8485000133514404,0.8479999899864197,0.8475000262260437,0.847000002861023,0.847000002861023,0.8479999899864197,0.847000002861023,0.8479999899864197,0.8485000133514404,0.8479999899864197,0.8479999899864197,0.8475000262260437,0.847000002861023,0.8464999794960022,0.8479999899864197,0.8485000133514404,0.8479999899864197,0.8489999771118164,0.8475000262260437,0.8464999794960022,0.847000002861023,0.8475000262260437,0.8479999899864197,0.847000002861023,0.8464999794960022,0.8475000262260437,0.8479999899864197,0.8485000133514404,0.8479999899864197,0.8475000262260437,0.8454999923706055,0.8460000157356262,0.8464999794960022,0.8485000133514404,0.8485000133514404,0.847000002861023,0.8454999923706055,0.8479999899864197,0.8475000262260437,0.8464999794960022,0.8475000262260437,0.8464999794960022,0.8479999899864197,0.8489999771118164,0.8475000262260437,0.8479999899864197,0.8485000133514404,0.8475000262260437,0.8464999794960022,0.8454999923706055,0.8460000157356262,0.847000002861023,0.8475000262260437,0.8479999899864197,0.8485000133514404,0.8464999794960022,0.8485000133514404,0.8485000133514404,0.8479999899864197,0.8479999899864197,0.8485000133514404,0.8485000133514404,0.8475000262260437,0.8460000157356262,0.8460000157356262,0.8460000157356262,0.8479999899864197,0.8454999923706055,0.847000002861023,0.8475000262260437,0.8475000262260437,0.8479999899864197,0.8475000262260437,0.847000002861023,0.8475000262260437,0.847000002861023,0.8485000133514404,0.8479999899864197,0.847000002861023,0.8485000133514404,0.847000002861023,0.8450000286102295,0.8464999794960022,0.847000002861023,0.8464999794960022,0.8485000133514404,0.8475000262260437,0.8454999923706055,0.8460000157356262,0.8475000262260437,0.847000002861023,0.8475000262260437,0.847000002861023,0.8485000133514404,0.8489999771118164,0.8479999899864197,0.847000002861023,0.8460000157356262,0.8475000262260437,0.8460000157356262,0.8460000157356262,0.847000002861023,0.8460000157356262,0.8454999923706055,0.8460000157356262,0.8460000157356262,0.8464999794960022,0.843500018119812,0.8475000262260437,0.847000002861023,0.8460000157356262,0.8464999794960022,0.8479999899864197,0.8460000157356262,0.8475000262260437,0.8460000157356262,0.847000002861023,0.8479999899864197,0.8460000157356262,0.847000002861023,0.8460000157356262,0.847000002861023,0.8460000157356262,0.8460000157356262,0.8475000262260437,0.8464999794960022,0.8460000157356262,0.8479999899864197,0.8475000262260437,0.847000002861023,0.847000002861023,0.8479999899864197,0.8489999771118164,0.847000002861023,0.8475000262260437,0.8475000262260437,0.8475000262260437,0.8475000262260437,0.8464999794960022,0.8479999899864197,0.8475000262260437,0.8489999771118164,0.8495000004768372,0.8460000157356262,0.8464999794960022,0.8485000133514404,0.847000002861023,0.8479999899864197,0.8479999899864197,0.847000002861023,0.8485000133514404,0.8475000262260437,0.8485000133514404,0.847000002861023,0.847000002861023,0.8460000157356262,0.847000002861023,0.8450000286102295,0.847000002861023,0.847000002861023,0.8475000262260437,0.8475000262260437,0.847000002861023,0.8454999923706055,0.847000002861023,0.8475000262260437,0.8475000262260437,0.8460000157356262,0.8475000262260437,0.8485000133514404,0.847000002861023,0.8475000262260437,0.8475000262260437,0.8464999794960022,0.8479999899864197,0.8460000157356262,0.8454999923706055,0.8445000052452087,0.8464999794960022,0.8479999899864197,0.847000002861023,0.8464999794960022,0.8464999794960022,0.8464999794960022,0.8464999794960022,0.8464999794960022,0.8485000133514404,0.8464999794960022,0.847000002861023,0.8464999794960022,0.8464999794960022,0.847000002861023,0.847000002861023,0.8464999794960022,0.8485000133514404,0.8475000262260437,0.847000002861023,0.8479999899864197,0.8475000262260437,0.8479999899864197,0.8485000133514404,0.847000002861023,0.8460000157356262,0.847000002861023,0.8460000157356262,0.8460000157356262,0.8475000262260437,0.8475000262260437,0.8464999794960022,0.8464999794960022,0.8475000262260437,0.847000002861023,0.8489999771118164,0.8460000157356262,0.8460000157356262,0.8445000052452087,0.8460000157356262,0.8464999794960022,0.8475000262260437,0.8475000262260437,0.8485000133514404,0.8475000262260437,0.8460000157356262,0.847000002861023,0.8485000133514404,0.847000002861023,0.8475000262260437,0.847000002861023,0.8460000157356262,0.8464999794960022,0.8464999794960022,0.8454999923706055,0.8464999794960022,0.8464999794960022,0.847000002861023,0.8485000133514404,0.8475000262260437,0.8475000262260437,0.8475000262260437,0.8475000262260437,0.8450000286102295,0.8454999923706055,0.8475000262260437,0.847000002861023,0.8464999794960022,0.847000002861023,0.847000002861023,0.847000002861023,0.8464999794960022,0.8460000157356262,0.8464999794960022,0.8460000157356262,0.8475000262260437,0.8475000262260437,0.8445000052452087,0.8475000262260437,0.8460000157356262,0.8475000262260437,0.847000002861023,0.8475000262260437,0.8479999899864197,0.8485000133514404,0.8464999794960022,0.8475000262260437,0.8479999899864197,0.8475000262260437,0.8475000262260437,0.8479999899864197,0.8475000262260437,0.847000002861023,0.8485000133514404,0.8479999899864197,0.8464999794960022,0.8479999899864197,0.8485000133514404,0.8460000157356262,0.8464999794960022,0.8479999899864197,0.8485000133514404,0.8479999899864197,0.847000002861023,0.847000002861023,0.8454999923706055,0.8454999923706055,0.8475000262260437,0.8475000262260437,0.8485000133514404,0.847000002861023,0.8460000157356262,0.8475000262260437,0.8454999923706055,0.8485000133514404,0.847000002861023,0.8460000157356262,0.8454999923706055,0.8464999794960022,0.8454999923706055,0.8450000286102295,0.847000002861023,0.8489999771118164,0.8485000133514404,0.847000002861023,0.8464999794960022,0.8479999899864197,0.8450000286102295,0.8475000262260437,0.8479999899864197,0.8464999794960022,0.8454999923706055,0.8450000286102295,0.8460000157356262,0.8464999794960022,0.8454999923706055,0.8460000157356262,0.8450000286102295,0.8460000157356262,0.847000002861023,0.847000002861023,0.8475000262260437,0.8460000157356262,0.847000002861023,0.8460000157356262,0.8475000262260437,0.8475000262260437,0.8475000262260437,0.847000002861023,0.8485000133514404,0.8489999771118164,0.8479999899864197,0.8479999899864197,0.8464999794960022,0.8464999794960022,0.8464999794960022,0.8460000157356262,0.8475000262260437,0.8460000157356262,0.8479999899864197,0.8460000157356262,0.8454999923706055,0.847000002861023,0.8475000262260437,0.847000002861023,0.8464999794960022,0.847000002861023,0.8460000157356262,0.847000002861023,0.847000002861023,0.8475000262260437,0.8485000133514404,0.8479999899864197,0.8475000262260437,0.8475000262260437,0.8475000262260437,0.847000002861023,0.8479999899864197,0.8475000262260437,0.8460000157356262,0.847000002861023,0.8475000262260437,0.8475000262260437,0.8454999923706055,0.847000002861023,0.847000002861023,0.8454999923706055,0.8475000262260437,0.8475000262260437,0.8475000262260437,0.8460000157356262,0.8475000262260437,0.8464999794960022,0.847000002861023,0.847000002861023,0.8464999794960022,0.8460000157356262,0.847000002861023,0.8485000133514404,0.8485000133514404,0.8475000262260437,0.8445000052452087,0.8464999794960022,0.847000002861023,0.8485000133514404,0.847000002861023,0.8460000157356262,0.8454999923706055,0.8475000262260437,0.8485000133514404,0.847000002861023,0.8445000052452087,0.8445000052452087,0.8454999923706055,0.8464999794960022,0.8485000133514404,0.8464999794960022,0.8464999794960022,0.8460000157356262,0.8464999794960022,0.8450000286102295,0.8450000286102295,0.8479999899864197,0.8450000286102295,0.8475000262260437,0.8460000157356262,0.8464999794960022,0.8464999794960022,0.8475000262260437,0.8479999899864197,0.8464999794960022,0.847000002861023,0.847000002861023,0.8460000157356262,0.8450000286102295,0.847000002861023,0.8475000262260437,0.8464999794960022,0.8464999794960022,0.8454999923706055,0.8464999794960022,0.8460000157356262,0.8445000052452087,0.8450000286102295,0.8454999923706055,0.8460000157356262,0.847000002861023,0.8460000157356262,0.8460000157356262,0.847000002861023,0.8464999794960022,0.8475000262260437,0.8464999794960022,0.8460000157356262,0.847000002861023,0.8479999899864197,0.847000002861023,0.8454999923706055,0.8429999947547913,0.8460000157356262,0.8460000157356262,0.8460000157356262,0.8464999794960022,0.8460000157356262,0.8454999923706055,0.8460000157356262,0.8464999794960022,0.8454999923706055,0.8460000157356262,0.8445000052452087,0.8450000286102295,0.8460000157356262,0.847000002861023,0.8475000262260437,0.8475000262260437,0.8475000262260437,0.8454999923706055,0.8454999923706055,0.8464999794960022,0.8475000262260437,0.847000002861023,0.8464999794960022,0.8460000157356262,0.8464999794960022,0.843999981880188,0.847000002861023,0.847000002861023,0.8464999794960022,0.8460000157356262,0.8460000157356262,0.8454999923706055,0.8460000157356262,0.8445000052452087,0.8445000052452087,0.847000002861023,0.8464999794960022,0.8460000157356262,0.8464999794960022,0.8479999899864197,0.8479999899864197,0.8479999899864197,0.8460000157356262,0.847000002861023,0.8454999923706055,0.8450000286102295,0.847000002861023,0.8454999923706055,0.8464999794960022,0.847000002861023,0.8460000157356262,0.8454999923706055,0.8454999923706055,0.847000002861023,0.8460000157356262,0.8460000157356262,0.8460000157356262,0.8460000157356262,0.8464999794960022,0.8454999923706055,0.8450000286102295,0.8454999923706055,0.8460000157356262,0.8460000157356262,0.8450000286102295,0.843999981880188,0.8460000157356262,0.8460000157356262,0.8464999794960022,0.8445000052452087,0.8464999794960022,0.8454999923706055,0.8450000286102295,0.847000002861023,0.8445000052452087,0.8454999923706055,0.847000002861023],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Accuracy\"},\"xaxis\":{\"title\":{\"text\":\"epochs\"}},\"yaxis\":{\"title\":{\"text\":\"\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a66de6f9-bfcf-4254-ae90-b2b6eb2462c1');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Model"
      ],
      "metadata": {
        "id": "ohKcZzwn4ZG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
        "_, val_acc = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Train: %.4f, Validation: %.4f' % (train_acc, val_acc))"
      ],
      "metadata": {
        "id": "mzDFPiWJ4aCF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c3c40b-7a18-4c2e-d890-4c8e59ed1710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.8433, Validation: 0.8470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.predict(x_train)\n",
        "\n",
        "print(res[:10])"
      ],
      "metadata": {
        "id": "bTvqZvXf4beG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c628d15-3525-4bea-a033-052ee9ca6980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 1ms/step\n",
            "[[7.1689618e-01]\n",
            " [4.1717902e-01]\n",
            " [8.3091235e-01]\n",
            " [7.9341684e-05]\n",
            " [7.4682467e-02]\n",
            " [7.3391306e-01]\n",
            " [8.4415138e-01]\n",
            " [3.5346204e-01]\n",
            " [1.4176142e-01]\n",
            " [1.6003476e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "จากภาพด้านบน Model จะส่งผลการทำนายเป็นค่าความน่าจะเป็นว่ามีโอกาสที่จะเป็น Class 1 กี่เปอร์เซ็นต์ ซึ่งโดย Default จะทำนายว่าเป็น Class 1 เมื่อค่าความน่าจะเป็นมากกว่า 0.5"
      ],
      "metadata": {
        "id": "_UkW0ZkF4cU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(60, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(1, activation='softmax')) #sigmoid"
      ],
      "metadata": {
        "id": "V3SvJr3wbOjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxTmqNV-bUdm",
        "outputId": "17475fc5-4af5-4cbc-88d7-4b194c895cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "his = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=2000, verbose=1, batch_size = 256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLeR-h3AbYVk",
        "outputId": "4cc6bfd0-0262-4de8-e4d4-6ba69869125f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "12/12 [==============================] - 1s 16ms/step - loss: 0.7512 - accuracy: 0.5027 - val_loss: 0.6878 - val_accuracy: 0.4960\n",
            "Epoch 2/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7023 - accuracy: 0.5027 - val_loss: 0.6881 - val_accuracy: 0.4960\n",
            "Epoch 3/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7034 - accuracy: 0.5027 - val_loss: 0.6826 - val_accuracy: 0.4960\n",
            "Epoch 4/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6987 - accuracy: 0.5027 - val_loss: 0.6772 - val_accuracy: 0.4960\n",
            "Epoch 5/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6889 - accuracy: 0.5027 - val_loss: 0.6739 - val_accuracy: 0.4960\n",
            "Epoch 6/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6922 - accuracy: 0.5027 - val_loss: 0.6699 - val_accuracy: 0.4960\n",
            "Epoch 7/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6823 - accuracy: 0.5027 - val_loss: 0.6667 - val_accuracy: 0.4960\n",
            "Epoch 8/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6811 - accuracy: 0.5027 - val_loss: 0.6633 - val_accuracy: 0.4960\n",
            "Epoch 9/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6707 - accuracy: 0.5027 - val_loss: 0.6614 - val_accuracy: 0.4960\n",
            "Epoch 10/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6694 - accuracy: 0.5027 - val_loss: 0.6567 - val_accuracy: 0.4960\n",
            "Epoch 11/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.5027 - val_loss: 0.6533 - val_accuracy: 0.4960\n",
            "Epoch 12/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6560 - accuracy: 0.5027 - val_loss: 0.6514 - val_accuracy: 0.4960\n",
            "Epoch 13/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6580 - accuracy: 0.5027 - val_loss: 0.6481 - val_accuracy: 0.4960\n",
            "Epoch 14/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6541 - accuracy: 0.5027 - val_loss: 0.6452 - val_accuracy: 0.4960\n",
            "Epoch 15/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6514 - accuracy: 0.5027 - val_loss: 0.6413 - val_accuracy: 0.4960\n",
            "Epoch 16/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6511 - accuracy: 0.5027 - val_loss: 0.6404 - val_accuracy: 0.4960\n",
            "Epoch 17/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6471 - accuracy: 0.5027 - val_loss: 0.6362 - val_accuracy: 0.4960\n",
            "Epoch 18/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6433 - accuracy: 0.5027 - val_loss: 0.6340 - val_accuracy: 0.4960\n",
            "Epoch 19/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6383 - accuracy: 0.5027 - val_loss: 0.6309 - val_accuracy: 0.4960\n",
            "Epoch 20/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6361 - accuracy: 0.5027 - val_loss: 0.6286 - val_accuracy: 0.4960\n",
            "Epoch 21/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6365 - accuracy: 0.5027 - val_loss: 0.6265 - val_accuracy: 0.4960\n",
            "Epoch 22/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6334 - accuracy: 0.5027 - val_loss: 0.6231 - val_accuracy: 0.4960\n",
            "Epoch 23/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6339 - accuracy: 0.5027 - val_loss: 0.6203 - val_accuracy: 0.4960\n",
            "Epoch 24/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6237 - accuracy: 0.5027 - val_loss: 0.6187 - val_accuracy: 0.4960\n",
            "Epoch 25/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6306 - accuracy: 0.5027 - val_loss: 0.6173 - val_accuracy: 0.4960\n",
            "Epoch 26/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6230 - accuracy: 0.5027 - val_loss: 0.6129 - val_accuracy: 0.4960\n",
            "Epoch 27/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6203 - accuracy: 0.5027 - val_loss: 0.6107 - val_accuracy: 0.4960\n",
            "Epoch 28/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6205 - accuracy: 0.5027 - val_loss: 0.6106 - val_accuracy: 0.4960\n",
            "Epoch 29/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6152 - accuracy: 0.5027 - val_loss: 0.6067 - val_accuracy: 0.4960\n",
            "Epoch 30/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.5027 - val_loss: 0.6041 - val_accuracy: 0.4960\n",
            "Epoch 31/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6146 - accuracy: 0.5027 - val_loss: 0.6027 - val_accuracy: 0.4960\n",
            "Epoch 32/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6071 - accuracy: 0.5027 - val_loss: 0.5996 - val_accuracy: 0.4960\n",
            "Epoch 33/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6096 - accuracy: 0.5027 - val_loss: 0.5970 - val_accuracy: 0.4960\n",
            "Epoch 34/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6098 - accuracy: 0.5027 - val_loss: 0.5953 - val_accuracy: 0.4960\n",
            "Epoch 35/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6012 - accuracy: 0.5027 - val_loss: 0.5933 - val_accuracy: 0.4960\n",
            "Epoch 36/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6024 - accuracy: 0.5027 - val_loss: 0.5905 - val_accuracy: 0.4960\n",
            "Epoch 37/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5972 - accuracy: 0.5027 - val_loss: 0.5892 - val_accuracy: 0.4960\n",
            "Epoch 38/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.5027 - val_loss: 0.5872 - val_accuracy: 0.4960\n",
            "Epoch 39/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5990 - accuracy: 0.5027 - val_loss: 0.5837 - val_accuracy: 0.4960\n",
            "Epoch 40/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5942 - accuracy: 0.5027 - val_loss: 0.5826 - val_accuracy: 0.4960\n",
            "Epoch 41/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5902 - accuracy: 0.5027 - val_loss: 0.5800 - val_accuracy: 0.4960\n",
            "Epoch 42/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5900 - accuracy: 0.5027 - val_loss: 0.5794 - val_accuracy: 0.4960\n",
            "Epoch 43/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5898 - accuracy: 0.5027 - val_loss: 0.5758 - val_accuracy: 0.4960\n",
            "Epoch 44/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5884 - accuracy: 0.5027 - val_loss: 0.5745 - val_accuracy: 0.4960\n",
            "Epoch 45/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5859 - accuracy: 0.5027 - val_loss: 0.5724 - val_accuracy: 0.4960\n",
            "Epoch 46/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.5027 - val_loss: 0.5694 - val_accuracy: 0.4960\n",
            "Epoch 47/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5776 - accuracy: 0.5027 - val_loss: 0.5682 - val_accuracy: 0.4960\n",
            "Epoch 48/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5761 - accuracy: 0.5027 - val_loss: 0.5666 - val_accuracy: 0.4960\n",
            "Epoch 49/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5797 - accuracy: 0.5027 - val_loss: 0.5634 - val_accuracy: 0.4960\n",
            "Epoch 50/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5751 - accuracy: 0.5027 - val_loss: 0.5618 - val_accuracy: 0.4960\n",
            "Epoch 51/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5770 - accuracy: 0.5027 - val_loss: 0.5602 - val_accuracy: 0.4960\n",
            "Epoch 52/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5715 - accuracy: 0.5027 - val_loss: 0.5579 - val_accuracy: 0.4960\n",
            "Epoch 53/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5715 - accuracy: 0.5027 - val_loss: 0.5564 - val_accuracy: 0.4960\n",
            "Epoch 54/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5707 - accuracy: 0.5027 - val_loss: 0.5540 - val_accuracy: 0.4960\n",
            "Epoch 55/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5660 - accuracy: 0.5027 - val_loss: 0.5521 - val_accuracy: 0.4960\n",
            "Epoch 56/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5660 - accuracy: 0.5027 - val_loss: 0.5504 - val_accuracy: 0.4960\n",
            "Epoch 57/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5643 - accuracy: 0.5027 - val_loss: 0.5482 - val_accuracy: 0.4960\n",
            "Epoch 58/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5656 - accuracy: 0.5027 - val_loss: 0.5461 - val_accuracy: 0.4960\n",
            "Epoch 59/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5557 - accuracy: 0.5027 - val_loss: 0.5445 - val_accuracy: 0.4960\n",
            "Epoch 60/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5578 - accuracy: 0.5027 - val_loss: 0.5433 - val_accuracy: 0.4960\n",
            "Epoch 61/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5656 - accuracy: 0.5027 - val_loss: 0.5404 - val_accuracy: 0.4960\n",
            "Epoch 62/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5531 - accuracy: 0.5027 - val_loss: 0.5383 - val_accuracy: 0.4960\n",
            "Epoch 63/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5537 - accuracy: 0.5027 - val_loss: 0.5375 - val_accuracy: 0.4960\n",
            "Epoch 64/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.5027 - val_loss: 0.5354 - val_accuracy: 0.4960\n",
            "Epoch 65/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5555 - accuracy: 0.5027 - val_loss: 0.5331 - val_accuracy: 0.4960\n",
            "Epoch 66/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5516 - accuracy: 0.5027 - val_loss: 0.5319 - val_accuracy: 0.4960\n",
            "Epoch 67/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5479 - accuracy: 0.5027 - val_loss: 0.5299 - val_accuracy: 0.4960\n",
            "Epoch 68/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5497 - accuracy: 0.5027 - val_loss: 0.5289 - val_accuracy: 0.4960\n",
            "Epoch 69/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5473 - accuracy: 0.5027 - val_loss: 0.5264 - val_accuracy: 0.4960\n",
            "Epoch 70/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5448 - accuracy: 0.5027 - val_loss: 0.5249 - val_accuracy: 0.4960\n",
            "Epoch 71/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5420 - accuracy: 0.5027 - val_loss: 0.5235 - val_accuracy: 0.4960\n",
            "Epoch 72/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.5027 - val_loss: 0.5214 - val_accuracy: 0.4960\n",
            "Epoch 73/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.5027 - val_loss: 0.5189 - val_accuracy: 0.4960\n",
            "Epoch 74/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5377 - accuracy: 0.5027 - val_loss: 0.5175 - val_accuracy: 0.4960\n",
            "Epoch 75/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.5027 - val_loss: 0.5160 - val_accuracy: 0.4960\n",
            "Epoch 76/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5398 - accuracy: 0.5027 - val_loss: 0.5150 - val_accuracy: 0.4960\n",
            "Epoch 77/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.5027 - val_loss: 0.5126 - val_accuracy: 0.4960\n",
            "Epoch 78/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5380 - accuracy: 0.5027 - val_loss: 0.5107 - val_accuracy: 0.4960\n",
            "Epoch 79/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5356 - accuracy: 0.5027 - val_loss: 0.5095 - val_accuracy: 0.4960\n",
            "Epoch 80/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5339 - accuracy: 0.5027 - val_loss: 0.5085 - val_accuracy: 0.4960\n",
            "Epoch 81/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.5027 - val_loss: 0.5073 - val_accuracy: 0.4960\n",
            "Epoch 82/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.5027 - val_loss: 0.5047 - val_accuracy: 0.4960\n",
            "Epoch 83/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.5027 - val_loss: 0.5031 - val_accuracy: 0.4960\n",
            "Epoch 84/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5261 - accuracy: 0.5027 - val_loss: 0.5020 - val_accuracy: 0.4960\n",
            "Epoch 85/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.5027 - val_loss: 0.5002 - val_accuracy: 0.4960\n",
            "Epoch 86/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.5027 - val_loss: 0.4989 - val_accuracy: 0.4960\n",
            "Epoch 87/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5306 - accuracy: 0.5027 - val_loss: 0.4977 - val_accuracy: 0.4960\n",
            "Epoch 88/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5135 - accuracy: 0.5027 - val_loss: 0.4956 - val_accuracy: 0.4960\n",
            "Epoch 89/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5216 - accuracy: 0.5027 - val_loss: 0.4944 - val_accuracy: 0.4960\n",
            "Epoch 90/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5216 - accuracy: 0.5027 - val_loss: 0.4937 - val_accuracy: 0.4960\n",
            "Epoch 91/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.5027 - val_loss: 0.4911 - val_accuracy: 0.4960\n",
            "Epoch 92/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.5027 - val_loss: 0.4899 - val_accuracy: 0.4960\n",
            "Epoch 93/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5165 - accuracy: 0.5027 - val_loss: 0.4888 - val_accuracy: 0.4960\n",
            "Epoch 94/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5182 - accuracy: 0.5027 - val_loss: 0.4869 - val_accuracy: 0.4960\n",
            "Epoch 95/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5167 - accuracy: 0.5027 - val_loss: 0.4852 - val_accuracy: 0.4960\n",
            "Epoch 96/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5092 - accuracy: 0.5027 - val_loss: 0.4845 - val_accuracy: 0.4960\n",
            "Epoch 97/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5117 - accuracy: 0.5027 - val_loss: 0.4827 - val_accuracy: 0.4960\n",
            "Epoch 98/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.5027 - val_loss: 0.4817 - val_accuracy: 0.4960\n",
            "Epoch 99/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5074 - accuracy: 0.5027 - val_loss: 0.4801 - val_accuracy: 0.4960\n",
            "Epoch 100/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5073 - accuracy: 0.5027 - val_loss: 0.4794 - val_accuracy: 0.4960\n",
            "Epoch 101/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5033 - accuracy: 0.5027 - val_loss: 0.4785 - val_accuracy: 0.4960\n",
            "Epoch 102/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5112 - accuracy: 0.5027 - val_loss: 0.4765 - val_accuracy: 0.4960\n",
            "Epoch 103/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5025 - accuracy: 0.5027 - val_loss: 0.4756 - val_accuracy: 0.4960\n",
            "Epoch 104/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.5027 - val_loss: 0.4742 - val_accuracy: 0.4960\n",
            "Epoch 105/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5025 - accuracy: 0.5027 - val_loss: 0.4724 - val_accuracy: 0.4960\n",
            "Epoch 106/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5073 - accuracy: 0.5027 - val_loss: 0.4706 - val_accuracy: 0.4960\n",
            "Epoch 107/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5013 - accuracy: 0.5027 - val_loss: 0.4704 - val_accuracy: 0.4960\n",
            "Epoch 108/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5038 - accuracy: 0.5027 - val_loss: 0.4689 - val_accuracy: 0.4960\n",
            "Epoch 109/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.5027 - val_loss: 0.4677 - val_accuracy: 0.4960\n",
            "Epoch 110/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.5027 - val_loss: 0.4663 - val_accuracy: 0.4960\n",
            "Epoch 111/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.5027 - val_loss: 0.4658 - val_accuracy: 0.4960\n",
            "Epoch 112/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.5027 - val_loss: 0.4645 - val_accuracy: 0.4960\n",
            "Epoch 113/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.5027 - val_loss: 0.4632 - val_accuracy: 0.4960\n",
            "Epoch 114/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4967 - accuracy: 0.5027 - val_loss: 0.4620 - val_accuracy: 0.4960\n",
            "Epoch 115/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4940 - accuracy: 0.5027 - val_loss: 0.4611 - val_accuracy: 0.4960\n",
            "Epoch 116/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4926 - accuracy: 0.5027 - val_loss: 0.4602 - val_accuracy: 0.4960\n",
            "Epoch 117/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4834 - accuracy: 0.5027 - val_loss: 0.4582 - val_accuracy: 0.4960\n",
            "Epoch 118/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4923 - accuracy: 0.5027 - val_loss: 0.4571 - val_accuracy: 0.4960\n",
            "Epoch 119/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4923 - accuracy: 0.5027 - val_loss: 0.4563 - val_accuracy: 0.4960\n",
            "Epoch 120/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.5027 - val_loss: 0.4557 - val_accuracy: 0.4960\n",
            "Epoch 121/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4923 - accuracy: 0.5027 - val_loss: 0.4541 - val_accuracy: 0.4960\n",
            "Epoch 122/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4881 - accuracy: 0.5027 - val_loss: 0.4531 - val_accuracy: 0.4960\n",
            "Epoch 123/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4844 - accuracy: 0.5027 - val_loss: 0.4520 - val_accuracy: 0.4960\n",
            "Epoch 124/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4820 - accuracy: 0.5027 - val_loss: 0.4512 - val_accuracy: 0.4960\n",
            "Epoch 125/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.5027 - val_loss: 0.4502 - val_accuracy: 0.4960\n",
            "Epoch 126/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.5027 - val_loss: 0.4490 - val_accuracy: 0.4960\n",
            "Epoch 127/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4878 - accuracy: 0.5027 - val_loss: 0.4479 - val_accuracy: 0.4960\n",
            "Epoch 128/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.5027 - val_loss: 0.4475 - val_accuracy: 0.4960\n",
            "Epoch 129/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4836 - accuracy: 0.5027 - val_loss: 0.4461 - val_accuracy: 0.4960\n",
            "Epoch 130/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4782 - accuracy: 0.5027 - val_loss: 0.4447 - val_accuracy: 0.4960\n",
            "Epoch 131/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4850 - accuracy: 0.5027 - val_loss: 0.4446 - val_accuracy: 0.4960\n",
            "Epoch 132/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.5027 - val_loss: 0.4437 - val_accuracy: 0.4960\n",
            "Epoch 133/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4800 - accuracy: 0.5027 - val_loss: 0.4425 - val_accuracy: 0.4960\n",
            "Epoch 134/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.5027 - val_loss: 0.4424 - val_accuracy: 0.4960\n",
            "Epoch 135/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4802 - accuracy: 0.5027 - val_loss: 0.4409 - val_accuracy: 0.4960\n",
            "Epoch 136/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4778 - accuracy: 0.5027 - val_loss: 0.4395 - val_accuracy: 0.4960\n",
            "Epoch 137/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.5027 - val_loss: 0.4392 - val_accuracy: 0.4960\n",
            "Epoch 138/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.5027 - val_loss: 0.4386 - val_accuracy: 0.4960\n",
            "Epoch 139/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.5027 - val_loss: 0.4379 - val_accuracy: 0.4960\n",
            "Epoch 140/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4795 - accuracy: 0.5027 - val_loss: 0.4364 - val_accuracy: 0.4960\n",
            "Epoch 141/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.5027 - val_loss: 0.4355 - val_accuracy: 0.4960\n",
            "Epoch 142/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4783 - accuracy: 0.5027 - val_loss: 0.4353 - val_accuracy: 0.4960\n",
            "Epoch 143/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.5027 - val_loss: 0.4339 - val_accuracy: 0.4960\n",
            "Epoch 144/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.5027 - val_loss: 0.4327 - val_accuracy: 0.4960\n",
            "Epoch 145/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.5027 - val_loss: 0.4322 - val_accuracy: 0.4960\n",
            "Epoch 146/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.5027 - val_loss: 0.4314 - val_accuracy: 0.4960\n",
            "Epoch 147/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4717 - accuracy: 0.5027 - val_loss: 0.4309 - val_accuracy: 0.4960\n",
            "Epoch 148/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.5027 - val_loss: 0.4303 - val_accuracy: 0.4960\n",
            "Epoch 149/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4728 - accuracy: 0.5027 - val_loss: 0.4288 - val_accuracy: 0.4960\n",
            "Epoch 150/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4673 - accuracy: 0.5027 - val_loss: 0.4280 - val_accuracy: 0.4960\n",
            "Epoch 151/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.5027 - val_loss: 0.4277 - val_accuracy: 0.4960\n",
            "Epoch 152/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4755 - accuracy: 0.5027 - val_loss: 0.4269 - val_accuracy: 0.4960\n",
            "Epoch 153/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4634 - accuracy: 0.5027 - val_loss: 0.4259 - val_accuracy: 0.4960\n",
            "Epoch 154/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4625 - accuracy: 0.5027 - val_loss: 0.4253 - val_accuracy: 0.4960\n",
            "Epoch 155/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4679 - accuracy: 0.5027 - val_loss: 0.4247 - val_accuracy: 0.4960\n",
            "Epoch 156/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4683 - accuracy: 0.5027 - val_loss: 0.4238 - val_accuracy: 0.4960\n",
            "Epoch 157/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4599 - accuracy: 0.5027 - val_loss: 0.4228 - val_accuracy: 0.4960\n",
            "Epoch 158/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4612 - accuracy: 0.5027 - val_loss: 0.4225 - val_accuracy: 0.4960\n",
            "Epoch 159/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4619 - accuracy: 0.5027 - val_loss: 0.4221 - val_accuracy: 0.4960\n",
            "Epoch 160/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.5027 - val_loss: 0.4214 - val_accuracy: 0.4960\n",
            "Epoch 161/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4625 - accuracy: 0.5027 - val_loss: 0.4203 - val_accuracy: 0.4960\n",
            "Epoch 162/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4537 - accuracy: 0.5027 - val_loss: 0.4194 - val_accuracy: 0.4960\n",
            "Epoch 163/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.5027 - val_loss: 0.4189 - val_accuracy: 0.4960\n",
            "Epoch 164/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4558 - accuracy: 0.5027 - val_loss: 0.4185 - val_accuracy: 0.4960\n",
            "Epoch 165/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4610 - accuracy: 0.5027 - val_loss: 0.4181 - val_accuracy: 0.4960\n",
            "Epoch 166/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4533 - accuracy: 0.5027 - val_loss: 0.4173 - val_accuracy: 0.4960\n",
            "Epoch 167/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4562 - accuracy: 0.5027 - val_loss: 0.4164 - val_accuracy: 0.4960\n",
            "Epoch 168/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4573 - accuracy: 0.5027 - val_loss: 0.4154 - val_accuracy: 0.4960\n",
            "Epoch 169/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4489 - accuracy: 0.5027 - val_loss: 0.4151 - val_accuracy: 0.4960\n",
            "Epoch 170/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.5027 - val_loss: 0.4143 - val_accuracy: 0.4960\n",
            "Epoch 171/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4577 - accuracy: 0.5027 - val_loss: 0.4140 - val_accuracy: 0.4960\n",
            "Epoch 172/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.5027 - val_loss: 0.4135 - val_accuracy: 0.4960\n",
            "Epoch 173/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.5027 - val_loss: 0.4124 - val_accuracy: 0.4960\n",
            "Epoch 174/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.5027 - val_loss: 0.4121 - val_accuracy: 0.4960\n",
            "Epoch 175/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.5027 - val_loss: 0.4114 - val_accuracy: 0.4960\n",
            "Epoch 176/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.5027 - val_loss: 0.4107 - val_accuracy: 0.4960\n",
            "Epoch 177/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.5027 - val_loss: 0.4100 - val_accuracy: 0.4960\n",
            "Epoch 178/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.5027 - val_loss: 0.4098 - val_accuracy: 0.4960\n",
            "Epoch 179/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.5027 - val_loss: 0.4092 - val_accuracy: 0.4960\n",
            "Epoch 180/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.5027 - val_loss: 0.4084 - val_accuracy: 0.4960\n",
            "Epoch 181/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.5027 - val_loss: 0.4079 - val_accuracy: 0.4960\n",
            "Epoch 182/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.5027 - val_loss: 0.4070 - val_accuracy: 0.4960\n",
            "Epoch 183/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.5027 - val_loss: 0.4067 - val_accuracy: 0.4960\n",
            "Epoch 184/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4502 - accuracy: 0.5027 - val_loss: 0.4068 - val_accuracy: 0.4960\n",
            "Epoch 185/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.5027 - val_loss: 0.4062 - val_accuracy: 0.4960\n",
            "Epoch 186/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.5027 - val_loss: 0.4053 - val_accuracy: 0.4960\n",
            "Epoch 187/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.5027 - val_loss: 0.4044 - val_accuracy: 0.4960\n",
            "Epoch 188/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.5027 - val_loss: 0.4042 - val_accuracy: 0.4960\n",
            "Epoch 189/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4492 - accuracy: 0.5027 - val_loss: 0.4035 - val_accuracy: 0.4960\n",
            "Epoch 190/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.5027 - val_loss: 0.4032 - val_accuracy: 0.4960\n",
            "Epoch 191/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.5027 - val_loss: 0.4026 - val_accuracy: 0.4960\n",
            "Epoch 192/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.5027 - val_loss: 0.4018 - val_accuracy: 0.4960\n",
            "Epoch 193/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.5027 - val_loss: 0.4012 - val_accuracy: 0.4960\n",
            "Epoch 194/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.5027 - val_loss: 0.4014 - val_accuracy: 0.4960\n",
            "Epoch 195/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.5027 - val_loss: 0.4004 - val_accuracy: 0.4960\n",
            "Epoch 196/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.5027 - val_loss: 0.4000 - val_accuracy: 0.4960\n",
            "Epoch 197/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.5027 - val_loss: 0.3996 - val_accuracy: 0.4960\n",
            "Epoch 198/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4495 - accuracy: 0.5027 - val_loss: 0.3993 - val_accuracy: 0.4960\n",
            "Epoch 199/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.5027 - val_loss: 0.3988 - val_accuracy: 0.4960\n",
            "Epoch 200/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.5027 - val_loss: 0.3977 - val_accuracy: 0.4960\n",
            "Epoch 201/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.5027 - val_loss: 0.3975 - val_accuracy: 0.4960\n",
            "Epoch 202/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.5027 - val_loss: 0.3971 - val_accuracy: 0.4960\n",
            "Epoch 203/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4349 - accuracy: 0.5027 - val_loss: 0.3965 - val_accuracy: 0.4960\n",
            "Epoch 204/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.5027 - val_loss: 0.3964 - val_accuracy: 0.4960\n",
            "Epoch 205/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.5027 - val_loss: 0.3962 - val_accuracy: 0.4960\n",
            "Epoch 206/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.5027 - val_loss: 0.3957 - val_accuracy: 0.4960\n",
            "Epoch 207/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4353 - accuracy: 0.5027 - val_loss: 0.3956 - val_accuracy: 0.4960\n",
            "Epoch 208/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.5027 - val_loss: 0.3948 - val_accuracy: 0.4960\n",
            "Epoch 209/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.5027 - val_loss: 0.3945 - val_accuracy: 0.4960\n",
            "Epoch 210/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.5027 - val_loss: 0.3938 - val_accuracy: 0.4960\n",
            "Epoch 211/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.5027 - val_loss: 0.3934 - val_accuracy: 0.4960\n",
            "Epoch 212/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.5027 - val_loss: 0.3935 - val_accuracy: 0.4960\n",
            "Epoch 213/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4374 - accuracy: 0.5027 - val_loss: 0.3928 - val_accuracy: 0.4960\n",
            "Epoch 214/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4375 - accuracy: 0.5027 - val_loss: 0.3923 - val_accuracy: 0.4960\n",
            "Epoch 215/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.5027 - val_loss: 0.3918 - val_accuracy: 0.4960\n",
            "Epoch 216/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.5027 - val_loss: 0.3912 - val_accuracy: 0.4960\n",
            "Epoch 217/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.5027 - val_loss: 0.3908 - val_accuracy: 0.4960\n",
            "Epoch 218/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4316 - accuracy: 0.5027 - val_loss: 0.3904 - val_accuracy: 0.4960\n",
            "Epoch 219/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.5027 - val_loss: 0.3903 - val_accuracy: 0.4960\n",
            "Epoch 220/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.5027 - val_loss: 0.3898 - val_accuracy: 0.4960\n",
            "Epoch 221/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.5027 - val_loss: 0.3892 - val_accuracy: 0.4960\n",
            "Epoch 222/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.5027 - val_loss: 0.3889 - val_accuracy: 0.4960\n",
            "Epoch 223/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.5027 - val_loss: 0.3884 - val_accuracy: 0.4960\n",
            "Epoch 224/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.5027 - val_loss: 0.3883 - val_accuracy: 0.4960\n",
            "Epoch 225/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.5027 - val_loss: 0.3880 - val_accuracy: 0.4960\n",
            "Epoch 226/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.5027 - val_loss: 0.3876 - val_accuracy: 0.4960\n",
            "Epoch 227/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.5027 - val_loss: 0.3874 - val_accuracy: 0.4960\n",
            "Epoch 228/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.5027 - val_loss: 0.3868 - val_accuracy: 0.4960\n",
            "Epoch 229/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.5027 - val_loss: 0.3867 - val_accuracy: 0.4960\n",
            "Epoch 230/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.5027 - val_loss: 0.3861 - val_accuracy: 0.4960\n",
            "Epoch 231/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.5027 - val_loss: 0.3858 - val_accuracy: 0.4960\n",
            "Epoch 232/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.5027 - val_loss: 0.3856 - val_accuracy: 0.4960\n",
            "Epoch 233/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4257 - accuracy: 0.5027 - val_loss: 0.3856 - val_accuracy: 0.4960\n",
            "Epoch 234/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.5027 - val_loss: 0.3850 - val_accuracy: 0.4960\n",
            "Epoch 235/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.5027 - val_loss: 0.3846 - val_accuracy: 0.4960\n",
            "Epoch 236/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.5027 - val_loss: 0.3841 - val_accuracy: 0.4960\n",
            "Epoch 237/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.5027 - val_loss: 0.3838 - val_accuracy: 0.4960\n",
            "Epoch 238/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.5027 - val_loss: 0.3835 - val_accuracy: 0.4960\n",
            "Epoch 239/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.5027 - val_loss: 0.3833 - val_accuracy: 0.4960\n",
            "Epoch 240/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.5027 - val_loss: 0.3828 - val_accuracy: 0.4960\n",
            "Epoch 241/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4348 - accuracy: 0.5027 - val_loss: 0.3824 - val_accuracy: 0.4960\n",
            "Epoch 242/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4310 - accuracy: 0.5027 - val_loss: 0.3826 - val_accuracy: 0.4960\n",
            "Epoch 243/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.5027 - val_loss: 0.3825 - val_accuracy: 0.4960\n",
            "Epoch 244/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.5027 - val_loss: 0.3823 - val_accuracy: 0.4960\n",
            "Epoch 245/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.5027 - val_loss: 0.3814 - val_accuracy: 0.4960\n",
            "Epoch 246/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.5027 - val_loss: 0.3813 - val_accuracy: 0.4960\n",
            "Epoch 247/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.5027 - val_loss: 0.3812 - val_accuracy: 0.4960\n",
            "Epoch 248/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.5027 - val_loss: 0.3805 - val_accuracy: 0.4960\n",
            "Epoch 249/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.5027 - val_loss: 0.3805 - val_accuracy: 0.4960\n",
            "Epoch 250/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4273 - accuracy: 0.5027 - val_loss: 0.3803 - val_accuracy: 0.4960\n",
            "Epoch 251/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4196 - accuracy: 0.5027 - val_loss: 0.3800 - val_accuracy: 0.4960\n",
            "Epoch 252/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.5027 - val_loss: 0.3793 - val_accuracy: 0.4960\n",
            "Epoch 253/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.5027 - val_loss: 0.3790 - val_accuracy: 0.4960\n",
            "Epoch 254/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.5027 - val_loss: 0.3790 - val_accuracy: 0.4960\n",
            "Epoch 255/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4227 - accuracy: 0.5027 - val_loss: 0.3788 - val_accuracy: 0.4960\n",
            "Epoch 256/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.5027 - val_loss: 0.3783 - val_accuracy: 0.4960\n",
            "Epoch 257/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4208 - accuracy: 0.5027 - val_loss: 0.3782 - val_accuracy: 0.4960\n",
            "Epoch 258/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4254 - accuracy: 0.5027 - val_loss: 0.3782 - val_accuracy: 0.4960\n",
            "Epoch 259/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4225 - accuracy: 0.5027 - val_loss: 0.3779 - val_accuracy: 0.4960\n",
            "Epoch 260/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.5027 - val_loss: 0.3776 - val_accuracy: 0.4960\n",
            "Epoch 261/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4170 - accuracy: 0.5027 - val_loss: 0.3773 - val_accuracy: 0.4960\n",
            "Epoch 262/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4233 - accuracy: 0.5027 - val_loss: 0.3769 - val_accuracy: 0.4960\n",
            "Epoch 263/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.5027 - val_loss: 0.3768 - val_accuracy: 0.4960\n",
            "Epoch 264/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4208 - accuracy: 0.5027 - val_loss: 0.3768 - val_accuracy: 0.4960\n",
            "Epoch 265/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4276 - accuracy: 0.5027 - val_loss: 0.3767 - val_accuracy: 0.4960\n",
            "Epoch 266/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.5027 - val_loss: 0.3763 - val_accuracy: 0.4960\n",
            "Epoch 267/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.5027 - val_loss: 0.3758 - val_accuracy: 0.4960\n",
            "Epoch 268/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.5027 - val_loss: 0.3756 - val_accuracy: 0.4960\n",
            "Epoch 269/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.5027 - val_loss: 0.3754 - val_accuracy: 0.4960\n",
            "Epoch 270/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.5027 - val_loss: 0.3752 - val_accuracy: 0.4960\n",
            "Epoch 271/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.5027 - val_loss: 0.3755 - val_accuracy: 0.4960\n",
            "Epoch 272/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.5027 - val_loss: 0.3750 - val_accuracy: 0.4960\n",
            "Epoch 273/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4240 - accuracy: 0.5027 - val_loss: 0.3747 - val_accuracy: 0.4960\n",
            "Epoch 274/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.5027 - val_loss: 0.3741 - val_accuracy: 0.4960\n",
            "Epoch 275/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.5027 - val_loss: 0.3741 - val_accuracy: 0.4960\n",
            "Epoch 276/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.5027 - val_loss: 0.3742 - val_accuracy: 0.4960\n",
            "Epoch 277/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.5027 - val_loss: 0.3738 - val_accuracy: 0.4960\n",
            "Epoch 278/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.5027 - val_loss: 0.3735 - val_accuracy: 0.4960\n",
            "Epoch 279/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.5027 - val_loss: 0.3734 - val_accuracy: 0.4960\n",
            "Epoch 280/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.5027 - val_loss: 0.3731 - val_accuracy: 0.4960\n",
            "Epoch 281/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.5027 - val_loss: 0.3731 - val_accuracy: 0.4960\n",
            "Epoch 282/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.5027 - val_loss: 0.3729 - val_accuracy: 0.4960\n",
            "Epoch 283/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.5027 - val_loss: 0.3726 - val_accuracy: 0.4960\n",
            "Epoch 284/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.5027 - val_loss: 0.3725 - val_accuracy: 0.4960\n",
            "Epoch 285/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.5027 - val_loss: 0.3723 - val_accuracy: 0.4960\n",
            "Epoch 286/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.5027 - val_loss: 0.3717 - val_accuracy: 0.4960\n",
            "Epoch 287/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.5027 - val_loss: 0.3716 - val_accuracy: 0.4960\n",
            "Epoch 288/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.5027 - val_loss: 0.3718 - val_accuracy: 0.4960\n",
            "Epoch 289/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.5027 - val_loss: 0.3715 - val_accuracy: 0.4960\n",
            "Epoch 290/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.5027 - val_loss: 0.3710 - val_accuracy: 0.4960\n",
            "Epoch 291/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.5027 - val_loss: 0.3707 - val_accuracy: 0.4960\n",
            "Epoch 292/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.5027 - val_loss: 0.3709 - val_accuracy: 0.4960\n",
            "Epoch 293/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.5027 - val_loss: 0.3708 - val_accuracy: 0.4960\n",
            "Epoch 294/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.5027 - val_loss: 0.3705 - val_accuracy: 0.4960\n",
            "Epoch 295/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.5027 - val_loss: 0.3703 - val_accuracy: 0.4960\n",
            "Epoch 296/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.5027 - val_loss: 0.3703 - val_accuracy: 0.4960\n",
            "Epoch 297/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.5027 - val_loss: 0.3699 - val_accuracy: 0.4960\n",
            "Epoch 298/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.5027 - val_loss: 0.3695 - val_accuracy: 0.4960\n",
            "Epoch 299/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.5027 - val_loss: 0.3697 - val_accuracy: 0.4960\n",
            "Epoch 300/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.5027 - val_loss: 0.3695 - val_accuracy: 0.4960\n",
            "Epoch 301/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.5027 - val_loss: 0.3692 - val_accuracy: 0.4960\n",
            "Epoch 302/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.5027 - val_loss: 0.3692 - val_accuracy: 0.4960\n",
            "Epoch 303/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.5027 - val_loss: 0.3692 - val_accuracy: 0.4960\n",
            "Epoch 304/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.5027 - val_loss: 0.3688 - val_accuracy: 0.4960\n",
            "Epoch 305/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4055 - accuracy: 0.5027 - val_loss: 0.3686 - val_accuracy: 0.4960\n",
            "Epoch 306/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.5027 - val_loss: 0.3684 - val_accuracy: 0.4960\n",
            "Epoch 307/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4101 - accuracy: 0.5027 - val_loss: 0.3686 - val_accuracy: 0.4960\n",
            "Epoch 308/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.5027 - val_loss: 0.3682 - val_accuracy: 0.4960\n",
            "Epoch 309/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.5027 - val_loss: 0.3679 - val_accuracy: 0.4960\n",
            "Epoch 310/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.5027 - val_loss: 0.3678 - val_accuracy: 0.4960\n",
            "Epoch 311/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.5027 - val_loss: 0.3674 - val_accuracy: 0.4960\n",
            "Epoch 312/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.5027 - val_loss: 0.3675 - val_accuracy: 0.4960\n",
            "Epoch 313/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.5027 - val_loss: 0.3671 - val_accuracy: 0.4960\n",
            "Epoch 314/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.5027 - val_loss: 0.3672 - val_accuracy: 0.4960\n",
            "Epoch 315/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.5027 - val_loss: 0.3667 - val_accuracy: 0.4960\n",
            "Epoch 316/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4019 - accuracy: 0.5027 - val_loss: 0.3667 - val_accuracy: 0.4960\n",
            "Epoch 317/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4091 - accuracy: 0.5027 - val_loss: 0.3669 - val_accuracy: 0.4960\n",
            "Epoch 318/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4025 - accuracy: 0.5027 - val_loss: 0.3667 - val_accuracy: 0.4960\n",
            "Epoch 319/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.5027 - val_loss: 0.3665 - val_accuracy: 0.4960\n",
            "Epoch 320/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4093 - accuracy: 0.5027 - val_loss: 0.3666 - val_accuracy: 0.4960\n",
            "Epoch 321/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.5027 - val_loss: 0.3661 - val_accuracy: 0.4960\n",
            "Epoch 322/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4093 - accuracy: 0.5027 - val_loss: 0.3660 - val_accuracy: 0.4960\n",
            "Epoch 323/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.5027 - val_loss: 0.3660 - val_accuracy: 0.4960\n",
            "Epoch 324/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.5027 - val_loss: 0.3658 - val_accuracy: 0.4960\n",
            "Epoch 325/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4100 - accuracy: 0.5027 - val_loss: 0.3655 - val_accuracy: 0.4960\n",
            "Epoch 326/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4096 - accuracy: 0.5027 - val_loss: 0.3653 - val_accuracy: 0.4960\n",
            "Epoch 327/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.5027 - val_loss: 0.3652 - val_accuracy: 0.4960\n",
            "Epoch 328/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.5027 - val_loss: 0.3653 - val_accuracy: 0.4960\n",
            "Epoch 329/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.5027 - val_loss: 0.3651 - val_accuracy: 0.4960\n",
            "Epoch 330/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.5027 - val_loss: 0.3650 - val_accuracy: 0.4960\n",
            "Epoch 331/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.5027 - val_loss: 0.3652 - val_accuracy: 0.4960\n",
            "Epoch 332/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.5027 - val_loss: 0.3649 - val_accuracy: 0.4960\n",
            "Epoch 333/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.5027 - val_loss: 0.3648 - val_accuracy: 0.4960\n",
            "Epoch 334/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.5027 - val_loss: 0.3646 - val_accuracy: 0.4960\n",
            "Epoch 335/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.5027 - val_loss: 0.3647 - val_accuracy: 0.4960\n",
            "Epoch 336/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.5027 - val_loss: 0.3644 - val_accuracy: 0.4960\n",
            "Epoch 337/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.5027 - val_loss: 0.3641 - val_accuracy: 0.4960\n",
            "Epoch 338/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.5027 - val_loss: 0.3640 - val_accuracy: 0.4960\n",
            "Epoch 339/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.5027 - val_loss: 0.3643 - val_accuracy: 0.4960\n",
            "Epoch 340/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4020 - accuracy: 0.5027 - val_loss: 0.3642 - val_accuracy: 0.4960\n",
            "Epoch 341/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.5027 - val_loss: 0.3639 - val_accuracy: 0.4960\n",
            "Epoch 342/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.5027 - val_loss: 0.3636 - val_accuracy: 0.4960\n",
            "Epoch 343/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.5027 - val_loss: 0.3634 - val_accuracy: 0.4960\n",
            "Epoch 344/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.5027 - val_loss: 0.3633 - val_accuracy: 0.4960\n",
            "Epoch 345/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.5027 - val_loss: 0.3635 - val_accuracy: 0.4960\n",
            "Epoch 346/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4169 - accuracy: 0.5027 - val_loss: 0.3634 - val_accuracy: 0.4960\n",
            "Epoch 347/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.5027 - val_loss: 0.3632 - val_accuracy: 0.4960\n",
            "Epoch 348/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4092 - accuracy: 0.5027 - val_loss: 0.3630 - val_accuracy: 0.4960\n",
            "Epoch 349/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.5027 - val_loss: 0.3627 - val_accuracy: 0.4960\n",
            "Epoch 350/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.5027 - val_loss: 0.3624 - val_accuracy: 0.4960\n",
            "Epoch 351/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4042 - accuracy: 0.5027 - val_loss: 0.3627 - val_accuracy: 0.4960\n",
            "Epoch 352/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.5027 - val_loss: 0.3628 - val_accuracy: 0.4960\n",
            "Epoch 353/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.5027 - val_loss: 0.3626 - val_accuracy: 0.4960\n",
            "Epoch 354/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.5027 - val_loss: 0.3626 - val_accuracy: 0.4960\n",
            "Epoch 355/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.5027 - val_loss: 0.3624 - val_accuracy: 0.4960\n",
            "Epoch 356/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4098 - accuracy: 0.5027 - val_loss: 0.3622 - val_accuracy: 0.4960\n",
            "Epoch 357/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.5027 - val_loss: 0.3622 - val_accuracy: 0.4960\n",
            "Epoch 358/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.5027 - val_loss: 0.3620 - val_accuracy: 0.4960\n",
            "Epoch 359/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.5027 - val_loss: 0.3621 - val_accuracy: 0.4960\n",
            "Epoch 360/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.5027 - val_loss: 0.3621 - val_accuracy: 0.4960\n",
            "Epoch 361/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.5027 - val_loss: 0.3617 - val_accuracy: 0.4960\n",
            "Epoch 362/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.5027 - val_loss: 0.3615 - val_accuracy: 0.4960\n",
            "Epoch 363/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.5027 - val_loss: 0.3614 - val_accuracy: 0.4960\n",
            "Epoch 364/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.5027 - val_loss: 0.3613 - val_accuracy: 0.4960\n",
            "Epoch 365/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4016 - accuracy: 0.5027 - val_loss: 0.3615 - val_accuracy: 0.4960\n",
            "Epoch 366/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.5027 - val_loss: 0.3614 - val_accuracy: 0.4960\n",
            "Epoch 367/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.5027 - val_loss: 0.3615 - val_accuracy: 0.4960\n",
            "Epoch 368/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.5027 - val_loss: 0.3614 - val_accuracy: 0.4960\n",
            "Epoch 369/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.5027 - val_loss: 0.3613 - val_accuracy: 0.4960\n",
            "Epoch 370/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.5027 - val_loss: 0.3609 - val_accuracy: 0.4960\n",
            "Epoch 371/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.5027 - val_loss: 0.3606 - val_accuracy: 0.4960\n",
            "Epoch 372/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.5027 - val_loss: 0.3608 - val_accuracy: 0.4960\n",
            "Epoch 373/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.5027 - val_loss: 0.3608 - val_accuracy: 0.4960\n",
            "Epoch 374/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4027 - accuracy: 0.5027 - val_loss: 0.3607 - val_accuracy: 0.4960\n",
            "Epoch 375/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.5027 - val_loss: 0.3609 - val_accuracy: 0.4960\n",
            "Epoch 376/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.5027 - val_loss: 0.3605 - val_accuracy: 0.4960\n",
            "Epoch 377/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.5027 - val_loss: 0.3602 - val_accuracy: 0.4960\n",
            "Epoch 378/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.5027 - val_loss: 0.3601 - val_accuracy: 0.4960\n",
            "Epoch 379/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4058 - accuracy: 0.5027 - val_loss: 0.3601 - val_accuracy: 0.4960\n",
            "Epoch 380/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.5027 - val_loss: 0.3602 - val_accuracy: 0.4960\n",
            "Epoch 381/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4064 - accuracy: 0.5027 - val_loss: 0.3599 - val_accuracy: 0.4960\n",
            "Epoch 382/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.5027 - val_loss: 0.3597 - val_accuracy: 0.4960\n",
            "Epoch 383/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4002 - accuracy: 0.5027 - val_loss: 0.3600 - val_accuracy: 0.4960\n",
            "Epoch 384/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.5027 - val_loss: 0.3599 - val_accuracy: 0.4960\n",
            "Epoch 385/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4088 - accuracy: 0.5027 - val_loss: 0.3600 - val_accuracy: 0.4960\n",
            "Epoch 386/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.5027 - val_loss: 0.3598 - val_accuracy: 0.4960\n",
            "Epoch 387/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4017 - accuracy: 0.5027 - val_loss: 0.3597 - val_accuracy: 0.4960\n",
            "Epoch 388/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.5027 - val_loss: 0.3596 - val_accuracy: 0.4960\n",
            "Epoch 389/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.5027 - val_loss: 0.3593 - val_accuracy: 0.4960\n",
            "Epoch 390/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4027 - accuracy: 0.5027 - val_loss: 0.3592 - val_accuracy: 0.4960\n",
            "Epoch 391/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.5027 - val_loss: 0.3593 - val_accuracy: 0.4960\n",
            "Epoch 392/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4037 - accuracy: 0.5027 - val_loss: 0.3595 - val_accuracy: 0.4960\n",
            "Epoch 393/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.5027 - val_loss: 0.3591 - val_accuracy: 0.4960\n",
            "Epoch 394/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.5027 - val_loss: 0.3589 - val_accuracy: 0.4960\n",
            "Epoch 395/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3981 - accuracy: 0.5027 - val_loss: 0.3587 - val_accuracy: 0.4960\n",
            "Epoch 396/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.5027 - val_loss: 0.3589 - val_accuracy: 0.4960\n",
            "Epoch 397/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.5027 - val_loss: 0.3590 - val_accuracy: 0.4960\n",
            "Epoch 398/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4018 - accuracy: 0.5027 - val_loss: 0.3593 - val_accuracy: 0.4960\n",
            "Epoch 399/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4069 - accuracy: 0.5027 - val_loss: 0.3588 - val_accuracy: 0.4960\n",
            "Epoch 400/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.5027 - val_loss: 0.3589 - val_accuracy: 0.4960\n",
            "Epoch 401/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.5027 - val_loss: 0.3589 - val_accuracy: 0.4960\n",
            "Epoch 402/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.5027 - val_loss: 0.3588 - val_accuracy: 0.4960\n",
            "Epoch 403/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.5027 - val_loss: 0.3588 - val_accuracy: 0.4960\n",
            "Epoch 404/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.5027 - val_loss: 0.3585 - val_accuracy: 0.4960\n",
            "Epoch 405/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4055 - accuracy: 0.5027 - val_loss: 0.3583 - val_accuracy: 0.4960\n",
            "Epoch 406/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.5027 - val_loss: 0.3584 - val_accuracy: 0.4960\n",
            "Epoch 407/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.5027 - val_loss: 0.3581 - val_accuracy: 0.4960\n",
            "Epoch 408/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.5027 - val_loss: 0.3581 - val_accuracy: 0.4960\n",
            "Epoch 409/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4003 - accuracy: 0.5027 - val_loss: 0.3579 - val_accuracy: 0.4960\n",
            "Epoch 410/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4018 - accuracy: 0.5027 - val_loss: 0.3578 - val_accuracy: 0.4960\n",
            "Epoch 411/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4008 - accuracy: 0.5027 - val_loss: 0.3577 - val_accuracy: 0.4960\n",
            "Epoch 412/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3923 - accuracy: 0.5027 - val_loss: 0.3576 - val_accuracy: 0.4960\n",
            "Epoch 413/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.5027 - val_loss: 0.3576 - val_accuracy: 0.4960\n",
            "Epoch 414/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4020 - accuracy: 0.5027 - val_loss: 0.3575 - val_accuracy: 0.4960\n",
            "Epoch 415/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4044 - accuracy: 0.5027 - val_loss: 0.3574 - val_accuracy: 0.4960\n",
            "Epoch 416/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.5027 - val_loss: 0.3574 - val_accuracy: 0.4960\n",
            "Epoch 417/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.5027 - val_loss: 0.3578 - val_accuracy: 0.4960\n",
            "Epoch 418/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.5027 - val_loss: 0.3575 - val_accuracy: 0.4960\n",
            "Epoch 419/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.5027 - val_loss: 0.3571 - val_accuracy: 0.4960\n",
            "Epoch 420/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.5027 - val_loss: 0.3570 - val_accuracy: 0.4960\n",
            "Epoch 421/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.5027 - val_loss: 0.3571 - val_accuracy: 0.4960\n",
            "Epoch 422/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.5027 - val_loss: 0.3570 - val_accuracy: 0.4960\n",
            "Epoch 423/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.5027 - val_loss: 0.3569 - val_accuracy: 0.4960\n",
            "Epoch 424/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.5027 - val_loss: 0.3567 - val_accuracy: 0.4960\n",
            "Epoch 425/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.5027 - val_loss: 0.3569 - val_accuracy: 0.4960\n",
            "Epoch 426/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3941 - accuracy: 0.5027 - val_loss: 0.3569 - val_accuracy: 0.4960\n",
            "Epoch 427/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.5027 - val_loss: 0.3567 - val_accuracy: 0.4960\n",
            "Epoch 428/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.5027 - val_loss: 0.3567 - val_accuracy: 0.4960\n",
            "Epoch 429/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4030 - accuracy: 0.5027 - val_loss: 0.3568 - val_accuracy: 0.4960\n",
            "Epoch 430/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4026 - accuracy: 0.5027 - val_loss: 0.3567 - val_accuracy: 0.4960\n",
            "Epoch 431/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.5027 - val_loss: 0.3568 - val_accuracy: 0.4960\n",
            "Epoch 432/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.5027 - val_loss: 0.3564 - val_accuracy: 0.4960\n",
            "Epoch 433/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.5027 - val_loss: 0.3564 - val_accuracy: 0.4960\n",
            "Epoch 434/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.5027 - val_loss: 0.3563 - val_accuracy: 0.4960\n",
            "Epoch 435/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.5027 - val_loss: 0.3564 - val_accuracy: 0.4960\n",
            "Epoch 436/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.5027 - val_loss: 0.3563 - val_accuracy: 0.4960\n",
            "Epoch 437/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4029 - accuracy: 0.5027 - val_loss: 0.3566 - val_accuracy: 0.4960\n",
            "Epoch 438/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3946 - accuracy: 0.5027 - val_loss: 0.3562 - val_accuracy: 0.4960\n",
            "Epoch 439/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.5027 - val_loss: 0.3560 - val_accuracy: 0.4960\n",
            "Epoch 440/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4014 - accuracy: 0.5027 - val_loss: 0.3560 - val_accuracy: 0.4960\n",
            "Epoch 441/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4014 - accuracy: 0.5027 - val_loss: 0.3560 - val_accuracy: 0.4960\n",
            "Epoch 442/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.5027 - val_loss: 0.3560 - val_accuracy: 0.4960\n",
            "Epoch 443/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4008 - accuracy: 0.5027 - val_loss: 0.3560 - val_accuracy: 0.4960\n",
            "Epoch 444/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.5027 - val_loss: 0.3559 - val_accuracy: 0.4960\n",
            "Epoch 445/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.5027 - val_loss: 0.3559 - val_accuracy: 0.4960\n",
            "Epoch 446/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.5027 - val_loss: 0.3559 - val_accuracy: 0.4960\n",
            "Epoch 447/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.5027 - val_loss: 0.3558 - val_accuracy: 0.4960\n",
            "Epoch 448/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3983 - accuracy: 0.5027 - val_loss: 0.3556 - val_accuracy: 0.4960\n",
            "Epoch 449/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.5027 - val_loss: 0.3558 - val_accuracy: 0.4960\n",
            "Epoch 450/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.5027 - val_loss: 0.3557 - val_accuracy: 0.4960\n",
            "Epoch 451/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.5027 - val_loss: 0.3554 - val_accuracy: 0.4960\n",
            "Epoch 452/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3999 - accuracy: 0.5027 - val_loss: 0.3557 - val_accuracy: 0.4960\n",
            "Epoch 453/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4028 - accuracy: 0.5027 - val_loss: 0.3558 - val_accuracy: 0.4960\n",
            "Epoch 454/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4003 - accuracy: 0.5027 - val_loss: 0.3553 - val_accuracy: 0.4960\n",
            "Epoch 455/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3980 - accuracy: 0.5027 - val_loss: 0.3553 - val_accuracy: 0.4960\n",
            "Epoch 456/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.5027 - val_loss: 0.3553 - val_accuracy: 0.4960\n",
            "Epoch 457/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4012 - accuracy: 0.5027 - val_loss: 0.3553 - val_accuracy: 0.4960\n",
            "Epoch 458/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3920 - accuracy: 0.5027 - val_loss: 0.3554 - val_accuracy: 0.4960\n",
            "Epoch 459/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3971 - accuracy: 0.5027 - val_loss: 0.3553 - val_accuracy: 0.4960\n",
            "Epoch 460/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4102 - accuracy: 0.5027 - val_loss: 0.3553 - val_accuracy: 0.4960\n",
            "Epoch 461/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4015 - accuracy: 0.5027 - val_loss: 0.3549 - val_accuracy: 0.4960\n",
            "Epoch 462/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3930 - accuracy: 0.5027 - val_loss: 0.3548 - val_accuracy: 0.4960\n",
            "Epoch 463/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3950 - accuracy: 0.5027 - val_loss: 0.3547 - val_accuracy: 0.4960\n",
            "Epoch 464/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3951 - accuracy: 0.5027 - val_loss: 0.3546 - val_accuracy: 0.4960\n",
            "Epoch 465/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3975 - accuracy: 0.5027 - val_loss: 0.3545 - val_accuracy: 0.4960\n",
            "Epoch 466/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3980 - accuracy: 0.5027 - val_loss: 0.3544 - val_accuracy: 0.4960\n",
            "Epoch 467/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4062 - accuracy: 0.5027 - val_loss: 0.3548 - val_accuracy: 0.4960\n",
            "Epoch 468/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3974 - accuracy: 0.5027 - val_loss: 0.3548 - val_accuracy: 0.4960\n",
            "Epoch 469/2000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3939 - accuracy: 0.5027 - val_loss: 0.3548 - val_accuracy: 0.4960\n",
            "Epoch 470/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3833 - accuracy: 0.5027 - val_loss: 0.3545 - val_accuracy: 0.4960\n",
            "Epoch 471/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3988 - accuracy: 0.5027 - val_loss: 0.3544 - val_accuracy: 0.4960\n",
            "Epoch 472/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3921 - accuracy: 0.5027 - val_loss: 0.3541 - val_accuracy: 0.4960\n",
            "Epoch 473/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3991 - accuracy: 0.5027 - val_loss: 0.3543 - val_accuracy: 0.4960\n",
            "Epoch 474/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.4052 - accuracy: 0.5027 - val_loss: 0.3543 - val_accuracy: 0.4960\n",
            "Epoch 475/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4017 - accuracy: 0.5027 - val_loss: 0.3542 - val_accuracy: 0.4960\n",
            "Epoch 476/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3931 - accuracy: 0.5027 - val_loss: 0.3543 - val_accuracy: 0.4960\n",
            "Epoch 477/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4034 - accuracy: 0.5027 - val_loss: 0.3540 - val_accuracy: 0.4960\n",
            "Epoch 478/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3951 - accuracy: 0.5027 - val_loss: 0.3539 - val_accuracy: 0.4960\n",
            "Epoch 479/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4054 - accuracy: 0.5027 - val_loss: 0.3538 - val_accuracy: 0.4960\n",
            "Epoch 480/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3933 - accuracy: 0.5027 - val_loss: 0.3537 - val_accuracy: 0.4960\n",
            "Epoch 481/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4019 - accuracy: 0.5027 - val_loss: 0.3539 - val_accuracy: 0.4960\n",
            "Epoch 482/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3892 - accuracy: 0.5027 - val_loss: 0.3538 - val_accuracy: 0.4960\n",
            "Epoch 483/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3972 - accuracy: 0.5027 - val_loss: 0.3537 - val_accuracy: 0.4960\n",
            "Epoch 484/2000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.5027 - val_loss: 0.3536 - val_accuracy: 0.4960\n",
            "Epoch 485/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.5027 - val_loss: 0.3535 - val_accuracy: 0.4960\n",
            "Epoch 486/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.5027 - val_loss: 0.3536 - val_accuracy: 0.4960\n",
            "Epoch 487/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.5027 - val_loss: 0.3536 - val_accuracy: 0.4960\n",
            "Epoch 488/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.5027 - val_loss: 0.3536 - val_accuracy: 0.4960\n",
            "Epoch 489/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3921 - accuracy: 0.5027 - val_loss: 0.3537 - val_accuracy: 0.4960\n",
            "Epoch 490/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.5027 - val_loss: 0.3535 - val_accuracy: 0.4960\n",
            "Epoch 491/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.5027 - val_loss: 0.3534 - val_accuracy: 0.4960\n",
            "Epoch 492/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3970 - accuracy: 0.5027 - val_loss: 0.3533 - val_accuracy: 0.4960\n",
            "Epoch 493/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3953 - accuracy: 0.5027 - val_loss: 0.3533 - val_accuracy: 0.4960\n",
            "Epoch 494/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.5027 - val_loss: 0.3533 - val_accuracy: 0.4960\n",
            "Epoch 495/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.5027 - val_loss: 0.3533 - val_accuracy: 0.4960\n",
            "Epoch 496/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.5027 - val_loss: 0.3529 - val_accuracy: 0.4960\n",
            "Epoch 497/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.5027 - val_loss: 0.3529 - val_accuracy: 0.4960\n",
            "Epoch 498/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3883 - accuracy: 0.5027 - val_loss: 0.3529 - val_accuracy: 0.4960\n",
            "Epoch 499/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.5027 - val_loss: 0.3528 - val_accuracy: 0.4960\n",
            "Epoch 500/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.5027 - val_loss: 0.3527 - val_accuracy: 0.4960\n",
            "Epoch 501/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.5027 - val_loss: 0.3529 - val_accuracy: 0.4960\n",
            "Epoch 502/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.5027 - val_loss: 0.3529 - val_accuracy: 0.4960\n",
            "Epoch 503/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.5027 - val_loss: 0.3532 - val_accuracy: 0.4960\n",
            "Epoch 504/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3924 - accuracy: 0.5027 - val_loss: 0.3532 - val_accuracy: 0.4960\n",
            "Epoch 505/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.5027 - val_loss: 0.3529 - val_accuracy: 0.4960\n",
            "Epoch 506/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.5027 - val_loss: 0.3528 - val_accuracy: 0.4960\n",
            "Epoch 507/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.5027 - val_loss: 0.3526 - val_accuracy: 0.4960\n",
            "Epoch 508/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.5027 - val_loss: 0.3526 - val_accuracy: 0.4960\n",
            "Epoch 509/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.5027 - val_loss: 0.3525 - val_accuracy: 0.4960\n",
            "Epoch 510/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.5027 - val_loss: 0.3526 - val_accuracy: 0.4960\n",
            "Epoch 511/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.5027 - val_loss: 0.3527 - val_accuracy: 0.4960\n",
            "Epoch 512/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.5027 - val_loss: 0.3529 - val_accuracy: 0.4960\n",
            "Epoch 513/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.5027 - val_loss: 0.3524 - val_accuracy: 0.4960\n",
            "Epoch 514/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.5027 - val_loss: 0.3525 - val_accuracy: 0.4960\n",
            "Epoch 515/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.5027 - val_loss: 0.3524 - val_accuracy: 0.4960\n",
            "Epoch 516/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.5027 - val_loss: 0.3524 - val_accuracy: 0.4960\n",
            "Epoch 517/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.5027 - val_loss: 0.3525 - val_accuracy: 0.4960\n",
            "Epoch 518/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.5027 - val_loss: 0.3525 - val_accuracy: 0.4960\n",
            "Epoch 519/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.5027 - val_loss: 0.3523 - val_accuracy: 0.4960\n",
            "Epoch 520/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.5027 - val_loss: 0.3526 - val_accuracy: 0.4960\n",
            "Epoch 521/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.5027 - val_loss: 0.3522 - val_accuracy: 0.4960\n",
            "Epoch 522/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.5027 - val_loss: 0.3521 - val_accuracy: 0.4960\n",
            "Epoch 523/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.5027 - val_loss: 0.3523 - val_accuracy: 0.4960\n",
            "Epoch 524/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.5027 - val_loss: 0.3522 - val_accuracy: 0.4960\n",
            "Epoch 525/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.5027 - val_loss: 0.3522 - val_accuracy: 0.4960\n",
            "Epoch 526/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.5027 - val_loss: 0.3518 - val_accuracy: 0.4960\n",
            "Epoch 527/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.5027 - val_loss: 0.3519 - val_accuracy: 0.4960\n",
            "Epoch 528/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.5027 - val_loss: 0.3521 - val_accuracy: 0.4960\n",
            "Epoch 529/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.5027 - val_loss: 0.3523 - val_accuracy: 0.4960\n",
            "Epoch 530/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.5027 - val_loss: 0.3522 - val_accuracy: 0.4960\n",
            "Epoch 531/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.5027 - val_loss: 0.3523 - val_accuracy: 0.4960\n",
            "Epoch 532/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.5027 - val_loss: 0.3520 - val_accuracy: 0.4960\n",
            "Epoch 533/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.5027 - val_loss: 0.3518 - val_accuracy: 0.4960\n",
            "Epoch 534/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.5027 - val_loss: 0.3518 - val_accuracy: 0.4960\n",
            "Epoch 535/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.5027 - val_loss: 0.3521 - val_accuracy: 0.4960\n",
            "Epoch 536/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.5027 - val_loss: 0.3519 - val_accuracy: 0.4960\n",
            "Epoch 537/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.5027 - val_loss: 0.3519 - val_accuracy: 0.4960\n",
            "Epoch 538/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.5027 - val_loss: 0.3520 - val_accuracy: 0.4960\n",
            "Epoch 539/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.5027 - val_loss: 0.3522 - val_accuracy: 0.4960\n",
            "Epoch 540/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.5027 - val_loss: 0.3522 - val_accuracy: 0.4960\n",
            "Epoch 541/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3871 - accuracy: 0.5027 - val_loss: 0.3521 - val_accuracy: 0.4960\n",
            "Epoch 542/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3888 - accuracy: 0.5027 - val_loss: 0.3522 - val_accuracy: 0.4960\n",
            "Epoch 543/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.5027 - val_loss: 0.3519 - val_accuracy: 0.4960\n",
            "Epoch 544/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.5027 - val_loss: 0.3517 - val_accuracy: 0.4960\n",
            "Epoch 545/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3935 - accuracy: 0.5027 - val_loss: 0.3517 - val_accuracy: 0.4960\n",
            "Epoch 546/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.5027 - val_loss: 0.3518 - val_accuracy: 0.4960\n",
            "Epoch 547/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.5027 - val_loss: 0.3519 - val_accuracy: 0.4960\n",
            "Epoch 548/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.5027 - val_loss: 0.3517 - val_accuracy: 0.4960\n",
            "Epoch 549/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3914 - accuracy: 0.5027 - val_loss: 0.3516 - val_accuracy: 0.4960\n",
            "Epoch 550/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3912 - accuracy: 0.5027 - val_loss: 0.3514 - val_accuracy: 0.4960\n",
            "Epoch 551/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.5027 - val_loss: 0.3514 - val_accuracy: 0.4960\n",
            "Epoch 552/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.5027 - val_loss: 0.3517 - val_accuracy: 0.4960\n",
            "Epoch 553/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.5027 - val_loss: 0.3516 - val_accuracy: 0.4960\n",
            "Epoch 554/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.5027 - val_loss: 0.3518 - val_accuracy: 0.4960\n",
            "Epoch 555/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3896 - accuracy: 0.5027 - val_loss: 0.3520 - val_accuracy: 0.4960\n",
            "Epoch 556/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.5027 - val_loss: 0.3519 - val_accuracy: 0.4960\n",
            "Epoch 557/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.5027 - val_loss: 0.3514 - val_accuracy: 0.4960\n",
            "Epoch 558/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.5027 - val_loss: 0.3512 - val_accuracy: 0.4960\n",
            "Epoch 559/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.5027 - val_loss: 0.3511 - val_accuracy: 0.4960\n",
            "Epoch 560/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.5027 - val_loss: 0.3509 - val_accuracy: 0.4960\n",
            "Epoch 561/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.5027 - val_loss: 0.3509 - val_accuracy: 0.4960\n",
            "Epoch 562/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.5027 - val_loss: 0.3513 - val_accuracy: 0.4960\n",
            "Epoch 563/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.5027 - val_loss: 0.3509 - val_accuracy: 0.4960\n",
            "Epoch 564/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.5027 - val_loss: 0.3512 - val_accuracy: 0.4960\n",
            "Epoch 565/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.5027 - val_loss: 0.3512 - val_accuracy: 0.4960\n",
            "Epoch 566/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.5027 - val_loss: 0.3511 - val_accuracy: 0.4960\n",
            "Epoch 567/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3908 - accuracy: 0.5027 - val_loss: 0.3509 - val_accuracy: 0.4960\n",
            "Epoch 568/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.5027 - val_loss: 0.3512 - val_accuracy: 0.4960\n",
            "Epoch 569/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3880 - accuracy: 0.5027 - val_loss: 0.3511 - val_accuracy: 0.4960\n",
            "Epoch 570/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.5027 - val_loss: 0.3512 - val_accuracy: 0.4960\n",
            "Epoch 571/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.5027 - val_loss: 0.3510 - val_accuracy: 0.4960\n",
            "Epoch 572/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.5027 - val_loss: 0.3509 - val_accuracy: 0.4960\n",
            "Epoch 573/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3913 - accuracy: 0.5027 - val_loss: 0.3510 - val_accuracy: 0.4960\n",
            "Epoch 574/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.5027 - val_loss: 0.3510 - val_accuracy: 0.4960\n",
            "Epoch 575/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3895 - accuracy: 0.5027 - val_loss: 0.3515 - val_accuracy: 0.4960\n",
            "Epoch 576/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3935 - accuracy: 0.5027 - val_loss: 0.3512 - val_accuracy: 0.4960\n",
            "Epoch 577/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.5027 - val_loss: 0.3509 - val_accuracy: 0.4960\n",
            "Epoch 578/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3916 - accuracy: 0.5027 - val_loss: 0.3509 - val_accuracy: 0.4960\n",
            "Epoch 579/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3926 - accuracy: 0.5027 - val_loss: 0.3511 - val_accuracy: 0.4960\n",
            "Epoch 580/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3909 - accuracy: 0.5027 - val_loss: 0.3509 - val_accuracy: 0.4960\n",
            "Epoch 581/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.5027 - val_loss: 0.3508 - val_accuracy: 0.4960\n",
            "Epoch 582/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3890 - accuracy: 0.5027 - val_loss: 0.3506 - val_accuracy: 0.4960\n",
            "Epoch 583/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3890 - accuracy: 0.5027 - val_loss: 0.3508 - val_accuracy: 0.4960\n",
            "Epoch 584/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.5027 - val_loss: 0.3510 - val_accuracy: 0.4960\n",
            "Epoch 585/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3896 - accuracy: 0.5027 - val_loss: 0.3510 - val_accuracy: 0.4960\n",
            "Epoch 586/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3968 - accuracy: 0.5027 - val_loss: 0.3509 - val_accuracy: 0.4960\n",
            "Epoch 587/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3911 - accuracy: 0.5027 - val_loss: 0.3508 - val_accuracy: 0.4960\n",
            "Epoch 588/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3944 - accuracy: 0.5027 - val_loss: 0.3509 - val_accuracy: 0.4960\n",
            "Epoch 589/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3939 - accuracy: 0.5027 - val_loss: 0.3507 - val_accuracy: 0.4960\n",
            "Epoch 590/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.5027 - val_loss: 0.3506 - val_accuracy: 0.4960\n",
            "Epoch 591/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.5027 - val_loss: 0.3507 - val_accuracy: 0.4960\n",
            "Epoch 592/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3947 - accuracy: 0.5027 - val_loss: 0.3513 - val_accuracy: 0.4960\n",
            "Epoch 593/2000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3954 - accuracy: 0.5027 - val_loss: 0.3509 - val_accuracy: 0.4960\n",
            "Epoch 594/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3970 - accuracy: 0.5027 - val_loss: 0.3508 - val_accuracy: 0.4960\n",
            "Epoch 595/2000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3980 - accuracy: 0.5027 - val_loss: 0.3509 - val_accuracy: 0.4960\n",
            "Epoch 596/2000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3998 - accuracy: 0.5027 - val_loss: 0.3507 - val_accuracy: 0.4960\n",
            "Epoch 597/2000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.3867 - accuracy: 0.5027 - val_loss: 0.3506 - val_accuracy: 0.4960\n",
            "Epoch 598/2000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3960 - accuracy: 0.5027 - val_loss: 0.3507 - val_accuracy: 0.4960\n",
            "Epoch 599/2000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3916 - accuracy: 0.5027 - val_loss: 0.3509 - val_accuracy: 0.4960\n",
            "Epoch 600/2000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.3921 - accuracy: 0.5027 - val_loss: 0.3508 - val_accuracy: 0.4960\n",
            "Epoch 601/2000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3883 - accuracy: 0.5027 - val_loss: 0.3508 - val_accuracy: 0.4960\n",
            "Epoch 602/2000\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3975 - accuracy: 0.5027 - val_loss: 0.3507 - val_accuracy: 0.4960\n",
            "Epoch 603/2000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3953 - accuracy: 0.5027 - val_loss: 0.3509 - val_accuracy: 0.4960\n",
            "Epoch 604/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3882 - accuracy: 0.5027 - val_loss: 0.3507 - val_accuracy: 0.4960\n",
            "Epoch 605/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3904 - accuracy: 0.5027 - val_loss: 0.3508 - val_accuracy: 0.4960\n",
            "Epoch 606/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.5027 - val_loss: 0.3509 - val_accuracy: 0.4960\n",
            "Epoch 607/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4005 - accuracy: 0.5027 - val_loss: 0.3508 - val_accuracy: 0.4960\n",
            "Epoch 608/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.5027 - val_loss: 0.3505 - val_accuracy: 0.4960\n",
            "Epoch 609/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3846 - accuracy: 0.5027 - val_loss: 0.3507 - val_accuracy: 0.4960\n",
            "Epoch 610/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3923 - accuracy: 0.5027 - val_loss: 0.3507 - val_accuracy: 0.4960\n",
            "Epoch 611/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3867 - accuracy: 0.5027 - val_loss: 0.3505 - val_accuracy: 0.4960\n",
            "Epoch 612/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3903 - accuracy: 0.5027 - val_loss: 0.3507 - val_accuracy: 0.4960\n",
            "Epoch 613/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.5027 - val_loss: 0.3507 - val_accuracy: 0.4960\n",
            "Epoch 614/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.5027 - val_loss: 0.3506 - val_accuracy: 0.4960\n",
            "Epoch 615/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3870 - accuracy: 0.5027 - val_loss: 0.3508 - val_accuracy: 0.4960\n",
            "Epoch 616/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.5027 - val_loss: 0.3509 - val_accuracy: 0.4960\n",
            "Epoch 617/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.5027 - val_loss: 0.3504 - val_accuracy: 0.4960\n",
            "Epoch 618/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3854 - accuracy: 0.5027 - val_loss: 0.3507 - val_accuracy: 0.4960\n",
            "Epoch 619/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.5027 - val_loss: 0.3504 - val_accuracy: 0.4960\n",
            "Epoch 620/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3871 - accuracy: 0.5027 - val_loss: 0.3501 - val_accuracy: 0.4960\n",
            "Epoch 621/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.5027 - val_loss: 0.3504 - val_accuracy: 0.4960\n",
            "Epoch 622/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.5027 - val_loss: 0.3507 - val_accuracy: 0.4960\n",
            "Epoch 623/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3960 - accuracy: 0.5027 - val_loss: 0.3506 - val_accuracy: 0.4960\n",
            "Epoch 624/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.5027 - val_loss: 0.3502 - val_accuracy: 0.4960\n",
            "Epoch 625/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3893 - accuracy: 0.5027 - val_loss: 0.3501 - val_accuracy: 0.4960\n",
            "Epoch 626/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3894 - accuracy: 0.5027 - val_loss: 0.3504 - val_accuracy: 0.4960\n",
            "Epoch 627/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3929 - accuracy: 0.5027 - val_loss: 0.3507 - val_accuracy: 0.4960\n",
            "Epoch 628/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3866 - accuracy: 0.5027 - val_loss: 0.3505 - val_accuracy: 0.4960\n",
            "Epoch 629/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3902 - accuracy: 0.5027 - val_loss: 0.3503 - val_accuracy: 0.4960\n",
            "Epoch 630/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3862 - accuracy: 0.5027 - val_loss: 0.3504 - val_accuracy: 0.4960\n",
            "Epoch 631/2000\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3927 - accuracy: 0.5027 - val_loss: 0.3502 - val_accuracy: 0.4960\n",
            "Epoch 632/2000\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3921 - accuracy: 0.5027 - val_loss: 0.3500 - val_accuracy: 0.4960\n",
            "Epoch 633/2000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3889 - accuracy: 0.5027 - val_loss: 0.3504 - val_accuracy: 0.4960\n",
            "Epoch 634/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3861 - accuracy: 0.5027 - val_loss: 0.3503 - val_accuracy: 0.4960\n",
            "Epoch 635/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3804 - accuracy: 0.5027 - val_loss: 0.3501 - val_accuracy: 0.4960\n",
            "Epoch 636/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3878 - accuracy: 0.5027 - val_loss: 0.3499 - val_accuracy: 0.4960\n",
            "Epoch 637/2000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3930 - accuracy: 0.5027 - val_loss: 0.3504 - val_accuracy: 0.4960\n",
            "Epoch 638/2000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3921 - accuracy: 0.5027 - val_loss: 0.3501 - val_accuracy: 0.4960\n",
            "Epoch 639/2000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3869 - accuracy: 0.5027 - val_loss: 0.3501 - val_accuracy: 0.4960\n",
            "Epoch 640/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3952 - accuracy: 0.5027 - val_loss: 0.3501 - val_accuracy: 0.4960\n",
            "Epoch 641/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3879 - accuracy: 0.5027 - val_loss: 0.3499 - val_accuracy: 0.4960\n",
            "Epoch 642/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3877 - accuracy: 0.5027 - val_loss: 0.3500 - val_accuracy: 0.4960\n",
            "Epoch 643/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.5027 - val_loss: 0.3499 - val_accuracy: 0.4960\n",
            "Epoch 644/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.5027 - val_loss: 0.3502 - val_accuracy: 0.4960\n",
            "Epoch 645/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3890 - accuracy: 0.5027 - val_loss: 0.3503 - val_accuracy: 0.4960\n",
            "Epoch 646/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.5027 - val_loss: 0.3503 - val_accuracy: 0.4960\n",
            "Epoch 647/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.5027 - val_loss: 0.3504 - val_accuracy: 0.4960\n",
            "Epoch 648/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3838 - accuracy: 0.5027 - val_loss: 0.3503 - val_accuracy: 0.4960\n",
            "Epoch 649/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.5027 - val_loss: 0.3504 - val_accuracy: 0.4960\n",
            "Epoch 650/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3832 - accuracy: 0.5027 - val_loss: 0.3504 - val_accuracy: 0.4960\n",
            "Epoch 651/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.5027 - val_loss: 0.3502 - val_accuracy: 0.4960\n",
            "Epoch 652/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.5027 - val_loss: 0.3503 - val_accuracy: 0.4960\n",
            "Epoch 653/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.5027 - val_loss: 0.3502 - val_accuracy: 0.4960\n",
            "Epoch 654/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.5027 - val_loss: 0.3502 - val_accuracy: 0.4960\n",
            "Epoch 655/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3861 - accuracy: 0.5027 - val_loss: 0.3502 - val_accuracy: 0.4960\n",
            "Epoch 656/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.5027 - val_loss: 0.3501 - val_accuracy: 0.4960\n",
            "Epoch 657/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3840 - accuracy: 0.5027 - val_loss: 0.3499 - val_accuracy: 0.4960\n",
            "Epoch 658/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.5027 - val_loss: 0.3500 - val_accuracy: 0.4960\n",
            "Epoch 659/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3895 - accuracy: 0.5027 - val_loss: 0.3502 - val_accuracy: 0.4960\n",
            "Epoch 660/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.5027 - val_loss: 0.3500 - val_accuracy: 0.4960\n",
            "Epoch 661/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.5027 - val_loss: 0.3500 - val_accuracy: 0.4960\n",
            "Epoch 662/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.5027 - val_loss: 0.3499 - val_accuracy: 0.4960\n",
            "Epoch 663/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3910 - accuracy: 0.5027 - val_loss: 0.3499 - val_accuracy: 0.4960\n",
            "Epoch 664/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.5027 - val_loss: 0.3498 - val_accuracy: 0.4960\n",
            "Epoch 665/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.5027 - val_loss: 0.3501 - val_accuracy: 0.4960\n",
            "Epoch 666/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3839 - accuracy: 0.5027 - val_loss: 0.3500 - val_accuracy: 0.4960\n",
            "Epoch 667/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.5027 - val_loss: 0.3500 - val_accuracy: 0.4960\n",
            "Epoch 668/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.5027 - val_loss: 0.3499 - val_accuracy: 0.4960\n",
            "Epoch 669/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.5027 - val_loss: 0.3499 - val_accuracy: 0.4960\n",
            "Epoch 670/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3924 - accuracy: 0.5027 - val_loss: 0.3497 - val_accuracy: 0.4960\n",
            "Epoch 671/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.5027 - val_loss: 0.3498 - val_accuracy: 0.4960\n",
            "Epoch 672/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3866 - accuracy: 0.5027 - val_loss: 0.3497 - val_accuracy: 0.4960\n",
            "Epoch 673/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.5027 - val_loss: 0.3497 - val_accuracy: 0.4960\n",
            "Epoch 674/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.5027 - val_loss: 0.3498 - val_accuracy: 0.4960\n",
            "Epoch 675/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.5027 - val_loss: 0.3498 - val_accuracy: 0.4960\n",
            "Epoch 676/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.5027 - val_loss: 0.3499 - val_accuracy: 0.4960\n",
            "Epoch 677/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3814 - accuracy: 0.5027 - val_loss: 0.3498 - val_accuracy: 0.4960\n",
            "Epoch 678/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.5027 - val_loss: 0.3498 - val_accuracy: 0.4960\n",
            "Epoch 679/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.5027 - val_loss: 0.3494 - val_accuracy: 0.4960\n",
            "Epoch 680/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.5027 - val_loss: 0.3493 - val_accuracy: 0.4960\n",
            "Epoch 681/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.5027 - val_loss: 0.3495 - val_accuracy: 0.4960\n",
            "Epoch 682/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.5027 - val_loss: 0.3499 - val_accuracy: 0.4960\n",
            "Epoch 683/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.5027 - val_loss: 0.3497 - val_accuracy: 0.4960\n",
            "Epoch 684/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.5027 - val_loss: 0.3498 - val_accuracy: 0.4960\n",
            "Epoch 685/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3887 - accuracy: 0.5027 - val_loss: 0.3496 - val_accuracy: 0.4960\n",
            "Epoch 686/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.5027 - val_loss: 0.3495 - val_accuracy: 0.4960\n",
            "Epoch 687/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3862 - accuracy: 0.5027 - val_loss: 0.3494 - val_accuracy: 0.4960\n",
            "Epoch 688/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.5027 - val_loss: 0.3497 - val_accuracy: 0.4960\n",
            "Epoch 689/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.5027 - val_loss: 0.3495 - val_accuracy: 0.4960\n",
            "Epoch 690/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.5027 - val_loss: 0.3495 - val_accuracy: 0.4960\n",
            "Epoch 691/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.5027 - val_loss: 0.3496 - val_accuracy: 0.4960\n",
            "Epoch 692/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3824 - accuracy: 0.5027 - val_loss: 0.3497 - val_accuracy: 0.4960\n",
            "Epoch 693/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3885 - accuracy: 0.5027 - val_loss: 0.3494 - val_accuracy: 0.4960\n",
            "Epoch 694/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3871 - accuracy: 0.5027 - val_loss: 0.3492 - val_accuracy: 0.4960\n",
            "Epoch 695/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.5027 - val_loss: 0.3491 - val_accuracy: 0.4960\n",
            "Epoch 696/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.5027 - val_loss: 0.3492 - val_accuracy: 0.4960\n",
            "Epoch 697/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.5027 - val_loss: 0.3491 - val_accuracy: 0.4960\n",
            "Epoch 698/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.5027 - val_loss: 0.3492 - val_accuracy: 0.4960\n",
            "Epoch 699/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3887 - accuracy: 0.5027 - val_loss: 0.3494 - val_accuracy: 0.4960\n",
            "Epoch 700/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3928 - accuracy: 0.5027 - val_loss: 0.3494 - val_accuracy: 0.4960\n",
            "Epoch 701/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.5027 - val_loss: 0.3493 - val_accuracy: 0.4960\n",
            "Epoch 702/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3777 - accuracy: 0.5027 - val_loss: 0.3491 - val_accuracy: 0.4960\n",
            "Epoch 703/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3894 - accuracy: 0.5027 - val_loss: 0.3493 - val_accuracy: 0.4960\n",
            "Epoch 704/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3849 - accuracy: 0.5027 - val_loss: 0.3495 - val_accuracy: 0.4960\n",
            "Epoch 705/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3828 - accuracy: 0.5027 - val_loss: 0.3495 - val_accuracy: 0.4960\n",
            "Epoch 706/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3828 - accuracy: 0.5027 - val_loss: 0.3493 - val_accuracy: 0.4960\n",
            "Epoch 707/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.5027 - val_loss: 0.3491 - val_accuracy: 0.4960\n",
            "Epoch 708/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3828 - accuracy: 0.5027 - val_loss: 0.3490 - val_accuracy: 0.4960\n",
            "Epoch 709/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3805 - accuracy: 0.5027 - val_loss: 0.3491 - val_accuracy: 0.4960\n",
            "Epoch 710/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3879 - accuracy: 0.5027 - val_loss: 0.3491 - val_accuracy: 0.4960\n",
            "Epoch 711/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3892 - accuracy: 0.5027 - val_loss: 0.3491 - val_accuracy: 0.4960\n",
            "Epoch 712/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3868 - accuracy: 0.5027 - val_loss: 0.3493 - val_accuracy: 0.4960\n",
            "Epoch 713/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3850 - accuracy: 0.5027 - val_loss: 0.3491 - val_accuracy: 0.4960\n",
            "Epoch 714/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3775 - accuracy: 0.5027 - val_loss: 0.3490 - val_accuracy: 0.4960\n",
            "Epoch 715/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3882 - accuracy: 0.5027 - val_loss: 0.3490 - val_accuracy: 0.4960\n",
            "Epoch 716/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3824 - accuracy: 0.5027 - val_loss: 0.3487 - val_accuracy: 0.4960\n",
            "Epoch 717/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3864 - accuracy: 0.5027 - val_loss: 0.3492 - val_accuracy: 0.4960\n",
            "Epoch 718/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3843 - accuracy: 0.5027 - val_loss: 0.3493 - val_accuracy: 0.4960\n",
            "Epoch 719/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3785 - accuracy: 0.5027 - val_loss: 0.3490 - val_accuracy: 0.4960\n",
            "Epoch 720/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3913 - accuracy: 0.5027 - val_loss: 0.3490 - val_accuracy: 0.4960\n",
            "Epoch 721/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3856 - accuracy: 0.5027 - val_loss: 0.3489 - val_accuracy: 0.4960\n",
            "Epoch 722/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3861 - accuracy: 0.5027 - val_loss: 0.3493 - val_accuracy: 0.4960\n",
            "Epoch 723/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3927 - accuracy: 0.5027 - val_loss: 0.3490 - val_accuracy: 0.4960\n",
            "Epoch 724/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3846 - accuracy: 0.5027 - val_loss: 0.3491 - val_accuracy: 0.4960\n",
            "Epoch 725/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.5027 - val_loss: 0.3489 - val_accuracy: 0.4960\n",
            "Epoch 726/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3916 - accuracy: 0.5027 - val_loss: 0.3488 - val_accuracy: 0.4960\n",
            "Epoch 727/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.5027 - val_loss: 0.3487 - val_accuracy: 0.4960\n",
            "Epoch 728/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3841 - accuracy: 0.5027 - val_loss: 0.3486 - val_accuracy: 0.4960\n",
            "Epoch 729/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3800 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 730/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3949 - accuracy: 0.5027 - val_loss: 0.3485 - val_accuracy: 0.4960\n",
            "Epoch 731/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3819 - accuracy: 0.5027 - val_loss: 0.3487 - val_accuracy: 0.4960\n",
            "Epoch 732/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3899 - accuracy: 0.5027 - val_loss: 0.3487 - val_accuracy: 0.4960\n",
            "Epoch 733/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3843 - accuracy: 0.5027 - val_loss: 0.3488 - val_accuracy: 0.4960\n",
            "Epoch 734/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3921 - accuracy: 0.5027 - val_loss: 0.3487 - val_accuracy: 0.4960\n",
            "Epoch 735/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3827 - accuracy: 0.5027 - val_loss: 0.3487 - val_accuracy: 0.4960\n",
            "Epoch 736/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3836 - accuracy: 0.5027 - val_loss: 0.3489 - val_accuracy: 0.4960\n",
            "Epoch 737/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3786 - accuracy: 0.5027 - val_loss: 0.3486 - val_accuracy: 0.4960\n",
            "Epoch 738/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3898 - accuracy: 0.5027 - val_loss: 0.3487 - val_accuracy: 0.4960\n",
            "Epoch 739/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3899 - accuracy: 0.5027 - val_loss: 0.3489 - val_accuracy: 0.4960\n",
            "Epoch 740/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3864 - accuracy: 0.5027 - val_loss: 0.3488 - val_accuracy: 0.4960\n",
            "Epoch 741/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3815 - accuracy: 0.5027 - val_loss: 0.3490 - val_accuracy: 0.4960\n",
            "Epoch 742/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3872 - accuracy: 0.5027 - val_loss: 0.3488 - val_accuracy: 0.4960\n",
            "Epoch 743/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3832 - accuracy: 0.5027 - val_loss: 0.3487 - val_accuracy: 0.4960\n",
            "Epoch 744/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3827 - accuracy: 0.5027 - val_loss: 0.3489 - val_accuracy: 0.4960\n",
            "Epoch 745/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.5027 - val_loss: 0.3490 - val_accuracy: 0.4960\n",
            "Epoch 746/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.5027 - val_loss: 0.3486 - val_accuracy: 0.4960\n",
            "Epoch 747/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.5027 - val_loss: 0.3486 - val_accuracy: 0.4960\n",
            "Epoch 748/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3849 - accuracy: 0.5027 - val_loss: 0.3486 - val_accuracy: 0.4960\n",
            "Epoch 749/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3861 - accuracy: 0.5027 - val_loss: 0.3486 - val_accuracy: 0.4960\n",
            "Epoch 750/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.5027 - val_loss: 0.3485 - val_accuracy: 0.4960\n",
            "Epoch 751/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3867 - accuracy: 0.5027 - val_loss: 0.3487 - val_accuracy: 0.4960\n",
            "Epoch 752/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.5027 - val_loss: 0.3488 - val_accuracy: 0.4960\n",
            "Epoch 753/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.5027 - val_loss: 0.3490 - val_accuracy: 0.4960\n",
            "Epoch 754/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3900 - accuracy: 0.5027 - val_loss: 0.3488 - val_accuracy: 0.4960\n",
            "Epoch 755/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.5027 - val_loss: 0.3488 - val_accuracy: 0.4960\n",
            "Epoch 756/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.5027 - val_loss: 0.3490 - val_accuracy: 0.4960\n",
            "Epoch 757/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3840 - accuracy: 0.5027 - val_loss: 0.3489 - val_accuracy: 0.4960\n",
            "Epoch 758/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3840 - accuracy: 0.5027 - val_loss: 0.3488 - val_accuracy: 0.4960\n",
            "Epoch 759/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.5027 - val_loss: 0.3487 - val_accuracy: 0.4960\n",
            "Epoch 760/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.5027 - val_loss: 0.3486 - val_accuracy: 0.4960\n",
            "Epoch 761/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.5027 - val_loss: 0.3485 - val_accuracy: 0.4960\n",
            "Epoch 762/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.5027 - val_loss: 0.3485 - val_accuracy: 0.4960\n",
            "Epoch 763/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3899 - accuracy: 0.5027 - val_loss: 0.3485 - val_accuracy: 0.4960\n",
            "Epoch 764/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3871 - accuracy: 0.5027 - val_loss: 0.3488 - val_accuracy: 0.4960\n",
            "Epoch 765/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3798 - accuracy: 0.5027 - val_loss: 0.3486 - val_accuracy: 0.4960\n",
            "Epoch 766/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3874 - accuracy: 0.5027 - val_loss: 0.3488 - val_accuracy: 0.4960\n",
            "Epoch 767/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.5027 - val_loss: 0.3486 - val_accuracy: 0.4960\n",
            "Epoch 768/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.5027 - val_loss: 0.3486 - val_accuracy: 0.4960\n",
            "Epoch 769/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.5027 - val_loss: 0.3485 - val_accuracy: 0.4960\n",
            "Epoch 770/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3803 - accuracy: 0.5027 - val_loss: 0.3485 - val_accuracy: 0.4960\n",
            "Epoch 771/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.5027 - val_loss: 0.3486 - val_accuracy: 0.4960\n",
            "Epoch 772/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3829 - accuracy: 0.5027 - val_loss: 0.3485 - val_accuracy: 0.4960\n",
            "Epoch 773/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3877 - accuracy: 0.5027 - val_loss: 0.3485 - val_accuracy: 0.4960\n",
            "Epoch 774/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 775/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 776/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 777/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.5027 - val_loss: 0.3484 - val_accuracy: 0.4960\n",
            "Epoch 778/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 779/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3794 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 780/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.5027 - val_loss: 0.3485 - val_accuracy: 0.4960\n",
            "Epoch 781/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 782/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3915 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 783/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.5027 - val_loss: 0.3484 - val_accuracy: 0.4960\n",
            "Epoch 784/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3821 - accuracy: 0.5027 - val_loss: 0.3485 - val_accuracy: 0.4960\n",
            "Epoch 785/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.5027 - val_loss: 0.3485 - val_accuracy: 0.4960\n",
            "Epoch 786/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3870 - accuracy: 0.5027 - val_loss: 0.3484 - val_accuracy: 0.4960\n",
            "Epoch 787/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.5027 - val_loss: 0.3485 - val_accuracy: 0.4960\n",
            "Epoch 788/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3869 - accuracy: 0.5027 - val_loss: 0.3489 - val_accuracy: 0.4960\n",
            "Epoch 789/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.5027 - val_loss: 0.3488 - val_accuracy: 0.4960\n",
            "Epoch 790/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.5027 - val_loss: 0.3487 - val_accuracy: 0.4960\n",
            "Epoch 791/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3911 - accuracy: 0.5027 - val_loss: 0.3487 - val_accuracy: 0.4960\n",
            "Epoch 792/2000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.3945 - accuracy: 0.5027 - val_loss: 0.3486 - val_accuracy: 0.4960\n",
            "Epoch 793/2000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.3859 - accuracy: 0.5027 - val_loss: 0.3484 - val_accuracy: 0.4960\n",
            "Epoch 794/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 795/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 796/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3897 - accuracy: 0.5027 - val_loss: 0.3487 - val_accuracy: 0.4960\n",
            "Epoch 797/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3843 - accuracy: 0.5027 - val_loss: 0.3487 - val_accuracy: 0.4960\n",
            "Epoch 798/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3850 - accuracy: 0.5027 - val_loss: 0.3486 - val_accuracy: 0.4960\n",
            "Epoch 799/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3900 - accuracy: 0.5027 - val_loss: 0.3486 - val_accuracy: 0.4960\n",
            "Epoch 800/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.5027 - val_loss: 0.3485 - val_accuracy: 0.4960\n",
            "Epoch 801/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.5027 - val_loss: 0.3486 - val_accuracy: 0.4960\n",
            "Epoch 802/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.5027 - val_loss: 0.3485 - val_accuracy: 0.4960\n",
            "Epoch 803/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 804/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.5027 - val_loss: 0.3484 - val_accuracy: 0.4960\n",
            "Epoch 805/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 806/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.5027 - val_loss: 0.3486 - val_accuracy: 0.4960\n",
            "Epoch 807/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.5027 - val_loss: 0.3485 - val_accuracy: 0.4960\n",
            "Epoch 808/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.5027 - val_loss: 0.3486 - val_accuracy: 0.4960\n",
            "Epoch 809/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3900 - accuracy: 0.5027 - val_loss: 0.3484 - val_accuracy: 0.4960\n",
            "Epoch 810/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3882 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 811/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 812/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 813/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 814/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 815/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.5027 - val_loss: 0.3484 - val_accuracy: 0.4960\n",
            "Epoch 816/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3864 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 817/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3882 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 818/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3834 - accuracy: 0.5027 - val_loss: 0.3484 - val_accuracy: 0.4960\n",
            "Epoch 819/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 820/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 821/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3901 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 822/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 823/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 824/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 825/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3874 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 826/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3832 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 827/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 828/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 829/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 830/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 831/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 832/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 833/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 834/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 835/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 836/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 837/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 838/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 839/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 840/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 841/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 842/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 843/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3849 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 844/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3874 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 845/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 846/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 847/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3879 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 848/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3829 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 849/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 850/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 851/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 852/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 853/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 854/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 855/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 856/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 857/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 858/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.5027 - val_loss: 0.3484 - val_accuracy: 0.4960\n",
            "Epoch 859/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 860/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 861/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3832 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 862/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 863/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.5027 - val_loss: 0.3484 - val_accuracy: 0.4960\n",
            "Epoch 864/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3838 - accuracy: 0.5027 - val_loss: 0.3484 - val_accuracy: 0.4960\n",
            "Epoch 865/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3820 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 866/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 867/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3880 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 868/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3825 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 869/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3859 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 870/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3796 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 871/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 872/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 873/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3811 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 874/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3749 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 875/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3864 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 876/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3793 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 877/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3809 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 878/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3794 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 879/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3796 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 880/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3785 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 881/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3829 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 882/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3795 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 883/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3823 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 884/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3804 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 885/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3769 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 886/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3843 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 887/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3780 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 888/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3894 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 889/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3781 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 890/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3781 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 891/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3806 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 892/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3815 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 893/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3834 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 894/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3815 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 895/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3879 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 896/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 897/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 898/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3880 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 899/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 900/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 901/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 902/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3826 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 903/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3784 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 904/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 905/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 906/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 907/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 908/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 909/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.5027 - val_loss: 0.3484 - val_accuracy: 0.4960\n",
            "Epoch 910/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 911/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 912/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3877 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 913/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 914/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 915/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 916/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 917/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3813 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 918/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.5027 - val_loss: 0.3484 - val_accuracy: 0.4960\n",
            "Epoch 919/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 920/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3822 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 921/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 922/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 923/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 924/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 925/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3837 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 926/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 927/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 928/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 929/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 930/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 931/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 932/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 933/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3789 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 934/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 935/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 936/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3769 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 937/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 938/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3798 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 939/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 940/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3820 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 941/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3788 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 942/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 943/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 944/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 945/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3891 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 946/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3839 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 947/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3758 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 948/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3920 - accuracy: 0.5027 - val_loss: 0.3484 - val_accuracy: 0.4960\n",
            "Epoch 949/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3825 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 950/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 951/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3826 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 952/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 953/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3818 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 954/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3862 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 955/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 956/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 957/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 958/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3882 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 959/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 960/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 961/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 962/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 963/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3827 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 964/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 965/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 966/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 967/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3832 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 968/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 969/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 970/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 971/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 972/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 973/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 974/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 975/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3831 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 976/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 977/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 978/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3821 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 979/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3782 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 980/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3834 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 981/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 982/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3869 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 983/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3752 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 984/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 985/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3801 - accuracy: 0.5027 - val_loss: 0.3486 - val_accuracy: 0.4960\n",
            "Epoch 986/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3854 - accuracy: 0.5027 - val_loss: 0.3485 - val_accuracy: 0.4960\n",
            "Epoch 987/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 988/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3837 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 989/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 990/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 991/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 992/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3818 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 993/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3793 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 994/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 995/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 996/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3873 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 997/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.5027 - val_loss: 0.3484 - val_accuracy: 0.4960\n",
            "Epoch 998/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3809 - accuracy: 0.5027 - val_loss: 0.3483 - val_accuracy: 0.4960\n",
            "Epoch 999/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 1000/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1001/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 1002/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 1003/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1004/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 1005/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 1006/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 1007/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1008/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3760 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 1009/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3817 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 1010/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1011/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1012/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3861 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 1013/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3790 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 1014/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.5027 - val_loss: 0.3482 - val_accuracy: 0.4960\n",
            "Epoch 1015/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 1016/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1017/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1018/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1019/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1020/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3800 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1021/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3820 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1022/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3753 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1023/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3811 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1024/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3849 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1025/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1026/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3791 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1027/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3807 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1028/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3805 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1029/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3798 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1030/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3802 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1031/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3809 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1032/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1033/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3757 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 1034/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3711 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1035/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1036/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3766 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1037/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3742 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1038/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3848 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1039/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3782 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1040/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3829 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1041/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3871 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1042/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3740 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1043/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3889 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1044/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3785 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1045/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3893 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1046/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3839 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1047/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3903 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1048/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1049/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1050/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1051/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3820 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1052/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1053/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1054/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3846 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1055/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3818 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1056/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1057/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1058/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1059/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1060/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1061/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3789 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1062/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1063/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1064/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3868 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1065/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3762 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1066/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3813 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1067/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3769 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1068/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1069/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1070/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1071/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1072/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3794 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1073/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3798 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1074/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1075/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1076/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1077/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3829 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1078/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1079/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1080/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3733 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1081/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1082/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3697 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1083/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3773 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1084/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3861 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1085/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3785 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1086/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3847 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1087/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1088/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3768 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1089/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3832 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1090/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1091/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1092/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1093/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1094/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1095/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3801 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1096/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1097/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3809 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1098/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1099/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1100/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1101/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1102/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1103/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3784 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1104/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1105/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3871 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1106/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1107/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1108/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1109/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1110/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3782 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1111/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1112/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1113/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3833 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1114/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1115/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1116/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3811 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1117/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1118/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1119/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3778 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1120/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3804 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1121/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3831 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1122/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3801 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1123/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1124/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1125/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3797 - accuracy: 0.5027 - val_loss: 0.3469 - val_accuracy: 0.4960\n",
            "Epoch 1126/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3840 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1127/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3810 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1128/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1129/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3857 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1130/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3784 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1131/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3839 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1132/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3801 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1133/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3834 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1134/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3812 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1135/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3779 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1136/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1137/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1138/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3839 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1139/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1140/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3782 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1141/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3828 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1142/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1143/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1144/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1145/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1146/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3816 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1147/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1148/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1149/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3815 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1150/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3735 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1151/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1152/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3753 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1153/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1154/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3825 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1155/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1156/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3831 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1157/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1158/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3837 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1159/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3821 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1160/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3769 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1161/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3738 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1162/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1163/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1164/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1165/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3820 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1166/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3778 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1167/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1168/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3771 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1169/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3774 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1170/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3822 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1171/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3802 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1172/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3874 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1173/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3810 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1174/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3866 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1175/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3806 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1176/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3766 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1177/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3762 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1178/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3818 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1179/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3785 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1180/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3863 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1181/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3784 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1182/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3751 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1183/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3837 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1184/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3873 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1185/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3707 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1186/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3784 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1187/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3849 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1188/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3752 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1189/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3853 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1190/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3829 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1191/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3778 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1192/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3819 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1193/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3783 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1194/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3838 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1195/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3828 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1196/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1197/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1198/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3819 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1199/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3751 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1200/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1201/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1202/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1203/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3780 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1204/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1205/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1206/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1207/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1208/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1209/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3795 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1210/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3815 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1211/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1212/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3764 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1213/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3874 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1214/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1215/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1216/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1217/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1218/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1219/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1220/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1221/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3834 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1222/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3817 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1223/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1224/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1225/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3829 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1226/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3742 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1227/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1228/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1229/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3808 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1230/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1231/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1232/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3817 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1233/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 1234/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3743 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1235/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1236/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1237/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3788 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1238/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1239/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3831 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1240/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1241/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1242/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1243/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1244/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1245/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1246/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1247/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3838 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1248/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1249/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1250/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1251/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3768 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1252/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3706 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1253/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1254/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3774 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1255/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1256/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3830 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1257/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3872 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1258/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1259/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1260/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1261/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3784 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1262/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1263/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3799 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1264/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1265/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1266/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1267/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3790 - accuracy: 0.5027 - val_loss: 0.3469 - val_accuracy: 0.4960\n",
            "Epoch 1268/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.5027 - val_loss: 0.3467 - val_accuracy: 0.4960\n",
            "Epoch 1269/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3740 - accuracy: 0.5027 - val_loss: 0.3468 - val_accuracy: 0.4960\n",
            "Epoch 1270/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1271/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3749 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1272/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1273/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1274/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1275/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3818 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1276/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3771 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1277/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1278/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3875 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1279/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1280/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3802 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1281/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1282/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1283/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1284/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1285/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3768 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1286/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3759 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1287/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1288/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3882 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1289/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3777 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1290/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3794 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1291/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3835 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1292/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3768 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1293/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1294/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1295/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1296/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1297/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1298/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3785 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1299/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3731 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1300/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1301/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3811 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1302/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3839 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1303/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.5027 - val_loss: 0.3469 - val_accuracy: 0.4960\n",
            "Epoch 1304/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.5027 - val_loss: 0.3469 - val_accuracy: 0.4960\n",
            "Epoch 1305/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1306/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1307/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3826 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1308/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3859 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1309/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3794 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1310/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1311/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1312/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1313/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1314/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3758 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1315/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3768 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1316/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3842 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1317/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3793 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1318/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1319/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1320/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3790 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1321/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3835 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1322/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3781 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1323/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3756 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1324/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1325/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3904 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1326/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3786 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1327/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3761 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1328/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1329/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3736 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1330/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1331/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3809 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1332/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1333/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3792 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1334/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3777 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1335/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3787 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1336/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3845 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1337/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3786 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1338/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3829 - accuracy: 0.5027 - val_loss: 0.3469 - val_accuracy: 0.4960\n",
            "Epoch 1339/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3788 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1340/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3768 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1341/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3757 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1342/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3825 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1343/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3847 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1344/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3743 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1345/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3804 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1346/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3763 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1347/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3734 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1348/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1349/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3724 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1350/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1351/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3785 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1352/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3843 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1353/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1354/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3804 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1355/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1356/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.5027 - val_loss: 0.3469 - val_accuracy: 0.4960\n",
            "Epoch 1357/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1358/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3856 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1359/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1360/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1361/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1362/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1363/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1364/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1365/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3777 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1366/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1367/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3749 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1368/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1369/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1370/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3836 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1371/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1372/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1373/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1374/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1375/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1376/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1377/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 1378/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3752 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1379/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1380/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1381/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1382/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1383/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3734 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1384/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1385/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1386/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1387/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3776 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 1388/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3777 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1389/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3823 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1390/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1391/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3813 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1392/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1393/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1394/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1395/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1396/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1397/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1398/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3826 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1399/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3773 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1400/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3769 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1401/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1402/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1403/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3852 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1404/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1405/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1406/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1407/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1408/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1409/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3825 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1410/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 1411/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3724 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1412/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3777 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1413/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1414/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3769 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1415/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1416/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1417/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1418/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3755 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1419/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1420/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3732 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1421/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1422/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3821 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1423/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1424/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3797 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1425/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1426/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1427/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3823 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1428/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1429/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3832 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1430/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1431/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1432/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 1433/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3708 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1434/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1435/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3760 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1436/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1437/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3725 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1438/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1439/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3790 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1440/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3805 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1441/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3766 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1442/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3828 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1443/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 1444/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1445/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3801 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1446/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3797 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1447/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1448/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 1449/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3734 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 1450/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1451/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3760 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1452/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 1453/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1454/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1455/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1456/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1457/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1458/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1459/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3801 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1460/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1461/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1462/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3783 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 1463/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3730 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 1464/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 1465/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3774 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 1466/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3745 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 1467/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3768 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 1468/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1469/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1470/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3741 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1471/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1472/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1473/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3768 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1474/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3730 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1475/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3780 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1476/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3814 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1477/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3799 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1478/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3804 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1479/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3753 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1480/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3829 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 1481/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3861 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 1482/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3838 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 1483/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3786 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1484/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3746 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1485/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3730 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1486/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3810 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1487/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1488/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3749 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1489/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3768 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1490/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3731 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1491/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1492/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3776 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1493/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1494/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3802 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1495/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3774 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1496/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3908 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1497/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3747 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1498/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3770 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1499/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3775 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1500/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1501/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3743 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1502/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1503/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3830 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1504/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3761 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1505/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1506/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1507/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3744 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1508/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1509/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1510/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1511/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1512/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3813 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1513/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1514/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3765 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1515/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3819 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1516/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3783 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1517/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1518/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3760 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1519/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1520/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1521/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3829 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1522/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3806 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1523/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3793 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1524/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1525/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1526/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3776 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1527/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1528/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1529/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1530/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3711 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1531/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3795 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1532/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1533/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1534/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1535/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3788 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1536/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3790 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1537/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1538/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3781 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1539/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1540/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1541/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1542/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1543/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3835 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1544/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3732 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1545/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3812 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1546/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1547/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1548/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3803 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1549/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3861 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1550/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1551/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1552/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3761 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1553/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1554/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1555/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1556/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3788 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1557/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3801 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1558/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1559/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3781 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1560/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1561/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 1562/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3776 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1563/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1564/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1565/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1566/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1567/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3818 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1568/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3823 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1569/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1570/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1571/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3831 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1572/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1573/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1574/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3843 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1575/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1576/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3789 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1577/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1578/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1579/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3768 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1580/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3777 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1581/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1582/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1583/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1584/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3867 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1585/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1586/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1587/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1588/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1589/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3805 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1590/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1591/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1592/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1593/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3783 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1594/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3784 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1595/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3796 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1596/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3761 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1597/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1598/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1599/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1600/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3850 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1601/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3824 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1602/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3836 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1603/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3801 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1604/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3797 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1605/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1606/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1607/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1608/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1609/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3723 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1610/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3850 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1611/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1612/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3783 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1613/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3763 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1614/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3725 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1615/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1616/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1617/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3772 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1618/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3752 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1619/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3811 - accuracy: 0.5027 - val_loss: 0.3469 - val_accuracy: 0.4960\n",
            "Epoch 1620/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1621/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1622/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1623/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1624/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3764 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1625/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1626/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1627/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3741 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1628/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1629/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3766 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1630/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3794 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1631/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3786 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1632/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3803 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1633/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3758 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1634/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3784 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1635/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3768 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1636/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3744 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1637/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3793 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1638/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3762 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1639/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3808 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1640/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3765 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1641/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3725 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1642/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3813 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1643/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3743 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1644/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1645/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3773 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1646/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3745 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1647/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3817 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1648/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3794 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1649/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3743 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1650/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3741 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1651/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1652/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3759 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1653/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3758 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1654/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3835 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1655/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3814 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1656/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3771 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1657/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1658/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3759 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1659/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3815 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1660/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1661/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1662/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1663/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1664/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1665/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3854 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1666/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3817 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1667/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1668/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1669/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1670/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1671/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1672/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1673/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1674/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1675/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1676/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3766 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1677/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1678/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3659 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1679/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3799 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1680/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3768 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1681/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3750 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1682/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3774 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1683/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1684/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1685/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3753 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1686/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1687/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1688/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1689/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1690/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3771 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 1691/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3737 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1692/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1693/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3762 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1694/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1695/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1696/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1697/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1698/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1699/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1700/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3831 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1701/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3680 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1702/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1703/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1704/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3837 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1705/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1706/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1707/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1708/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1709/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1710/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 1711/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1712/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1713/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1714/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3802 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1715/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3789 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1716/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1717/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3710 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1718/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.5027 - val_loss: 0.3481 - val_accuracy: 0.4960\n",
            "Epoch 1719/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3785 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1720/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.5027 - val_loss: 0.3480 - val_accuracy: 0.4960\n",
            "Epoch 1721/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1722/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3756 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1723/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1724/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1725/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3846 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1726/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1727/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1728/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1729/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1730/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1731/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1732/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1733/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1734/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1735/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3797 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1736/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3781 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1737/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3718 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1738/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3729 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1739/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1740/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3808 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1741/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1742/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1743/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1744/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1745/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3760 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1746/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3794 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1747/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1748/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1749/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1750/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1751/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1752/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1753/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3793 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1754/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1755/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1756/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.5027 - val_loss: 0.3479 - val_accuracy: 0.4960\n",
            "Epoch 1757/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3845 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1758/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1759/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3821 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1760/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3795 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1761/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3829 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1762/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1763/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1764/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3830 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1765/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1766/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1767/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1768/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3762 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1769/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1770/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1771/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3771 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1772/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3814 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1773/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1774/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1775/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1776/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3803 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1777/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1778/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1779/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1780/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1781/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3714 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1782/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1783/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1784/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1785/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3730 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1786/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3750 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1787/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3772 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1788/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3682 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1789/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3755 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1790/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3826 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1791/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3824 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1792/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3773 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1793/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3791 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1794/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3777 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1795/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3848 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1796/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3770 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1797/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3783 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1798/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3730 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1799/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3789 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1800/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3770 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1801/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3802 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1802/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3804 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1803/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3751 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1804/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3831 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1805/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3707 - accuracy: 0.5027 - val_loss: 0.3478 - val_accuracy: 0.4960\n",
            "Epoch 1806/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3735 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1807/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3770 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1808/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1809/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3805 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1810/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3793 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1811/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3812 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1812/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3847 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1813/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1814/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3766 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1815/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3835 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1816/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3747 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1817/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3774 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1818/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1819/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1820/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3798 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1821/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1822/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1823/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1824/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3695 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1825/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1826/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1827/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1828/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1829/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3762 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1830/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1831/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1832/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1833/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1834/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1835/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1836/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1837/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1838/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1839/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3766 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1840/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1841/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1842/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1843/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1844/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3773 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1845/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3818 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1846/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1847/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3741 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1848/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1849/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1850/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3776 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1851/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1852/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3733 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1853/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3834 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1854/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1855/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1856/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1857/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1858/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1859/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3707 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1860/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1861/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3777 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1862/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3755 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1863/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3783 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1864/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1865/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3724 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1866/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1867/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3709 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1868/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3857 - accuracy: 0.5027 - val_loss: 0.3469 - val_accuracy: 0.4960\n",
            "Epoch 1869/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1870/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1871/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1872/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1873/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1874/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1875/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1876/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3762 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1877/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3805 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1878/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3695 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1879/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1880/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3834 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1881/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1882/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1883/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3733 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1884/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3717 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1885/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1886/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1887/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1888/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1889/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3810 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1890/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1891/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1892/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1893/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1894/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1895/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1896/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1897/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1898/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1899/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1900/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1901/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1902/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3789 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1903/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3748 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1904/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1905/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1906/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1907/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3774 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1908/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3714 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1909/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1910/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3761 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1911/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1912/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1913/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3745 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1914/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1915/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3764 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1916/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3750 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1917/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3751 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1918/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1919/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1920/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1921/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1922/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3714 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1923/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3757 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1924/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3845 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1925/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1926/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1927/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3748 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1928/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3793 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1929/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1930/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1931/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3805 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1932/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3792 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1933/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1934/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3730 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1935/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3794 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1936/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3741 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1937/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3714 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1938/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3800 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1939/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1940/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3783 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1941/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3784 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1942/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3817 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1943/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3736 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1944/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3730 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1945/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3872 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1946/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3694 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1947/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3791 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1948/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3754 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1949/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3724 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1950/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3735 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1951/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3766 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1952/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3753 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1953/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3802 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1954/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3838 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1955/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3731 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1956/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3802 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1957/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3780 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1958/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3804 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1959/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3738 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1960/2000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3778 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1961/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3785 - accuracy: 0.5027 - val_loss: 0.3469 - val_accuracy: 0.4960\n",
            "Epoch 1962/2000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3809 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1963/2000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3756 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1964/2000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3761 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1965/2000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3742 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1966/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3784 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1967/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3752 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1968/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1969/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3826 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1970/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1971/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3825 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1972/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3803 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n",
            "Epoch 1973/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1974/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3788 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1975/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3785 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1976/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1977/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1978/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1979/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1980/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3836 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1981/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1982/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3755 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 1983/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3721 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1984/2000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3755 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1985/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3721 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1986/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.5027 - val_loss: 0.3472 - val_accuracy: 0.4960\n",
            "Epoch 1987/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.5027 - val_loss: 0.3473 - val_accuracy: 0.4960\n",
            "Epoch 1988/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3816 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1989/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1990/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1991/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1992/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1993/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.5027 - val_loss: 0.3476 - val_accuracy: 0.4960\n",
            "Epoch 1994/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.5027 - val_loss: 0.3477 - val_accuracy: 0.4960\n",
            "Epoch 1995/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3781 - accuracy: 0.5027 - val_loss: 0.3475 - val_accuracy: 0.4960\n",
            "Epoch 1996/2000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3717 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1997/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3871 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1998/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.5027 - val_loss: 0.3474 - val_accuracy: 0.4960\n",
            "Epoch 1999/2000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3730 - accuracy: 0.5027 - val_loss: 0.3471 - val_accuracy: 0.4960\n",
            "Epoch 2000/2000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.5027 - val_loss: 0.3470 - val_accuracy: 0.4960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = go.Scatter(y=his.history['loss'],\n",
        "                    mode=\"lines\",\n",
        "                    line=dict(\n",
        "                        width=2,\n",
        "                        color='blue'),\n",
        "                        name=\"loss\"\n",
        "                   )\n",
        "h2 = go.Scatter(y=his.history['val_loss'],\n",
        "                    mode=\"lines\",\n",
        "                    line=dict(\n",
        "                        width=2,\n",
        "                        color='red'),\n",
        "                        name=\"val_loss\"\n",
        "                   )\n",
        "\n",
        "data = [h1,h2]\n",
        "layout1 = go.Layout(title='Loss',\n",
        "                   xaxis=dict(title='epochs'),\n",
        "                   yaxis=dict(title=''))\n",
        "fig1 = go.Figure(data = data, layout=layout1)\n",
        "plotly.offline.iplot(fig1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "QeI1fDg8bdIz",
        "outputId": "559661fe-c3be-407a-a802-2cb623cf9509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"613ea522-b210-4183-be49-a688bc1922f7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"613ea522-b210-4183-be49-a688bc1922f7\")) {                    Plotly.newPlot(                        \"613ea522-b210-4183-be49-a688bc1922f7\",                        [{\"line\":{\"color\":\"blue\",\"width\":2},\"mode\":\"lines\",\"name\":\"loss\",\"y\":[0.7511744499206543,0.7022558450698853,0.7034189701080322,0.6986660361289978,0.6888707876205444,0.6922365427017212,0.6823328137397766,0.6811171770095825,0.67070072889328,0.669365406036377,0.6672477126121521,0.6559728384017944,0.6579984426498413,0.654090404510498,0.6514332890510559,0.6511102914810181,0.6471236944198608,0.6432613730430603,0.6383199691772461,0.6360788345336914,0.6364944577217102,0.6334046125411987,0.6338719129562378,0.6236783862113953,0.6306188702583313,0.6229508519172668,0.6203402280807495,0.620471179485321,0.6152138113975525,0.6142566800117493,0.6145778894424438,0.6071463823318481,0.609617292881012,0.6098299026489258,0.6011692881584167,0.6023930907249451,0.597180962562561,0.5969542860984802,0.5989875793457031,0.5942102074623108,0.5902136564254761,0.5899820327758789,0.5897905230522156,0.5884325504302979,0.585931658744812,0.5844938158988953,0.5775532126426697,0.576050877571106,0.5796551704406738,0.575104832649231,0.5770212411880493,0.5715040564537048,0.5715271234512329,0.5707406997680664,0.5660309791564941,0.566000759601593,0.5642617344856262,0.5655669569969177,0.5557424426078796,0.5577861070632935,0.5656413435935974,0.5531291365623474,0.5536815524101257,0.555538535118103,0.5554723143577576,0.5516316890716553,0.5479438900947571,0.549733579158783,0.5473300814628601,0.5447791218757629,0.5420316457748413,0.541454017162323,0.5388372540473938,0.5377287268638611,0.5361658930778503,0.5397817492485046,0.5338250398635864,0.5379894375801086,0.5356216430664062,0.5338855981826782,0.5348337888717651,0.5348949432373047,0.5275764465332031,0.5260746479034424,0.5287506580352783,0.5323011875152588,0.5305818915367126,0.5134751200675964,0.5215903520584106,0.5215998291969299,0.5214347839355469,0.5139186382293701,0.5164650678634644,0.5182258486747742,0.5166783928871155,0.5091795325279236,0.5117177367210388,0.5118494629859924,0.5074379444122314,0.5073015093803406,0.5032539963722229,0.5111783742904663,0.5025380253791809,0.5054031014442444,0.5025327801704407,0.5073482990264893,0.5013278126716614,0.5038204193115234,0.5019662380218506,0.4987238645553589,0.4992965757846832,0.49558165669441223,0.4899492561817169,0.49667659401893616,0.4940049648284912,0.4925665557384491,0.4834493398666382,0.4922585189342499,0.4922979772090912,0.4899272918701172,0.4922843873500824,0.4880870282649994,0.48436471819877625,0.4820178747177124,0.4883230924606323,0.48387444019317627,0.4877590835094452,0.47953954339027405,0.4835774004459381,0.47815266251564026,0.4849821925163269,0.48085135221481323,0.4800437092781067,0.47677716612815857,0.4802086055278778,0.47783714532852173,0.4780058264732361,0.47659122943878174,0.4728747606277466,0.4795067608356476,0.4715000092983246,0.4783102571964264,0.4677581787109375,0.4728716313838959,0.46578356623649597,0.4695671498775482,0.4716693162918091,0.46502095460891724,0.4727705419063568,0.46728068590164185,0.4627196490764618,0.4754714369773865,0.46344703435897827,0.4625476896762848,0.46788784861564636,0.4682971239089966,0.45985615253448486,0.4611511528491974,0.4619353115558624,0.45984598994255066,0.46251705288887024,0.453696072101593,0.46995988488197327,0.45579153299331665,0.46101823449134827,0.45333462953567505,0.4562276303768158,0.45731303095817566,0.44892746210098267,0.4539996385574341,0.457702100276947,0.46137234568595886,0.4506590962409973,0.4538949728012085,0.4545130729675293,0.45889222621917725,0.4461906850337982,0.4560968279838562,0.44961458444595337,0.44763749837875366,0.4446696639060974,0.446189820766449,0.44830065965652466,0.4501906633377075,0.4529699683189392,0.44169071316719055,0.4435437321662903,0.4458787739276886,0.44919082522392273,0.4412083029747009,0.4438280463218689,0.4476138949394226,0.4370861351490021,0.44045397639274597,0.44011440873146057,0.44772928953170776,0.4418289363384247,0.4494735598564148,0.4417056739330292,0.433497816324234,0.44130638241767883,0.43021833896636963,0.43490052223205566,0.44035035371780396,0.4394458830356598,0.439570814371109,0.43528956174850464,0.4395443797111511,0.4365445673465729,0.43657222390174866,0.4312001168727875,0.4330384433269501,0.4374195635318756,0.43750759959220886,0.4303489923477173,0.433163046836853,0.4351763427257538,0.4316319525241852,0.44115155935287476,0.4259394407272339,0.4262177348136902,0.42914333939552307,0.428246408700943,0.4263637959957123,0.4222196936607361,0.4247826337814331,0.42814600467681885,0.43529772758483887,0.4346752166748047,0.4257791042327881,0.4378013610839844,0.4334293603897095,0.4257388412952423,0.4243304431438446,0.42439696192741394,0.431282103061676,0.4216507077217102,0.41907793283462524,0.42435482144355774,0.4214605391025543,0.43477457761764526,0.4310140013694763,0.42766228318214417,0.42181411385536194,0.43286389112472534,0.41953402757644653,0.4264996647834778,0.42679712176322937,0.4314342737197876,0.42727869749069214,0.41961410641670227,0.4293936789035797,0.4272844195365906,0.4155302047729492,0.42266178131103516,0.4103127121925354,0.42076966166496277,0.4254060387611389,0.42246076464653015,0.4185482859611511,0.41701242327690125,0.42333751916885376,0.42016035318374634,0.4207668602466583,0.42757222056388855,0.42117902636528015,0.41449278593063354,0.4166889190673828,0.4248403012752533,0.4160420298576355,0.419983446598053,0.41760051250457764,0.42403629422187805,0.419766366481781,0.4213153123855591,0.41259628534317017,0.415989488363266,0.4143645763397217,0.42080220580101013,0.4207938313484192,0.4170987606048584,0.4141821563243866,0.4217972755432129,0.41219648718833923,0.4169498383998871,0.42120105028152466,0.41797110438346863,0.4135361611843109,0.420035183429718,0.41703081130981445,0.4058164060115814,0.41919565200805664,0.40695899724960327,0.41422030329704285,0.41418778896331787,0.4143023192882538,0.42150652408599854,0.41258594393730164,0.4157976508140564,0.4171575903892517,0.4123581051826477,0.4177584648132324,0.4157538115978241,0.4180649518966675,0.405489057302475,0.41393303871154785,0.41008317470550537,0.4110223054885864,0.4114013612270355,0.4103793799877167,0.4164961874485016,0.4056476652622223,0.40815767645835876,0.41233476996421814,0.4122239947319031,0.40193742513656616,0.40908047556877136,0.4025161862373352,0.41311511397361755,0.4093243479728699,0.4119771718978882,0.4093210995197296,0.4174883961677551,0.41978898644447327,0.4100298583507538,0.40962499380111694,0.41603001952171326,0.4126417636871338,0.40596243739128113,0.41919466853141785,0.40970858931541443,0.40774837136268616,0.4027850031852722,0.40760111808776855,0.4081118106842041,0.41068699955940247,0.41465112566947937,0.4010259211063385,0.4058811068534851,0.4019799828529358,0.4073220491409302,0.3964352309703827,0.411921888589859,0.41280972957611084,0.4095633625984192,0.41694319248199463,0.41031786799430847,0.40916895866394043,0.40977489948272705,0.40665048360824585,0.4042327404022217,0.4155905246734619,0.3999883532524109,0.3995944857597351,0.40662315487861633,0.4098396301269531,0.4021013677120209,0.4114000201225281,0.40046387910842896,0.40797320008277893,0.3928076922893524,0.4060233533382416,0.39706045389175415,0.4103473722934723,0.40161314606666565,0.398247629404068,0.4040270149707794,0.3984571397304535,0.4009508490562439,0.41218921542167664,0.4015520513057709,0.4111689329147339,0.4071716368198395,0.40272822976112366,0.41232824325561523,0.40474918484687805,0.40009310841560364,0.4022732377052307,0.4058147072792053,0.3938470184803009,0.4064265191555023,0.4118586480617523,0.4002140164375305,0.40181323885917664,0.4088049829006195,0.39850351214408875,0.4017026722431183,0.4093991219997406,0.4005368649959564,0.4027349352836609,0.4052619934082031,0.4037303924560547,0.39667391777038574,0.4005873203277588,0.398149698972702,0.40812981128692627,0.41153842210769653,0.40184441208839417,0.40692615509033203,0.40457695722579956,0.3970673084259033,0.40088361501693726,0.4058215320110321,0.4026070237159729,0.40554431080818176,0.4115805923938751,0.4028087854385376,0.40479806065559387,0.40031903982162476,0.40183377265930176,0.4007703363895416,0.3923470377922058,0.3960055708885193,0.40197890996932983,0.4044249951839447,0.4009391665458679,0.39482808113098145,0.4049755930900574,0.39807620644569397,0.4056052565574646,0.39985665678977966,0.3930870294570923,0.39031288027763367,0.3973456919193268,0.39455729722976685,0.3941449522972107,0.40667426586151123,0.39953669905662537,0.40299805998802185,0.4026142656803131,0.4075925350189209,0.40295565128326416,0.4038842022418976,0.40085774660110474,0.3955720067024231,0.3963724672794342,0.4028933644294739,0.3946231007575989,0.39470890164375305,0.4013744592666626,0.4014163911342621,0.4021929204463959,0.4007522463798523,0.3911066949367523,0.393618643283844,0.4055117070674896,0.39576706290245056,0.39829546213150024,0.39666882157325745,0.39765191078186035,0.39592456817626953,0.39994409680366516,0.40284207463264465,0.40032991766929626,0.39798495173454285,0.39589130878448486,0.4012203514575958,0.39200422167778015,0.3970547318458557,0.4102347791194916,0.40151384472846985,0.39303889870643616,0.39496052265167236,0.3950788676738739,0.39749160408973694,0.39801567792892456,0.40615174174308777,0.39740389585494995,0.3939250111579895,0.3832606077194214,0.3987950086593628,0.3921279311180115,0.39908289909362793,0.40523141622543335,0.4017218053340912,0.39307868480682373,0.4033770263195038,0.3951341211795807,0.4053977131843567,0.3932761251926422,0.4018716514110565,0.38916340470314026,0.3971629738807678,0.3974674344062805,0.3961067199707031,0.3921639025211334,0.3913276493549347,0.3980652987957001,0.39213284850120544,0.3986451029777527,0.39335814118385315,0.3969990611076355,0.3952558636665344,0.3928082585334778,0.400277316570282,0.38907596468925476,0.3964281678199768,0.38825497031211853,0.3948397934436798,0.3993377387523651,0.3902840316295624,0.38221150636672974,0.39345112442970276,0.392428457736969,0.38461267948150635,0.391730397939682,0.39655038714408875,0.3973281979560852,0.39055803418159485,0.39624840021133423,0.3909819722175598,0.387751966714859,0.4018232524394989,0.40236547589302063,0.3987298309803009,0.4022100567817688,0.4025713801383972,0.3955281972885132,0.4016369581222534,0.3928696811199188,0.39826545119285583,0.4067156910896301,0.3938850462436676,0.39489203691482544,0.396797776222229,0.39225438237190247,0.3999842405319214,0.3907068371772766,0.39264431595802307,0.38412734866142273,0.39137065410614014,0.38826003670692444,0.3942587077617645,0.393917977809906,0.391797810792923,0.3895103633403778,0.3912935256958008,0.39009517431259155,0.3907957077026367,0.39789676666259766,0.3870733380317688,0.38880106806755066,0.3938889503479004,0.3883548676967621,0.3934841454029083,0.3994237780570984,0.3919496238231659,0.38947269320487976,0.39139699935913086,0.3912147581577301,0.3974083960056305,0.38626429438591003,0.3951514959335327,0.40016305446624756,0.38959217071533203,0.3861716389656067,0.39791181683540344,0.3890022933483124,0.3927888870239258,0.39628085494041443,0.3900527358055115,0.389137327671051,0.39449039101600647,0.39367732405662537,0.3837323784828186,0.38227567076683044,0.3907817304134369,0.38793355226516724,0.3879961371421814,0.39017561078071594,0.3862510025501251,0.3882972002029419,0.3913417160511017,0.39661404490470886,0.3894515037536621,0.3935184180736542,0.3897092342376709,0.3915969729423523,0.392569363117218,0.3909095823764801,0.39128679037094116,0.38896167278289795,0.38895732164382935,0.4019930958747864,0.38960132002830505,0.39676207304000854,0.3910592496395111,0.3944350481033325,0.39386865496635437,0.3882933259010315,0.39623942971229553,0.394679456949234,0.3954252004623413,0.3969511389732361,0.3979659080505371,0.3998117744922638,0.386730432510376,0.39602407813072205,0.3916269540786743,0.39214032888412476,0.3883419632911682,0.39750128984451294,0.39534255862236023,0.3881804645061493,0.3904006779193878,0.3945750594139099,0.40052348375320435,0.3954128324985504,0.38462764024734497,0.3922583758831024,0.3867324888706207,0.3903394639492035,0.3864104151725769,0.39206477999687195,0.3870309293270111,0.39040109515190125,0.386732816696167,0.38539817929267883,0.3882133662700653,0.3870803713798523,0.38961702585220337,0.390214204788208,0.39601457118988037,0.38808703422546387,0.3892782926559448,0.3894156217575073,0.3929262161254883,0.38663288950920105,0.3901509642601013,0.3862324357032776,0.3927253782749176,0.39206787943840027,0.3888874053955078,0.3860987424850464,0.3804473876953125,0.387754887342453,0.39297229051589966,0.39207494258880615,0.38691478967666626,0.3951844573020935,0.38794225454330444,0.3877033293247223,0.3930463492870331,0.3844541311264038,0.388985276222229,0.38949766755104065,0.381023108959198,0.383827805519104,0.38591551780700684,0.38317930698394775,0.39302507042884827,0.38484734296798706,0.3929412066936493,0.3962656259536743,0.38612836599349976,0.3908131420612335,0.38402193784713745,0.3903234601020813,0.3894789218902588,0.39133429527282715,0.39130091667175293,0.3915930986404419,0.3909609019756317,0.3967568874359131,0.3948781192302704,0.3838544487953186,0.3792046010494232,0.38938605785369873,0.3820684850215912,0.392437219619751,0.3978508710861206,0.386588454246521,0.3903006315231323,0.3850233554840088,0.3930729925632477,0.39699438214302063,0.38143229484558105,0.39091214537620544,0.3928384482860565,0.38125669956207275,0.39221659302711487,0.3956226408481598,0.38633036613464355,0.3855817914009094,0.388670414686203,0.3934248387813568,0.3861819803714752,0.38961100578308105,0.3916914165019989,0.3870700001716614,0.39173534512519836,0.3824343979358673,0.3885139524936676,0.3870540261268616,0.3843728303909302,0.3921853303909302,0.38527530431747437,0.3943215608596802,0.38865572214126587,0.3928084671497345,0.39370906352996826,0.377737432718277,0.3893972933292389,0.3849465250968933,0.38282352685928345,0.3827880322933197,0.38845714926719666,0.38276880979537964,0.38054540753364563,0.387919157743454,0.3892087936401367,0.38679027557373047,0.3850474953651428,0.3775428533554077,0.3881969749927521,0.38241589069366455,0.3864194452762604,0.3842509090900421,0.37850046157836914,0.39127007126808167,0.38562914729118347,0.3860750198364258,0.3927382528781891,0.3846343159675598,0.3853309452533722,0.3915784955024719,0.38635966181755066,0.3841266334056854,0.38004371523857117,0.3949218690395355,0.38186508417129517,0.3898596465587616,0.38429513573646545,0.39214685559272766,0.382714182138443,0.3836304247379303,0.3785880208015442,0.3897705376148224,0.38990965485572815,0.38636913895606995,0.3815482258796692,0.3871507942676544,0.3831576704978943,0.3826749324798584,0.3854162096977234,0.3786763846874237,0.3914051055908203,0.3849155306816101,0.3861022889614105,0.38314953446388245,0.3867236375808716,0.38529181480407715,0.3809511363506317,0.38997945189476013,0.3909347355365753,0.39370036125183105,0.38398829102516174,0.3840140700340271,0.3854726254940033,0.3847595751285553,0.3821346163749695,0.38274767994880676,0.3899267315864563,0.3870544731616974,0.3798108696937561,0.3874390423297882,0.3860439360141754,0.37962833046913147,0.3863770067691803,0.38029745221138,0.3843085467815399,0.38285917043685913,0.38768431544303894,0.3925018012523651,0.3844662606716156,0.3902934491634369,0.38135865330696106,0.39041057229042053,0.3794044554233551,0.38626688718795776,0.38084715604782104,0.39147982001304626,0.3798985183238983,0.38210389018058777,0.3855321407318115,0.3870450556278229,0.38625428080558777,0.38687828183174133,0.3813755214214325,0.3928171694278717,0.39114144444465637,0.3945430517196655,0.3858654797077179,0.3852883279323578,0.3811682164669037,0.3897213935852051,0.3843183219432831,0.3850218653678894,0.3899565041065216,0.3842410445213318,0.38281309604644775,0.3847002387046814,0.3853035569190979,0.3870459794998169,0.3862224221229553,0.38857412338256836,0.38578832149505615,0.3891511559486389,0.38997265696525574,0.3881979286670685,0.38520410656929016,0.3854953646659851,0.3946778476238251,0.3840506076812744,0.378279447555542,0.3863949477672577,0.3881712555885315,0.38340267539024353,0.38468196988105774,0.38953304290771484,0.39010319113731384,0.3779144585132599,0.38709011673927307,0.38601741194725037,0.38742518424987793,0.3831818401813507,0.3850773572921753,0.3877905309200287,0.38978877663612366,0.38474446535110474,0.3792847990989685,0.3843359649181366,0.38647592067718506,0.3811327815055847,0.38965970277786255,0.3828205466270447,0.38505205512046814,0.3907378017902374,0.3800319731235504,0.3847804069519043,0.38456255197525024,0.3820270895957947,0.3848689794540405,0.3874269127845764,0.386292040348053,0.3833487927913666,0.3879105746746063,0.3828883469104767,0.3837321698665619,0.3786945044994354,0.37274429202079773,0.3850973844528198,0.38444897532463074,0.38562431931495667,0.3863469362258911,0.3878788650035858,0.3846283257007599,0.38663333654403687,0.3856613039970398,0.3817422389984131,0.38317662477493286,0.3790877163410187,0.3879917860031128,0.3837606906890869,0.3819853663444519,0.39365071058273315,0.38799649477005005,0.38253575563430786,0.38588422536849976,0.37957873940467834,0.37580057978630066,0.38530704379081726,0.3810749053955078,0.3748997747898102,0.38641348481178284,0.3793000876903534,0.3808790147304535,0.3793611228466034,0.3795943558216095,0.3785112798213959,0.3828849792480469,0.37947261333465576,0.3822680711746216,0.38039636611938477,0.3769111633300781,0.38426533341407776,0.3779967427253723,0.3893508315086365,0.37808123230934143,0.3781158924102783,0.3805680274963379,0.3815048336982727,0.38337481021881104,0.38152605295181274,0.3878723680973053,0.3850480914115906,0.3866153955459595,0.38796353340148926,0.38659968972206116,0.3823300004005432,0.3818759620189667,0.3826119899749756,0.3784143924713135,0.3915789723396301,0.37935757637023926,0.383318692445755,0.3796669542789459,0.37995991110801697,0.3850383162498474,0.38028720021247864,0.38514038920402527,0.38774335384368896,0.3795994818210602,0.37584471702575684,0.38934260606765747,0.3883218467235565,0.381326824426651,0.3815269470214844,0.37844717502593994,0.38224849104881287,0.37871378660202026,0.37756991386413574,0.37868252396583557,0.38405489921569824,0.3836851119995117,0.37926775217056274,0.3845987021923065,0.3784043490886688,0.3898222744464874,0.38357892632484436,0.37990275025367737,0.38071882724761963,0.3788817226886749,0.37780681252479553,0.37909504771232605,0.3769044578075409,0.3796848952770233,0.3797686696052551,0.3857137858867645,0.3820302188396454,0.37877824902534485,0.3815886974334717,0.39465469121932983,0.3809501528739929,0.3891492187976837,0.38387516140937805,0.3757598400115967,0.3919719159603119,0.3825060725212097,0.38155797123908997,0.38257327675819397,0.3842763304710388,0.3818184435367584,0.3861536979675293,0.38028913736343384,0.38421428203582764,0.38450106978416443,0.388191819190979,0.37616902589797974,0.3846684694290161,0.38409721851348877,0.3780680000782013,0.3827279806137085,0.3749971389770508,0.3851938545703888,0.3769584894180298,0.3831768035888672,0.38813790678977966,0.38067859411239624,0.3836396336555481,0.3852376341819763,0.37513792514801025,0.3816341459751129,0.3814952075481415,0.38312020897865295,0.3819933235645294,0.3828246593475342,0.38214734196662903,0.37815621495246887,0.383422315120697,0.3859982192516327,0.3869444727897644,0.37518802285194397,0.37642666697502136,0.3801289498806,0.38535305857658386,0.38188669085502625,0.38371866941452026,0.3812086582183838,0.38634562492370605,0.38422733545303345,0.3818039000034332,0.37933796644210815,0.3858133852481842,0.37660518288612366,0.3873153626918793,0.38074085116386414,0.3809061646461487,0.38206449151039124,0.38211527466773987,0.382489949464798,0.38156697154045105,0.38574105501174927,0.3854651153087616,0.385488897562027,0.37955111265182495,0.38892969489097595,0.3759740889072418,0.38173601031303406,0.3770325183868408,0.38693270087242126,0.3861040771007538,0.3790316581726074,0.38417038321495056,0.3835967481136322,0.38571152091026306,0.3847344219684601,0.3743210434913635,0.38107630610466003,0.3800279498100281,0.38199517130851746,0.3753478229045868,0.38110411167144775,0.38490062952041626,0.3808215856552124,0.3791351616382599,0.38067612051963806,0.38052523136138916,0.37978610396385193,0.3801867961883545,0.38090384006500244,0.37553420662879944,0.3756929636001587,0.3710726201534271,0.3859834671020508,0.37661412358283997,0.374243825674057,0.3848462402820587,0.37816813588142395,0.38290876150131226,0.3870563209056854,0.3740171194076538,0.3889191746711731,0.37848159670829773,0.3893063962459564,0.38392695784568787,0.39029186964035034,0.38547876477241516,0.3796338737010956,0.3843717575073242,0.3820440173149109,0.3820841610431671,0.37793290615081787,0.384633332490921,0.381835013628006,0.3801723122596741,0.38262271881103516,0.3746764063835144,0.39157891273498535,0.38414818048477173,0.37885838747024536,0.37829825282096863,0.3819141089916229,0.38682860136032104,0.3761689364910126,0.3813399374485016,0.3768611252307892,0.3805859386920929,0.3796738386154175,0.38041791319847107,0.38262394070625305,0.3794482350349426,0.37979382276535034,0.38474565744400024,0.382442831993103,0.37917280197143555,0.3829185366630554,0.38364675641059875,0.37764424085617065,0.3732810914516449,0.38103583455085754,0.3696916103363037,0.37731513381004333,0.38614240288734436,0.3785499632358551,0.3846627473831177,0.3862188756465912,0.37675967812538147,0.383231520652771,0.38266560435295105,0.38293635845184326,0.3823612332344055,0.3862575590610504,0.3792881965637207,0.38014930486679077,0.37581539154052734,0.38088008761405945,0.3819749057292938,0.37701281905174255,0.38421431183815,0.37691277265548706,0.38252201676368713,0.3783797323703766,0.37750017642974854,0.38708898425102234,0.3833239674568176,0.3810157775878906,0.3805977404117584,0.3836665451526642,0.3781556785106659,0.37754523754119873,0.3866176903247833,0.38327959179878235,0.3771633803844452,0.3804754912853241,0.3810926377773285,0.38122156262397766,0.3794061541557312,0.37780526280403137,0.38039445877075195,0.38306134939193726,0.3801446855068207,0.379149854183197,0.37908902764320374,0.3796989321708679,0.3839501142501831,0.3810166120529175,0.3710671067237854,0.3856877088546753,0.37835806608200073,0.3838557004928589,0.38007962703704834,0.3833872079849243,0.38116657733917236,0.37789469957351685,0.3828337788581848,0.3849632143974304,0.38390597701072693,0.3843206465244293,0.3782236874103546,0.38284656405448914,0.38046422600746155,0.38048049807548523,0.3790404498577118,0.3821350932121277,0.38155752420425415,0.378361314535141,0.38234859704971313,0.3815440237522125,0.3734634220600128,0.3819705545902252,0.37531283497810364,0.37536701560020447,0.38247179985046387,0.37894490361213684,0.38314470648765564,0.3769606649875641,0.38368692994117737,0.3821239769458771,0.3769431412220001,0.3738434612751007,0.38196203112602234,0.38886621594429016,0.38194823265075684,0.3819679021835327,0.3778189420700073,0.3856137990951538,0.37705838680267334,0.37737783789634705,0.38217321038246155,0.3802497982978821,0.3874078094959259,0.38102999329566956,0.38662654161453247,0.38056981563568115,0.37658336758613586,0.37620770931243896,0.3818453252315521,0.3785155117511749,0.38625630736351013,0.37840962409973145,0.3751375377178192,0.383710116147995,0.38733187317848206,0.37073221802711487,0.37837132811546326,0.38491764664649963,0.3752022683620453,0.3852755129337311,0.3829091787338257,0.3777589797973633,0.3818613588809967,0.3783133625984192,0.38381892442703247,0.38276994228363037,0.3821963667869568,0.38347139954566956,0.38186827301979065,0.3751004934310913,0.37918612360954285,0.38158679008483887,0.3746141791343689,0.37801676988601685,0.38931721448898315,0.37954214215278625,0.37785616517066956,0.3801734745502472,0.3783183693885803,0.3795381784439087,0.3814522624015808,0.376670777797699,0.37640848755836487,0.38740772008895874,0.3745802342891693,0.3870140016078949,0.3820120096206665,0.3826739192008972,0.39065396785736084,0.3817339539527893,0.3764365613460541,0.3833675682544708,0.3816865086555481,0.378105103969574,0.37567418813705444,0.38287806510925293,0.37419945001602173,0.38347652554512024,0.3826344907283783,0.38077375292778015,0.38067975640296936,0.37467777729034424,0.381673663854599,0.38242271542549133,0.37425345182418823,0.38031095266342163,0.38465049862861633,0.3788154721260071,0.3798598647117615,0.38306209444999695,0.38184741139411926,0.38277262449264526,0.3897165060043335,0.37859296798706055,0.38332056999206543,0.378958523273468,0.38360631465911865,0.38380318880081177,0.3824998438358307,0.37504759430885315,0.3750939965248108,0.3768426477909088,0.3705631196498871,0.38067495822906494,0.3773617446422577,0.37859609723091125,0.3830300271511078,0.3871939182281494,0.3810900151729584,0.3747076392173767,0.37231358885765076,0.37844717502593994,0.38058602809906006,0.37991011142730713,0.37747177481651306,0.37303730845451355,0.3819446563720703,0.3790441155433655,0.37895411252975464,0.3740246891975403,0.37640780210494995,0.374938040971756,0.3797862231731415,0.38198956847190857,0.38143277168273926,0.3817879557609558,0.3770510256290436,0.3776931166648865,0.3874990940093994,0.3737187385559082,0.38017159700393677,0.3758883476257324,0.3732534646987915,0.37800008058547974,0.3846248388290405,0.37683409452438354,0.37585416436195374,0.38041362166404724,0.38817790150642395,0.3776855170726776,0.3794313669204712,0.38352006673812866,0.37681326270103455,0.3774563670158386,0.38137680292129517,0.37572428584098816,0.3796619474887848,0.3806002736091614,0.3784513771533966,0.37307581305503845,0.3780492842197418,0.3811415731906891,0.3839437961578369,0.37919268012046814,0.37865328788757324,0.37974438071250916,0.3834632635116577,0.3825685679912567,0.38588541746139526,0.37941282987594604,0.37118250131607056,0.37591373920440674,0.37238040566444397,0.3844849467277527,0.37578433752059937,0.37681546807289124,0.3842383623123169,0.37929025292396545,0.37803059816360474,0.38276517391204834,0.37904348969459534,0.3835342526435852,0.3780847489833832,0.3756144344806671,0.38105905055999756,0.39038318395614624,0.3785965144634247,0.3761019706726074,0.3777237832546234,0.3736215829849243,0.3798012435436249,0.38089677691459656,0.3790883719921112,0.3792233169078827,0.3777102530002594,0.3787281811237335,0.3844970762729645,0.37861567735671997,0.3829095959663391,0.3787885308265686,0.37676578760147095,0.37570321559906006,0.38249632716178894,0.3847353458404541,0.37431955337524414,0.38040977716445923,0.37631234526634216,0.3734264671802521,0.3732568025588989,0.37236058712005615,0.38373056054115295,0.37850072979927063,0.38431575894355774,0.37458547949790955,0.3803946077823639,0.3851081132888794,0.38045939803123474,0.3777787685394287,0.38559797406196594,0.3852260708808899,0.3785349428653717,0.379930704832077,0.3772144913673401,0.3745954930782318,0.37771517038345337,0.3776622414588928,0.3787681758403778,0.37490150332450867,0.37907952070236206,0.37964531779289246,0.38359639048576355,0.3788144886493683,0.3826887309551239,0.38268163800239563,0.37654829025268555,0.3833073377609253,0.37886226177215576,0.3811682164669037,0.37523674964904785,0.3826759159564972,0.3771848678588867,0.3812485635280609,0.37767016887664795,0.37335360050201416,0.3817426860332489,0.37793827056884766,0.3797372579574585,0.37758705019950867,0.37768790125846863,0.38230976462364197,0.37702229619026184,0.38127580285072327,0.37570101022720337,0.3811817169189453,0.37541601061820984,0.3783252239227295,0.3773372769355774,0.38229161500930786,0.3826127052307129,0.37729036808013916,0.37685102224349976,0.39058536291122437,0.3841101825237274,0.38524752855300903,0.3814043700695038,0.3802211880683899,0.3774748146533966,0.3785715401172638,0.3750203847885132,0.38252246379852295,0.3827037215232849,0.37235087156295776,0.3776886463165283,0.3820137083530426,0.37692704796791077,0.37975215911865234,0.38138437271118164,0.37706759572029114,0.3754892647266388,0.3791652321815491,0.37323886156082153,0.3782622814178467,0.38209256529808044,0.3843574523925781,0.3797169625759125,0.3810199499130249,0.3810434937477112,0.3823329210281372,0.3851575553417206,0.38320931792259216,0.37623363733291626,0.3756161332130432,0.3795945942401886,0.3708197772502899,0.38172364234924316,0.37603577971458435,0.37573274970054626,0.37248939275741577,0.3836413025856018,0.37901604175567627,0.3804702162742615,0.3766154646873474,0.3827770948410034,0.3764709532260895,0.380595326423645,0.3801243007183075,0.379670649766922,0.3816947937011719,0.3841438889503479,0.37342536449432373,0.37586095929145813,0.37596479058265686,0.3790229856967926,0.3789442181587219,0.37703680992126465,0.3764547109603882,0.3740573823451996,0.37885454297065735,0.3846648037433624,0.3801296353340149,0.3816981315612793,0.3737561106681824,0.3783350884914398,0.3729720413684845,0.3781186640262604,0.377414345741272,0.37446126341819763,0.37681859731674194,0.37864580750465393,0.3772169053554535,0.3741430342197418,0.3689066469669342,0.3821767568588257,0.3767646551132202,0.3730478882789612,0.37795761227607727,0.3814026415348053,0.37989214062690735,0.3804088830947876,0.3752509355545044,0.3828577995300293,0.3861040771007538,0.3837677836418152,0.37861642241477966,0.37462490797042847,0.3730201721191406,0.3810432553291321,0.37798449397087097,0.3749334216117859,0.3768414258956909,0.3730637729167938,0.37762516736984253,0.37760624289512634,0.37993595004081726,0.38024088740348816,0.37743717432022095,0.39083895087242126,0.3747205138206482,0.3770004212856293,0.37745150923728943,0.3844732642173767,0.37430211901664734,0.3796699345111847,0.3830375075340271,0.37607046961784363,0.38114985823631287,0.3825990855693817,0.3744172751903534,0.3790360391139984,0.3741128742694855,0.3829328715801239,0.3747190833091736,0.38130396604537964,0.38099154829978943,0.3765198290348053,0.3818812668323517,0.378282755613327,0.37634968757629395,0.3760101795196533,0.3804737627506256,0.38021060824394226,0.3829307556152344,0.3806392550468445,0.3792577385902405,0.3763868808746338,0.378083735704422,0.3775826692581177,0.37704724073410034,0.37465542554855347,0.38114282488822937,0.3710523545742035,0.3795444667339325,0.3865390121936798,0.38352999091148376,0.37689006328582764,0.3788134753704071,0.379006952047348,0.3770380914211273,0.3781201243400574,0.3845365047454834,0.3779882490634918,0.37973082065582275,0.3802145719528198,0.38346606492996216,0.37319231033325195,0.38116130232810974,0.3778347074985504,0.3800070285797119,0.3802761137485504,0.38610726594924927,0.37983807921409607,0.37803518772125244,0.376126229763031,0.37323296070098877,0.37042948603630066,0.3755328357219696,0.3787631392478943,0.3801316022872925,0.3703571856021881,0.37809422612190247,0.3835675120353699,0.37758541107177734,0.3775925636291504,0.38651612401008606,0.3782985508441925,0.38359174132347107,0.3789532482624054,0.3818284571170807,0.3822720944881439,0.3793118894100189,0.37646955251693726,0.38305217027664185,0.37888607382774353,0.37957581877708435,0.3842740058898926,0.37325114011764526,0.3788553476333618,0.3806461691856384,0.3753334879875183,0.37682729959487915,0.3777025640010834,0.38054561614990234,0.3789786100387573,0.3770160675048828,0.3866678774356842,0.37817472219467163,0.3762730360031128,0.3730631172657013,0.3796381950378418,0.38051408529281616,0.3753588795661926,0.37461715936660767,0.3766683340072632,0.3782578408718109,0.3783852159976959,0.37960049510002136,0.3760868310928345,0.37494954466819763,0.37288424372673035,0.37624430656433105,0.3850460350513458,0.3823932409286499,0.38364335894584656,0.3800603449344635,0.3797321915626526,0.3717047870159149,0.37838229537010193,0.3755775988101959,0.37568843364715576,0.372337281703949,0.3849944770336151,0.3765011429786682,0.3782671391963959,0.3762798607349396,0.3725370764732361,0.3795965313911438,0.3810460567474365,0.3771969676017761,0.37518221139907837,0.38109514117240906,0.3792027533054352,0.384806364774704,0.3758953809738159,0.38550493121147156,0.3763541281223297,0.37755119800567627,0.37533465027809143,0.3740551769733429,0.38108769059181213,0.376614511013031,0.3793949782848358,0.3785824477672577,0.38025963306427,0.37583523988723755,0.37839049100875854,0.37679365277290344,0.37437573075294495,0.379341721534729,0.37620532512664795,0.38084352016448975,0.3764532506465912,0.3725234866142273,0.38131287693977356,0.3743188977241516,0.3740137815475464,0.37734469771385193,0.3745044469833374,0.38171857595443726,0.37939122319221497,0.37428805232048035,0.37413567304611206,0.37865471839904785,0.37589606642723083,0.37579065561294556,0.38351544737815857,0.38139599561691284,0.3771419823169708,0.38100749254226685,0.3758813440799713,0.381470263004303,0.3763944208621979,0.37794241309165955,0.38082024455070496,0.3805723488330841,0.3787853717803955,0.3853508234024048,0.3817400336265564,0.37798625230789185,0.3795115053653717,0.3701344132423401,0.3755711615085602,0.37332817912101746,0.3790588080883026,0.376870334148407,0.372333824634552,0.3797071576118469,0.3766009509563446,0.3760316073894501,0.3659355342388153,0.3799046576023102,0.3767852783203125,0.3749687969684601,0.3773570656776428,0.3812399208545685,0.37700155377388,0.375324010848999,0.37718087434768677,0.38104262948036194,0.3818815052509308,0.3752298057079315,0.3770579695701599,0.3736708164215088,0.380893349647522,0.3762277364730835,0.37836042046546936,0.3743050992488861,0.3756963610649109,0.3809525668621063,0.37644481658935547,0.379342645406723,0.3830753266811371,0.36803343892097473,0.38276830315589905,0.3773547410964966,0.3837258815765381,0.38094112277030945,0.37912219762802124,0.3782688081264496,0.37866541743278503,0.37674209475517273,0.3727298676967621,0.378884881734848,0.3752170503139496,0.3742113411426544,0.38021212816238403,0.37891271710395813,0.3767260015010834,0.3709636330604553,0.37994298338890076,0.37850162386894226,0.3774716854095459,0.3751903176307678,0.375598669052124,0.37973934412002563,0.3805464804172516,0.3846489191055298,0.3791605532169342,0.37568527460098267,0.37776118516921997,0.37891629338264465,0.3802865445613861,0.37132567167282104,0.3776650130748749,0.3808436393737793,0.3806286156177521,0.3797282576560974,0.3781329393386841,0.3718290328979492,0.3728620111942291,0.3756650388240814,0.3808174133300781,0.37665504217147827,0.3762792944908142,0.38309550285339355,0.37234339118003845,0.3759697675704956,0.37935298681259155,0.3765091896057129,0.37594377994537354,0.3822140693664551,0.37771761417388916,0.36962345242500305,0.37544336915016174,0.3792939782142639,0.38117536902427673,0.3790082633495331,0.3788194954395294,0.38451582193374634,0.37857410311698914,0.38214531540870667,0.37952595949172974,0.3829011917114258,0.3818943202495575,0.378599613904953,0.38298672437667847,0.3750106692314148,0.3779526352882385,0.38303717970848083,0.3762111961841583,0.37609216570854187,0.3819984197616577,0.37713801860809326,0.3813555836677551,0.37861931324005127,0.3770960569381714,0.3761676847934723,0.3802855312824249,0.3796091675758362,0.3800314962863922,0.37061089277267456,0.37886741757392883,0.37138831615448,0.3797444701194763,0.3792637586593628,0.380170077085495,0.372977614402771,0.3750002980232239,0.3772459030151367,0.36819756031036377,0.3755172789096832,0.3825543522834778,0.3823801279067993,0.3772593140602112,0.37908780574798584,0.37770047783851624,0.38479065895080566,0.3770020008087158,0.3783080577850342,0.37297940254211426,0.37893974781036377,0.3770226538181305,0.38022229075431824,0.38039395213127136,0.37510937452316284,0.3830665647983551,0.37065693736076355,0.3734912872314453,0.37696537375450134,0.37203046679496765,0.38052478432655334,0.37931835651397705,0.3811837434768677,0.3847286105155945,0.3809888958930969,0.3765813112258911,0.3835371434688568,0.37470415234565735,0.377390593290329,0.3741184175014496,0.37749022245407104,0.37977978587150574,0.37375590205192566,0.3758079409599304,0.3780575394630432,0.36947518587112427,0.3778649568557739,0.37192511558532715,0.37878650426864624,0.3753679692745209,0.3762419521808624,0.3747912049293518,0.3731967806816101,0.3792870342731476,0.3781299293041229,0.373707115650177,0.37504062056541443,0.37861043214797974,0.37739986181259155,0.37892770767211914,0.3765551447868347,0.37373676896095276,0.38085106015205383,0.3711339235305786,0.3764687180519104,0.3773389160633087,0.3818393051624298,0.3738369941711426,0.37408629059791565,0.37435442209243774,0.3748985230922699,0.3776251971721649,0.3748338222503662,0.37332186102867126,0.3833705186843872,0.37720826268196106,0.37111011147499084,0.37746021151542664,0.37875568866729736,0.38171061873435974,0.37072575092315674,0.3798758089542389,0.3777085840702057,0.375478595495224,0.3783421218395233,0.37264323234558105,0.37236204743385315,0.3756965398788452,0.3708854019641876,0.3856690227985382,0.3786132335662842,0.3769952058792114,0.3795473277568817,0.3782348930835724,0.377968966960907,0.3769380748271942,0.3791656494140625,0.37619662284851074,0.3804577589035034,0.36945950984954834,0.3738091289997101,0.3834441602230072,0.3816881775856018,0.37402456998825073,0.373264878988266,0.3716511130332947,0.3822430372238159,0.3716316223144531,0.3758407533168793,0.37528690695762634,0.38100916147232056,0.38254594802856445,0.3750661313533783,0.37320172786712646,0.37824109196662903,0.3763289749622345,0.3821817934513092,0.37391966581344604,0.37184569239616394,0.37613797187805176,0.38330814242362976,0.3757077753543854,0.3765914738178253,0.37885090708732605,0.3747583031654358,0.3782193660736084,0.3744240403175354,0.3799130916595459,0.37735697627067566,0.3713608384132385,0.37894120812416077,0.3761049807071686,0.3773737847805023,0.3744484782218933,0.3744714856147766,0.37191882729530334,0.37641197443008423,0.3749717175960541,0.37510210275650024,0.3828069567680359,0.3762368857860565,0.3716895878314972,0.3842894434928894,0.3714412450790405,0.37568238377571106,0.3844982087612152,0.37462201714515686,0.3747076690196991,0.37481367588043213,0.3793485462665558,0.3736383020877838,0.3791290819644928,0.3804525136947632,0.37915220856666565,0.3755417466163635,0.3730103373527527,0.37938016653060913,0.3741135597229004,0.3713506758213043,0.3800118863582611,0.3841802179813385,0.37833335995674133,0.3784136474132538,0.3816516399383545,0.37361735105514526,0.37299081683158875,0.3871949017047882,0.3694078326225281,0.3791334927082062,0.37540584802627563,0.37243756651878357,0.37349486351013184,0.3765518069267273,0.3752513527870178,0.3801739513874054,0.3837737739086151,0.37314480543136597,0.3802271783351898,0.3779512643814087,0.3803556263446808,0.37384557723999023,0.37783148884773254,0.37846851348876953,0.38091737031936646,0.3755737245082855,0.37613117694854736,0.3741706907749176,0.37843286991119385,0.37515127658843994,0.37244734168052673,0.3826332688331604,0.3746902346611023,0.38249731063842773,0.3802555799484253,0.3779953122138977,0.37878158688545227,0.37849023938179016,0.37434396147727966,0.38213998079299927,0.37271466851234436,0.3740372359752655,0.3835800886154175,0.3789810240268707,0.37551847100257874,0.372050017118454,0.37551233172416687,0.37213170528411865,0.37434008717536926,0.3773949444293976,0.3815596401691437,0.37626221776008606,0.38038167357444763,0.3844052255153656,0.3783138692378998,0.3779463768005371,0.3809376358985901,0.3780727684497833,0.3716767430305481,0.3871188461780548,0.37786564230918884,0.37295791506767273,0.38268131017684937],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\",\"width\":2},\"mode\":\"lines\",\"name\":\"val_loss\",\"y\":[0.6877765655517578,0.6880788803100586,0.6825851798057556,0.6772028207778931,0.6739334464073181,0.6699446439743042,0.6667259931564331,0.6633033156394958,0.6613666415214539,0.6567009687423706,0.6532643437385559,0.6513740420341492,0.6480536460876465,0.6452497839927673,0.6413421034812927,0.640386164188385,0.6361935138702393,0.6339574456214905,0.630949854850769,0.6285605430603027,0.6265438199043274,0.6231220960617065,0.6202521324157715,0.6186941862106323,0.6172534227371216,0.6128730177879333,0.6107025742530823,0.6106287240982056,0.6067180633544922,0.6041037440299988,0.6026883125305176,0.5995573401451111,0.5969775319099426,0.5953289270401001,0.5932663083076477,0.5904715657234192,0.5891777276992798,0.5872324109077454,0.5837422013282776,0.5825729370117188,0.5799909830093384,0.5793777704238892,0.5758418440818787,0.5744578838348389,0.5724130272865295,0.5693935751914978,0.5682246088981628,0.5665968656539917,0.563368022441864,0.5618438124656677,0.5602306127548218,0.5578539967536926,0.5563890337944031,0.5540145635604858,0.5520598292350769,0.550426185131073,0.5482316613197327,0.5460699796676636,0.5445023775100708,0.543255090713501,0.5404311418533325,0.5383164286613464,0.5375283360481262,0.5353971123695374,0.5330734252929688,0.5319311022758484,0.529924750328064,0.5288583636283875,0.5263906717300415,0.5249083638191223,0.5234837532043457,0.5214123725891113,0.5189191699028015,0.5174935460090637,0.5159603953361511,0.5150460600852966,0.5125892162322998,0.5107334852218628,0.5095051527023315,0.5084546208381653,0.5072885155677795,0.5047308206558228,0.5030646920204163,0.502031683921814,0.5002415180206299,0.49890226125717163,0.4976547956466675,0.4955676198005676,0.4944356381893158,0.49372565746307373,0.4910563826560974,0.48992374539375305,0.4887982904911041,0.48687395453453064,0.48519548773765564,0.4845309257507324,0.4826626181602478,0.48170334100723267,0.4801471531391144,0.47936296463012695,0.47847825288772583,0.4764934778213501,0.47557395696640015,0.4742041528224945,0.47236913442611694,0.47059839963912964,0.47044986486434937,0.4689314663410187,0.46767857670783997,0.46629762649536133,0.4657794237136841,0.46448421478271484,0.4632083773612976,0.4620008170604706,0.46105602383613586,0.46016809344291687,0.4582372009754181,0.4571019411087036,0.4563234746456146,0.4557415843009949,0.45413464307785034,0.4531005024909973,0.45199233293533325,0.45117151737213135,0.45020097494125366,0.44895708560943604,0.44788289070129395,0.44751837849617004,0.44612830877304077,0.4446744918823242,0.44461315870285034,0.44368571043014526,0.4424535036087036,0.44236981868743896,0.44085797667503357,0.439469575881958,0.4391741156578064,0.43857988715171814,0.4378742277622223,0.4364044666290283,0.4354689419269562,0.43533647060394287,0.4338567554950714,0.43267419934272766,0.4321550130844116,0.43138426542282104,0.4308773875236511,0.43025878071784973,0.4288192093372345,0.42799001932144165,0.42766135931015015,0.4269430339336395,0.42585137486457825,0.425270140171051,0.4246867597103119,0.42375531792640686,0.42276057600975037,0.4224562644958496,0.42206010222435,0.4214433431625366,0.42025330662727356,0.4194278419017792,0.41885003447532654,0.4184627830982208,0.4180530905723572,0.41734811663627625,0.41638481616973877,0.41540852189064026,0.4151363670825958,0.414311945438385,0.4139605462551117,0.413490891456604,0.4124250113964081,0.4121333956718445,0.4114188253879547,0.4107165038585663,0.4100241959095001,0.4097566604614258,0.4092213809490204,0.4083932638168335,0.40788036584854126,0.4069744348526001,0.40667489171028137,0.4067865312099457,0.40622082352638245,0.4052506685256958,0.40438804030418396,0.4041787385940552,0.4034976661205292,0.40321916341781616,0.40255630016326904,0.4017553925514221,0.4011795222759247,0.40142637491226196,0.40035584568977356,0.39995649456977844,0.3996274173259735,0.39926689863204956,0.3987919092178345,0.39774996042251587,0.3975406885147095,0.39707329869270325,0.3965166509151459,0.3963734209537506,0.39619943499565125,0.3957393169403076,0.3956206738948822,0.394768089056015,0.39447253942489624,0.39380910992622375,0.393362820148468,0.39351096749305725,0.39283034205436707,0.3923366665840149,0.3917788863182068,0.39115631580352783,0.39079374074935913,0.3903857469558716,0.3903120458126068,0.3898475170135498,0.3892189860343933,0.3889397084712982,0.38838160037994385,0.38830438256263733,0.38796496391296387,0.3876150846481323,0.38735947012901306,0.38679951429367065,0.38671424984931946,0.38607484102249146,0.3857947289943695,0.3856359124183655,0.3855697214603424,0.385008841753006,0.38457050919532776,0.38409098982810974,0.3838409185409546,0.38350316882133484,0.3833378553390503,0.3828069567680359,0.38237324357032776,0.3825667202472687,0.38248685002326965,0.3822645843029022,0.38142019510269165,0.38125675916671753,0.3811818063259125,0.38051262497901917,0.3804744780063629,0.38032296299934387,0.38000813126564026,0.37930774688720703,0.37895113229751587,0.3790229260921478,0.3788334131240845,0.3783389925956726,0.3781905770301819,0.37819209694862366,0.3778558373451233,0.37756627798080444,0.3772715628147125,0.376920610666275,0.3768484592437744,0.37675511837005615,0.3766944110393524,0.3762553930282593,0.37581878900527954,0.3755829334259033,0.3753952383995056,0.3752440810203552,0.3754975199699402,0.3750084936618805,0.37469616532325745,0.374136358499527,0.37412208318710327,0.3742224872112274,0.3737618625164032,0.3735094666481018,0.373386412858963,0.37305212020874023,0.37308937311172485,0.37285590171813965,0.37256044149398804,0.37254589796066284,0.37234970927238464,0.3716675341129303,0.37163257598876953,0.37181776762008667,0.3714554011821747,0.37101298570632935,0.3707488477230072,0.37092873454093933,0.3707638382911682,0.37049973011016846,0.37032651901245117,0.3702546954154968,0.3698625862598419,0.3694872558116913,0.3696639835834503,0.36953458189964294,0.3692206144332886,0.3691602051258087,0.36920446157455444,0.3687911629676819,0.36862677335739136,0.36844971776008606,0.3686198592185974,0.3682151436805725,0.3678809106349945,0.3677809536457062,0.36743924021720886,0.3675128221511841,0.36714968085289,0.3672347664833069,0.36672869324684143,0.366728276014328,0.366941899061203,0.3667459785938263,0.3665211498737335,0.3665854334831238,0.3661275804042816,0.3659553825855255,0.3660117983818054,0.36576423048973083,0.36547815799713135,0.36530831456184387,0.3652302920818329,0.3653334081172943,0.3650953471660614,0.36495351791381836,0.3652344346046448,0.36487698554992676,0.364807665348053,0.364578515291214,0.36465686559677124,0.3643946051597595,0.36408472061157227,0.3639872074127197,0.36428776383399963,0.36417046189308167,0.3639059066772461,0.36360570788383484,0.3633574843406677,0.363347589969635,0.36346614360809326,0.3634375035762787,0.36321741342544556,0.3629518151283264,0.36272355914115906,0.36241433024406433,0.36267876625061035,0.3628460466861725,0.3625756502151489,0.36262181401252747,0.36237862706184387,0.3622324764728546,0.36215052008628845,0.36202409863471985,0.36209720373153687,0.36213400959968567,0.3616602122783661,0.36151188611984253,0.3613951802253723,0.36133942008018494,0.3614959418773651,0.36135178804397583,0.36146992444992065,0.361359179019928,0.3612825870513916,0.36085841059684753,0.36061492562294006,0.360806405544281,0.360841304063797,0.36067914962768555,0.36094218492507935,0.36054378747940063,0.36020737886428833,0.36011195182800293,0.3601282238960266,0.3602432608604431,0.35991141200065613,0.35968291759490967,0.36002400517463684,0.35994836688041687,0.35996878147125244,0.3598204255104065,0.3597244918346405,0.3595743477344513,0.3593306541442871,0.3592492640018463,0.3592614531517029,0.3594529330730438,0.3591342568397522,0.35886844992637634,0.35867512226104736,0.3589205741882324,0.3589504063129425,0.35927170515060425,0.35881927609443665,0.3588666021823883,0.358892023563385,0.35882285237312317,0.35883674025535583,0.358517050743103,0.3582614064216614,0.3583821952342987,0.3581301271915436,0.3581095039844513,0.3578605651855469,0.35779690742492676,0.35771259665489197,0.35761281847953796,0.3576328456401825,0.35754162073135376,0.35735735297203064,0.35738760232925415,0.35776418447494507,0.3574540913105011,0.357092946767807,0.3570430278778076,0.3570982813835144,0.3569905459880829,0.35690832138061523,0.356728196144104,0.35690921545028687,0.35692811012268066,0.35668230056762695,0.35670924186706543,0.3568098247051239,0.3566545248031616,0.35681816935539246,0.3564162850379944,0.35638725757598877,0.35632845759391785,0.35641399025917053,0.3563343584537506,0.35655197501182556,0.3562183678150177,0.3560001254081726,0.35603073239326477,0.35597771406173706,0.355966180562973,0.3559858500957489,0.3559216558933258,0.3559000492095947,0.3558807969093323,0.35578063130378723,0.35564395785331726,0.35578566789627075,0.3556670844554901,0.3553944230079651,0.3557155132293701,0.3557775914669037,0.3552830219268799,0.3552817106246948,0.35533031821250916,0.3553047776222229,0.3553997576236725,0.35534173250198364,0.35528239607810974,0.35486310720443726,0.3548242151737213,0.3547486364841461,0.3546166718006134,0.3545033037662506,0.35440564155578613,0.35475558042526245,0.35478538274765015,0.35476967692375183,0.35447821021080017,0.35438287258148193,0.35413801670074463,0.3542739748954773,0.3542826473712921,0.354188472032547,0.35425397753715515,0.35397112369537354,0.3538530766963959,0.35381242632865906,0.3537461757659912,0.35392045974731445,0.3537905216217041,0.3537193834781647,0.3536408245563507,0.35354331135749817,0.35362106561660767,0.35361412167549133,0.3535808026790619,0.3536953628063202,0.3535381555557251,0.35343459248542786,0.3532746136188507,0.3532763123512268,0.35332050919532776,0.3532826900482178,0.35293182730674744,0.3528880476951599,0.352889746427536,0.35282042622566223,0.35274115204811096,0.3528650104999542,0.3529256582260132,0.35316309332847595,0.35319530963897705,0.352927565574646,0.3528427481651306,0.35261431336402893,0.3525838851928711,0.3524840772151947,0.3525519371032715,0.3527066111564636,0.3528631627559662,0.3524143695831299,0.3524726331233978,0.3524132966995239,0.352446973323822,0.3525404632091522,0.35252615809440613,0.35233816504478455,0.35256144404411316,0.3521612286567688,0.3521491289138794,0.3522888123989105,0.3521824777126312,0.35223129391670227,0.3517644703388214,0.35189467668533325,0.3520568907260895,0.3523203730583191,0.3522038459777832,0.3523375391960144,0.35203954577445984,0.3517926335334778,0.35183069109916687,0.35205507278442383,0.35190314054489136,0.35193774104118347,0.3519827723503113,0.3521623909473419,0.35223501920700073,0.35205399990081787,0.35223427414894104,0.35194894671440125,0.35172906517982483,0.3517010509967804,0.35177016258239746,0.35186949372291565,0.3517235219478607,0.35163167119026184,0.35139328241348267,0.35141459107398987,0.351721853017807,0.3516016900539398,0.35181570053100586,0.3519588112831116,0.3518524765968323,0.3514145016670227,0.35120999813079834,0.3510952889919281,0.3508884608745575,0.35091325640678406,0.3513244688510895,0.3509342074394226,0.35123324394226074,0.3511926233768463,0.3510775566101074,0.35091543197631836,0.35118329524993896,0.3511147201061249,0.3511718809604645,0.3510079085826874,0.35092753171920776,0.351024329662323,0.3510347604751587,0.3514747619628906,0.3512168526649475,0.35087254643440247,0.3508833348751068,0.3510833978652954,0.35088425874710083,0.3508486747741699,0.3505508005619049,0.3507964611053467,0.35103291273117065,0.3510171175003052,0.3509202003479004,0.3508104979991913,0.3508831262588501,0.3507368266582489,0.35059794783592224,0.3506545126438141,0.3513118624687195,0.3509327471256256,0.3508113920688629,0.3509232699871063,0.3507429361343384,0.3506261110305786,0.3507365882396698,0.3509291112422943,0.3508337438106537,0.3507521152496338,0.35073497891426086,0.35089030861854553,0.35074952244758606,0.3507758378982544,0.3509068489074707,0.3508128821849823,0.3504970073699951,0.35070735216140747,0.35066112875938416,0.3505459725856781,0.3506825566291809,0.3507017195224762,0.350571870803833,0.3507518470287323,0.35087308287620544,0.3504253923892975,0.35068994760513306,0.3504480719566345,0.35014790296554565,0.3504146933555603,0.35072246193885803,0.3506183326244354,0.35020357370376587,0.35005706548690796,0.3504095673561096,0.3507152199745178,0.35047587752342224,0.3502914011478424,0.3503892123699188,0.35017773509025574,0.3500373959541321,0.3503879904747009,0.35034728050231934,0.35010382533073425,0.34986016154289246,0.3503760099411011,0.3501383066177368,0.35006576776504517,0.3500927686691284,0.34989652037620544,0.3500286936759949,0.3499109447002411,0.35019218921661377,0.3502854108810425,0.3502509295940399,0.3503991365432739,0.3502795696258545,0.3503848612308502,0.3503924608230591,0.35022059082984924,0.35034433007240295,0.35017576813697815,0.35017675161361694,0.35015010833740234,0.35014113783836365,0.3499038815498352,0.3500070869922638,0.35018613934516907,0.3499815762042999,0.3499993085861206,0.3498598635196686,0.34991568326950073,0.3498469591140747,0.35008594393730164,0.3500320315361023,0.34998950362205505,0.3499266505241394,0.3499346077442169,0.34969058632850647,0.34979814291000366,0.34972044825553894,0.3497195541858673,0.3498193025588989,0.3498446047306061,0.34992703795433044,0.3497629761695862,0.3498104512691498,0.3493718206882477,0.3492879569530487,0.34953320026397705,0.34990715980529785,0.34970805048942566,0.34984666109085083,0.34961315989494324,0.349483847618103,0.34943005442619324,0.3497476875782013,0.3495299220085144,0.34947890043258667,0.3495692014694214,0.3496553599834442,0.34943345189094543,0.34921517968177795,0.34913378953933716,0.3492085337638855,0.34909331798553467,0.3492200970649719,0.34944915771484375,0.349366694688797,0.34925591945648193,0.3490760624408722,0.3493439257144928,0.34953033924102783,0.34948357939720154,0.34926214814186096,0.3490869104862213,0.34898024797439575,0.3490969240665436,0.34905388951301575,0.34908610582351685,0.3493475615978241,0.34914630651474,0.349019855260849,0.34897077083587646,0.34872642159461975,0.3491649925708771,0.3493466079235077,0.3489646911621094,0.3490143418312073,0.34894686937332153,0.34927111864089966,0.34900519251823425,0.3490578532218933,0.34892362356185913,0.34875524044036865,0.3486911952495575,0.34856873750686646,0.34833118319511414,0.3485446870326996,0.34869638085365295,0.34870731830596924,0.348783940076828,0.34867313504219055,0.3487393260002136,0.3488922417163849,0.34858912229537964,0.3487125039100647,0.34890663623809814,0.34884002804756165,0.3489815294742584,0.34875717759132385,0.3487395644187927,0.34890449047088623,0.34900543093681335,0.34864601492881775,0.34859582781791687,0.34858036041259766,0.34858250617980957,0.34853124618530273,0.3486916422843933,0.3487760126590729,0.34897473454475403,0.34878009557724,0.34878942370414734,0.3490113615989685,0.348927766084671,0.34881705045700073,0.34874045848846436,0.348587304353714,0.3485216796398163,0.3484710156917572,0.34851202368736267,0.3487755060195923,0.34864628314971924,0.3487798869609833,0.3485523760318756,0.34855392575263977,0.34849458932876587,0.34848764538764954,0.3485616445541382,0.34854137897491455,0.3484623432159424,0.3482726216316223,0.34826523065567017,0.34830212593078613,0.34839916229248047,0.3482667803764343,0.3483417332172394,0.3484661877155304,0.34822729229927063,0.3483410179615021,0.34838801622390747,0.3484577536582947,0.3484523296356201,0.34836724400520325,0.34852442145347595,0.3488825857639313,0.34876561164855957,0.34869781136512756,0.34868255257606506,0.34862416982650757,0.3483720123767853,0.34830164909362793,0.348140686750412,0.34868040680885315,0.34869563579559326,0.34856340289115906,0.34855976700782776,0.34848785400390625,0.3485991358757019,0.34849536418914795,0.3482932150363922,0.3483875095844269,0.34827306866645813,0.3485885560512543,0.3485076129436493,0.34855788946151733,0.3484165370464325,0.34827980399131775,0.34827739000320435,0.34823206067085266,0.34824106097221375,0.348300576210022,0.34836339950561523,0.34805992245674133,0.3479965925216675,0.3484093248844147,0.3481561839580536,0.3482607305049896,0.34815528988838196,0.3478555381298065,0.3481987714767456,0.34796637296676636,0.34778377413749695,0.34783968329429626,0.3481837511062622,0.34805065393447876,0.3480573892593384,0.3480427861213684,0.3482600450515747,0.34797510504722595,0.3480948805809021,0.34815332293510437,0.34818047285079956,0.34798356890678406,0.34828516840934753,0.34831416606903076,0.34815314412117004,0.34818777441978455,0.348283588886261,0.34815001487731934,0.3482201099395752,0.3481103777885437,0.3480336368083954,0.347903847694397,0.3480985164642334,0.348148375749588,0.3481566607952118,0.3481343984603882,0.34830862283706665,0.3482940196990967,0.34813860058784485,0.3480255901813507,0.3481132388114929,0.34801438450813293,0.34809398651123047,0.348355770111084,0.3482144773006439,0.34797215461730957,0.3480473756790161,0.3480558693408966,0.34836477041244507,0.34838372468948364,0.34820395708084106,0.34810417890548706,0.3482496738433838,0.3480320870876312,0.3480502963066101,0.34808459877967834,0.3481021821498871,0.34807637333869934,0.3478887975215912,0.3479323089122772,0.348076730966568,0.3481219708919525,0.3479952812194824,0.34804171323776245,0.3482140600681305,0.3479171693325043,0.3480457663536072,0.3478471636772156,0.3477366268634796,0.34797564148902893,0.347982794046402,0.3480641543865204,0.34792619943618774,0.3482600748538971,0.3479163348674774,0.3478296101093292,0.3479861319065094,0.3479224145412445,0.3479585647583008,0.3479522168636322,0.34780558943748474,0.3478384017944336,0.3479549288749695,0.3481484055519104,0.3482776880264282,0.3481067419052124,0.3480893671512604,0.3480449914932251,0.3478751480579376,0.3480299413204193,0.34807518124580383,0.34803301095962524,0.3481842279434204,0.34830954670906067,0.34840142726898193,0.34832221269607544,0.34828004240989685,0.34809741377830505,0.3481241762638092,0.34832292795181274,0.34834739565849304,0.34822893142700195,0.34833085536956787,0.34839433431625366,0.34817251563072205,0.3479403555393219,0.3481505215167999,0.34791532158851624,0.3481105864048004,0.3478983938694,0.347868949174881,0.3481772243976593,0.3481309711933136,0.3482234477996826,0.3483118414878845,0.34806159138679504,0.3480241298675537,0.3480915129184723,0.34825873374938965,0.34832465648651123,0.3482327163219452,0.34805184602737427,0.3481591045856476,0.3479580879211426,0.34791144728660583,0.3477923572063446,0.34793269634246826,0.34778034687042236,0.3479035496711731,0.34823861718177795,0.3482348918914795,0.34807854890823364,0.3480978012084961,0.34841424226760864,0.3482923209667206,0.3481840491294861,0.3480265736579895,0.3481076955795288,0.3480253219604492,0.34790900349617004,0.3478222191333771,0.3479453921318054,0.3480072021484375,0.34807896614074707,0.34810346364974976,0.3479529023170471,0.3478408753871918,0.3480410873889923,0.34773820638656616,0.3478292226791382,0.3478333652019501,0.3476024866104126,0.34771332144737244,0.3478546440601349,0.34818798303604126,0.34826451539993286,0.348113477230072,0.347806841135025,0.34793201088905334,0.34800878167152405,0.3478255271911621,0.34796595573425293,0.34796851873397827,0.34769052267074585,0.3475673794746399,0.34809327125549316,0.34798333048820496,0.3479921519756317,0.3480393886566162,0.3480851650238037,0.34858936071395874,0.3485223948955536,0.34833770990371704,0.3482542335987091,0.3479301333427429,0.34785956144332886,0.3481889069080353,0.34813645482063293,0.34824445843696594,0.3480396866798401,0.3479735255241394,0.3481574058532715,0.34840503334999084,0.34829869866371155,0.34810763597488403,0.3477986752986908,0.3480110168457031,0.3478749692440033,0.3476870357990265,0.34790343046188354,0.3480710983276367,0.3480698764324188,0.3477504253387451,0.34789565205574036,0.34807634353637695,0.3476981818675995,0.3478313982486725,0.3479917645454407,0.3481273055076599,0.3481632173061371,0.3479742407798767,0.34753692150115967,0.34767794609069824,0.3477986454963684,0.3477436304092407,0.3477765619754791,0.3474472463130951,0.3473992943763733,0.34753575921058655,0.3472641706466675,0.3475567698478699,0.34753644466400146,0.3473702669143677,0.3474285304546356,0.3473929166793823,0.3476119339466095,0.34765496850013733,0.347569078207016,0.3478809893131256,0.3476649224758148,0.3474758267402649,0.3477345407009125,0.3477899432182312,0.3475450575351715,0.34738630056381226,0.34728753566741943,0.3475688695907593,0.34753096103668213,0.3475296199321747,0.34745028614997864,0.34761589765548706,0.3475840985774994,0.3473513722419739,0.3473643958568573,0.3473929166793823,0.3474811911582947,0.3473356068134308,0.34753522276878357,0.34755775332450867,0.3476967215538025,0.34742000699043274,0.347443550825119,0.3476603627204895,0.3477500081062317,0.3475721478462219,0.34762144088745117,0.34774795174598694,0.34773707389831543,0.3478446304798126,0.34778761863708496,0.3477790355682373,0.34784165024757385,0.3476313054561615,0.34755271673202515,0.34753674268722534,0.3475150167942047,0.34768736362457275,0.34741485118865967,0.34749847650527954,0.3474825620651245,0.3475400507450104,0.3474261164665222,0.3475967049598694,0.34759262204170227,0.3476586937904358,0.3472416400909424,0.3472398817539215,0.34746697545051575,0.34772127866744995,0.3474234938621521,0.3472238779067993,0.3472954034805298,0.3475545048713684,0.3474583923816681,0.3471378684043884,0.34738802909851074,0.347688227891922,0.34755581617355347,0.3477194607257843,0.34750494360923767,0.3473171591758728,0.3473834693431854,0.3474547863006592,0.3472176790237427,0.3472100496292114,0.34754741191864014,0.3475980758666992,0.34750446677207947,0.3471858501434326,0.3471854329109192,0.3475553095340729,0.3473641574382782,0.3474684953689575,0.347511887550354,0.3475072681903839,0.3475353717803955,0.34738534688949585,0.34735381603240967,0.3475809395313263,0.3473288416862488,0.3473745584487915,0.3472760021686554,0.3473394811153412,0.34729164838790894,0.347435861825943,0.3474918007850647,0.34724971652030945,0.34746482968330383,0.34723204374313354,0.3470791280269623,0.3468533456325531,0.3472135663032532,0.34743261337280273,0.34718450903892517,0.34720462560653687,0.3476104140281677,0.34746113419532776,0.34758618474006653,0.34744971990585327,0.34745824337005615,0.34705430269241333,0.34700071811676025,0.3471815586090088,0.34725597500801086,0.34738683700561523,0.34742072224617004,0.347223699092865,0.34719622135162354,0.347194641828537,0.3473343253135681,0.34740787744522095,0.3475086987018585,0.34742116928100586,0.3471956253051758,0.34728768467903137,0.3472706377506256,0.34731799364089966,0.3471919000148773,0.34747952222824097,0.34747546911239624,0.3474840223789215,0.34733960032463074,0.34753674268722534,0.3473638892173767,0.3474050760269165,0.3477362096309662,0.3476349711418152,0.3477596938610077,0.34761640429496765,0.34747663140296936,0.3474802076816559,0.34733301401138306,0.3473712205886841,0.3477032482624054,0.3475068211555481,0.34749066829681396,0.3472856879234314,0.3472890257835388,0.3472888767719269,0.3474007248878479,0.3474540710449219,0.34728166460990906,0.34741026163101196,0.3475492596626282,0.347425252199173,0.3473270535469055,0.3471828103065491,0.34736916422843933,0.34732964634895325,0.3474109470844269,0.34712767601013184,0.3471921980381012,0.34709182381629944,0.3472630977630615,0.3472961187362671,0.34739822149276733,0.3472549319267273,0.34716904163360596,0.3472512364387512,0.3472464978694916,0.3472449481487274,0.34734436869621277,0.3472957909107208,0.3472905457019806,0.3472156226634979,0.3474572002887726,0.34760743379592896,0.34737420082092285,0.3473363220691681,0.34758442640304565,0.3474533259868622,0.3476197123527527,0.3474336862564087,0.34745410084724426,0.3474349081516266,0.34732484817504883,0.3472743034362793,0.3473178744316101,0.347026526927948,0.34717655181884766,0.3473030626773834,0.3474043607711792,0.34733015298843384,0.3474249243736267,0.3476329743862152,0.3477648198604584,0.34744924306869507,0.34730803966522217,0.3471711277961731,0.3472401201725006,0.3474971354007721,0.34747612476348877,0.34733453392982483,0.3471929728984833,0.3472515046596527,0.3473607301712036,0.34731578826904297,0.34746307134628296,0.3480015993118286,0.3475987911224365,0.34747621417045593,0.3476548492908478,0.34743836522102356,0.3475097715854645,0.3478284180164337,0.34755975008010864,0.3472476303577423,0.34707343578338623,0.3470524847507477,0.3472256064414978,0.3473081588745117,0.3474721908569336,0.3475886285305023,0.3475445806980133,0.34759843349456787,0.3474593162536621,0.34755754470825195,0.347327321767807,0.34736424684524536,0.347364604473114,0.34715986251831055,0.34708309173583984,0.34712132811546326,0.3472449779510498,0.3470200300216675,0.3472433090209961,0.3471035361289978,0.34722936153411865,0.3474302589893341,0.3470993936061859,0.34711405634880066,0.3470366895198822,0.34685659408569336,0.34672069549560547,0.3468042016029358,0.3470800220966339,0.34703633189201355,0.34718072414398193,0.3473855257034302,0.3469886779785156,0.3470899164676666,0.3471619486808777,0.3473183512687683,0.34708350896835327,0.347317099571228,0.34728842973709106,0.347299188375473,0.34731602668762207,0.3476317226886749,0.3474884033203125,0.3474057912826538,0.3476145267486572,0.34733715653419495,0.3472818434238434,0.3471904993057251,0.34709471464157104,0.3471185863018036,0.34712207317352295,0.34726959466934204,0.34724390506744385,0.34732726216316223,0.3473161458969116,0.347286581993103,0.3473154902458191,0.34735020995140076,0.3472409248352051,0.34745922684669495,0.3470743000507355,0.34687885642051697,0.3468887507915497,0.3469559848308563,0.34695377945899963,0.3471619784832001,0.3473552167415619,0.34756702184677124,0.34756794571876526,0.3473414182662964,0.3470242917537689,0.3470443785190582,0.34704434871673584,0.3471900224685669,0.3472059369087219,0.34722161293029785,0.3472467064857483,0.3473156690597534,0.34741535782814026,0.34761548042297363,0.34748128056526184,0.34743279218673706,0.3470152020454407,0.3472020924091339,0.3471737802028656,0.34732896089553833,0.34709733724594116,0.34727391600608826,0.3474019765853882,0.347226083278656,0.347255140542984,0.34746626019477844,0.34743961691856384,0.34719574451446533,0.34719422459602356,0.3470388352870941,0.3469461500644684,0.3470597565174103,0.3470604121685028,0.3472720682621002,0.34716174006462097,0.34744715690612793,0.3473467528820038,0.34723877906799316,0.347310334444046,0.34742477536201477,0.3473711311817169,0.34735867381095886,0.34723442792892456,0.3472605049610138,0.34746894240379333,0.3474024534225464,0.34751105308532715,0.3470969498157501,0.3469471335411072,0.3471847474575043,0.34737786650657654,0.3473350405693054,0.3472185432910919,0.3470633625984192,0.3471280634403229,0.34742432832717896,0.347445547580719,0.3472565710544586,0.34757867455482483,0.34748372435569763,0.34742510318756104,0.34732669591903687,0.3474489450454712,0.3474959433078766,0.347468763589859,0.347244530916214,0.34757810831069946,0.3476296067237854,0.34770599007606506,0.3479953706264496,0.34757229685783386,0.3477339446544647,0.34759512543678284,0.3476729691028595,0.3477559983730316,0.3475866913795471,0.3476347327232361,0.3475537598133087,0.3475266396999359,0.34790363907814026,0.3476548194885254,0.34748950600624084,0.3478466272354126,0.3476751148700714,0.34769463539123535,0.3477177321910858,0.3473522663116455,0.34742534160614014,0.3477495610713959,0.347633421421051,0.3475031852722168,0.3476044833660126,0.34751611948013306,0.34745773673057556,0.34751489758491516,0.3476863503456116,0.3475285768508911,0.3475840389728546,0.3474365472793579,0.34743762016296387,0.34738868474960327,0.3476566672325134,0.3478548526763916,0.34768059849739075,0.3474895656108856,0.34779462218284607,0.34747567772865295,0.3474692106246948,0.3474031686782837,0.34757840633392334,0.34754103422164917,0.3474772274494171,0.34734997153282166,0.34744641184806824,0.3475790023803711,0.34757429361343384,0.34764930605888367,0.3476082682609558,0.34764617681503296,0.34772709012031555,0.3475070595741272,0.34749913215637207,0.3476472496986389,0.3476984202861786,0.3478783071041107,0.34743207693099976,0.34750378131866455,0.3474693298339844,0.3476385474205017,0.347628116607666,0.34754031896591187,0.3475434184074402,0.34745946526527405,0.3476446270942688,0.3477939963340759,0.3480512201786041,0.3476869761943817,0.3473392426967621,0.34747207164764404,0.3477107584476471,0.347858190536499,0.34796446561813354,0.347749263048172,0.3475096523761749,0.3478929400444031,0.34772515296936035,0.34752655029296875,0.34742265939712524,0.3474175035953522,0.3473992347717285,0.34751757979393005,0.34733790159225464,0.3475325107574463,0.34781527519226074,0.34801429510116577,0.3479585647583008,0.3480551838874817,0.34788617491722107,0.3478805124759674,0.3478897511959076,0.3477967381477356,0.34761932492256165,0.3474665582180023,0.34726929664611816,0.3471672236919403,0.3474632203578949,0.3476450443267822,0.3473454415798187,0.34748774766921997,0.34751343727111816,0.34729984402656555,0.3476830720901489,0.3478773534297943,0.34795081615448,0.3478645384311676,0.34762901067733765,0.34766268730163574,0.3476729094982147,0.3473426401615143,0.3475342392921448,0.34747618436813354,0.3475628197193146,0.34749817848205566,0.3474763035774231,0.3475504219532013,0.3473320007324219,0.34709686040878296,0.34743303060531616,0.34739333391189575,0.3473455309867859,0.34726789593696594,0.3473108410835266,0.34733453392982483,0.34736230969429016,0.34730544686317444,0.3473983407020569,0.3475577235221863,0.3476424515247345,0.34731796383857727,0.3472146689891815,0.3471965193748474,0.3475032448768616,0.3476790189743042,0.34773603081703186,0.34776169061660767,0.3475610911846161,0.34750792384147644,0.3475135266780853,0.3476537764072418,0.3476085066795349,0.34739306569099426,0.3473368287086487,0.34762969613075256,0.3477231562137604,0.3477655053138733,0.34783461689949036,0.3474816679954529,0.3474433422088623,0.34728938341140747,0.3474161922931671,0.34715914726257324,0.3474780321121216,0.34762004017829895,0.34759148955345154,0.34744516015052795,0.3471906781196594,0.34719544649124146,0.3474518954753876,0.3472200632095337,0.3473187983036041,0.3475364148616791,0.3475833237171173,0.3476060926914215,0.3473269045352936,0.34712788462638855,0.34712445735931396,0.347592294216156,0.347687691450119,0.34733766317367554,0.34749045968055725,0.34728676080703735,0.34754523634910583,0.3473711311817169,0.3474062383174896,0.3473488688468933,0.3472456932067871,0.34728288650512695,0.3473179340362549,0.3474048376083374,0.3474588692188263,0.3474883437156677,0.3474646806716919,0.3474067747592926,0.3479912579059601,0.3475557565689087,0.3476777672767639,0.34759521484375,0.347444087266922,0.34740957617759705,0.34728899598121643,0.34728753566741943,0.3476470410823822,0.347348690032959,0.34727343916893005,0.3473665416240692,0.3470974564552307,0.347210168838501,0.34748849272727966,0.34731683135032654,0.3474368155002594,0.34739625453948975,0.3477010130882263,0.3474896252155304,0.34739062190055847,0.3476603329181671,0.3478084206581116,0.34742453694343567,0.3474005162715912,0.34714028239250183,0.34707111120224,0.3471328616142273,0.3474283218383789,0.347633957862854,0.34764018654823303,0.34731146693229675,0.34743133187294006,0.34734469652175903,0.34726184606552124,0.3475307524204254,0.34746843576431274,0.34743377566337585,0.3474179208278656,0.34726789593696594,0.3472106456756592,0.3474132716655731,0.3475082218647003,0.34725043177604675,0.34747081995010376,0.34732452034950256,0.3473522663116455,0.34737950563430786,0.3474668562412262,0.3475566506385803,0.3475382328033447,0.3473305106163025,0.34746265411376953,0.3475159704685211,0.34751397371292114,0.3472995460033417,0.34705623984336853,0.3471111059188843,0.3469226658344269,0.3472616374492645,0.3472939431667328,0.3472170829772949,0.34743478894233704,0.34762337803840637,0.34742727875709534,0.3472834527492523,0.3470478653907776,0.3470410108566284,0.34705638885498047,0.34710079431533813,0.3474636971950531,0.34747567772865295,0.34777992963790894,0.34758031368255615,0.3475149869918823,0.34727293252944946,0.3473779857158661,0.34728744626045227,0.34750089049339294,0.34744712710380554,0.347395122051239,0.3472220301628113,0.3472740948200226,0.34695520997047424,0.3471328616142273,0.34743496775627136,0.3477199971675873,0.3475871980190277,0.3473225235939026,0.3475172519683838,0.34736162424087524,0.34744349122047424,0.3472038209438324,0.34730905294418335,0.34742194414138794,0.3474845290184021,0.34771528840065,0.34755557775497437,0.34728845953941345,0.3472921848297119,0.3474423885345459,0.34717315435409546,0.3472251892089844,0.3473161458969116,0.34724298119544983,0.347333699464798,0.3474322557449341,0.347506582736969,0.3476075530052185,0.34768709540367126,0.34741121530532837,0.3473666310310364,0.34742000699043274,0.3477535843849182,0.34744498133659363,0.34753668308258057,0.3474748134613037,0.3475843667984009,0.34749504923820496,0.3474697768688202,0.3472874164581299,0.3474922478199005,0.3473954498767853,0.3477000296115875,0.3475952446460724,0.3476656675338745,0.3476429283618927,0.347465842962265,0.34776654839515686,0.3478670120239258,0.3477584719657898,0.34778693318367004,0.34770962595939636,0.3477111756801605,0.347676545381546,0.34773117303848267,0.34749990701675415,0.34761279821395874,0.34771275520324707,0.34760531783103943,0.3473811149597168,0.3473232388496399,0.34756436944007874,0.3477780520915985,0.3475648760795593,0.3473907709121704,0.3474152088165283,0.34776541590690613,0.3477822244167328,0.3479585647583008,0.347825288772583,0.34747615456581116,0.34735292196273804,0.3475028872489929,0.34751081466674805,0.3475063741207123,0.3478074073791504,0.3481174409389496,0.34782618284225464,0.3480021059513092,0.3475988209247589,0.3476411998271942,0.34762680530548096,0.34769493341445923,0.3477383255958557,0.34774231910705566,0.3474280536174774,0.34728386998176575,0.34744447469711304,0.3478051424026489,0.3474613130092621,0.34743228554725647,0.3472751975059509,0.34722504019737244,0.34734252095222473,0.3475179672241211,0.3475660979747772,0.3476663827896118,0.34770989418029785,0.3475569486618042,0.34773164987564087,0.34758639335632324,0.3474683463573456,0.3474361002445221,0.34739312529563904,0.34733498096466064,0.34727469086647034,0.3469685912132263,0.3471672236919403,0.3472900390625,0.3474304974079132,0.3472352921962738,0.34722039103507996,0.34745556116104126,0.34769636392593384,0.34789136052131653,0.34780287742614746,0.3475850224494934,0.34772977232933044,0.3478197753429413,0.34773164987564087,0.34768813848495483,0.34735107421875,0.34749823808670044,0.3475140333175659,0.3473034203052521,0.3474428057670593,0.34780141711235046,0.34743431210517883,0.34761977195739746,0.3478146195411682,0.3478345572948456,0.3477541208267212,0.34766653180122375,0.34756651520729065,0.3476601243019104,0.3476511538028717,0.3475278317928314,0.347590833902359,0.34746190905570984,0.3475120961666107,0.347504585981369,0.347329705953598,0.34744954109191895,0.3474878966808319,0.34735849499702454,0.347303569316864,0.34729158878326416,0.34774506092071533,0.34774789214134216,0.3476772606372833,0.34752899408340454,0.34765055775642395,0.34760260581970215,0.3475814759731293,0.3475443124771118,0.3475669324398041,0.34746649861335754,0.34773877263069153,0.3476425111293793,0.3475775122642517,0.3477869927883148,0.3477572500705719,0.3477180302143097,0.34775227308273315,0.3475337028503418,0.3475256562232971,0.34757038950920105,0.3474489748477936,0.34744346141815186,0.34735894203186035,0.34745919704437256,0.3473877012729645,0.34737658500671387,0.34745633602142334,0.3473745584487915,0.34730231761932373,0.34747645258903503,0.3472421169281006,0.34719589352607727,0.3473703861236572,0.34751588106155396,0.3474811017513275,0.34744322299957275,0.3474198281764984,0.3472483456134796,0.3471541404724121,0.34759393334388733,0.34732532501220703,0.34739404916763306,0.3474658727645874,0.3476793169975281,0.34722769260406494,0.34747788310050964,0.34750640392303467,0.3474672734737396,0.3475848436355591,0.34745559096336365,0.347322940826416,0.34743210673332214,0.347538024187088,0.34755662083625793,0.3477442264556885,0.3473843038082123,0.34726789593696594,0.3472961485385895,0.3472588062286377,0.34719085693359375,0.3473209738731384,0.34735241532325745,0.34718695282936096,0.34721603989601135,0.34716686606407166,0.347289115190506,0.34743067622184753,0.347284734249115,0.34731394052505493,0.34728509187698364,0.3472481667995453,0.34740954637527466,0.34728822112083435,0.34721216559410095,0.34743767976760864,0.34759655594825745,0.3474672734737396,0.3474888205528259,0.347146600484848,0.34685245156288147,0.3470270335674286,0.3472398817539215,0.3471163809299469,0.3471857011318207,0.34724530577659607,0.34696418046951294,0.34730181097984314,0.34739673137664795,0.3471950888633728,0.3471966087818146,0.34740087389945984,0.34755563735961914,0.347370445728302,0.3473889231681824,0.3474721312522888,0.3473353683948517,0.34723395109176636,0.3472916781902313,0.3473106324672699,0.3475550413131714,0.347572386264801,0.34735235571861267,0.34731414914131165,0.34744003415107727,0.34741201996803284,0.3470646142959595,0.3470354378223419,0.3471564054489136,0.34722161293029785,0.3474110960960388,0.3476286828517914,0.3474065661430359,0.34735357761383057,0.3471100330352783,0.34705936908721924,0.34715479612350464,0.34723085165023804,0.34761565923690796,0.3473648428916931,0.34770527482032776,0.3475479483604431,0.347538024187088,0.34734779596328735,0.3474333882331848,0.34738337993621826,0.3476147949695587,0.34756749868392944,0.34749194979667664,0.3476540148258209,0.3477233648300171,0.34737762808799744,0.3473667800426483,0.34737882018089294,0.34733161330223083,0.34704408049583435,0.34728479385375977,0.34741756319999695,0.3474627733230591,0.3476770520210266,0.34759101271629333,0.34742406010627747,0.34743615984916687,0.3474062979221344,0.3472996652126312,0.34716156125068665,0.34727942943573,0.3472307324409485,0.3471581041812897,0.3471987545490265,0.3473258316516876,0.34737271070480347,0.34732821583747864,0.3476872444152832,0.34753337502479553,0.34719040989875793,0.34712809324264526,0.34724122285842896,0.34731677174568176,0.3471340537071228,0.34725525975227356,0.3471031188964844,0.34718212485313416,0.34752196073532104,0.34766748547554016,0.34746667742729187,0.34731507301330566,0.34725502133369446,0.3471517860889435,0.34711986780166626,0.34721678495407104,0.3469856083393097,0.347066193819046,0.3469308614730835,0.34741485118865967,0.34726962447166443,0.34745585918426514,0.3471396267414093,0.3472098112106323,0.347483366727829,0.34736838936805725,0.3473772406578064,0.34715384244918823,0.34722691774368286,0.34704047441482544,0.3470619022846222,0.34708496928215027,0.34734046459198,0.34729352593421936,0.3471532464027405,0.34733593463897705,0.34721893072128296,0.3471313714981079,0.34721454977989197,0.34712454676628113,0.34724000096321106,0.34727203845977783,0.34717318415641785,0.3471606969833374,0.3473208546638489,0.3475781977176666,0.3476211428642273,0.34742215275764465,0.3475151062011719,0.3475241959095001,0.34756460785865784,0.34767642617225647,0.34749090671539307,0.3474087417125702,0.3473738729953766,0.3473507761955261,0.34708938002586365,0.34699079394340515],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Loss\"},\"xaxis\":{\"title\":{\"text\":\"epochs\"}},\"yaxis\":{\"title\":{\"text\":\"\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('613ea522-b210-4183-be49-a688bc1922f7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = go.Scatter(y=his.history['accuracy'],\n",
        "                    mode=\"lines\", line=dict(\n",
        "                    width=2,\n",
        "                    color='blue'),\n",
        "                    name=\"acc\"\n",
        "                   )\n",
        "h2 = go.Scatter(y=his.history['val_accuracy'],\n",
        "                    mode=\"lines\", line=dict(\n",
        "                    width=2,\n",
        "                    color='red'),\n",
        "                    name=\"val_acc\"\n",
        "                   )\n",
        "\n",
        "data = [h1,h2]\n",
        "layout1 = go.Layout(title='Accuracy',\n",
        "                   xaxis=dict(title='epochs'),\n",
        "                   yaxis=dict(title=''))\n",
        "fig1 = go.Figure(data = data, layout=layout1)\n",
        "plotly.offline.iplot(fig1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "0-8LXiSVbhuO",
        "outputId": "4fad06bf-1791-4bf9-f5da-4f4f1c19f2b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"740a6ad9-845b-4669-a7dd-6e089a7092f9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"740a6ad9-845b-4669-a7dd-6e089a7092f9\")) {                    Plotly.newPlot(                        \"740a6ad9-845b-4669-a7dd-6e089a7092f9\",                        [{\"line\":{\"color\":\"blue\",\"width\":2},\"mode\":\"lines\",\"name\":\"acc\",\"y\":[0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062,0.5026666522026062],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\",\"width\":2},\"mode\":\"lines\",\"name\":\"val_acc\",\"y\":[0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683,0.4959999918937683],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Accuracy\"},\"xaxis\":{\"title\":{\"text\":\"epochs\"}},\"yaxis\":{\"title\":{\"text\":\"\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('740a6ad9-845b-4669-a7dd-6e089a7092f9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
        "_, val_acc = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Train: %.4f, Validation: %.4f' % (train_acc, val_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpkDtSCRbkE7",
        "outputId": "ca202317-aed8-44dd-e64a-b4198f1b9679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.5027, Validation: 0.4960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.predict(x_train)\n",
        "\n",
        "print(res[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbydWBYMbm-Q",
        "outputId": "02fc76e8-089b-49d2-cfcc-cbddabda4b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 3ms/step\n",
            "[[0.99999994]\n",
            " [0.99999994]\n",
            " [0.99999994]\n",
            " [0.99999994]\n",
            " [0.99999994]\n",
            " [0.99999994]\n",
            " [0.99999994]\n",
            " [0.99999994]\n",
            " [0.99999994]\n",
            " [0.99999994]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multi-Class Classification Loss Functions"
      ],
      "metadata": {
        "id": "cqe3rN3k4dVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-Class Classification เป็น Model ที่มีการกำหนด Label หรือ Class มากกว่า 2 Class ซึ่งโดยมากจะเริ่มต้นที่ Class 0 จนถึง num_class - 1 ผลลัพธ์ของ Model จะบอกถึงค่าความเชื่อมั่นในการทำนายของแต่ละ Class โดยค่าความเชื่อมั่นทุก Class รวมกันจะเท่ากับ 1.0\n",
        "\n",
        "เราจะทดลอง Train Multi-Class Classification Model โดยใช้ Categorical Crossentropy Loss ของ Keras Framework ด้วย Dataset ที่ Make ขึ้นจากฟังก์ชัน make_blobs ของ sklearn Library\n",
        "\n",
        "*เพื่อจะทำให้ Model ทำนายผลออกมาเป็นค่าความเชื่อมั่นที่ทุก Class รวมกันเท่ากับ 1.0 เราจะต้องคอนฟิก Activate Function ใน Output Layer แบบ Softmax ครับ"
      ],
      "metadata": {
        "id": "XNJkfmcU4fRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(vector):\n",
        "    e = np.exp(vector)\n",
        "    return e/e.sum()\n",
        "\n",
        "data = [1, 3, 2.5]\n",
        "result = softmax(data)\n",
        "\n",
        "print(result)\n",
        "print(sum(result))"
      ],
      "metadata": {
        "id": "B_uduJMf4gfx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e79e9ebc-8125-4381-89bb-ef80cfd2237b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.07769558 0.57409699 0.34820743]\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Categorical Crossentropy Loss"
      ],
      "metadata": {
        "id": "LjHMDLYw4htX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "events = ['Class 0', 'Class 1', 'Class 2']\n",
        "\n",
        "actual = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
        "predicted = [[0.9, 0.05, 0.05], [0.05, 0.89, 0.06], [0.05, 0.01, 0.94]]\n",
        "\n",
        "p = actual[0]\n",
        "q = predicted[0]"
      ],
      "metadata": {
        "id": "SXilAP2I4tPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure(data=[\n",
        "    go.Bar(name='Actual Probability Distribution', x=events, y=p, text=p, textposition='auto'),\n",
        "    go.Bar(name='Predicted Probability Distribution', x=events, y=q, text=q, textposition='auto')\n",
        "])\n",
        "\n",
        "fig.update_layout(barmode='group', title='Record 1')"
      ],
      "metadata": {
        "id": "y1zhXG5L4uEu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "2e3d37bd-fb5b-47b4-bf41-4eac371fb978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"b2c22a13-6da6-4e88-b610-8e510182869d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b2c22a13-6da6-4e88-b610-8e510182869d\")) {                    Plotly.newPlot(                        \"b2c22a13-6da6-4e88-b610-8e510182869d\",                        [{\"name\":\"Actual Probability Distribution\",\"text\":[\"1\",\"0\",\"0\"],\"textposition\":\"auto\",\"x\":[\"Class 0\",\"Class 1\",\"Class 2\"],\"y\":[1,0,0],\"type\":\"bar\"},{\"name\":\"Predicted Probability Distribution\",\"text\":[\"0.9\",\"0.05\",\"0.05\"],\"textposition\":\"auto\",\"x\":[\"Class 0\",\"Class 1\",\"Class 2\"],\"y\":[0.9,0.05,0.05],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"barmode\":\"group\",\"title\":{\"text\":\"Record 1\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b2c22a13-6da6-4e88-b610-8e510182869d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = actual[1]\n",
        "q = predicted[1]\n",
        "\n",
        "fig = go.Figure(data=[\n",
        "    go.Bar(name='Actual Probability Distribution', x=events, y=p, text=p, textposition='auto'),\n",
        "    go.Bar(name='Predicted Probability Distribution', x=events, y=q, text=q, textposition='auto')\n",
        "])\n",
        "\n",
        "fig.update_layout(barmode='group', title='Record 2')"
      ],
      "metadata": {
        "id": "nEt3cmmx4wZP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "51db5f38-cb95-4f3b-c63a-44799c807ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"4acaf29d-8957-4852-85cd-7a00b35e8c41\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4acaf29d-8957-4852-85cd-7a00b35e8c41\")) {                    Plotly.newPlot(                        \"4acaf29d-8957-4852-85cd-7a00b35e8c41\",                        [{\"name\":\"Actual Probability Distribution\",\"text\":[\"0\",\"1\",\"0\"],\"textposition\":\"auto\",\"x\":[\"Class 0\",\"Class 1\",\"Class 2\"],\"y\":[0,1,0],\"type\":\"bar\"},{\"name\":\"Predicted Probability Distribution\",\"text\":[\"0.05\",\"0.89\",\"0.06\"],\"textposition\":\"auto\",\"x\":[\"Class 0\",\"Class 1\",\"Class 2\"],\"y\":[0.05,0.89,0.06],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"barmode\":\"group\",\"title\":{\"text\":\"Record 2\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4acaf29d-8957-4852-85cd-7a00b35e8c41');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = actual[2]\n",
        "q = predicted[2]\n",
        "\n",
        "fig = go.Figure(data=[\n",
        "    go.Bar(name='Actual Probability Distribution', x=events, y=p, text=p, textposition='auto'),\n",
        "    go.Bar(name='Predicted Probability Distribution', x=events, y=q, text=q, textposition='auto')\n",
        "])\n",
        "\n",
        "fig.update_layout(barmode='group', title='Record 3')"
      ],
      "metadata": {
        "id": "ioILvW7M4yGg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "39450582-8fd2-44cb-ba6e-4fe7660258df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"73dc83d4-49b8-4efa-9a23-83333087999e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"73dc83d4-49b8-4efa-9a23-83333087999e\")) {                    Plotly.newPlot(                        \"73dc83d4-49b8-4efa-9a23-83333087999e\",                        [{\"name\":\"Actual Probability Distribution\",\"text\":[\"0\",\"0\",\"1\"],\"textposition\":\"auto\",\"x\":[\"Class 0\",\"Class 1\",\"Class 2\"],\"y\":[0,0,1],\"type\":\"bar\"},{\"name\":\"Predicted Probability Distribution\",\"text\":[\"0.05\",\"0.01\",\"0.94\"],\"textposition\":\"auto\",\"x\":[\"Class 0\",\"Class 1\",\"Class 2\"],\"y\":[0.05,0.01,0.94],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"barmode\":\"group\",\"title\":{\"text\":\"Record 3\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('73dc83d4-49b8-4efa-9a23-83333087999e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical Crossentropy คือ ค่าเฉลี่ยของ Cross-Entropy ที่เกิดจากการแจกแจงความน่าจะเป็น 2 แบบ คือ การแจกแจงความน่าจะเป็นที่เราอยากได้ (Actual) กับการแจกแจงความน่าจะเป็นที่ถูกประมาณโดย Model (Predicted) ของ Class ต่างๆ (Class 0, 1, 2) ดังภาพด้านบน ซึ่งการได้ค่าเฉลี่ยน้อยนั้นดีกว่าการได้ค่าเฉลี่ยมาก โดย Categorical Crossentropy Loss ของ Keras จะมีการใช้งาน Logarithm ฐาน e เช่นเดียวกับ Binary Crossentropy Loss ครับ"
      ],
      "metadata": {
        "id": "0uUsqUJm4zuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorical_cross_entropy(actual, predicted):\n",
        "    sum = 0.0\n",
        "    for i in range(len(actual)):\n",
        "        for j in range(len(actual[i])):\n",
        "            sum += actual[i][j] * log(1e-15 + predicted[i][j])\n",
        "    mean = 1.0 / len(actual) * sum\n",
        "    return -mean\n",
        "\n",
        "np.around(categorical_cross_entropy(actual, predicted),5)"
      ],
      "metadata": {
        "id": "VIdTFQai40yg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be9a16ba-6118-486e-b0e2-e20d84c46793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09459"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*บวกตัวเลขขนาดเล็ก (1e+15) เพื่อป้องกันการคำนวนค่า log ของ 0"
      ],
      "metadata": {
        "id": "ylhp1YgS42H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "np.around(cce(actual, predicted).numpy(),5)"
      ],
      "metadata": {
        "id": "QP-gT45f43Ia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6020e679-729e-43e5-a4b1-ca0bf6acfd9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09459"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Example"
      ],
      "metadata": {
        "id": "u_BQ2SNw45qG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "เราจะทดลอง Train Model แบบ Multi-Class Classification จากข้อมูลที่ Make ขึ้นมาด้วยฟังก์ชัน make_blobs ตามขั้นตอนต่อไปนี้"
      ],
      "metadata": {
        "id": "FZC0yKRP4_ul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "สร้าง Dataset แบบ 3 Class โดยใช้ Function make_blobs ของ Sklearn"
      ],
      "metadata": {
        "id": "7X-8oGn05AoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=2)"
      ],
      "metadata": {
        "id": "bZzBBfvZ44a3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "เข้ารหัสผลเฉลยแบบ One-hot Encoding เพื่อสร้างการแจกแจงความน่าจะเป็นที่เราอยากได้ (Actual Probability Distribution)"
      ],
      "metadata": {
        "id": "hw1-Cw4h5Cof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y)\n",
        "\n",
        "y[:10]"
      ],
      "metadata": {
        "id": "UpBkACuU5Dmd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a5a0562-771c-4b5d-f273-3061f3b5e360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "แบ่งข้อมูลสำหรับ Train และ Test โดยการสุ่มในสัดส่วน 50:50"
      ],
      "metadata": {
        "id": "u-YZ3XqK5EqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.5, shuffle= True)\n",
        "\n",
        "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
      ],
      "metadata": {
        "id": "1EY53nMO5FtB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c853389e-314d-48c3-e343-000b03ac21d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((500, 2), (500, 2), (500, 3), (500, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "นำ Dataset ส่วนที่ Train มาแปลงเป็น DataFrame โดยเปลี่ยนชนิดข้อมูลใน Column \"class\" เป็น String เพื่อทำให้สามารถแสดงสีแบบไม่ต่อเนื่องได้ แล้วนำไป Plot"
      ],
      "metadata": {
        "id": "sRF41ezg5HlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.argmax(y_train,axis=1)\n",
        "\n",
        "x_train_pd = pd.DataFrame(x_train, columns=['x', 'y'])\n",
        "y_train_pd = pd.DataFrame(y, columns=['class'], dtype='str')\n",
        "\n",
        "df = pd.concat([x_train_pd, y_train_pd], axis=1)"
      ],
      "metadata": {
        "id": "hfjUSoWK5IkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(df, x=\"x\", y=\"y\", color=\"class\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "BKHcshVM5Jsf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "c2f7fef4-0597-4aa4-cf9e-05c237ed5977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"ad711fff-911a-4411-8c2f-3faa296403a9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ad711fff-911a-4411-8c2f-3faa296403a9\")) {                    Plotly.newPlot(                        \"ad711fff-911a-4411-8c2f-3faa296403a9\",                        [{\"hovertemplate\":\"class=1<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"1\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"1\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.4789996191255451,3.5518905685737456,1.499097789390548,1.1127114641770597,1.4558837907519386,2.2423576486190733,0.07497970090612538,1.809146282915024,-0.13698920969885364,0.3988999894371996,-0.22457883401960088,-3.075652901991754,-1.3071857847015576,3.1843340760858556,-0.4859645943309896,0.7463018649223263,-0.08704246882685873,4.061960479338628,1.6362614143831835,-0.37199764380117006,3.220082011932951,-1.1494188754239003,0.6114004282635925,-0.1629287399439472,-0.4073066171515456,2.501571503058235,4.879160843421303,2.9154581828093384,1.1009373126910778,0.8326383734992547,-0.5252011256915425,0.8013330174655211,0.8447674546002703,3.80230905034132,0.6068416170033796,1.8428516431804347,0.5249675593147216,1.0582389940163486,4.373012108026882,1.984426348266531,-2.582162512853689,3.141972382451018,4.348337685657982,2.079188045665796,-0.1441407169789648,1.5222167656993575,7.01211193468733,0.1978380454027111,1.4789981396107832,1.8172009360443995,2.0289218713228996,-0.21566712561718648,3.7672297824113214,-0.19268386418878514,-0.6806153520562153,0.5089255264477623,2.1593569103112964,0.3732832078189483,0.4969628866720774,1.7786958837859657,0.40783080150731177,-1.9321071337469369,0.22562986521904638,0.132578450215033,-0.06702925895710643,0.25251079344993876,0.6727244399082146,-2.3407046981872064,-0.360951783080145,1.504333493291922,2.5908701759422055,-0.7269426252123843,2.53865703723009,2.628950741280092,-2.2775633089804495,5.607480118958537,4.07072154542859,1.8117728796645003,-0.06723594767370278,1.6721691008245807,-1.2943521042194202,3.068379370493183,0.4178421383187302,-1.1124986603632352,0.5624012552965646,4.529844421064501,2.3864828794296886,4.611539527800225,1.5764765655680808,2.5005654163248217,0.6169587780776431,0.6993631822765526,2.4513676524689902,0.5508887056416767,0.06751780483750891,3.7775097877744486,0.219997995798758,4.475698671522132,3.019835301122817,1.7487678971785652,2.497789888409784,2.9961922176779052,-4.035507864421396,1.324146096991075,1.7025907916803624,-0.7035793572959343,-2.0434956956011656,2.0039793492004443,1.8214570534428758,0.48815779309511986,-0.20694686322485722,2.761967555364422,-1.1357717457826357,2.913893973511648,3.393727262004478,-0.2150141801771095,4.824607321818844,-1.0360758085693602,0.8302212282231324,1.3887493849324226,-0.7791886927275502,-3.213867127612276,1.4296411027060216,3.635182186289549,1.2713146111776086,2.260671175594265,3.387609228444416,-0.851637699764116,1.85160470092683,6.200648893278886,-0.3183643689664466,1.5678833337586515,-1.3358040414232288,0.38111131811230325,1.1588945181970913,-1.2234537762429363,5.152002860047304,1.522406905814833,-2.354022413337527,-1.6754676006460718,2.6908924549028495,0.007279043871790458,0.29960288804461876,2.793027745579984,-2.2745177052249277,0.6226371356068685,-0.46680667783711116,-1.8359077539521609,-1.2333530670034616,2.572294678395032,1.0634700328243623,0.6791123562556333,-0.7238225970635923,-0.6344020723231079,-0.14397444837895623,-0.05206062247424126,2.0877731645958084],\"xaxis\":\"x\",\"y\":[-1.5675087398111562,-3.0139859457552216,-2.4509249821210766,-3.286202457283068,-2.142053863132632,0.4452898795446065,0.5299435829969816,-1.2807317348087162,-0.16330867861065523,-3.5221750902240587,-1.7179404240869978,0.2294180094011995,0.07768334502339536,-3.701888085451691,-3.185055571617116,-3.4527200006399545,-1.8025745695966608,-3.3249380451512005,-1.9069717697820912,-0.12832448523092133,-2.7801468144781376,-0.17612670703461442,-2.5440591838582094,-0.8461715777411682,-0.10756656110780938,-1.2217015827242363,-4.705634275020883,0.9394798328510929,1.36728300879874,-3.877999769997728,-0.07267662512473994,-0.031609023728748964,-2.6911970523846427,-2.296577117334569,-0.8895565709617637,0.5334588195645527,-5.798922711138934,-2.8819080749018164,-2.051527724052752,-1.837194400287348,0.3471899249474064,2.6986694075805606,-3.955875604356519,-0.12340005978414426,-2.0626188167122144,-4.037700806005596,-0.9902579631070922,-1.2922947794128676,2.6668877616651914,-1.1783808464641614,-2.744182853784466,-1.061917860833852,-1.7053609223345827,-0.6703441805747887,-2.1084649943680933,-3.5125681493960625,-0.27049749708168114,-3.400216169982376,-1.1064085733782258,-1.5686292066467624,1.8763198036284825,-2.527241088304312,1.1501483739685399,-5.1941062730945955,-3.8119661783612298,-0.6105081264630806,-1.187499182114684,-0.8429165432144949,-0.9970972758232309,-2.810575192712528,-4.736611180830222,1.4490887963475467,0.8310864797451538,-1.712295835366252,-2.35025812126113,-2.5626344478774685,-2.909482120857852,-2.6857803926637125,-1.1326913499396825,0.39323386726867304,-0.700161876298334,-1.333938824772077,-1.2334320359247632,-3.0915231297803203,-2.182461690448445,-2.060522513834697,-0.7643291220956028,-1.6836279658889444,-3.0679466833953617,0.005720208741511579,-0.8416299943868601,1.7852746274879694,1.0636388051271584,1.0805206888801386,-1.722457648143037,-3.471055502401081,-3.062707554221161,-5.899617786645228,2.2219094991981025,-1.9670954281028683,-0.2999581913082203,1.0954681782388414,-2.1238360871808206,-2.818669314735578,-5.726888798728132,-4.0104602378597365,1.6243897946775476,0.18375152455189125,-3.339528585993381,-0.7420499672794137,-0.9892385609648076,-0.9957797699800089,-1.8052077931237673,-1.7580492116942927,-0.7005713787957023,-0.453226267950799,-4.614361829198565,1.1990113169818528,-1.3733391909954642,-0.6198798751716526,-3.4453366953618616,-2.796301831119373,-1.3774130035976053,-0.7575285794578315,-3.5543603283110934,-3.230551664799565,-0.8699777921118663,-2.3315015180508913,-2.6878488596464063,0.5782801522828602,-0.02225637074005915,-3.6962838218125755,-3.0457506356819053,-2.41181852169048,-3.468341741105835,-2.4737333485972113,-2.3185394145190843,0.7163361533531036,-0.2951834325392232,0.0722905935981677,-2.5600745291373377,-1.4857170606539298,-3.4251847280502243,0.18695122034273637,-0.11376353989308408,1.2135823608363308,-0.17350803063989084,-2.210408519117778,-0.7775460984245919,-1.4550480625106008,-0.8999816076950675,-1.0167141125430894,-4.491361951581016,-1.8581447486127316,-4.580637770413693,-2.151576674334739,-1.8261878844093253],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"class=0<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[-0.20198531599834713,-3.4564250947624595,-2.876799415259534,-2.505605072493064,-3.1580999526376745,-1.1970231711631178,-0.8875761689966055,-0.5136930302397951,2.003727317783969,1.3910303795215189,0.3951296307721175,0.2238277412698364,-1.508944551220166,-0.5618352935723158,-0.673633091342461,-0.7212344440701802,-2.2167944762763887,2.5239324894411483,-2.9800929625900565,-0.1560196819796289,-2.1089191522185162,0.810854018117086,-1.94145364413508,0.17060456155419224,0.897614974722889,-3.593500298196208,0.2516329605175325,-3.4459610715541147,-1.6144395058606849,-0.24225210883515902,-1.2845148479792483,3.4808669637028986,1.9620839981862863,-2.4811427679785676,-1.9071183511467424,-1.6466151047190876,-4.245032912805266,1.5005900630580933,-1.9739830207485212,-4.837303239809609,0.29801734000470215,-2.97743395936125,-0.07707032982552531,-3.02200618396057,-3.309028084200252,-1.8324609416614004,-1.5995502174026976,-1.0445088576492612,0.3182580329101059,-6.149637110202013,-0.2535990685412588,-3.841892313045266,-2.5871848452290176,0.9556715097417587,-2.009060140385242,-1.5763963395145284,-1.6581900600914292,-1.1093730903146244,0.09554636068188982,-2.4676131229251386,0.583672758624699,-0.9777076065260638,-1.9046432964772122,2.5862119755382307,-2.32988529140032,-1.3154233171408238,0.5543389981990263,-5.113362995178168,-6.599000869926901,5.279388845062874,-0.7669610531573335,3.6942671935033706,0.13508377492195356,-4.373451179688757,-0.24242970333697822,1.0989543166487414,-1.7417279733824322,1.7834186754739876,-0.7863869402263096,-2.031440803317912,0.11229400206293638,-0.5270101350918427,-1.2953042339865162,0.14402049769178138,0.29219018248665085,0.3788149040668629,-0.6259678811224512,-4.117723059456994,-0.49019551640061776,1.3014339665274943,-3.3899333058597385,-3.414236204726571,-3.494979409711199,-1.895972735681554,-1.4664976898120996,-3.0845940933009284,-3.839215724860959,-5.326829835175633,0.6262528434317685,1.9502505798633503,2.34406909709714,0.9381846055633711,-1.306781459861665,-3.036317743640609,-2.586602492743996,-1.7102022205100207,-3.6701017470096917,-0.0093744416850019,-3.253241287017609,-2.023140205871541,-2.4863835414759077,-2.4090888212830803,-0.6976339371586358,-1.9272620973129726,-3.4775798511520377,3.2849773219355,0.27885815158707095,-0.5163694889065309,2.390563488569725,-3.04551960030829,-4.70823677935199,-4.50110047418185,-2.855601037798526,-3.3271319267559853,-1.9560462558887894,-1.6262442876108745,-3.9006430150555556,-0.9884218108722822,3.3726798450824402,0.048340869631335215,-2.948976738248154,-4.756020965929061,1.655254063986901,-1.214971018534942,-0.5499949242782435,-4.035617820152115,-2.240072180225227,-3.5487389232211615,-3.478696575416773,-1.6590404865846864,-2.5168529273352824,-1.818215877591952,-2.9491323719308813,-0.44805845902439967,2.5450993998216265,-2.0878864958358037,-4.122536411768179,-0.8716859993317009,-0.7972226994765401,-4.33888466815236,6.937283290450477,-4.019379302412462,-4.9809099047428775,-2.2527391185285683,-1.0601999315184083,-1.6468554272729876,-2.6764439523257106,0.21509592639861075,0.3596682759088421,-1.722743842622509,-3.453198262927942,-1.486024019682124,-2.917900357393062,-0.05981378434661,1.4874601125788796,0.7859561746953179,-1.5792846624557217,-0.12628252154756003,-0.17719386806707615,-0.17477456595152674,-1.7026473400179398,2.2035224197845436,-2.0431349206900973,2.3817913568093316,0.08941798073789409,-3.0463530793877296],\"xaxis\":\"x\",\"y\":[-10.673794763055108,-10.99718646988111,-9.470159769179336,-12.268359397444325,-8.223923749042873,-11.717326253669206,-11.233268103472078,-10.31546366119282,-8.858079950117732,-8.876216691085975,-9.744840169945862,-11.468997329679356,-10.47782375128569,-8.237034534506307,-11.141225052862984,-13.125937900323848,-11.990915977667884,-10.642241439551611,-11.186158956819009,-10.113663419110964,-9.346848538738131,-6.743443314640237,-8.907058959122011,-10.200424281732234,-6.810851859779543,-7.013406000713024,-10.013948839434535,-11.394726403572042,-10.634697224012243,-10.46746518635126,-9.760059128979426,-11.23263802355907,-8.056108816483178,-6.2517288893156575,-7.939451887303351,-7.441765904703699,-7.788851579758014,-12.784834563025033,-8.658588330765431,-10.483058342473083,-12.724822969404835,-8.818396067228393,-9.474156382013234,-9.828598136347681,-11.712003289517417,-10.515243150907347,-8.383582243796937,-10.554845981117197,-6.956248036792534,-9.256022353808875,-10.15116361435761,-8.861782808672672,-6.663807395517225,-10.029959541169225,-11.233434318772963,-6.478601532929018,-10.380132564874822,-8.150806807597721,-8.698109634801698,-7.182474228006209,-6.544811098002875,-7.951336401517235,-5.1921191852201,-11.623068014716521,-10.661092730273328,-9.009393517613677,-6.92982156180455,-13.9361579480371,-9.66438060922349,-7.5397527233616275,-11.459033460981416,-10.384197472143475,-9.253367607587457,-13.646779234932072,-8.752579353149525,-9.439072267727934,-7.703230727665289,-13.453166911027465,-12.419026962016737,-9.630416889230135,-8.086642818888315,-9.752434892048537,-11.34913668627596,-13.082907445014017,-9.093137972125717,-8.220231428887933,-12.39219425339867,-9.985023600181822,-11.889102302331622,-8.753258126478544,-11.846989772071817,-10.787337653718732,-9.83404764594837,-9.915137892494622,-9.210212531330031,-10.663419914381064,-8.01617533661443,-8.945530210484911,-10.171959293420068,-8.630262941255513,-13.594006844916251,-13.011310819993685,-11.018121862628822,-9.794343704211421,-7.796562800299494,-11.631532491311656,-10.457336451825903,-5.277016828537036,-6.394402685235034,-3.1595434243504066,-9.397560105048187,-13.657090288019623,-9.876137259691626,-8.633825947710413,-6.312501250650821,-10.473033059871163,-7.428279462312084,-8.348924480557262,-8.600095618611954,-7.711986975039438,-9.634754491436912,-8.481595835502079,-8.631968018891591,-10.37782501013091,-8.795049899049078,-10.27216816577579,-8.754607419683,-10.28168747639649,-10.749581618715085,-8.01170602796027,-10.796912257657244,-7.3998274566607165,-10.152830040489869,-12.762595813051856,-7.933311296632776,-7.109378012069442,-11.520773562394034,-10.896317138569747,-10.844536652370225,-9.635912694148088,-8.723886432028225,-5.018741785668965,-11.47539473759053,-9.597169888725974,-9.572001769706302,-12.250512696513903,-9.788465754796071,-6.668082880119433,-8.4866240655927,-10.097450836938691,-7.8392336088183505,-4.140800873842785,-8.820499235444334,-10.138612303435186,-13.308521800036345,-11.80108915599539,-9.0015729668964,-9.947269365539729,-10.743712728612365,-11.827786606327741,-9.94331035800437,-8.143017304961562,-10.14675389313707,-8.634481562556429,-9.184776876639202,-10.139480232843587,-9.966356563705581,-8.045863973189721,-4.897059337812259,-11.162361388425168,-12.796944852308629,-10.376477115827466,-9.348497345149884,-7.601123377966716,-12.89655346454436,-6.390701710498476],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"class=2<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"2\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"2\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[-3.817822067984693,-3.8289658761550966,-0.06974715199869896,-0.8874184831738391,0.9793975553047978,-1.1807930438169478,-4.357820787951322,-2.339485706857601,-0.5925980356263365,1.499883088176015,-0.8315462382080578,-0.4923679257814295,-1.1652000899102166,-1.0682331862825025,-3.3368538428179644,-0.5578924126273088,-1.3259852023616,-2.7921344239095784,-4.602311878488992,-1.7396170529278383,-0.8333875879297449,1.1805093823701553,-2.7996680397987834,-2.5113530926828234,-2.417481280617781,-5.699538169301676,-2.9074777509936762,-0.659059909460478,3.7982107701880166,-1.4895887915186194,0.5907733021836572,-0.16172874828523942,1.346314145643547,-0.7561111366745096,-1.287223439586651,-2.3434303646345107,-0.6817842362807722,-2.554014709428208,-3.0313415965535313,-2.13868944980217,-1.8854332424502271,-1.572290852411778,-3.9584007491969477,-1.87569070554227,-0.9560024906908006,1.244611546713191,-4.500605572904243,-1.6544046100150192,-0.02886249214028913,-4.373618296060711,-2.717265577767126,-2.978440492255076,0.21904535447964646,-1.939069672655208,-3.922266610023732,-1.2557985802786549,-0.68003221666668,-2.30938891261667,-2.6495957502826366,1.8768814114373713,-4.607643012684047,-3.044708501871779,1.4951092362593141,3.2378696005114707,-0.32647853790691084,0.040690301285772446,-2.0113953728083604,-4.950063446349245,-3.0531299745415765,0.8978303933032019,-1.2862437260178106,-4.198654116227869,-1.7215493038124383,0.9316421236121442,-1.9247857192450353,-3.0810316833854454,-2.827545379227512,-2.7094179092814117,-1.9390203603172267,-2.7775517381113177,0.34536641963174497,-2.1812904456711886,-5.834190630432135,-2.1504146938089894,-1.3625114641588358,-1.3276421433337693,-1.3980727411617764,0.9985511403859935,1.8754731305221588,1.6566072969374104,2.0284193645962634,-2.447345829808844,-5.325255987051678,-1.7239887221187977,2.489951082526882,-0.9424017475590566,-0.04994847528967239,-3.342749556852463,0.4871981127474787,-2.1923114486508886,-2.4457855659259797,0.9720863494323839,-3.450541849904397,0.4929661244962298,-2.6238874142005457,-3.3702570456844727,1.2173317849452694,0.09793967374553891,-1.0696352861258454,-4.541771290304602,-1.8421434067734879,-2.2950458679513086,-1.0429111172035546,-0.3697712083022129,-2.768002650655098,-0.3061314024788815,0.24160389744230004,-0.7373618815345299,-4.608108713863379,-5.9764599238562,-1.364429469133837,-0.21797184844430983,-3.7914682072299484,-2.0298797175392993,-0.11536836427534469,0.6771075809435754,-3.663143376965434,-0.247113440394509,-4.54613212117035,-2.4919902550338837,-1.9166829795582911,-1.9057484831346208,-1.7671168523296605,0.8257975433857037,0.8819139857358032,-2.969546099914404,-1.872703062636463,0.18253362855020172,-0.2898566529418911,-1.4393461545014765,-1.4203055117040289,-3.4767131819740618,-3.570200069193896,-0.8393497373699483,-4.038201774328451,2.6382863961491987,-0.4193451631901235,0.0484759921154867,2.0159802345693847,-1.4768828573416934,-0.9375565097669925,-4.4583894284721595,-0.036913652115711626,0.13747081406180728,-1.1577839895051383,-1.9265916360355957,0.9025459064501051,0.03635051703258774,-1.7325995756283086,-1.0217610822902534,-0.7941113108780223,-1.7352604520404689,-0.5232800456056248,-1.312335614361884,-0.15528939000848063,2.6367620132332075,-2.8135431747002624],\"xaxis\":\"x\",\"y\":[-1.5983836329589232,-3.5342576816827576,-1.5887907983238294,-3.142057381918387,-0.09741431308933679,-2.77043182334942,-4.885941559621097,-1.8219860209934802,0.1824929214785289,-1.573736433880857,-6.5979320665937635,-6.643750577763033,-4.459987784141227,-5.729919292183411,-3.6862134635463586,-0.5255469924137954,-2.1968695734688524,-3.300282234422843,-4.446235424822471,-1.1385157421266356,-5.23122415093677,-2.7517527533630357,-6.179807945037216,-2.638742061424305,-5.034300919200529,-3.8693333397754857,-5.129286534861002,-5.367224512513915,-1.5976242159431449,-3.4791574150716293,-2.4449818736694526,-7.178574046958765,-5.001279119682554,-1.851267593223523,-3.9339202515586233,-5.239575375921939,-3.6230926358586135,-2.843903666272579,-5.684014447453496,-1.4123201320321666,-2.246617762905556,-3.6960837317157584,-1.2646818115659126,-3.417015036274682,-1.7284172488105567,-4.853704346906227,-6.617188556800492,-5.576447666608852,-4.230985323588229,-2.9212667572940325,-3.157476414895018,-1.6545032265255888,-2.661421286514045,-3.2251137598229254,-6.7981949424505395,-3.983781227422122,-9.3008146785607,-5.233464762096417,-1.5482789390437055,-1.2157623134064548,-5.80043079985875,-2.7396691797358197,-7.0988222404514065,-4.249190260583327,-3.7115567102945053,-3.2616587589910253,-0.4466162856820004,-1.1495303822763865,-3.3345846907514685,-1.0184760819080179,-6.860642223647583,-4.977845952953224,-3.58061216115571,-1.745315156847875,-2.1626951548546693,-1.6432822729724184,-3.462063344844929,-2.849123822096076,-4.272473951438645,-5.973170411273832,-4.034685934110865,-4.09695753585229,-6.036527663652725,-4.745000590268531,-6.931496669184261,-4.085288422392338,0.9641934407828607,-4.498916935794,-1.9635889031936506,-2.141856660441693,-0.846191999820538,0.8691893957467327,-9.666397772408995,-7.314284412260708,-2.4657950433827724,-3.0847873187036523,-2.924989832602092,-7.058020517460415,-0.4316054814243375,-5.207669940162807,-2.4162228049965533,-2.694988325358117,-1.4332419027466803,-5.077512868927957,-3.8684323664940323,-4.5746594847944735,-3.839504917832041,-3.2661914846511344,-6.87807295128547,-4.935510062184802,-6.853204005057545,-3.90983774355408,-0.12240023353407903,-0.6109912665889605,-5.398536671346067,-2.7644161114835657,-6.2212246752045255,-1.903022336261762,-5.613169531118597,-7.793347557025278,-2.8588073981139646,-4.541928771598204,-3.516676650829242,-4.504863869334146,-6.567894732882401,-4.411152654246919,-1.976248513516763,-1.8598149911370192,-3.637007820411263,-4.670953138933986,-1.9242657421335239,-4.237659873717151,-4.789437459049788,-5.280755345571913,-3.5116385213834485,-0.04208698671648525,-6.098658624006918,-8.015600224562675,-6.309579077247424,-4.982751240677635,-1.1118593849494682,-4.860153712853135,-2.9205206862049184,-3.5991400909200797,-2.101417170345329,-1.9397289312529447,-3.7310232785914392,-4.069010964978123,-3.2005109508250507,-4.566839381093423,-6.015639769322162,-4.529534842134719,-3.2818979962507866,-3.8812635564604543,-4.4005529444724045,-3.235117390457372,-0.21969913756265003,-3.7206702203891324,-5.501782847493232,-2.4732857868525304,0.9004771538183238,-2.180385827810321,-7.08369270851248,-3.536090623768556,-2.073302552799557,-3.6755190661029444,-6.935127849730566],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"title\":{\"text\":\"class\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ad711fff-911a-4411-8c2f-3faa296403a9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "นิยาม Model แบบ 3 Class โดยกำหนด Activation Function ใน Layer สุดท้ายเป็น softmax"
      ],
      "metadata": {
        "id": "nuSvB7hh5KoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(60, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))"
      ],
      "metadata": {
        "id": "ZUCQUAhF5Lj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile Model โดยกำหนด Loss Function เป็น categorical_crossentropy"
      ],
      "metadata": {
        "id": "UlHM2UKr5MmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt =  tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "zoPjuOiA5Nsk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb4d286c-3e0a-4469-fc54-f71fb91579d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model"
      ],
      "metadata": {
        "id": "O8QH_2dh5Os3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "his = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=1000, verbose=1, batch_size = 128)"
      ],
      "metadata": {
        "id": "x9zVmaqS5QFB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c99ee01c-0cbe-47b2-ef23-6f3f67eae5ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 2.7527 - accuracy: 0.4000 - val_loss: 1.9235 - val_accuracy: 0.4260\n",
            "Epoch 2/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.2621 - accuracy: 0.5000 - val_loss: 1.4684 - val_accuracy: 0.6320\n",
            "Epoch 3/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.8595 - accuracy: 0.5860 - val_loss: 1.1586 - val_accuracy: 0.6580\n",
            "Epoch 4/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.4970 - accuracy: 0.6000 - val_loss: 1.1887 - val_accuracy: 0.5340\n",
            "Epoch 5/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.2655 - accuracy: 0.5640 - val_loss: 0.8092 - val_accuracy: 0.5940\n",
            "Epoch 6/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.1762 - accuracy: 0.5500 - val_loss: 1.0131 - val_accuracy: 0.6640\n",
            "Epoch 7/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2825 - accuracy: 0.5920 - val_loss: 0.9863 - val_accuracy: 0.6600\n",
            "Epoch 8/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.5426 - accuracy: 0.5920 - val_loss: 0.6863 - val_accuracy: 0.7080\n",
            "Epoch 9/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.4154 - accuracy: 0.5700 - val_loss: 1.3364 - val_accuracy: 0.5880\n",
            "Epoch 10/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2860 - accuracy: 0.5500 - val_loss: 0.8813 - val_accuracy: 0.6480\n",
            "Epoch 11/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2513 - accuracy: 0.6120 - val_loss: 0.8526 - val_accuracy: 0.7120\n",
            "Epoch 12/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0868 - accuracy: 0.6240 - val_loss: 0.9748 - val_accuracy: 0.6320\n",
            "Epoch 13/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9847 - accuracy: 0.6060 - val_loss: 1.0413 - val_accuracy: 0.4600\n",
            "Epoch 14/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1413 - accuracy: 0.5540 - val_loss: 0.6320 - val_accuracy: 0.7120\n",
            "Epoch 15/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.9354 - accuracy: 0.6260 - val_loss: 0.8833 - val_accuracy: 0.6560\n",
            "Epoch 16/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.8628 - accuracy: 0.6480 - val_loss: 0.6863 - val_accuracy: 0.7040\n",
            "Epoch 17/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.8103 - accuracy: 0.6720 - val_loss: 0.7538 - val_accuracy: 0.7100\n",
            "Epoch 18/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7805 - accuracy: 0.6400 - val_loss: 0.8183 - val_accuracy: 0.6600\n",
            "Epoch 19/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.8379 - accuracy: 0.6540 - val_loss: 0.6272 - val_accuracy: 0.7320\n",
            "Epoch 20/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.7555 - accuracy: 0.6780 - val_loss: 0.7003 - val_accuracy: 0.7640\n",
            "Epoch 21/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7075 - accuracy: 0.6720 - val_loss: 0.6224 - val_accuracy: 0.7060\n",
            "Epoch 22/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6679 - accuracy: 0.7140 - val_loss: 0.5948 - val_accuracy: 0.7220\n",
            "Epoch 23/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7028 - accuracy: 0.6880 - val_loss: 0.5636 - val_accuracy: 0.7660\n",
            "Epoch 24/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6382 - accuracy: 0.7180 - val_loss: 0.5850 - val_accuracy: 0.8100\n",
            "Epoch 25/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6363 - accuracy: 0.7180 - val_loss: 0.5631 - val_accuracy: 0.8080\n",
            "Epoch 26/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6123 - accuracy: 0.7200 - val_loss: 0.5663 - val_accuracy: 0.8140\n",
            "Epoch 27/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6440 - accuracy: 0.6960 - val_loss: 0.5679 - val_accuracy: 0.8020\n",
            "Epoch 28/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5930 - accuracy: 0.7400 - val_loss: 0.6388 - val_accuracy: 0.7180\n",
            "Epoch 29/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6787 - accuracy: 0.6920 - val_loss: 0.5546 - val_accuracy: 0.7600\n",
            "Epoch 30/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6417 - accuracy: 0.7040 - val_loss: 0.6541 - val_accuracy: 0.7420\n",
            "Epoch 31/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6328 - accuracy: 0.7240 - val_loss: 0.5259 - val_accuracy: 0.7820\n",
            "Epoch 32/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5768 - accuracy: 0.7420 - val_loss: 0.5517 - val_accuracy: 0.7600\n",
            "Epoch 33/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5954 - accuracy: 0.7120 - val_loss: 0.5497 - val_accuracy: 0.7480\n",
            "Epoch 34/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5988 - accuracy: 0.7380 - val_loss: 0.5534 - val_accuracy: 0.8120\n",
            "Epoch 35/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5806 - accuracy: 0.7360 - val_loss: 0.5587 - val_accuracy: 0.7540\n",
            "Epoch 36/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5517 - accuracy: 0.7600 - val_loss: 0.5379 - val_accuracy: 0.7660\n",
            "Epoch 37/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5838 - accuracy: 0.7400 - val_loss: 0.5351 - val_accuracy: 0.7920\n",
            "Epoch 38/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5626 - accuracy: 0.7440 - val_loss: 0.5276 - val_accuracy: 0.7980\n",
            "Epoch 39/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5616 - accuracy: 0.7520 - val_loss: 0.5087 - val_accuracy: 0.7940\n",
            "Epoch 40/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5449 - accuracy: 0.7520 - val_loss: 0.5279 - val_accuracy: 0.8120\n",
            "Epoch 41/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5426 - accuracy: 0.7700 - val_loss: 0.5151 - val_accuracy: 0.8080\n",
            "Epoch 42/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5503 - accuracy: 0.7720 - val_loss: 0.5067 - val_accuracy: 0.8020\n",
            "Epoch 43/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5734 - accuracy: 0.7420 - val_loss: 0.5431 - val_accuracy: 0.7560\n",
            "Epoch 44/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5499 - accuracy: 0.7620 - val_loss: 0.5035 - val_accuracy: 0.7940\n",
            "Epoch 45/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5466 - accuracy: 0.7740 - val_loss: 0.5081 - val_accuracy: 0.8260\n",
            "Epoch 46/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5539 - accuracy: 0.7560 - val_loss: 0.5092 - val_accuracy: 0.8000\n",
            "Epoch 47/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5443 - accuracy: 0.7760 - val_loss: 0.5237 - val_accuracy: 0.7640\n",
            "Epoch 48/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5727 - accuracy: 0.7540 - val_loss: 0.5170 - val_accuracy: 0.7920\n",
            "Epoch 49/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5332 - accuracy: 0.7420 - val_loss: 0.5313 - val_accuracy: 0.8300\n",
            "Epoch 50/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5599 - accuracy: 0.7540 - val_loss: 0.4956 - val_accuracy: 0.7820\n",
            "Epoch 51/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.7780 - val_loss: 0.5062 - val_accuracy: 0.7980\n",
            "Epoch 52/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5506 - accuracy: 0.7560 - val_loss: 0.5084 - val_accuracy: 0.7880\n",
            "Epoch 53/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5357 - accuracy: 0.7640 - val_loss: 0.4948 - val_accuracy: 0.8100\n",
            "Epoch 54/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5264 - accuracy: 0.7800 - val_loss: 0.4974 - val_accuracy: 0.8080\n",
            "Epoch 55/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5288 - accuracy: 0.7600 - val_loss: 0.4966 - val_accuracy: 0.8120\n",
            "Epoch 56/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5406 - accuracy: 0.7740 - val_loss: 0.4941 - val_accuracy: 0.8060\n",
            "Epoch 57/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5349 - accuracy: 0.7820 - val_loss: 0.4895 - val_accuracy: 0.8080\n",
            "Epoch 58/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5275 - accuracy: 0.7620 - val_loss: 0.5116 - val_accuracy: 0.7680\n",
            "Epoch 59/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5548 - accuracy: 0.7760 - val_loss: 0.4923 - val_accuracy: 0.8160\n",
            "Epoch 60/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5222 - accuracy: 0.7840 - val_loss: 0.5061 - val_accuracy: 0.8300\n",
            "Epoch 61/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5272 - accuracy: 0.7840 - val_loss: 0.4853 - val_accuracy: 0.7920\n",
            "Epoch 62/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5171 - accuracy: 0.7660 - val_loss: 0.4918 - val_accuracy: 0.8260\n",
            "Epoch 63/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5095 - accuracy: 0.7960 - val_loss: 0.4832 - val_accuracy: 0.8100\n",
            "Epoch 64/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5111 - accuracy: 0.7780 - val_loss: 0.4840 - val_accuracy: 0.8120\n",
            "Epoch 65/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5188 - accuracy: 0.7940 - val_loss: 0.4884 - val_accuracy: 0.7960\n",
            "Epoch 66/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5353 - accuracy: 0.7780 - val_loss: 0.5369 - val_accuracy: 0.8160\n",
            "Epoch 67/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5398 - accuracy: 0.7760 - val_loss: 0.4918 - val_accuracy: 0.8100\n",
            "Epoch 68/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5523 - accuracy: 0.7540 - val_loss: 0.5421 - val_accuracy: 0.7440\n",
            "Epoch 69/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5614 - accuracy: 0.7500 - val_loss: 0.4842 - val_accuracy: 0.8420\n",
            "Epoch 70/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5234 - accuracy: 0.7620 - val_loss: 0.4729 - val_accuracy: 0.8200\n",
            "Epoch 71/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5185 - accuracy: 0.7700 - val_loss: 0.5173 - val_accuracy: 0.7700\n",
            "Epoch 72/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5455 - accuracy: 0.7540 - val_loss: 0.4836 - val_accuracy: 0.8180\n",
            "Epoch 73/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5244 - accuracy: 0.7760 - val_loss: 0.4710 - val_accuracy: 0.8160\n",
            "Epoch 74/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5295 - accuracy: 0.7840 - val_loss: 0.5010 - val_accuracy: 0.7780\n",
            "Epoch 75/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5200 - accuracy: 0.7680 - val_loss: 0.4781 - val_accuracy: 0.8140\n",
            "Epoch 76/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5129 - accuracy: 0.7840 - val_loss: 0.4689 - val_accuracy: 0.8200\n",
            "Epoch 77/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5275 - accuracy: 0.7800 - val_loss: 0.5247 - val_accuracy: 0.7600\n",
            "Epoch 78/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5176 - accuracy: 0.7660 - val_loss: 0.5964 - val_accuracy: 0.7620\n",
            "Epoch 79/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6076 - accuracy: 0.7180 - val_loss: 0.5601 - val_accuracy: 0.7400\n",
            "Epoch 80/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5770 - accuracy: 0.7400 - val_loss: 0.4653 - val_accuracy: 0.8160\n",
            "Epoch 81/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5187 - accuracy: 0.7780 - val_loss: 0.4801 - val_accuracy: 0.8040\n",
            "Epoch 82/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5212 - accuracy: 0.7760 - val_loss: 0.4713 - val_accuracy: 0.7980\n",
            "Epoch 83/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5047 - accuracy: 0.7900 - val_loss: 0.4960 - val_accuracy: 0.8340\n",
            "Epoch 84/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4867 - accuracy: 0.7900 - val_loss: 0.4729 - val_accuracy: 0.7960\n",
            "Epoch 85/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4985 - accuracy: 0.7800 - val_loss: 0.4910 - val_accuracy: 0.8120\n",
            "Epoch 86/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5149 - accuracy: 0.7740 - val_loss: 0.4674 - val_accuracy: 0.8060\n",
            "Epoch 87/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4940 - accuracy: 0.7880 - val_loss: 0.4596 - val_accuracy: 0.8180\n",
            "Epoch 88/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4889 - accuracy: 0.7940 - val_loss: 0.4610 - val_accuracy: 0.8140\n",
            "Epoch 89/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4889 - accuracy: 0.7880 - val_loss: 0.4626 - val_accuracy: 0.7940\n",
            "Epoch 90/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5005 - accuracy: 0.7740 - val_loss: 0.5169 - val_accuracy: 0.8160\n",
            "Epoch 91/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5312 - accuracy: 0.7640 - val_loss: 0.4648 - val_accuracy: 0.8020\n",
            "Epoch 92/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4943 - accuracy: 0.8000 - val_loss: 0.4730 - val_accuracy: 0.7920\n",
            "Epoch 93/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5014 - accuracy: 0.7700 - val_loss: 0.4894 - val_accuracy: 0.8240\n",
            "Epoch 94/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5184 - accuracy: 0.7760 - val_loss: 0.4558 - val_accuracy: 0.8100\n",
            "Epoch 95/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4705 - accuracy: 0.8000 - val_loss: 0.4535 - val_accuracy: 0.8140\n",
            "Epoch 96/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4936 - accuracy: 0.7880 - val_loss: 0.4585 - val_accuracy: 0.8200\n",
            "Epoch 97/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4942 - accuracy: 0.7940 - val_loss: 0.4538 - val_accuracy: 0.8060\n",
            "Epoch 98/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4773 - accuracy: 0.7960 - val_loss: 0.4486 - val_accuracy: 0.8160\n",
            "Epoch 99/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4926 - accuracy: 0.7920 - val_loss: 0.4562 - val_accuracy: 0.8360\n",
            "Epoch 100/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4946 - accuracy: 0.7880 - val_loss: 0.4552 - val_accuracy: 0.8040\n",
            "Epoch 101/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4726 - accuracy: 0.7980 - val_loss: 0.4538 - val_accuracy: 0.8320\n",
            "Epoch 102/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4730 - accuracy: 0.7860 - val_loss: 0.4483 - val_accuracy: 0.8120\n",
            "Epoch 103/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4671 - accuracy: 0.8000 - val_loss: 0.4519 - val_accuracy: 0.8200\n",
            "Epoch 104/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4922 - accuracy: 0.7940 - val_loss: 0.4526 - val_accuracy: 0.8240\n",
            "Epoch 105/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5057 - accuracy: 0.7800 - val_loss: 0.4599 - val_accuracy: 0.8280\n",
            "Epoch 106/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4863 - accuracy: 0.7960 - val_loss: 0.4656 - val_accuracy: 0.8040\n",
            "Epoch 107/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4799 - accuracy: 0.7960 - val_loss: 0.4696 - val_accuracy: 0.8300\n",
            "Epoch 108/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4750 - accuracy: 0.7940 - val_loss: 0.4575 - val_accuracy: 0.7980\n",
            "Epoch 109/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4853 - accuracy: 0.7880 - val_loss: 0.4656 - val_accuracy: 0.8380\n",
            "Epoch 110/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4776 - accuracy: 0.7860 - val_loss: 0.4460 - val_accuracy: 0.8140\n",
            "Epoch 111/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4661 - accuracy: 0.7960 - val_loss: 0.4503 - val_accuracy: 0.8380\n",
            "Epoch 112/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4692 - accuracy: 0.8020 - val_loss: 0.4456 - val_accuracy: 0.8160\n",
            "Epoch 113/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4554 - accuracy: 0.8100 - val_loss: 0.4445 - val_accuracy: 0.8040\n",
            "Epoch 114/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4648 - accuracy: 0.7960 - val_loss: 0.4482 - val_accuracy: 0.8420\n",
            "Epoch 115/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4633 - accuracy: 0.7960 - val_loss: 0.4406 - val_accuracy: 0.8180\n",
            "Epoch 116/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4387 - accuracy: 0.8160 - val_loss: 0.4502 - val_accuracy: 0.8300\n",
            "Epoch 117/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4626 - accuracy: 0.7940 - val_loss: 0.4428 - val_accuracy: 0.8180\n",
            "Epoch 118/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4541 - accuracy: 0.8000 - val_loss: 0.4444 - val_accuracy: 0.8340\n",
            "Epoch 119/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4669 - accuracy: 0.8040 - val_loss: 0.4407 - val_accuracy: 0.8080\n",
            "Epoch 120/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4582 - accuracy: 0.8220 - val_loss: 0.4683 - val_accuracy: 0.8320\n",
            "Epoch 121/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4650 - accuracy: 0.8060 - val_loss: 0.4482 - val_accuracy: 0.8040\n",
            "Epoch 122/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4698 - accuracy: 0.8000 - val_loss: 0.4617 - val_accuracy: 0.8300\n",
            "Epoch 123/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4855 - accuracy: 0.8000 - val_loss: 0.4537 - val_accuracy: 0.8120\n",
            "Epoch 124/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5009 - accuracy: 0.7720 - val_loss: 0.4475 - val_accuracy: 0.8080\n",
            "Epoch 125/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4781 - accuracy: 0.7980 - val_loss: 0.4575 - val_accuracy: 0.8300\n",
            "Epoch 126/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4779 - accuracy: 0.8020 - val_loss: 0.4420 - val_accuracy: 0.8220\n",
            "Epoch 127/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4537 - accuracy: 0.8020 - val_loss: 0.4386 - val_accuracy: 0.8300\n",
            "Epoch 128/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4539 - accuracy: 0.8140 - val_loss: 0.4353 - val_accuracy: 0.8180\n",
            "Epoch 129/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4538 - accuracy: 0.8040 - val_loss: 0.4344 - val_accuracy: 0.8280\n",
            "Epoch 130/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4761 - accuracy: 0.7860 - val_loss: 0.4443 - val_accuracy: 0.8260\n",
            "Epoch 131/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4679 - accuracy: 0.8000 - val_loss: 0.4406 - val_accuracy: 0.8320\n",
            "Epoch 132/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4736 - accuracy: 0.7940 - val_loss: 0.4438 - val_accuracy: 0.8060\n",
            "Epoch 133/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4747 - accuracy: 0.7960 - val_loss: 0.4508 - val_accuracy: 0.8420\n",
            "Epoch 134/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4553 - accuracy: 0.7980 - val_loss: 0.4361 - val_accuracy: 0.8100\n",
            "Epoch 135/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4550 - accuracy: 0.7940 - val_loss: 0.4430 - val_accuracy: 0.8360\n",
            "Epoch 136/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4547 - accuracy: 0.8100 - val_loss: 0.4304 - val_accuracy: 0.8300\n",
            "Epoch 137/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4474 - accuracy: 0.8060 - val_loss: 0.4284 - val_accuracy: 0.8200\n",
            "Epoch 138/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4620 - accuracy: 0.7980 - val_loss: 0.4310 - val_accuracy: 0.8260\n",
            "Epoch 139/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4424 - accuracy: 0.8160 - val_loss: 0.4314 - val_accuracy: 0.8200\n",
            "Epoch 140/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4514 - accuracy: 0.8080 - val_loss: 0.4312 - val_accuracy: 0.8220\n",
            "Epoch 141/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4787 - accuracy: 0.7920 - val_loss: 0.4352 - val_accuracy: 0.8380\n",
            "Epoch 142/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4530 - accuracy: 0.8060 - val_loss: 0.4328 - val_accuracy: 0.8120\n",
            "Epoch 143/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4430 - accuracy: 0.8040 - val_loss: 0.4326 - val_accuracy: 0.8240\n",
            "Epoch 144/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4677 - accuracy: 0.7920 - val_loss: 0.4326 - val_accuracy: 0.8280\n",
            "Epoch 145/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4764 - accuracy: 0.7980 - val_loss: 0.4465 - val_accuracy: 0.8060\n",
            "Epoch 146/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4690 - accuracy: 0.8000 - val_loss: 0.4532 - val_accuracy: 0.8300\n",
            "Epoch 147/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4539 - accuracy: 0.8100 - val_loss: 0.4400 - val_accuracy: 0.8160\n",
            "Epoch 148/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4801 - accuracy: 0.7920 - val_loss: 0.4705 - val_accuracy: 0.8280\n",
            "Epoch 149/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4748 - accuracy: 0.7900 - val_loss: 0.4537 - val_accuracy: 0.8100\n",
            "Epoch 150/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4766 - accuracy: 0.7940 - val_loss: 0.4561 - val_accuracy: 0.8360\n",
            "Epoch 151/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4587 - accuracy: 0.7960 - val_loss: 0.4259 - val_accuracy: 0.8220\n",
            "Epoch 152/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4589 - accuracy: 0.8060 - val_loss: 0.4246 - val_accuracy: 0.8200\n",
            "Epoch 153/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4248 - accuracy: 0.8020 - val_loss: 0.4262 - val_accuracy: 0.8260\n",
            "Epoch 154/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4622 - accuracy: 0.7900 - val_loss: 0.4330 - val_accuracy: 0.8420\n",
            "Epoch 155/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4487 - accuracy: 0.8120 - val_loss: 0.4312 - val_accuracy: 0.8160\n",
            "Epoch 156/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4551 - accuracy: 0.8100 - val_loss: 0.4344 - val_accuracy: 0.8400\n",
            "Epoch 157/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4643 - accuracy: 0.8000 - val_loss: 0.4243 - val_accuracy: 0.8300\n",
            "Epoch 158/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4667 - accuracy: 0.8060 - val_loss: 0.4296 - val_accuracy: 0.8280\n",
            "Epoch 159/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4380 - accuracy: 0.8140 - val_loss: 0.4317 - val_accuracy: 0.8320\n",
            "Epoch 160/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4518 - accuracy: 0.8100 - val_loss: 0.4287 - val_accuracy: 0.8300\n",
            "Epoch 161/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4318 - accuracy: 0.8080 - val_loss: 0.4258 - val_accuracy: 0.8240\n",
            "Epoch 162/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4479 - accuracy: 0.7900 - val_loss: 0.4245 - val_accuracy: 0.8220\n",
            "Epoch 163/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4435 - accuracy: 0.8120 - val_loss: 0.4345 - val_accuracy: 0.8360\n",
            "Epoch 164/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4460 - accuracy: 0.7980 - val_loss: 0.4220 - val_accuracy: 0.8200\n",
            "Epoch 165/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4561 - accuracy: 0.8120 - val_loss: 0.4266 - val_accuracy: 0.8360\n",
            "Epoch 166/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4672 - accuracy: 0.8040 - val_loss: 0.4271 - val_accuracy: 0.8180\n",
            "Epoch 167/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4547 - accuracy: 0.8100 - val_loss: 0.4272 - val_accuracy: 0.8240\n",
            "Epoch 168/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4549 - accuracy: 0.8000 - val_loss: 0.4241 - val_accuracy: 0.8260\n",
            "Epoch 169/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4746 - accuracy: 0.7960 - val_loss: 0.4313 - val_accuracy: 0.8280\n",
            "Epoch 170/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4885 - accuracy: 0.8020 - val_loss: 0.4327 - val_accuracy: 0.8140\n",
            "Epoch 171/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4716 - accuracy: 0.8000 - val_loss: 0.4425 - val_accuracy: 0.8240\n",
            "Epoch 172/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4393 - accuracy: 0.7940 - val_loss: 0.4264 - val_accuracy: 0.8220\n",
            "Epoch 173/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4491 - accuracy: 0.8040 - val_loss: 0.4315 - val_accuracy: 0.8300\n",
            "Epoch 174/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4517 - accuracy: 0.7960 - val_loss: 0.4257 - val_accuracy: 0.8400\n",
            "Epoch 175/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4561 - accuracy: 0.8040 - val_loss: 0.4209 - val_accuracy: 0.8320\n",
            "Epoch 176/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4511 - accuracy: 0.8060 - val_loss: 0.4311 - val_accuracy: 0.8360\n",
            "Epoch 177/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4600 - accuracy: 0.7960 - val_loss: 0.4235 - val_accuracy: 0.8140\n",
            "Epoch 178/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4442 - accuracy: 0.8060 - val_loss: 0.4369 - val_accuracy: 0.8380\n",
            "Epoch 179/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4608 - accuracy: 0.8100 - val_loss: 0.4206 - val_accuracy: 0.8260\n",
            "Epoch 180/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4469 - accuracy: 0.8040 - val_loss: 0.4338 - val_accuracy: 0.8340\n",
            "Epoch 181/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4491 - accuracy: 0.8260 - val_loss: 0.4219 - val_accuracy: 0.8280\n",
            "Epoch 182/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4413 - accuracy: 0.8060 - val_loss: 0.4320 - val_accuracy: 0.8360\n",
            "Epoch 183/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4394 - accuracy: 0.8020 - val_loss: 0.4317 - val_accuracy: 0.8120\n",
            "Epoch 184/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4568 - accuracy: 0.8040 - val_loss: 0.4433 - val_accuracy: 0.8320\n",
            "Epoch 185/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4512 - accuracy: 0.8080 - val_loss: 0.4312 - val_accuracy: 0.8140\n",
            "Epoch 186/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4739 - accuracy: 0.8080 - val_loss: 0.4300 - val_accuracy: 0.8340\n",
            "Epoch 187/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4811 - accuracy: 0.7840 - val_loss: 0.4307 - val_accuracy: 0.8200\n",
            "Epoch 188/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4916 - accuracy: 0.7900 - val_loss: 0.4302 - val_accuracy: 0.8320\n",
            "Epoch 189/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4514 - accuracy: 0.8040 - val_loss: 0.4202 - val_accuracy: 0.8220\n",
            "Epoch 190/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4573 - accuracy: 0.7980 - val_loss: 0.4240 - val_accuracy: 0.8320\n",
            "Epoch 191/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4667 - accuracy: 0.7860 - val_loss: 0.4314 - val_accuracy: 0.8160\n",
            "Epoch 192/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4884 - accuracy: 0.7880 - val_loss: 0.4224 - val_accuracy: 0.8260\n",
            "Epoch 193/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4525 - accuracy: 0.8040 - val_loss: 0.4180 - val_accuracy: 0.8180\n",
            "Epoch 194/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4609 - accuracy: 0.7920 - val_loss: 0.4198 - val_accuracy: 0.8320\n",
            "Epoch 195/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4366 - accuracy: 0.8240 - val_loss: 0.4226 - val_accuracy: 0.8380\n",
            "Epoch 196/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4575 - accuracy: 0.8160 - val_loss: 0.4186 - val_accuracy: 0.8340\n",
            "Epoch 197/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4506 - accuracy: 0.8020 - val_loss: 0.4247 - val_accuracy: 0.8340\n",
            "Epoch 198/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4400 - accuracy: 0.8100 - val_loss: 0.4199 - val_accuracy: 0.8280\n",
            "Epoch 199/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4437 - accuracy: 0.8200 - val_loss: 0.4219 - val_accuracy: 0.8340\n",
            "Epoch 200/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4649 - accuracy: 0.8020 - val_loss: 0.4183 - val_accuracy: 0.8240\n",
            "Epoch 201/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4523 - accuracy: 0.8040 - val_loss: 0.4174 - val_accuracy: 0.8320\n",
            "Epoch 202/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4351 - accuracy: 0.8180 - val_loss: 0.4198 - val_accuracy: 0.8280\n",
            "Epoch 203/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4366 - accuracy: 0.8040 - val_loss: 0.4210 - val_accuracy: 0.8360\n",
            "Epoch 204/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4326 - accuracy: 0.8200 - val_loss: 0.4167 - val_accuracy: 0.8340\n",
            "Epoch 205/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4417 - accuracy: 0.8180 - val_loss: 0.4267 - val_accuracy: 0.8360\n",
            "Epoch 206/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4326 - accuracy: 0.8100 - val_loss: 0.4206 - val_accuracy: 0.8220\n",
            "Epoch 207/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4353 - accuracy: 0.8140 - val_loss: 0.4358 - val_accuracy: 0.8380\n",
            "Epoch 208/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4539 - accuracy: 0.8080 - val_loss: 0.4240 - val_accuracy: 0.8240\n",
            "Epoch 209/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4498 - accuracy: 0.8020 - val_loss: 0.4279 - val_accuracy: 0.8340\n",
            "Epoch 210/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4488 - accuracy: 0.8080 - val_loss: 0.4212 - val_accuracy: 0.8180\n",
            "Epoch 211/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4522 - accuracy: 0.8120 - val_loss: 0.4282 - val_accuracy: 0.8320\n",
            "Epoch 212/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4444 - accuracy: 0.8080 - val_loss: 0.4181 - val_accuracy: 0.8300\n",
            "Epoch 213/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4464 - accuracy: 0.8060 - val_loss: 0.4165 - val_accuracy: 0.8300\n",
            "Epoch 214/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4271 - accuracy: 0.8220 - val_loss: 0.4201 - val_accuracy: 0.8400\n",
            "Epoch 215/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4345 - accuracy: 0.8160 - val_loss: 0.4166 - val_accuracy: 0.8320\n",
            "Epoch 216/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4356 - accuracy: 0.8160 - val_loss: 0.4208 - val_accuracy: 0.8360\n",
            "Epoch 217/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4381 - accuracy: 0.8200 - val_loss: 0.4147 - val_accuracy: 0.8300\n",
            "Epoch 218/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4373 - accuracy: 0.8200 - val_loss: 0.4180 - val_accuracy: 0.8380\n",
            "Epoch 219/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4417 - accuracy: 0.8020 - val_loss: 0.4185 - val_accuracy: 0.8260\n",
            "Epoch 220/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4486 - accuracy: 0.8040 - val_loss: 0.4235 - val_accuracy: 0.8380\n",
            "Epoch 221/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4424 - accuracy: 0.8060 - val_loss: 0.4165 - val_accuracy: 0.8240\n",
            "Epoch 222/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4278 - accuracy: 0.8260 - val_loss: 0.4147 - val_accuracy: 0.8300\n",
            "Epoch 223/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4459 - accuracy: 0.8180 - val_loss: 0.4244 - val_accuracy: 0.8380\n",
            "Epoch 224/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4369 - accuracy: 0.8180 - val_loss: 0.4172 - val_accuracy: 0.8180\n",
            "Epoch 225/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4559 - accuracy: 0.7940 - val_loss: 0.4168 - val_accuracy: 0.8360\n",
            "Epoch 226/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4352 - accuracy: 0.8060 - val_loss: 0.4195 - val_accuracy: 0.8340\n",
            "Epoch 227/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4373 - accuracy: 0.8180 - val_loss: 0.4188 - val_accuracy: 0.8300\n",
            "Epoch 228/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4401 - accuracy: 0.8120 - val_loss: 0.4216 - val_accuracy: 0.8360\n",
            "Epoch 229/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4423 - accuracy: 0.8060 - val_loss: 0.4152 - val_accuracy: 0.8240\n",
            "Epoch 230/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4315 - accuracy: 0.8100 - val_loss: 0.4199 - val_accuracy: 0.8320\n",
            "Epoch 231/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4341 - accuracy: 0.8200 - val_loss: 0.4189 - val_accuracy: 0.8340\n",
            "Epoch 232/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4321 - accuracy: 0.8060 - val_loss: 0.4276 - val_accuracy: 0.8420\n",
            "Epoch 233/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4412 - accuracy: 0.8100 - val_loss: 0.4202 - val_accuracy: 0.8260\n",
            "Epoch 234/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4455 - accuracy: 0.8080 - val_loss: 0.4335 - val_accuracy: 0.8340\n",
            "Epoch 235/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4423 - accuracy: 0.8020 - val_loss: 0.4204 - val_accuracy: 0.8340\n",
            "Epoch 236/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4356 - accuracy: 0.8060 - val_loss: 0.4176 - val_accuracy: 0.8360\n",
            "Epoch 237/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4336 - accuracy: 0.8080 - val_loss: 0.4181 - val_accuracy: 0.8300\n",
            "Epoch 238/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4279 - accuracy: 0.8140 - val_loss: 0.4139 - val_accuracy: 0.8260\n",
            "Epoch 239/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4325 - accuracy: 0.8140 - val_loss: 0.4237 - val_accuracy: 0.8440\n",
            "Epoch 240/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4482 - accuracy: 0.7960 - val_loss: 0.4159 - val_accuracy: 0.8220\n",
            "Epoch 241/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4317 - accuracy: 0.8140 - val_loss: 0.4217 - val_accuracy: 0.8380\n",
            "Epoch 242/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4408 - accuracy: 0.8060 - val_loss: 0.4146 - val_accuracy: 0.8280\n",
            "Epoch 243/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4370 - accuracy: 0.7980 - val_loss: 0.4169 - val_accuracy: 0.8340\n",
            "Epoch 244/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4181 - accuracy: 0.8180 - val_loss: 0.4150 - val_accuracy: 0.8260\n",
            "Epoch 245/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4383 - accuracy: 0.8160 - val_loss: 0.4216 - val_accuracy: 0.8400\n",
            "Epoch 246/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4324 - accuracy: 0.8160 - val_loss: 0.4121 - val_accuracy: 0.8240\n",
            "Epoch 247/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4306 - accuracy: 0.8160 - val_loss: 0.4243 - val_accuracy: 0.8420\n",
            "Epoch 248/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4292 - accuracy: 0.8160 - val_loss: 0.4133 - val_accuracy: 0.8320\n",
            "Epoch 249/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4413 - accuracy: 0.8180 - val_loss: 0.4125 - val_accuracy: 0.8340\n",
            "Epoch 250/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4321 - accuracy: 0.8180 - val_loss: 0.4287 - val_accuracy: 0.8320\n",
            "Epoch 251/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4466 - accuracy: 0.8040 - val_loss: 0.4145 - val_accuracy: 0.8280\n",
            "Epoch 252/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4414 - accuracy: 0.8020 - val_loss: 0.4222 - val_accuracy: 0.8420\n",
            "Epoch 253/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4341 - accuracy: 0.8180 - val_loss: 0.4150 - val_accuracy: 0.8320\n",
            "Epoch 254/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4440 - accuracy: 0.8140 - val_loss: 0.4208 - val_accuracy: 0.8280\n",
            "Epoch 255/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4513 - accuracy: 0.8120 - val_loss: 0.4171 - val_accuracy: 0.8300\n",
            "Epoch 256/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4322 - accuracy: 0.8140 - val_loss: 0.4188 - val_accuracy: 0.8440\n",
            "Epoch 257/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4384 - accuracy: 0.8140 - val_loss: 0.4151 - val_accuracy: 0.8320\n",
            "Epoch 258/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4327 - accuracy: 0.8180 - val_loss: 0.4119 - val_accuracy: 0.8340\n",
            "Epoch 259/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4259 - accuracy: 0.8120 - val_loss: 0.4166 - val_accuracy: 0.8360\n",
            "Epoch 260/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4423 - accuracy: 0.8040 - val_loss: 0.4146 - val_accuracy: 0.8320\n",
            "Epoch 261/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4266 - accuracy: 0.8140 - val_loss: 0.4162 - val_accuracy: 0.8420\n",
            "Epoch 262/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4361 - accuracy: 0.8080 - val_loss: 0.4116 - val_accuracy: 0.8360\n",
            "Epoch 263/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4347 - accuracy: 0.8180 - val_loss: 0.4141 - val_accuracy: 0.8340\n",
            "Epoch 264/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4360 - accuracy: 0.8040 - val_loss: 0.4129 - val_accuracy: 0.8280\n",
            "Epoch 265/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4352 - accuracy: 0.8000 - val_loss: 0.4095 - val_accuracy: 0.8260\n",
            "Epoch 266/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4384 - accuracy: 0.8160 - val_loss: 0.4115 - val_accuracy: 0.8300\n",
            "Epoch 267/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4319 - accuracy: 0.8120 - val_loss: 0.4114 - val_accuracy: 0.8300\n",
            "Epoch 268/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4562 - accuracy: 0.7980 - val_loss: 0.4178 - val_accuracy: 0.8420\n",
            "Epoch 269/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4419 - accuracy: 0.8020 - val_loss: 0.4145 - val_accuracy: 0.8240\n",
            "Epoch 270/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4509 - accuracy: 0.8040 - val_loss: 0.4168 - val_accuracy: 0.8400\n",
            "Epoch 271/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4546 - accuracy: 0.8060 - val_loss: 0.4128 - val_accuracy: 0.8360\n",
            "Epoch 272/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4335 - accuracy: 0.8020 - val_loss: 0.4457 - val_accuracy: 0.8340\n",
            "Epoch 273/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4427 - accuracy: 0.8100 - val_loss: 0.4157 - val_accuracy: 0.8200\n",
            "Epoch 274/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4285 - accuracy: 0.8240 - val_loss: 0.4216 - val_accuracy: 0.8380\n",
            "Epoch 275/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4237 - accuracy: 0.8220 - val_loss: 0.4113 - val_accuracy: 0.8380\n",
            "Epoch 276/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4287 - accuracy: 0.8060 - val_loss: 0.4157 - val_accuracy: 0.8380\n",
            "Epoch 277/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4303 - accuracy: 0.8320 - val_loss: 0.4129 - val_accuracy: 0.8360\n",
            "Epoch 278/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4400 - accuracy: 0.8120 - val_loss: 0.4106 - val_accuracy: 0.8360\n",
            "Epoch 279/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4412 - accuracy: 0.7960 - val_loss: 0.4175 - val_accuracy: 0.8400\n",
            "Epoch 280/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4254 - accuracy: 0.8100 - val_loss: 0.4091 - val_accuracy: 0.8260\n",
            "Epoch 281/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4313 - accuracy: 0.8160 - val_loss: 0.4094 - val_accuracy: 0.8360\n",
            "Epoch 282/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4306 - accuracy: 0.8300 - val_loss: 0.4126 - val_accuracy: 0.8420\n",
            "Epoch 283/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4323 - accuracy: 0.8120 - val_loss: 0.4128 - val_accuracy: 0.8420\n",
            "Epoch 284/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4207 - accuracy: 0.8220 - val_loss: 0.4110 - val_accuracy: 0.8300\n",
            "Epoch 285/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4407 - accuracy: 0.8000 - val_loss: 0.4160 - val_accuracy: 0.8360\n",
            "Epoch 286/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4255 - accuracy: 0.8200 - val_loss: 0.4089 - val_accuracy: 0.8360\n",
            "Epoch 287/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4420 - accuracy: 0.8100 - val_loss: 0.4129 - val_accuracy: 0.8400\n",
            "Epoch 288/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4108 - accuracy: 0.8340 - val_loss: 0.4128 - val_accuracy: 0.8300\n",
            "Epoch 289/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4328 - accuracy: 0.8060 - val_loss: 0.4113 - val_accuracy: 0.8340\n",
            "Epoch 290/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4363 - accuracy: 0.8060 - val_loss: 0.4112 - val_accuracy: 0.8420\n",
            "Epoch 291/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4135 - accuracy: 0.8120 - val_loss: 0.4110 - val_accuracy: 0.8320\n",
            "Epoch 292/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4296 - accuracy: 0.8260 - val_loss: 0.4214 - val_accuracy: 0.8380\n",
            "Epoch 293/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4375 - accuracy: 0.8100 - val_loss: 0.4117 - val_accuracy: 0.8380\n",
            "Epoch 294/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4268 - accuracy: 0.8200 - val_loss: 0.4142 - val_accuracy: 0.8400\n",
            "Epoch 295/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4368 - accuracy: 0.8060 - val_loss: 0.4090 - val_accuracy: 0.8320\n",
            "Epoch 296/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4314 - accuracy: 0.8180 - val_loss: 0.4175 - val_accuracy: 0.8360\n",
            "Epoch 297/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4257 - accuracy: 0.8120 - val_loss: 0.4111 - val_accuracy: 0.8340\n",
            "Epoch 298/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4301 - accuracy: 0.8200 - val_loss: 0.4185 - val_accuracy: 0.8400\n",
            "Epoch 299/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4368 - accuracy: 0.8180 - val_loss: 0.4106 - val_accuracy: 0.8400\n",
            "Epoch 300/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4298 - accuracy: 0.8140 - val_loss: 0.4155 - val_accuracy: 0.8380\n",
            "Epoch 301/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4257 - accuracy: 0.8160 - val_loss: 0.4114 - val_accuracy: 0.8340\n",
            "Epoch 302/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4163 - accuracy: 0.8100 - val_loss: 0.4138 - val_accuracy: 0.8360\n",
            "Epoch 303/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4433 - accuracy: 0.8080 - val_loss: 0.4128 - val_accuracy: 0.8320\n",
            "Epoch 304/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4301 - accuracy: 0.8080 - val_loss: 0.4124 - val_accuracy: 0.8300\n",
            "Epoch 305/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4242 - accuracy: 0.8140 - val_loss: 0.4209 - val_accuracy: 0.8400\n",
            "Epoch 306/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4201 - accuracy: 0.8240 - val_loss: 0.4115 - val_accuracy: 0.8360\n",
            "Epoch 307/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4406 - accuracy: 0.8100 - val_loss: 0.4180 - val_accuracy: 0.8440\n",
            "Epoch 308/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4241 - accuracy: 0.8260 - val_loss: 0.4133 - val_accuracy: 0.8380\n",
            "Epoch 309/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4121 - accuracy: 0.8140 - val_loss: 0.4153 - val_accuracy: 0.8320\n",
            "Epoch 310/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4220 - accuracy: 0.8240 - val_loss: 0.4145 - val_accuracy: 0.8340\n",
            "Epoch 311/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4271 - accuracy: 0.8160 - val_loss: 0.4122 - val_accuracy: 0.8320\n",
            "Epoch 312/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4333 - accuracy: 0.8180 - val_loss: 0.4142 - val_accuracy: 0.8400\n",
            "Epoch 313/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4401 - accuracy: 0.8140 - val_loss: 0.4158 - val_accuracy: 0.8360\n",
            "Epoch 314/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4169 - accuracy: 0.8260 - val_loss: 0.4094 - val_accuracy: 0.8320\n",
            "Epoch 315/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4181 - accuracy: 0.8240 - val_loss: 0.4239 - val_accuracy: 0.8400\n",
            "Epoch 316/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4559 - accuracy: 0.8060 - val_loss: 0.4108 - val_accuracy: 0.8340\n",
            "Epoch 317/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4349 - accuracy: 0.8040 - val_loss: 0.4357 - val_accuracy: 0.8320\n",
            "Epoch 318/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4305 - accuracy: 0.8100 - val_loss: 0.4131 - val_accuracy: 0.8300\n",
            "Epoch 319/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4199 - accuracy: 0.8040 - val_loss: 0.4132 - val_accuracy: 0.8420\n",
            "Epoch 320/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4536 - accuracy: 0.7940 - val_loss: 0.4146 - val_accuracy: 0.8440\n",
            "Epoch 321/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4739 - accuracy: 0.8000 - val_loss: 0.4161 - val_accuracy: 0.8240\n",
            "Epoch 322/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4506 - accuracy: 0.8060 - val_loss: 0.4226 - val_accuracy: 0.8400\n",
            "Epoch 323/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4391 - accuracy: 0.8160 - val_loss: 0.4117 - val_accuracy: 0.8340\n",
            "Epoch 324/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4377 - accuracy: 0.8160 - val_loss: 0.4230 - val_accuracy: 0.8480\n",
            "Epoch 325/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4251 - accuracy: 0.8120 - val_loss: 0.4108 - val_accuracy: 0.8280\n",
            "Epoch 326/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4300 - accuracy: 0.8140 - val_loss: 0.4170 - val_accuracy: 0.8400\n",
            "Epoch 327/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4257 - accuracy: 0.8200 - val_loss: 0.4105 - val_accuracy: 0.8340\n",
            "Epoch 328/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4202 - accuracy: 0.8300 - val_loss: 0.4132 - val_accuracy: 0.8480\n",
            "Epoch 329/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4250 - accuracy: 0.8160 - val_loss: 0.4137 - val_accuracy: 0.8360\n",
            "Epoch 330/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4085 - accuracy: 0.8160 - val_loss: 0.4112 - val_accuracy: 0.8360\n",
            "Epoch 331/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4182 - accuracy: 0.8160 - val_loss: 0.4109 - val_accuracy: 0.8400\n",
            "Epoch 332/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4244 - accuracy: 0.8260 - val_loss: 0.4078 - val_accuracy: 0.8360\n",
            "Epoch 333/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4190 - accuracy: 0.8140 - val_loss: 0.4106 - val_accuracy: 0.8360\n",
            "Epoch 334/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4356 - accuracy: 0.8120 - val_loss: 0.4116 - val_accuracy: 0.8360\n",
            "Epoch 335/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4309 - accuracy: 0.8200 - val_loss: 0.4090 - val_accuracy: 0.8380\n",
            "Epoch 336/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4365 - accuracy: 0.8020 - val_loss: 0.4092 - val_accuracy: 0.8320\n",
            "Epoch 337/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4223 - accuracy: 0.8140 - val_loss: 0.4174 - val_accuracy: 0.8460\n",
            "Epoch 338/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4131 - accuracy: 0.8140 - val_loss: 0.4097 - val_accuracy: 0.8360\n",
            "Epoch 339/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4277 - accuracy: 0.8140 - val_loss: 0.4105 - val_accuracy: 0.8300\n",
            "Epoch 340/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4266 - accuracy: 0.8220 - val_loss: 0.4151 - val_accuracy: 0.8380\n",
            "Epoch 341/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4233 - accuracy: 0.8220 - val_loss: 0.4156 - val_accuracy: 0.8380\n",
            "Epoch 342/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4279 - accuracy: 0.8080 - val_loss: 0.4145 - val_accuracy: 0.8360\n",
            "Epoch 343/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4171 - accuracy: 0.8200 - val_loss: 0.4126 - val_accuracy: 0.8400\n",
            "Epoch 344/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4373 - accuracy: 0.8120 - val_loss: 0.4140 - val_accuracy: 0.8460\n",
            "Epoch 345/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4206 - accuracy: 0.8220 - val_loss: 0.4101 - val_accuracy: 0.8400\n",
            "Epoch 346/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4220 - accuracy: 0.8240 - val_loss: 0.4110 - val_accuracy: 0.8360\n",
            "Epoch 347/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4227 - accuracy: 0.8180 - val_loss: 0.4131 - val_accuracy: 0.8400\n",
            "Epoch 348/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4349 - accuracy: 0.8260 - val_loss: 0.4071 - val_accuracy: 0.8340\n",
            "Epoch 349/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4265 - accuracy: 0.8060 - val_loss: 0.4063 - val_accuracy: 0.8340\n",
            "Epoch 350/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4236 - accuracy: 0.8160 - val_loss: 0.4145 - val_accuracy: 0.8440\n",
            "Epoch 351/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4314 - accuracy: 0.8120 - val_loss: 0.4075 - val_accuracy: 0.8340\n",
            "Epoch 352/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4366 - accuracy: 0.8100 - val_loss: 0.4121 - val_accuracy: 0.8400\n",
            "Epoch 353/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4288 - accuracy: 0.8100 - val_loss: 0.4072 - val_accuracy: 0.8320\n",
            "Epoch 354/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4270 - accuracy: 0.8140 - val_loss: 0.4162 - val_accuracy: 0.8360\n",
            "Epoch 355/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4292 - accuracy: 0.8040 - val_loss: 0.4090 - val_accuracy: 0.8340\n",
            "Epoch 356/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4244 - accuracy: 0.8140 - val_loss: 0.4108 - val_accuracy: 0.8420\n",
            "Epoch 357/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4191 - accuracy: 0.8240 - val_loss: 0.4118 - val_accuracy: 0.8420\n",
            "Epoch 358/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4202 - accuracy: 0.8120 - val_loss: 0.4111 - val_accuracy: 0.8380\n",
            "Epoch 359/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4417 - accuracy: 0.8020 - val_loss: 0.4125 - val_accuracy: 0.8420\n",
            "Epoch 360/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4286 - accuracy: 0.8180 - val_loss: 0.4101 - val_accuracy: 0.8380\n",
            "Epoch 361/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4402 - accuracy: 0.8140 - val_loss: 0.4096 - val_accuracy: 0.8380\n",
            "Epoch 362/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4489 - accuracy: 0.8000 - val_loss: 0.4123 - val_accuracy: 0.8420\n",
            "Epoch 363/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4313 - accuracy: 0.8200 - val_loss: 0.4072 - val_accuracy: 0.8360\n",
            "Epoch 364/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4186 - accuracy: 0.8120 - val_loss: 0.4188 - val_accuracy: 0.8440\n",
            "Epoch 365/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4221 - accuracy: 0.8260 - val_loss: 0.4056 - val_accuracy: 0.8360\n",
            "Epoch 366/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4318 - accuracy: 0.8220 - val_loss: 0.4122 - val_accuracy: 0.8380\n",
            "Epoch 367/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4202 - accuracy: 0.8200 - val_loss: 0.4066 - val_accuracy: 0.8400\n",
            "Epoch 368/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4253 - accuracy: 0.8200 - val_loss: 0.4094 - val_accuracy: 0.8440\n",
            "Epoch 369/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4369 - accuracy: 0.8200 - val_loss: 0.4076 - val_accuracy: 0.8380\n",
            "Epoch 370/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4450 - accuracy: 0.8000 - val_loss: 0.4081 - val_accuracy: 0.8360\n",
            "Epoch 371/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4208 - accuracy: 0.8120 - val_loss: 0.4237 - val_accuracy: 0.8440\n",
            "Epoch 372/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4196 - accuracy: 0.8200 - val_loss: 0.4070 - val_accuracy: 0.8340\n",
            "Epoch 373/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4244 - accuracy: 0.8260 - val_loss: 0.4090 - val_accuracy: 0.8320\n",
            "Epoch 374/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4200 - accuracy: 0.8300 - val_loss: 0.4552 - val_accuracy: 0.8320\n",
            "Epoch 375/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4566 - accuracy: 0.8200 - val_loss: 0.4096 - val_accuracy: 0.8280\n",
            "Epoch 376/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4316 - accuracy: 0.8120 - val_loss: 0.4138 - val_accuracy: 0.8380\n",
            "Epoch 377/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4249 - accuracy: 0.8080 - val_loss: 0.4114 - val_accuracy: 0.8400\n",
            "Epoch 378/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4180 - accuracy: 0.8340 - val_loss: 0.4106 - val_accuracy: 0.8280\n",
            "Epoch 379/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4294 - accuracy: 0.8120 - val_loss: 0.4159 - val_accuracy: 0.8380\n",
            "Epoch 380/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4235 - accuracy: 0.8140 - val_loss: 0.4081 - val_accuracy: 0.8320\n",
            "Epoch 381/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4223 - accuracy: 0.8140 - val_loss: 0.4110 - val_accuracy: 0.8360\n",
            "Epoch 382/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4117 - accuracy: 0.8240 - val_loss: 0.4149 - val_accuracy: 0.8420\n",
            "Epoch 383/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4166 - accuracy: 0.8140 - val_loss: 0.4094 - val_accuracy: 0.8320\n",
            "Epoch 384/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4165 - accuracy: 0.8160 - val_loss: 0.4099 - val_accuracy: 0.8400\n",
            "Epoch 385/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4224 - accuracy: 0.8180 - val_loss: 0.4122 - val_accuracy: 0.8420\n",
            "Epoch 386/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4201 - accuracy: 0.8300 - val_loss: 0.4108 - val_accuracy: 0.8400\n",
            "Epoch 387/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4190 - accuracy: 0.8200 - val_loss: 0.4113 - val_accuracy: 0.8400\n",
            "Epoch 388/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4276 - accuracy: 0.8120 - val_loss: 0.4075 - val_accuracy: 0.8340\n",
            "Epoch 389/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4243 - accuracy: 0.8200 - val_loss: 0.4111 - val_accuracy: 0.8380\n",
            "Epoch 390/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4316 - accuracy: 0.8140 - val_loss: 0.4171 - val_accuracy: 0.8360\n",
            "Epoch 391/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4372 - accuracy: 0.8220 - val_loss: 0.4083 - val_accuracy: 0.8380\n",
            "Epoch 392/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4340 - accuracy: 0.8260 - val_loss: 0.4089 - val_accuracy: 0.8360\n",
            "Epoch 393/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4634 - accuracy: 0.8020 - val_loss: 0.4396 - val_accuracy: 0.8420\n",
            "Epoch 394/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4389 - accuracy: 0.8080 - val_loss: 0.4117 - val_accuracy: 0.8300\n",
            "Epoch 395/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4306 - accuracy: 0.8080 - val_loss: 0.4264 - val_accuracy: 0.8280\n",
            "Epoch 396/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4230 - accuracy: 0.8140 - val_loss: 0.4095 - val_accuracy: 0.8440\n",
            "Epoch 397/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4497 - accuracy: 0.7960 - val_loss: 0.4086 - val_accuracy: 0.8440\n",
            "Epoch 398/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4242 - accuracy: 0.8240 - val_loss: 0.4249 - val_accuracy: 0.8360\n",
            "Epoch 399/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4229 - accuracy: 0.8260 - val_loss: 0.4058 - val_accuracy: 0.8340\n",
            "Epoch 400/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4358 - accuracy: 0.8080 - val_loss: 0.4062 - val_accuracy: 0.8360\n",
            "Epoch 401/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4439 - accuracy: 0.8160 - val_loss: 0.4324 - val_accuracy: 0.8380\n",
            "Epoch 402/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4455 - accuracy: 0.8140 - val_loss: 0.4199 - val_accuracy: 0.8300\n",
            "Epoch 403/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4317 - accuracy: 0.8080 - val_loss: 0.4397 - val_accuracy: 0.8380\n",
            "Epoch 404/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4461 - accuracy: 0.8180 - val_loss: 0.4065 - val_accuracy: 0.8340\n",
            "Epoch 405/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4201 - accuracy: 0.8320 - val_loss: 0.4120 - val_accuracy: 0.8420\n",
            "Epoch 406/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4117 - accuracy: 0.8200 - val_loss: 0.4066 - val_accuracy: 0.8420\n",
            "Epoch 407/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4190 - accuracy: 0.8240 - val_loss: 0.4050 - val_accuracy: 0.8380\n",
            "Epoch 408/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4217 - accuracy: 0.8260 - val_loss: 0.4101 - val_accuracy: 0.8480\n",
            "Epoch 409/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4054 - accuracy: 0.8180 - val_loss: 0.4037 - val_accuracy: 0.8340\n",
            "Epoch 410/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4244 - accuracy: 0.8120 - val_loss: 0.4059 - val_accuracy: 0.8320\n",
            "Epoch 411/1000\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.4188 - accuracy: 0.8140 - val_loss: 0.4177 - val_accuracy: 0.8360\n",
            "Epoch 412/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4338 - accuracy: 0.8120 - val_loss: 0.4079 - val_accuracy: 0.8320\n",
            "Epoch 413/1000\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.4258 - accuracy: 0.8140 - val_loss: 0.4181 - val_accuracy: 0.8480\n",
            "Epoch 414/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4234 - accuracy: 0.8220 - val_loss: 0.4118 - val_accuracy: 0.8380\n",
            "Epoch 415/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4115 - accuracy: 0.8180 - val_loss: 0.4080 - val_accuracy: 0.8320\n",
            "Epoch 416/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4219 - accuracy: 0.8240 - val_loss: 0.4167 - val_accuracy: 0.8540\n",
            "Epoch 417/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4229 - accuracy: 0.8120 - val_loss: 0.4063 - val_accuracy: 0.8380\n",
            "Epoch 418/1000\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.4228 - accuracy: 0.8220 - val_loss: 0.4047 - val_accuracy: 0.8420\n",
            "Epoch 419/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4338 - accuracy: 0.8040 - val_loss: 0.4033 - val_accuracy: 0.8400\n",
            "Epoch 420/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.4330 - accuracy: 0.8200 - val_loss: 0.4054 - val_accuracy: 0.8420\n",
            "Epoch 421/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4127 - accuracy: 0.8240 - val_loss: 0.4095 - val_accuracy: 0.8480\n",
            "Epoch 422/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4228 - accuracy: 0.8140 - val_loss: 0.4055 - val_accuracy: 0.8400\n",
            "Epoch 423/1000\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.4163 - accuracy: 0.8160 - val_loss: 0.4105 - val_accuracy: 0.8380\n",
            "Epoch 424/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4104 - accuracy: 0.8240 - val_loss: 0.4089 - val_accuracy: 0.8420\n",
            "Epoch 425/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4231 - accuracy: 0.8180 - val_loss: 0.4054 - val_accuracy: 0.8400\n",
            "Epoch 426/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4262 - accuracy: 0.8180 - val_loss: 0.4133 - val_accuracy: 0.8400\n",
            "Epoch 427/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4200 - accuracy: 0.8300 - val_loss: 0.4054 - val_accuracy: 0.8420\n",
            "Epoch 428/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4236 - accuracy: 0.8200 - val_loss: 0.4052 - val_accuracy: 0.8360\n",
            "Epoch 429/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4287 - accuracy: 0.8160 - val_loss: 0.4068 - val_accuracy: 0.8460\n",
            "Epoch 430/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4113 - accuracy: 0.8160 - val_loss: 0.4070 - val_accuracy: 0.8320\n",
            "Epoch 431/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4398 - accuracy: 0.8200 - val_loss: 0.4074 - val_accuracy: 0.8380\n",
            "Epoch 432/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4204 - accuracy: 0.8140 - val_loss: 0.4039 - val_accuracy: 0.8400\n",
            "Epoch 433/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4289 - accuracy: 0.7980 - val_loss: 0.4071 - val_accuracy: 0.8400\n",
            "Epoch 434/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4229 - accuracy: 0.8140 - val_loss: 0.4068 - val_accuracy: 0.8420\n",
            "Epoch 435/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4152 - accuracy: 0.8140 - val_loss: 0.4178 - val_accuracy: 0.8420\n",
            "Epoch 436/1000\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.4435 - accuracy: 0.8180 - val_loss: 0.4030 - val_accuracy: 0.8320\n",
            "Epoch 437/1000\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4169 - accuracy: 0.8160 - val_loss: 0.4150 - val_accuracy: 0.8480\n",
            "Epoch 438/1000\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.4294 - accuracy: 0.8100 - val_loss: 0.4042 - val_accuracy: 0.8400\n",
            "Epoch 439/1000\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.4137 - accuracy: 0.8180 - val_loss: 0.4040 - val_accuracy: 0.8340\n",
            "Epoch 440/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4226 - accuracy: 0.8180 - val_loss: 0.4171 - val_accuracy: 0.8440\n",
            "Epoch 441/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4308 - accuracy: 0.8240 - val_loss: 0.4045 - val_accuracy: 0.8380\n",
            "Epoch 442/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4145 - accuracy: 0.8380 - val_loss: 0.4029 - val_accuracy: 0.8340\n",
            "Epoch 443/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4259 - accuracy: 0.8140 - val_loss: 0.4207 - val_accuracy: 0.8440\n",
            "Epoch 444/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4099 - accuracy: 0.8260 - val_loss: 0.4024 - val_accuracy: 0.8340\n",
            "Epoch 445/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4144 - accuracy: 0.8340 - val_loss: 0.4024 - val_accuracy: 0.8400\n",
            "Epoch 446/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4218 - accuracy: 0.8160 - val_loss: 0.4164 - val_accuracy: 0.8420\n",
            "Epoch 447/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4205 - accuracy: 0.8140 - val_loss: 0.4030 - val_accuracy: 0.8360\n",
            "Epoch 448/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4342 - accuracy: 0.8220 - val_loss: 0.4077 - val_accuracy: 0.8420\n",
            "Epoch 449/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4207 - accuracy: 0.8100 - val_loss: 0.4061 - val_accuracy: 0.8420\n",
            "Epoch 450/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4417 - accuracy: 0.7980 - val_loss: 0.4057 - val_accuracy: 0.8360\n",
            "Epoch 451/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4173 - accuracy: 0.8300 - val_loss: 0.4084 - val_accuracy: 0.8420\n",
            "Epoch 452/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4141 - accuracy: 0.8160 - val_loss: 0.4055 - val_accuracy: 0.8360\n",
            "Epoch 453/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4090 - accuracy: 0.8140 - val_loss: 0.4125 - val_accuracy: 0.8420\n",
            "Epoch 454/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4150 - accuracy: 0.8180 - val_loss: 0.4063 - val_accuracy: 0.8360\n",
            "Epoch 455/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4200 - accuracy: 0.8220 - val_loss: 0.4014 - val_accuracy: 0.8320\n",
            "Epoch 456/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4154 - accuracy: 0.8240 - val_loss: 0.4174 - val_accuracy: 0.8440\n",
            "Epoch 457/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4177 - accuracy: 0.8280 - val_loss: 0.4042 - val_accuracy: 0.8340\n",
            "Epoch 458/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4305 - accuracy: 0.8200 - val_loss: 0.4092 - val_accuracy: 0.8380\n",
            "Epoch 459/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4293 - accuracy: 0.8180 - val_loss: 0.4092 - val_accuracy: 0.8400\n",
            "Epoch 460/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4276 - accuracy: 0.8220 - val_loss: 0.4062 - val_accuracy: 0.8280\n",
            "Epoch 461/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4099 - accuracy: 0.8200 - val_loss: 0.4148 - val_accuracy: 0.8380\n",
            "Epoch 462/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4153 - accuracy: 0.8280 - val_loss: 0.4048 - val_accuracy: 0.8340\n",
            "Epoch 463/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4132 - accuracy: 0.8260 - val_loss: 0.4056 - val_accuracy: 0.8340\n",
            "Epoch 464/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4165 - accuracy: 0.8140 - val_loss: 0.4118 - val_accuracy: 0.8360\n",
            "Epoch 465/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4205 - accuracy: 0.8280 - val_loss: 0.4056 - val_accuracy: 0.8340\n",
            "Epoch 466/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4381 - accuracy: 0.8160 - val_loss: 0.4073 - val_accuracy: 0.8420\n",
            "Epoch 467/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4338 - accuracy: 0.8200 - val_loss: 0.4098 - val_accuracy: 0.8400\n",
            "Epoch 468/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4264 - accuracy: 0.8220 - val_loss: 0.4065 - val_accuracy: 0.8380\n",
            "Epoch 469/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4183 - accuracy: 0.8080 - val_loss: 0.4059 - val_accuracy: 0.8420\n",
            "Epoch 470/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4434 - accuracy: 0.8000 - val_loss: 0.4035 - val_accuracy: 0.8340\n",
            "Epoch 471/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4341 - accuracy: 0.8200 - val_loss: 0.4144 - val_accuracy: 0.8380\n",
            "Epoch 472/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4349 - accuracy: 0.8140 - val_loss: 0.4041 - val_accuracy: 0.8320\n",
            "Epoch 473/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4195 - accuracy: 0.8280 - val_loss: 0.4071 - val_accuracy: 0.8400\n",
            "Epoch 474/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4205 - accuracy: 0.8300 - val_loss: 0.4110 - val_accuracy: 0.8400\n",
            "Epoch 475/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4291 - accuracy: 0.8120 - val_loss: 0.4017 - val_accuracy: 0.8320\n",
            "Epoch 476/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4054 - accuracy: 0.8340 - val_loss: 0.4121 - val_accuracy: 0.8420\n",
            "Epoch 477/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4241 - accuracy: 0.8140 - val_loss: 0.4033 - val_accuracy: 0.8380\n",
            "Epoch 478/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4267 - accuracy: 0.8260 - val_loss: 0.4046 - val_accuracy: 0.8420\n",
            "Epoch 479/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4354 - accuracy: 0.8120 - val_loss: 0.4068 - val_accuracy: 0.8400\n",
            "Epoch 480/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4182 - accuracy: 0.8100 - val_loss: 0.4014 - val_accuracy: 0.8320\n",
            "Epoch 481/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4079 - accuracy: 0.8260 - val_loss: 0.4124 - val_accuracy: 0.8380\n",
            "Epoch 482/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4266 - accuracy: 0.8140 - val_loss: 0.4067 - val_accuracy: 0.8400\n",
            "Epoch 483/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4144 - accuracy: 0.8260 - val_loss: 0.4032 - val_accuracy: 0.8320\n",
            "Epoch 484/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4150 - accuracy: 0.8200 - val_loss: 0.4074 - val_accuracy: 0.8380\n",
            "Epoch 485/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4103 - accuracy: 0.8220 - val_loss: 0.4035 - val_accuracy: 0.8340\n",
            "Epoch 486/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4247 - accuracy: 0.8160 - val_loss: 0.4135 - val_accuracy: 0.8380\n",
            "Epoch 487/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4119 - accuracy: 0.8240 - val_loss: 0.4037 - val_accuracy: 0.8360\n",
            "Epoch 488/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4235 - accuracy: 0.8240 - val_loss: 0.4077 - val_accuracy: 0.8400\n",
            "Epoch 489/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4336 - accuracy: 0.8180 - val_loss: 0.4052 - val_accuracy: 0.8380\n",
            "Epoch 490/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4230 - accuracy: 0.8260 - val_loss: 0.4168 - val_accuracy: 0.8380\n",
            "Epoch 491/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4310 - accuracy: 0.8140 - val_loss: 0.4050 - val_accuracy: 0.8360\n",
            "Epoch 492/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4141 - accuracy: 0.8300 - val_loss: 0.4160 - val_accuracy: 0.8360\n",
            "Epoch 493/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4320 - accuracy: 0.8220 - val_loss: 0.4025 - val_accuracy: 0.8340\n",
            "Epoch 494/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4273 - accuracy: 0.8220 - val_loss: 0.4093 - val_accuracy: 0.8420\n",
            "Epoch 495/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4085 - accuracy: 0.8160 - val_loss: 0.4038 - val_accuracy: 0.8420\n",
            "Epoch 496/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4259 - accuracy: 0.8120 - val_loss: 0.4053 - val_accuracy: 0.8440\n",
            "Epoch 497/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4233 - accuracy: 0.8100 - val_loss: 0.4053 - val_accuracy: 0.8420\n",
            "Epoch 498/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4159 - accuracy: 0.8180 - val_loss: 0.4024 - val_accuracy: 0.8320\n",
            "Epoch 499/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4052 - accuracy: 0.8220 - val_loss: 0.4079 - val_accuracy: 0.8360\n",
            "Epoch 500/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4321 - accuracy: 0.8200 - val_loss: 0.4005 - val_accuracy: 0.8320\n",
            "Epoch 501/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4362 - accuracy: 0.8120 - val_loss: 0.4103 - val_accuracy: 0.8400\n",
            "Epoch 502/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4306 - accuracy: 0.8080 - val_loss: 0.4038 - val_accuracy: 0.8320\n",
            "Epoch 503/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4081 - accuracy: 0.8320 - val_loss: 0.4053 - val_accuracy: 0.8400\n",
            "Epoch 504/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4200 - accuracy: 0.8200 - val_loss: 0.4090 - val_accuracy: 0.8380\n",
            "Epoch 505/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4266 - accuracy: 0.8060 - val_loss: 0.4050 - val_accuracy: 0.8420\n",
            "Epoch 506/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4165 - accuracy: 0.8200 - val_loss: 0.4090 - val_accuracy: 0.8400\n",
            "Epoch 507/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4091 - accuracy: 0.8200 - val_loss: 0.4051 - val_accuracy: 0.8420\n",
            "Epoch 508/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4233 - accuracy: 0.8200 - val_loss: 0.4068 - val_accuracy: 0.8380\n",
            "Epoch 509/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4223 - accuracy: 0.8100 - val_loss: 0.4020 - val_accuracy: 0.8360\n",
            "Epoch 510/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4244 - accuracy: 0.8180 - val_loss: 0.4062 - val_accuracy: 0.8400\n",
            "Epoch 511/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4032 - accuracy: 0.8260 - val_loss: 0.4064 - val_accuracy: 0.8400\n",
            "Epoch 512/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4180 - accuracy: 0.8260 - val_loss: 0.4026 - val_accuracy: 0.8300\n",
            "Epoch 513/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4167 - accuracy: 0.8200 - val_loss: 0.4097 - val_accuracy: 0.8400\n",
            "Epoch 514/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4141 - accuracy: 0.8360 - val_loss: 0.4077 - val_accuracy: 0.8420\n",
            "Epoch 515/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4032 - accuracy: 0.8300 - val_loss: 0.4064 - val_accuracy: 0.8420\n",
            "Epoch 516/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4236 - accuracy: 0.8120 - val_loss: 0.4084 - val_accuracy: 0.8400\n",
            "Epoch 517/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4081 - accuracy: 0.8140 - val_loss: 0.4094 - val_accuracy: 0.8360\n",
            "Epoch 518/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4140 - accuracy: 0.8280 - val_loss: 0.4040 - val_accuracy: 0.8300\n",
            "Epoch 519/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4225 - accuracy: 0.8180 - val_loss: 0.4182 - val_accuracy: 0.8360\n",
            "Epoch 520/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4251 - accuracy: 0.8280 - val_loss: 0.4032 - val_accuracy: 0.8380\n",
            "Epoch 521/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4262 - accuracy: 0.8060 - val_loss: 0.4093 - val_accuracy: 0.8380\n",
            "Epoch 522/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4117 - accuracy: 0.8320 - val_loss: 0.4082 - val_accuracy: 0.8400\n",
            "Epoch 523/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4224 - accuracy: 0.8160 - val_loss: 0.4024 - val_accuracy: 0.8380\n",
            "Epoch 524/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4320 - accuracy: 0.7960 - val_loss: 0.4086 - val_accuracy: 0.8360\n",
            "Epoch 525/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4149 - accuracy: 0.8160 - val_loss: 0.4031 - val_accuracy: 0.8380\n",
            "Epoch 526/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4144 - accuracy: 0.8220 - val_loss: 0.4044 - val_accuracy: 0.8400\n",
            "Epoch 527/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4250 - accuracy: 0.8060 - val_loss: 0.4141 - val_accuracy: 0.8380\n",
            "Epoch 528/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4044 - accuracy: 0.8220 - val_loss: 0.4019 - val_accuracy: 0.8320\n",
            "Epoch 529/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4297 - accuracy: 0.8120 - val_loss: 0.4081 - val_accuracy: 0.8400\n",
            "Epoch 530/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4352 - accuracy: 0.8240 - val_loss: 0.4049 - val_accuracy: 0.8400\n",
            "Epoch 531/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4087 - accuracy: 0.8180 - val_loss: 0.4014 - val_accuracy: 0.8300\n",
            "Epoch 532/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4263 - accuracy: 0.8040 - val_loss: 0.4251 - val_accuracy: 0.8380\n",
            "Epoch 533/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4264 - accuracy: 0.8120 - val_loss: 0.4018 - val_accuracy: 0.8320\n",
            "Epoch 534/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4353 - accuracy: 0.8160 - val_loss: 0.4016 - val_accuracy: 0.8360\n",
            "Epoch 535/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4241 - accuracy: 0.8160 - val_loss: 0.4243 - val_accuracy: 0.8320\n",
            "Epoch 536/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4089 - accuracy: 0.8300 - val_loss: 0.4028 - val_accuracy: 0.8340\n",
            "Epoch 537/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4328 - accuracy: 0.8180 - val_loss: 0.4071 - val_accuracy: 0.8400\n",
            "Epoch 538/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4217 - accuracy: 0.8000 - val_loss: 0.4025 - val_accuracy: 0.8400\n",
            "Epoch 539/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4267 - accuracy: 0.8160 - val_loss: 0.4018 - val_accuracy: 0.8260\n",
            "Epoch 540/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4268 - accuracy: 0.8160 - val_loss: 0.4296 - val_accuracy: 0.8400\n",
            "Epoch 541/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4219 - accuracy: 0.8240 - val_loss: 0.4028 - val_accuracy: 0.8340\n",
            "Epoch 542/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4545 - accuracy: 0.8120 - val_loss: 0.4051 - val_accuracy: 0.8240\n",
            "Epoch 543/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4319 - accuracy: 0.8140 - val_loss: 0.4452 - val_accuracy: 0.8280\n",
            "Epoch 544/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4278 - accuracy: 0.8140 - val_loss: 0.4085 - val_accuracy: 0.8360\n",
            "Epoch 545/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4317 - accuracy: 0.8100 - val_loss: 0.4050 - val_accuracy: 0.8400\n",
            "Epoch 546/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4301 - accuracy: 0.8040 - val_loss: 0.4235 - val_accuracy: 0.8320\n",
            "Epoch 547/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4276 - accuracy: 0.8160 - val_loss: 0.4037 - val_accuracy: 0.8300\n",
            "Epoch 548/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4286 - accuracy: 0.8220 - val_loss: 0.4117 - val_accuracy: 0.8440\n",
            "Epoch 549/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4133 - accuracy: 0.8200 - val_loss: 0.4055 - val_accuracy: 0.8420\n",
            "Epoch 550/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.4127 - accuracy: 0.8200 - val_loss: 0.4008 - val_accuracy: 0.8280\n",
            "Epoch 551/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4188 - accuracy: 0.8120 - val_loss: 0.4053 - val_accuracy: 0.8380\n",
            "Epoch 552/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4306 - accuracy: 0.8240 - val_loss: 0.4042 - val_accuracy: 0.8400\n",
            "Epoch 553/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4223 - accuracy: 0.8260 - val_loss: 0.4021 - val_accuracy: 0.8400\n",
            "Epoch 554/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4055 - accuracy: 0.8340 - val_loss: 0.4034 - val_accuracy: 0.8400\n",
            "Epoch 555/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4159 - accuracy: 0.8080 - val_loss: 0.4008 - val_accuracy: 0.8360\n",
            "Epoch 556/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4248 - accuracy: 0.8260 - val_loss: 0.4040 - val_accuracy: 0.8380\n",
            "Epoch 557/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4101 - accuracy: 0.8160 - val_loss: 0.4073 - val_accuracy: 0.8380\n",
            "Epoch 558/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4107 - accuracy: 0.8160 - val_loss: 0.4026 - val_accuracy: 0.8400\n",
            "Epoch 559/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4210 - accuracy: 0.8160 - val_loss: 0.4068 - val_accuracy: 0.8400\n",
            "Epoch 560/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4152 - accuracy: 0.8200 - val_loss: 0.4029 - val_accuracy: 0.8440\n",
            "Epoch 561/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4216 - accuracy: 0.8220 - val_loss: 0.4044 - val_accuracy: 0.8380\n",
            "Epoch 562/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4044 - accuracy: 0.8260 - val_loss: 0.4006 - val_accuracy: 0.8260\n",
            "Epoch 563/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4215 - accuracy: 0.8220 - val_loss: 0.4105 - val_accuracy: 0.8380\n",
            "Epoch 564/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4376 - accuracy: 0.8180 - val_loss: 0.4023 - val_accuracy: 0.8320\n",
            "Epoch 565/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4365 - accuracy: 0.8140 - val_loss: 0.4177 - val_accuracy: 0.8380\n",
            "Epoch 566/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4120 - accuracy: 0.8280 - val_loss: 0.4021 - val_accuracy: 0.8260\n",
            "Epoch 567/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4140 - accuracy: 0.8200 - val_loss: 0.4081 - val_accuracy: 0.8360\n",
            "Epoch 568/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4190 - accuracy: 0.8220 - val_loss: 0.4071 - val_accuracy: 0.8400\n",
            "Epoch 569/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4236 - accuracy: 0.8160 - val_loss: 0.4033 - val_accuracy: 0.8400\n",
            "Epoch 570/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4204 - accuracy: 0.8200 - val_loss: 0.4174 - val_accuracy: 0.8380\n",
            "Epoch 571/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4223 - accuracy: 0.8100 - val_loss: 0.4022 - val_accuracy: 0.8360\n",
            "Epoch 572/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4171 - accuracy: 0.8180 - val_loss: 0.4041 - val_accuracy: 0.8400\n",
            "Epoch 573/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4068 - accuracy: 0.8260 - val_loss: 0.4065 - val_accuracy: 0.8400\n",
            "Epoch 574/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4108 - accuracy: 0.8360 - val_loss: 0.4063 - val_accuracy: 0.8380\n",
            "Epoch 575/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4208 - accuracy: 0.8180 - val_loss: 0.4074 - val_accuracy: 0.8300\n",
            "Epoch 576/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4152 - accuracy: 0.8260 - val_loss: 0.4178 - val_accuracy: 0.8400\n",
            "Epoch 577/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4109 - accuracy: 0.8280 - val_loss: 0.4060 - val_accuracy: 0.8380\n",
            "Epoch 578/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4078 - accuracy: 0.8180 - val_loss: 0.4036 - val_accuracy: 0.8360\n",
            "Epoch 579/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4088 - accuracy: 0.8180 - val_loss: 0.4072 - val_accuracy: 0.8380\n",
            "Epoch 580/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4188 - accuracy: 0.8120 - val_loss: 0.4044 - val_accuracy: 0.8420\n",
            "Epoch 581/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4199 - accuracy: 0.8200 - val_loss: 0.4059 - val_accuracy: 0.8440\n",
            "Epoch 582/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4272 - accuracy: 0.8200 - val_loss: 0.4038 - val_accuracy: 0.8360\n",
            "Epoch 583/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4295 - accuracy: 0.8080 - val_loss: 0.4257 - val_accuracy: 0.8380\n",
            "Epoch 584/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4193 - accuracy: 0.8160 - val_loss: 0.4032 - val_accuracy: 0.8340\n",
            "Epoch 585/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4185 - accuracy: 0.8080 - val_loss: 0.4049 - val_accuracy: 0.8380\n",
            "Epoch 586/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4167 - accuracy: 0.8200 - val_loss: 0.4105 - val_accuracy: 0.8380\n",
            "Epoch 587/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4224 - accuracy: 0.8160 - val_loss: 0.4011 - val_accuracy: 0.8360\n",
            "Epoch 588/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4184 - accuracy: 0.8100 - val_loss: 0.4104 - val_accuracy: 0.8420\n",
            "Epoch 589/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4250 - accuracy: 0.8020 - val_loss: 0.4029 - val_accuracy: 0.8380\n",
            "Epoch 590/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4210 - accuracy: 0.8200 - val_loss: 0.4020 - val_accuracy: 0.8280\n",
            "Epoch 591/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4233 - accuracy: 0.8280 - val_loss: 0.4123 - val_accuracy: 0.8420\n",
            "Epoch 592/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4137 - accuracy: 0.8260 - val_loss: 0.4015 - val_accuracy: 0.8400\n",
            "Epoch 593/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4220 - accuracy: 0.8120 - val_loss: 0.4022 - val_accuracy: 0.8400\n",
            "Epoch 594/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4164 - accuracy: 0.8320 - val_loss: 0.4037 - val_accuracy: 0.8340\n",
            "Epoch 595/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4300 - accuracy: 0.8240 - val_loss: 0.4025 - val_accuracy: 0.8400\n",
            "Epoch 596/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4170 - accuracy: 0.8300 - val_loss: 0.4276 - val_accuracy: 0.8320\n",
            "Epoch 597/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4125 - accuracy: 0.8240 - val_loss: 0.4056 - val_accuracy: 0.8320\n",
            "Epoch 598/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4253 - accuracy: 0.8160 - val_loss: 0.4053 - val_accuracy: 0.8340\n",
            "Epoch 599/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4132 - accuracy: 0.8240 - val_loss: 0.4098 - val_accuracy: 0.8360\n",
            "Epoch 600/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4302 - accuracy: 0.8080 - val_loss: 0.4056 - val_accuracy: 0.8320\n",
            "Epoch 601/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4110 - accuracy: 0.8100 - val_loss: 0.4121 - val_accuracy: 0.8400\n",
            "Epoch 602/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4358 - accuracy: 0.8160 - val_loss: 0.4085 - val_accuracy: 0.8400\n",
            "Epoch 603/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4163 - accuracy: 0.8180 - val_loss: 0.4031 - val_accuracy: 0.8320\n",
            "Epoch 604/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4317 - accuracy: 0.8240 - val_loss: 0.4162 - val_accuracy: 0.8360\n",
            "Epoch 605/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4382 - accuracy: 0.8080 - val_loss: 0.4038 - val_accuracy: 0.8400\n",
            "Epoch 606/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4247 - accuracy: 0.8060 - val_loss: 0.4028 - val_accuracy: 0.8400\n",
            "Epoch 607/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4103 - accuracy: 0.8160 - val_loss: 0.4092 - val_accuracy: 0.8380\n",
            "Epoch 608/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4058 - accuracy: 0.8180 - val_loss: 0.3995 - val_accuracy: 0.8300\n",
            "Epoch 609/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4047 - accuracy: 0.8280 - val_loss: 0.4053 - val_accuracy: 0.8400\n",
            "Epoch 610/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4298 - accuracy: 0.8240 - val_loss: 0.4075 - val_accuracy: 0.8380\n",
            "Epoch 611/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4088 - accuracy: 0.8300 - val_loss: 0.4016 - val_accuracy: 0.8340\n",
            "Epoch 612/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.4166 - accuracy: 0.8220 - val_loss: 0.4062 - val_accuracy: 0.8420\n",
            "Epoch 613/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.4119 - accuracy: 0.8200 - val_loss: 0.4103 - val_accuracy: 0.8400\n",
            "Epoch 614/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4280 - accuracy: 0.8220 - val_loss: 0.4033 - val_accuracy: 0.8300\n",
            "Epoch 615/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4205 - accuracy: 0.8260 - val_loss: 0.4123 - val_accuracy: 0.8360\n",
            "Epoch 616/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4092 - accuracy: 0.8260 - val_loss: 0.4042 - val_accuracy: 0.8420\n",
            "Epoch 617/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4076 - accuracy: 0.8240 - val_loss: 0.4037 - val_accuracy: 0.8420\n",
            "Epoch 618/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4060 - accuracy: 0.8260 - val_loss: 0.4111 - val_accuracy: 0.8380\n",
            "Epoch 619/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4097 - accuracy: 0.8160 - val_loss: 0.4020 - val_accuracy: 0.8340\n",
            "Epoch 620/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4262 - accuracy: 0.8060 - val_loss: 0.4022 - val_accuracy: 0.8400\n",
            "Epoch 621/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4093 - accuracy: 0.8220 - val_loss: 0.4166 - val_accuracy: 0.8380\n",
            "Epoch 622/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4176 - accuracy: 0.8220 - val_loss: 0.4004 - val_accuracy: 0.8300\n",
            "Epoch 623/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4307 - accuracy: 0.8260 - val_loss: 0.4023 - val_accuracy: 0.8340\n",
            "Epoch 624/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4104 - accuracy: 0.8260 - val_loss: 0.4127 - val_accuracy: 0.8380\n",
            "Epoch 625/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4077 - accuracy: 0.8420 - val_loss: 0.4014 - val_accuracy: 0.8320\n",
            "Epoch 626/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4086 - accuracy: 0.8280 - val_loss: 0.4034 - val_accuracy: 0.8420\n",
            "Epoch 627/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4108 - accuracy: 0.8240 - val_loss: 0.4042 - val_accuracy: 0.8380\n",
            "Epoch 628/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4092 - accuracy: 0.8180 - val_loss: 0.4032 - val_accuracy: 0.8420\n",
            "Epoch 629/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4020 - accuracy: 0.8260 - val_loss: 0.4072 - val_accuracy: 0.8400\n",
            "Epoch 630/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4015 - accuracy: 0.8320 - val_loss: 0.4016 - val_accuracy: 0.8280\n",
            "Epoch 631/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4105 - accuracy: 0.8420 - val_loss: 0.4044 - val_accuracy: 0.8340\n",
            "Epoch 632/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4196 - accuracy: 0.8160 - val_loss: 0.4104 - val_accuracy: 0.8380\n",
            "Epoch 633/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4140 - accuracy: 0.8140 - val_loss: 0.4008 - val_accuracy: 0.8300\n",
            "Epoch 634/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4123 - accuracy: 0.8220 - val_loss: 0.4121 - val_accuracy: 0.8380\n",
            "Epoch 635/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4231 - accuracy: 0.8120 - val_loss: 0.4023 - val_accuracy: 0.8400\n",
            "Epoch 636/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4026 - accuracy: 0.8340 - val_loss: 0.4044 - val_accuracy: 0.8380\n",
            "Epoch 637/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4191 - accuracy: 0.8140 - val_loss: 0.4049 - val_accuracy: 0.8360\n",
            "Epoch 638/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4139 - accuracy: 0.8220 - val_loss: 0.3985 - val_accuracy: 0.8320\n",
            "Epoch 639/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4143 - accuracy: 0.8180 - val_loss: 0.4018 - val_accuracy: 0.8340\n",
            "Epoch 640/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4066 - accuracy: 0.8240 - val_loss: 0.4017 - val_accuracy: 0.8360\n",
            "Epoch 641/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4226 - accuracy: 0.8180 - val_loss: 0.4018 - val_accuracy: 0.8400\n",
            "Epoch 642/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4005 - accuracy: 0.8480 - val_loss: 0.4038 - val_accuracy: 0.8420\n",
            "Epoch 643/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4151 - accuracy: 0.8240 - val_loss: 0.4032 - val_accuracy: 0.8360\n",
            "Epoch 644/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4208 - accuracy: 0.8160 - val_loss: 0.4051 - val_accuracy: 0.8400\n",
            "Epoch 645/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4091 - accuracy: 0.8180 - val_loss: 0.4032 - val_accuracy: 0.8400\n",
            "Epoch 646/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4113 - accuracy: 0.8220 - val_loss: 0.4060 - val_accuracy: 0.8420\n",
            "Epoch 647/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4119 - accuracy: 0.8280 - val_loss: 0.4014 - val_accuracy: 0.8420\n",
            "Epoch 648/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4077 - accuracy: 0.8380 - val_loss: 0.4115 - val_accuracy: 0.8320\n",
            "Epoch 649/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3994 - accuracy: 0.8240 - val_loss: 0.4018 - val_accuracy: 0.8420\n",
            "Epoch 650/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4201 - accuracy: 0.8340 - val_loss: 0.4066 - val_accuracy: 0.8400\n",
            "Epoch 651/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4106 - accuracy: 0.8300 - val_loss: 0.4015 - val_accuracy: 0.8380\n",
            "Epoch 652/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4119 - accuracy: 0.8140 - val_loss: 0.4038 - val_accuracy: 0.8380\n",
            "Epoch 653/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4061 - accuracy: 0.8300 - val_loss: 0.4045 - val_accuracy: 0.8400\n",
            "Epoch 654/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4070 - accuracy: 0.8260 - val_loss: 0.4054 - val_accuracy: 0.8420\n",
            "Epoch 655/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4107 - accuracy: 0.8260 - val_loss: 0.4073 - val_accuracy: 0.8400\n",
            "Epoch 656/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4149 - accuracy: 0.8240 - val_loss: 0.4025 - val_accuracy: 0.8340\n",
            "Epoch 657/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4229 - accuracy: 0.8180 - val_loss: 0.4112 - val_accuracy: 0.8400\n",
            "Epoch 658/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4202 - accuracy: 0.8220 - val_loss: 0.4087 - val_accuracy: 0.8380\n",
            "Epoch 659/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4207 - accuracy: 0.8220 - val_loss: 0.4023 - val_accuracy: 0.8320\n",
            "Epoch 660/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4262 - accuracy: 0.8120 - val_loss: 0.4148 - val_accuracy: 0.8380\n",
            "Epoch 661/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4091 - accuracy: 0.8200 - val_loss: 0.4016 - val_accuracy: 0.8320\n",
            "Epoch 662/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4198 - accuracy: 0.8200 - val_loss: 0.4047 - val_accuracy: 0.8360\n",
            "Epoch 663/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4095 - accuracy: 0.8200 - val_loss: 0.4088 - val_accuracy: 0.8420\n",
            "Epoch 664/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4216 - accuracy: 0.8160 - val_loss: 0.4028 - val_accuracy: 0.8380\n",
            "Epoch 665/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4101 - accuracy: 0.8240 - val_loss: 0.4065 - val_accuracy: 0.8400\n",
            "Epoch 666/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4132 - accuracy: 0.8200 - val_loss: 0.4061 - val_accuracy: 0.8380\n",
            "Epoch 667/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4261 - accuracy: 0.8120 - val_loss: 0.4010 - val_accuracy: 0.8300\n",
            "Epoch 668/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4363 - accuracy: 0.8240 - val_loss: 0.4192 - val_accuracy: 0.8380\n",
            "Epoch 669/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4255 - accuracy: 0.8220 - val_loss: 0.4023 - val_accuracy: 0.8380\n",
            "Epoch 670/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4032 - accuracy: 0.8280 - val_loss: 0.4081 - val_accuracy: 0.8380\n",
            "Epoch 671/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4168 - accuracy: 0.8180 - val_loss: 0.4125 - val_accuracy: 0.8400\n",
            "Epoch 672/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4005 - accuracy: 0.8180 - val_loss: 0.4034 - val_accuracy: 0.8320\n",
            "Epoch 673/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4165 - accuracy: 0.8300 - val_loss: 0.4067 - val_accuracy: 0.8400\n",
            "Epoch 674/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4041 - accuracy: 0.8280 - val_loss: 0.4061 - val_accuracy: 0.8360\n",
            "Epoch 675/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4154 - accuracy: 0.8200 - val_loss: 0.4008 - val_accuracy: 0.8300\n",
            "Epoch 676/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4138 - accuracy: 0.8180 - val_loss: 0.4081 - val_accuracy: 0.8420\n",
            "Epoch 677/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4056 - accuracy: 0.8220 - val_loss: 0.4029 - val_accuracy: 0.8360\n",
            "Epoch 678/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4193 - accuracy: 0.8100 - val_loss: 0.4010 - val_accuracy: 0.8340\n",
            "Epoch 679/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4174 - accuracy: 0.8180 - val_loss: 0.4079 - val_accuracy: 0.8340\n",
            "Epoch 680/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4010 - accuracy: 0.8140 - val_loss: 0.4022 - val_accuracy: 0.8300\n",
            "Epoch 681/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4051 - accuracy: 0.8240 - val_loss: 0.4096 - val_accuracy: 0.8360\n",
            "Epoch 682/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4192 - accuracy: 0.8300 - val_loss: 0.4083 - val_accuracy: 0.8440\n",
            "Epoch 683/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4161 - accuracy: 0.8100 - val_loss: 0.4007 - val_accuracy: 0.8340\n",
            "Epoch 684/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4116 - accuracy: 0.8300 - val_loss: 0.4025 - val_accuracy: 0.8340\n",
            "Epoch 685/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4139 - accuracy: 0.8140 - val_loss: 0.4033 - val_accuracy: 0.8320\n",
            "Epoch 686/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4090 - accuracy: 0.8220 - val_loss: 0.4025 - val_accuracy: 0.8380\n",
            "Epoch 687/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4203 - accuracy: 0.8160 - val_loss: 0.4106 - val_accuracy: 0.8400\n",
            "Epoch 688/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4096 - accuracy: 0.8180 - val_loss: 0.4076 - val_accuracy: 0.8360\n",
            "Epoch 689/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4103 - accuracy: 0.8220 - val_loss: 0.4016 - val_accuracy: 0.8280\n",
            "Epoch 690/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4195 - accuracy: 0.8200 - val_loss: 0.4127 - val_accuracy: 0.8380\n",
            "Epoch 691/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4110 - accuracy: 0.8180 - val_loss: 0.4091 - val_accuracy: 0.8400\n",
            "Epoch 692/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4177 - accuracy: 0.8220 - val_loss: 0.3996 - val_accuracy: 0.8300\n",
            "Epoch 693/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4107 - accuracy: 0.8200 - val_loss: 0.4023 - val_accuracy: 0.8360\n",
            "Epoch 694/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4156 - accuracy: 0.8080 - val_loss: 0.4138 - val_accuracy: 0.8380\n",
            "Epoch 695/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4211 - accuracy: 0.8140 - val_loss: 0.4011 - val_accuracy: 0.8280\n",
            "Epoch 696/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4161 - accuracy: 0.8320 - val_loss: 0.4028 - val_accuracy: 0.8320\n",
            "Epoch 697/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4184 - accuracy: 0.8180 - val_loss: 0.4058 - val_accuracy: 0.8400\n",
            "Epoch 698/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4198 - accuracy: 0.8240 - val_loss: 0.4021 - val_accuracy: 0.8420\n",
            "Epoch 699/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4268 - accuracy: 0.8240 - val_loss: 0.4014 - val_accuracy: 0.8380\n",
            "Epoch 700/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4236 - accuracy: 0.8040 - val_loss: 0.4170 - val_accuracy: 0.8380\n",
            "Epoch 701/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4219 - accuracy: 0.8260 - val_loss: 0.4015 - val_accuracy: 0.8340\n",
            "Epoch 702/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4270 - accuracy: 0.8200 - val_loss: 0.4135 - val_accuracy: 0.8380\n",
            "Epoch 703/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4147 - accuracy: 0.8260 - val_loss: 0.4013 - val_accuracy: 0.8320\n",
            "Epoch 704/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4128 - accuracy: 0.8360 - val_loss: 0.4036 - val_accuracy: 0.8300\n",
            "Epoch 705/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4213 - accuracy: 0.8160 - val_loss: 0.4136 - val_accuracy: 0.8380\n",
            "Epoch 706/1000\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4153 - accuracy: 0.8140 - val_loss: 0.4035 - val_accuracy: 0.8360\n",
            "Epoch 707/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4136 - accuracy: 0.8040 - val_loss: 0.4089 - val_accuracy: 0.8360\n",
            "Epoch 708/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4128 - accuracy: 0.8300 - val_loss: 0.4083 - val_accuracy: 0.8380\n",
            "Epoch 709/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4258 - accuracy: 0.8060 - val_loss: 0.4020 - val_accuracy: 0.8320\n",
            "Epoch 710/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4154 - accuracy: 0.8260 - val_loss: 0.4078 - val_accuracy: 0.8380\n",
            "Epoch 711/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4216 - accuracy: 0.8220 - val_loss: 0.4030 - val_accuracy: 0.8320\n",
            "Epoch 712/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4188 - accuracy: 0.8240 - val_loss: 0.4026 - val_accuracy: 0.8360\n",
            "Epoch 713/1000\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.4129 - accuracy: 0.8280 - val_loss: 0.4093 - val_accuracy: 0.8340\n",
            "Epoch 714/1000\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.4015 - accuracy: 0.8260 - val_loss: 0.4004 - val_accuracy: 0.8300\n",
            "Epoch 715/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.4133 - accuracy: 0.8240 - val_loss: 0.4123 - val_accuracy: 0.8380\n",
            "Epoch 716/1000\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4216 - accuracy: 0.8260 - val_loss: 0.4026 - val_accuracy: 0.8340\n",
            "Epoch 717/1000\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.4148 - accuracy: 0.8220 - val_loss: 0.4017 - val_accuracy: 0.8340\n",
            "Epoch 718/1000\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.4330 - accuracy: 0.8240 - val_loss: 0.4176 - val_accuracy: 0.8380\n",
            "Epoch 719/1000\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.4112 - accuracy: 0.8140 - val_loss: 0.4009 - val_accuracy: 0.8300\n",
            "Epoch 720/1000\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.4217 - accuracy: 0.8260 - val_loss: 0.4038 - val_accuracy: 0.8420\n",
            "Epoch 721/1000\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.4043 - accuracy: 0.8360 - val_loss: 0.4094 - val_accuracy: 0.8440\n",
            "Epoch 722/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.4174 - accuracy: 0.8220 - val_loss: 0.3996 - val_accuracy: 0.8300\n",
            "Epoch 723/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4133 - accuracy: 0.8200 - val_loss: 0.4017 - val_accuracy: 0.8300\n",
            "Epoch 724/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4185 - accuracy: 0.8200 - val_loss: 0.4107 - val_accuracy: 0.8320\n",
            "Epoch 725/1000\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.4107 - accuracy: 0.8200 - val_loss: 0.4014 - val_accuracy: 0.8280\n",
            "Epoch 726/1000\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4054 - accuracy: 0.8280 - val_loss: 0.4019 - val_accuracy: 0.8360\n",
            "Epoch 727/1000\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.4073 - accuracy: 0.8100 - val_loss: 0.4070 - val_accuracy: 0.8380\n",
            "Epoch 728/1000\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4116 - accuracy: 0.8280 - val_loss: 0.4044 - val_accuracy: 0.8380\n",
            "Epoch 729/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4045 - accuracy: 0.8220 - val_loss: 0.4011 - val_accuracy: 0.8320\n",
            "Epoch 730/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4182 - accuracy: 0.8220 - val_loss: 0.4040 - val_accuracy: 0.8380\n",
            "Epoch 731/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4143 - accuracy: 0.8180 - val_loss: 0.4070 - val_accuracy: 0.8340\n",
            "Epoch 732/1000\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.4163 - accuracy: 0.8220 - val_loss: 0.4002 - val_accuracy: 0.8280\n",
            "Epoch 733/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4330 - accuracy: 0.8100 - val_loss: 0.4098 - val_accuracy: 0.8380\n",
            "Epoch 734/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4261 - accuracy: 0.8160 - val_loss: 0.3984 - val_accuracy: 0.8300\n",
            "Epoch 735/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4106 - accuracy: 0.8200 - val_loss: 0.4145 - val_accuracy: 0.8380\n",
            "Epoch 736/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4120 - accuracy: 0.8180 - val_loss: 0.3994 - val_accuracy: 0.8260\n",
            "Epoch 737/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4191 - accuracy: 0.8160 - val_loss: 0.4043 - val_accuracy: 0.8300\n",
            "Epoch 738/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4178 - accuracy: 0.8180 - val_loss: 0.4067 - val_accuracy: 0.8360\n",
            "Epoch 739/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4154 - accuracy: 0.8160 - val_loss: 0.4016 - val_accuracy: 0.8380\n",
            "Epoch 740/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4172 - accuracy: 0.8160 - val_loss: 0.4049 - val_accuracy: 0.8360\n",
            "Epoch 741/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4141 - accuracy: 0.8280 - val_loss: 0.4022 - val_accuracy: 0.8360\n",
            "Epoch 742/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4114 - accuracy: 0.8240 - val_loss: 0.3993 - val_accuracy: 0.8280\n",
            "Epoch 743/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4168 - accuracy: 0.8060 - val_loss: 0.4024 - val_accuracy: 0.8360\n",
            "Epoch 744/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4126 - accuracy: 0.8160 - val_loss: 0.4053 - val_accuracy: 0.8360\n",
            "Epoch 745/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4007 - accuracy: 0.8220 - val_loss: 0.3992 - val_accuracy: 0.8300\n",
            "Epoch 746/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4030 - accuracy: 0.8260 - val_loss: 0.4064 - val_accuracy: 0.8380\n",
            "Epoch 747/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4048 - accuracy: 0.8260 - val_loss: 0.4000 - val_accuracy: 0.8400\n",
            "Epoch 748/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4181 - accuracy: 0.8080 - val_loss: 0.4001 - val_accuracy: 0.8420\n",
            "Epoch 749/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4103 - accuracy: 0.8180 - val_loss: 0.4080 - val_accuracy: 0.8360\n",
            "Epoch 750/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4056 - accuracy: 0.8160 - val_loss: 0.3992 - val_accuracy: 0.8340\n",
            "Epoch 751/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4060 - accuracy: 0.8320 - val_loss: 0.4020 - val_accuracy: 0.8380\n",
            "Epoch 752/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4123 - accuracy: 0.8340 - val_loss: 0.4120 - val_accuracy: 0.8380\n",
            "Epoch 753/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4306 - accuracy: 0.8240 - val_loss: 0.4010 - val_accuracy: 0.8280\n",
            "Epoch 754/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4142 - accuracy: 0.8220 - val_loss: 0.4007 - val_accuracy: 0.8300\n",
            "Epoch 755/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4149 - accuracy: 0.8280 - val_loss: 0.4164 - val_accuracy: 0.8400\n",
            "Epoch 756/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4170 - accuracy: 0.8200 - val_loss: 0.4011 - val_accuracy: 0.8340\n",
            "Epoch 757/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4134 - accuracy: 0.8200 - val_loss: 0.4024 - val_accuracy: 0.8360\n",
            "Epoch 758/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4170 - accuracy: 0.8160 - val_loss: 0.4091 - val_accuracy: 0.8360\n",
            "Epoch 759/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4157 - accuracy: 0.8140 - val_loss: 0.4009 - val_accuracy: 0.8320\n",
            "Epoch 760/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4050 - accuracy: 0.8280 - val_loss: 0.4018 - val_accuracy: 0.8360\n",
            "Epoch 761/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4007 - accuracy: 0.8360 - val_loss: 0.4145 - val_accuracy: 0.8420\n",
            "Epoch 762/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4129 - accuracy: 0.8240 - val_loss: 0.4001 - val_accuracy: 0.8340\n",
            "Epoch 763/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3927 - accuracy: 0.8120 - val_loss: 0.4013 - val_accuracy: 0.8380\n",
            "Epoch 764/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4139 - accuracy: 0.8140 - val_loss: 0.4060 - val_accuracy: 0.8360\n",
            "Epoch 765/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4058 - accuracy: 0.8300 - val_loss: 0.4006 - val_accuracy: 0.8360\n",
            "Epoch 766/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3994 - accuracy: 0.8240 - val_loss: 0.4024 - val_accuracy: 0.8400\n",
            "Epoch 767/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4035 - accuracy: 0.8260 - val_loss: 0.4060 - val_accuracy: 0.8400\n",
            "Epoch 768/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4223 - accuracy: 0.8160 - val_loss: 0.4020 - val_accuracy: 0.8320\n",
            "Epoch 769/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4108 - accuracy: 0.8200 - val_loss: 0.4023 - val_accuracy: 0.8380\n",
            "Epoch 770/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3971 - accuracy: 0.8300 - val_loss: 0.4023 - val_accuracy: 0.8380\n",
            "Epoch 771/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4233 - accuracy: 0.8180 - val_loss: 0.4041 - val_accuracy: 0.8340\n",
            "Epoch 772/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4177 - accuracy: 0.8060 - val_loss: 0.4020 - val_accuracy: 0.8400\n",
            "Epoch 773/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4117 - accuracy: 0.8280 - val_loss: 0.4020 - val_accuracy: 0.8400\n",
            "Epoch 774/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4029 - accuracy: 0.8320 - val_loss: 0.4017 - val_accuracy: 0.8360\n",
            "Epoch 775/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4195 - accuracy: 0.8080 - val_loss: 0.4018 - val_accuracy: 0.8360\n",
            "Epoch 776/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4145 - accuracy: 0.8160 - val_loss: 0.4011 - val_accuracy: 0.8400\n",
            "Epoch 777/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4166 - accuracy: 0.8200 - val_loss: 0.4031 - val_accuracy: 0.8400\n",
            "Epoch 778/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4059 - accuracy: 0.8380 - val_loss: 0.3983 - val_accuracy: 0.8320\n",
            "Epoch 779/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4033 - accuracy: 0.8200 - val_loss: 0.4053 - val_accuracy: 0.8400\n",
            "Epoch 780/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4122 - accuracy: 0.8180 - val_loss: 0.4052 - val_accuracy: 0.8400\n",
            "Epoch 781/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4183 - accuracy: 0.8180 - val_loss: 0.4011 - val_accuracy: 0.8400\n",
            "Epoch 782/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4131 - accuracy: 0.8340 - val_loss: 0.4016 - val_accuracy: 0.8360\n",
            "Epoch 783/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4116 - accuracy: 0.8160 - val_loss: 0.4010 - val_accuracy: 0.8360\n",
            "Epoch 784/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4094 - accuracy: 0.8160 - val_loss: 0.4020 - val_accuracy: 0.8360\n",
            "Epoch 785/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4127 - accuracy: 0.8120 - val_loss: 0.4034 - val_accuracy: 0.8400\n",
            "Epoch 786/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4085 - accuracy: 0.8280 - val_loss: 0.4054 - val_accuracy: 0.8420\n",
            "Epoch 787/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4166 - accuracy: 0.8260 - val_loss: 0.3999 - val_accuracy: 0.8320\n",
            "Epoch 788/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4054 - accuracy: 0.8200 - val_loss: 0.4028 - val_accuracy: 0.8380\n",
            "Epoch 789/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4099 - accuracy: 0.8160 - val_loss: 0.4039 - val_accuracy: 0.8380\n",
            "Epoch 790/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4204 - accuracy: 0.8200 - val_loss: 0.4022 - val_accuracy: 0.8360\n",
            "Epoch 791/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4260 - accuracy: 0.8120 - val_loss: 0.4099 - val_accuracy: 0.8420\n",
            "Epoch 792/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4153 - accuracy: 0.8220 - val_loss: 0.4003 - val_accuracy: 0.8320\n",
            "Epoch 793/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4132 - accuracy: 0.8200 - val_loss: 0.4084 - val_accuracy: 0.8340\n",
            "Epoch 794/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4154 - accuracy: 0.8180 - val_loss: 0.4043 - val_accuracy: 0.8360\n",
            "Epoch 795/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4219 - accuracy: 0.8360 - val_loss: 0.4019 - val_accuracy: 0.8340\n",
            "Epoch 796/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4062 - accuracy: 0.8380 - val_loss: 0.4143 - val_accuracy: 0.8400\n",
            "Epoch 797/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4160 - accuracy: 0.8120 - val_loss: 0.4073 - val_accuracy: 0.8380\n",
            "Epoch 798/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4159 - accuracy: 0.8060 - val_loss: 0.4032 - val_accuracy: 0.8340\n",
            "Epoch 799/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4217 - accuracy: 0.8120 - val_loss: 0.4142 - val_accuracy: 0.8340\n",
            "Epoch 800/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4139 - accuracy: 0.8220 - val_loss: 0.4060 - val_accuracy: 0.8340\n",
            "Epoch 801/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4133 - accuracy: 0.8180 - val_loss: 0.4005 - val_accuracy: 0.8320\n",
            "Epoch 802/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4120 - accuracy: 0.8200 - val_loss: 0.4080 - val_accuracy: 0.8360\n",
            "Epoch 803/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4118 - accuracy: 0.8260 - val_loss: 0.4061 - val_accuracy: 0.8400\n",
            "Epoch 804/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4228 - accuracy: 0.8220 - val_loss: 0.4014 - val_accuracy: 0.8380\n",
            "Epoch 805/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4104 - accuracy: 0.8260 - val_loss: 0.4075 - val_accuracy: 0.8360\n",
            "Epoch 806/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4181 - accuracy: 0.8120 - val_loss: 0.4057 - val_accuracy: 0.8320\n",
            "Epoch 807/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4123 - accuracy: 0.8100 - val_loss: 0.4017 - val_accuracy: 0.8320\n",
            "Epoch 808/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4189 - accuracy: 0.8140 - val_loss: 0.4084 - val_accuracy: 0.8380\n",
            "Epoch 809/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4086 - accuracy: 0.8360 - val_loss: 0.4033 - val_accuracy: 0.8420\n",
            "Epoch 810/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4079 - accuracy: 0.8220 - val_loss: 0.4030 - val_accuracy: 0.8340\n",
            "Epoch 811/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4257 - accuracy: 0.8240 - val_loss: 0.4039 - val_accuracy: 0.8360\n",
            "Epoch 812/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4176 - accuracy: 0.8080 - val_loss: 0.4011 - val_accuracy: 0.8300\n",
            "Epoch 813/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4059 - accuracy: 0.8180 - val_loss: 0.4142 - val_accuracy: 0.8380\n",
            "Epoch 814/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4194 - accuracy: 0.8260 - val_loss: 0.4044 - val_accuracy: 0.8380\n",
            "Epoch 815/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4017 - accuracy: 0.8360 - val_loss: 0.4054 - val_accuracy: 0.8300\n",
            "Epoch 816/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4062 - accuracy: 0.8100 - val_loss: 0.4089 - val_accuracy: 0.8360\n",
            "Epoch 817/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4158 - accuracy: 0.8200 - val_loss: 0.4108 - val_accuracy: 0.8360\n",
            "Epoch 818/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4013 - accuracy: 0.8120 - val_loss: 0.3991 - val_accuracy: 0.8300\n",
            "Epoch 819/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4144 - accuracy: 0.8120 - val_loss: 0.4044 - val_accuracy: 0.8360\n",
            "Epoch 820/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4063 - accuracy: 0.8320 - val_loss: 0.4122 - val_accuracy: 0.8360\n",
            "Epoch 821/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4307 - accuracy: 0.8120 - val_loss: 0.4009 - val_accuracy: 0.8320\n",
            "Epoch 822/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4052 - accuracy: 0.8080 - val_loss: 0.4160 - val_accuracy: 0.8340\n",
            "Epoch 823/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4173 - accuracy: 0.8080 - val_loss: 0.4020 - val_accuracy: 0.8300\n",
            "Epoch 824/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4254 - accuracy: 0.8220 - val_loss: 0.4020 - val_accuracy: 0.8360\n",
            "Epoch 825/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4191 - accuracy: 0.8120 - val_loss: 0.4045 - val_accuracy: 0.8360\n",
            "Epoch 826/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4171 - accuracy: 0.8000 - val_loss: 0.3992 - val_accuracy: 0.8300\n",
            "Epoch 827/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3972 - accuracy: 0.8280 - val_loss: 0.4029 - val_accuracy: 0.8380\n",
            "Epoch 828/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4008 - accuracy: 0.8360 - val_loss: 0.4086 - val_accuracy: 0.8340\n",
            "Epoch 829/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4197 - accuracy: 0.8140 - val_loss: 0.4040 - val_accuracy: 0.8360\n",
            "Epoch 830/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4123 - accuracy: 0.8200 - val_loss: 0.4031 - val_accuracy: 0.8340\n",
            "Epoch 831/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4149 - accuracy: 0.8140 - val_loss: 0.4070 - val_accuracy: 0.8340\n",
            "Epoch 832/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4071 - accuracy: 0.8200 - val_loss: 0.4059 - val_accuracy: 0.8360\n",
            "Epoch 833/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3991 - accuracy: 0.8400 - val_loss: 0.4035 - val_accuracy: 0.8400\n",
            "Epoch 834/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4031 - accuracy: 0.8260 - val_loss: 0.4030 - val_accuracy: 0.8380\n",
            "Epoch 835/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3951 - accuracy: 0.8260 - val_loss: 0.4071 - val_accuracy: 0.8400\n",
            "Epoch 836/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4232 - accuracy: 0.8160 - val_loss: 0.4004 - val_accuracy: 0.8320\n",
            "Epoch 837/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4100 - accuracy: 0.8160 - val_loss: 0.4026 - val_accuracy: 0.8400\n",
            "Epoch 838/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4173 - accuracy: 0.8340 - val_loss: 0.4078 - val_accuracy: 0.8380\n",
            "Epoch 839/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4063 - accuracy: 0.8200 - val_loss: 0.4009 - val_accuracy: 0.8320\n",
            "Epoch 840/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4021 - accuracy: 0.8420 - val_loss: 0.4035 - val_accuracy: 0.8380\n",
            "Epoch 841/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4125 - accuracy: 0.8180 - val_loss: 0.4048 - val_accuracy: 0.8360\n",
            "Epoch 842/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4079 - accuracy: 0.8240 - val_loss: 0.4019 - val_accuracy: 0.8420\n",
            "Epoch 843/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4049 - accuracy: 0.8240 - val_loss: 0.4015 - val_accuracy: 0.8380\n",
            "Epoch 844/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4257 - accuracy: 0.8180 - val_loss: 0.4017 - val_accuracy: 0.8360\n",
            "Epoch 845/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4049 - accuracy: 0.8340 - val_loss: 0.4039 - val_accuracy: 0.8340\n",
            "Epoch 846/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4158 - accuracy: 0.8140 - val_loss: 0.3982 - val_accuracy: 0.8280\n",
            "Epoch 847/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4190 - accuracy: 0.8080 - val_loss: 0.4060 - val_accuracy: 0.8360\n",
            "Epoch 848/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4141 - accuracy: 0.8240 - val_loss: 0.4036 - val_accuracy: 0.8400\n",
            "Epoch 849/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4110 - accuracy: 0.8340 - val_loss: 0.4017 - val_accuracy: 0.8300\n",
            "Epoch 850/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4084 - accuracy: 0.8080 - val_loss: 0.3993 - val_accuracy: 0.8300\n",
            "Epoch 851/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4079 - accuracy: 0.8260 - val_loss: 0.4008 - val_accuracy: 0.8360\n",
            "Epoch 852/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4065 - accuracy: 0.8160 - val_loss: 0.4116 - val_accuracy: 0.8360\n",
            "Epoch 853/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4165 - accuracy: 0.8380 - val_loss: 0.3996 - val_accuracy: 0.8320\n",
            "Epoch 854/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4164 - accuracy: 0.8160 - val_loss: 0.4019 - val_accuracy: 0.8340\n",
            "Epoch 855/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4051 - accuracy: 0.8320 - val_loss: 0.4123 - val_accuracy: 0.8380\n",
            "Epoch 856/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4050 - accuracy: 0.8260 - val_loss: 0.4001 - val_accuracy: 0.8360\n",
            "Epoch 857/1000\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.4185 - accuracy: 0.8120 - val_loss: 0.4007 - val_accuracy: 0.8260\n",
            "Epoch 858/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4148 - accuracy: 0.8200 - val_loss: 0.4102 - val_accuracy: 0.8360\n",
            "Epoch 859/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4220 - accuracy: 0.8180 - val_loss: 0.4006 - val_accuracy: 0.8320\n",
            "Epoch 860/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4191 - accuracy: 0.8180 - val_loss: 0.4016 - val_accuracy: 0.8380\n",
            "Epoch 861/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4085 - accuracy: 0.8300 - val_loss: 0.4156 - val_accuracy: 0.8380\n",
            "Epoch 862/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4159 - accuracy: 0.8260 - val_loss: 0.4004 - val_accuracy: 0.8320\n",
            "Epoch 863/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4106 - accuracy: 0.8040 - val_loss: 0.4031 - val_accuracy: 0.8360\n",
            "Epoch 864/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4068 - accuracy: 0.8060 - val_loss: 0.4081 - val_accuracy: 0.8360\n",
            "Epoch 865/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4016 - accuracy: 0.8240 - val_loss: 0.4039 - val_accuracy: 0.8360\n",
            "Epoch 866/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4080 - accuracy: 0.8200 - val_loss: 0.4016 - val_accuracy: 0.8380\n",
            "Epoch 867/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4088 - accuracy: 0.8140 - val_loss: 0.4198 - val_accuracy: 0.8380\n",
            "Epoch 868/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4077 - accuracy: 0.8220 - val_loss: 0.4015 - val_accuracy: 0.8320\n",
            "Epoch 869/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4157 - accuracy: 0.8200 - val_loss: 0.4032 - val_accuracy: 0.8380\n",
            "Epoch 870/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4136 - accuracy: 0.8200 - val_loss: 0.4061 - val_accuracy: 0.8360\n",
            "Epoch 871/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3991 - accuracy: 0.8280 - val_loss: 0.4043 - val_accuracy: 0.8380\n",
            "Epoch 872/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4166 - accuracy: 0.8200 - val_loss: 0.4024 - val_accuracy: 0.8320\n",
            "Epoch 873/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3888 - accuracy: 0.8260 - val_loss: 0.4035 - val_accuracy: 0.8340\n",
            "Epoch 874/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4115 - accuracy: 0.8240 - val_loss: 0.4012 - val_accuracy: 0.8380\n",
            "Epoch 875/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4089 - accuracy: 0.8160 - val_loss: 0.4019 - val_accuracy: 0.8380\n",
            "Epoch 876/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4157 - accuracy: 0.8180 - val_loss: 0.4052 - val_accuracy: 0.8340\n",
            "Epoch 877/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4044 - accuracy: 0.8380 - val_loss: 0.3998 - val_accuracy: 0.8340\n",
            "Epoch 878/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4184 - accuracy: 0.8220 - val_loss: 0.4020 - val_accuracy: 0.8380\n",
            "Epoch 879/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4147 - accuracy: 0.8160 - val_loss: 0.4081 - val_accuracy: 0.8380\n",
            "Epoch 880/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4062 - accuracy: 0.8320 - val_loss: 0.3999 - val_accuracy: 0.8300\n",
            "Epoch 881/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4154 - accuracy: 0.8300 - val_loss: 0.4041 - val_accuracy: 0.8400\n",
            "Epoch 882/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4011 - accuracy: 0.8360 - val_loss: 0.4051 - val_accuracy: 0.8400\n",
            "Epoch 883/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4074 - accuracy: 0.8120 - val_loss: 0.4006 - val_accuracy: 0.8320\n",
            "Epoch 884/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4090 - accuracy: 0.8360 - val_loss: 0.4039 - val_accuracy: 0.8360\n",
            "Epoch 885/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4007 - accuracy: 0.8280 - val_loss: 0.4010 - val_accuracy: 0.8400\n",
            "Epoch 886/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4111 - accuracy: 0.8140 - val_loss: 0.4015 - val_accuracy: 0.8360\n",
            "Epoch 887/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4098 - accuracy: 0.8120 - val_loss: 0.4047 - val_accuracy: 0.8340\n",
            "Epoch 888/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4071 - accuracy: 0.8280 - val_loss: 0.4044 - val_accuracy: 0.8380\n",
            "Epoch 889/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4172 - accuracy: 0.8260 - val_loss: 0.3992 - val_accuracy: 0.8380\n",
            "Epoch 890/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4269 - accuracy: 0.8140 - val_loss: 0.4138 - val_accuracy: 0.8420\n",
            "Epoch 891/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4125 - accuracy: 0.8200 - val_loss: 0.4053 - val_accuracy: 0.8380\n",
            "Epoch 892/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4377 - accuracy: 0.8100 - val_loss: 0.4005 - val_accuracy: 0.8320\n",
            "Epoch 893/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4095 - accuracy: 0.8180 - val_loss: 0.4089 - val_accuracy: 0.8360\n",
            "Epoch 894/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4131 - accuracy: 0.8280 - val_loss: 0.3997 - val_accuracy: 0.8320\n",
            "Epoch 895/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4204 - accuracy: 0.8120 - val_loss: 0.4017 - val_accuracy: 0.8340\n",
            "Epoch 896/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4143 - accuracy: 0.8160 - val_loss: 0.4043 - val_accuracy: 0.8360\n",
            "Epoch 897/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4099 - accuracy: 0.8220 - val_loss: 0.4009 - val_accuracy: 0.8380\n",
            "Epoch 898/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4125 - accuracy: 0.8220 - val_loss: 0.4056 - val_accuracy: 0.8400\n",
            "Epoch 899/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4056 - accuracy: 0.8280 - val_loss: 0.4042 - val_accuracy: 0.8400\n",
            "Epoch 900/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3891 - accuracy: 0.8280 - val_loss: 0.4005 - val_accuracy: 0.8360\n",
            "Epoch 901/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4115 - accuracy: 0.8120 - val_loss: 0.4043 - val_accuracy: 0.8340\n",
            "Epoch 902/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3950 - accuracy: 0.8160 - val_loss: 0.4012 - val_accuracy: 0.8380\n",
            "Epoch 903/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4148 - accuracy: 0.8320 - val_loss: 0.4041 - val_accuracy: 0.8400\n",
            "Epoch 904/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4159 - accuracy: 0.8280 - val_loss: 0.4010 - val_accuracy: 0.8300\n",
            "Epoch 905/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4169 - accuracy: 0.8220 - val_loss: 0.4042 - val_accuracy: 0.8380\n",
            "Epoch 906/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4144 - accuracy: 0.8180 - val_loss: 0.4046 - val_accuracy: 0.8380\n",
            "Epoch 907/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4073 - accuracy: 0.8360 - val_loss: 0.4023 - val_accuracy: 0.8360\n",
            "Epoch 908/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3925 - accuracy: 0.8360 - val_loss: 0.4002 - val_accuracy: 0.8300\n",
            "Epoch 909/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4106 - accuracy: 0.8320 - val_loss: 0.4005 - val_accuracy: 0.8300\n",
            "Epoch 910/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4164 - accuracy: 0.8340 - val_loss: 0.4212 - val_accuracy: 0.8400\n",
            "Epoch 911/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4165 - accuracy: 0.8180 - val_loss: 0.4007 - val_accuracy: 0.8340\n",
            "Epoch 912/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4134 - accuracy: 0.8180 - val_loss: 0.4032 - val_accuracy: 0.8360\n",
            "Epoch 913/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4218 - accuracy: 0.8320 - val_loss: 0.4087 - val_accuracy: 0.8380\n",
            "Epoch 914/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4022 - accuracy: 0.8240 - val_loss: 0.4046 - val_accuracy: 0.8400\n",
            "Epoch 915/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4111 - accuracy: 0.8320 - val_loss: 0.4004 - val_accuracy: 0.8360\n",
            "Epoch 916/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4100 - accuracy: 0.8360 - val_loss: 0.4112 - val_accuracy: 0.8360\n",
            "Epoch 917/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4082 - accuracy: 0.8280 - val_loss: 0.3999 - val_accuracy: 0.8280\n",
            "Epoch 918/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4189 - accuracy: 0.8100 - val_loss: 0.4002 - val_accuracy: 0.8360\n",
            "Epoch 919/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.4060 - accuracy: 0.8240 - val_loss: 0.4019 - val_accuracy: 0.8420\n",
            "Epoch 920/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4135 - accuracy: 0.8100 - val_loss: 0.3997 - val_accuracy: 0.8380\n",
            "Epoch 921/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4166 - accuracy: 0.8220 - val_loss: 0.4037 - val_accuracy: 0.8340\n",
            "Epoch 922/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4142 - accuracy: 0.8180 - val_loss: 0.4038 - val_accuracy: 0.8320\n",
            "Epoch 923/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4261 - accuracy: 0.8160 - val_loss: 0.3996 - val_accuracy: 0.8320\n",
            "Epoch 924/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3940 - accuracy: 0.8380 - val_loss: 0.4072 - val_accuracy: 0.8400\n",
            "Epoch 925/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4217 - accuracy: 0.8200 - val_loss: 0.4031 - val_accuracy: 0.8400\n",
            "Epoch 926/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4153 - accuracy: 0.8140 - val_loss: 0.4025 - val_accuracy: 0.8340\n",
            "Epoch 927/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4207 - accuracy: 0.8140 - val_loss: 0.4143 - val_accuracy: 0.8400\n",
            "Epoch 928/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4137 - accuracy: 0.8180 - val_loss: 0.4030 - val_accuracy: 0.8320\n",
            "Epoch 929/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4201 - accuracy: 0.8100 - val_loss: 0.4028 - val_accuracy: 0.8360\n",
            "Epoch 930/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4119 - accuracy: 0.8200 - val_loss: 0.4120 - val_accuracy: 0.8360\n",
            "Epoch 931/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.4069 - accuracy: 0.8280 - val_loss: 0.3986 - val_accuracy: 0.8360\n",
            "Epoch 932/1000\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.4236 - accuracy: 0.8120 - val_loss: 0.4006 - val_accuracy: 0.8400\n",
            "Epoch 933/1000\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.4066 - accuracy: 0.8080 - val_loss: 0.4088 - val_accuracy: 0.8360\n",
            "Epoch 934/1000\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.4206 - accuracy: 0.8220 - val_loss: 0.4019 - val_accuracy: 0.8340\n",
            "Epoch 935/1000\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3986 - accuracy: 0.8200 - val_loss: 0.3999 - val_accuracy: 0.8380\n",
            "Epoch 936/1000\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.4057 - accuracy: 0.8280 - val_loss: 0.4019 - val_accuracy: 0.8400\n",
            "Epoch 937/1000\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.4133 - accuracy: 0.8180 - val_loss: 0.4033 - val_accuracy: 0.8360\n",
            "Epoch 938/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4124 - accuracy: 0.8180 - val_loss: 0.4029 - val_accuracy: 0.8300\n",
            "Epoch 939/1000\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4249 - accuracy: 0.8200 - val_loss: 0.3990 - val_accuracy: 0.8280\n",
            "Epoch 940/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4079 - accuracy: 0.8300 - val_loss: 0.4148 - val_accuracy: 0.8340\n",
            "Epoch 941/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4083 - accuracy: 0.8300 - val_loss: 0.3988 - val_accuracy: 0.8380\n",
            "Epoch 942/1000\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4163 - accuracy: 0.8180 - val_loss: 0.3988 - val_accuracy: 0.8340\n",
            "Epoch 943/1000\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4280 - accuracy: 0.8200 - val_loss: 0.4162 - val_accuracy: 0.8400\n",
            "Epoch 944/1000\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.4283 - accuracy: 0.8160 - val_loss: 0.4041 - val_accuracy: 0.8360\n",
            "Epoch 945/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4228 - accuracy: 0.8180 - val_loss: 0.4002 - val_accuracy: 0.8300\n",
            "Epoch 946/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4108 - accuracy: 0.8180 - val_loss: 0.4047 - val_accuracy: 0.8380\n",
            "Epoch 947/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4245 - accuracy: 0.8200 - val_loss: 0.4107 - val_accuracy: 0.8420\n",
            "Epoch 948/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4104 - accuracy: 0.8200 - val_loss: 0.3995 - val_accuracy: 0.8320\n",
            "Epoch 949/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4211 - accuracy: 0.8260 - val_loss: 0.4046 - val_accuracy: 0.8380\n",
            "Epoch 950/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4249 - accuracy: 0.8120 - val_loss: 0.4182 - val_accuracy: 0.8420\n",
            "Epoch 951/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4058 - accuracy: 0.8140 - val_loss: 0.3992 - val_accuracy: 0.8340\n",
            "Epoch 952/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4248 - accuracy: 0.8080 - val_loss: 0.3990 - val_accuracy: 0.8360\n",
            "Epoch 953/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.4060 - accuracy: 0.8380 - val_loss: 0.4080 - val_accuracy: 0.8360\n",
            "Epoch 954/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4120 - accuracy: 0.8160 - val_loss: 0.3987 - val_accuracy: 0.8360\n",
            "Epoch 955/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4013 - accuracy: 0.8360 - val_loss: 0.4000 - val_accuracy: 0.8360\n",
            "Epoch 956/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4050 - accuracy: 0.8340 - val_loss: 0.4002 - val_accuracy: 0.8360\n",
            "Epoch 957/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4181 - accuracy: 0.8220 - val_loss: 0.4011 - val_accuracy: 0.8320\n",
            "Epoch 958/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4070 - accuracy: 0.8240 - val_loss: 0.4073 - val_accuracy: 0.8340\n",
            "Epoch 959/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4026 - accuracy: 0.8300 - val_loss: 0.3972 - val_accuracy: 0.8320\n",
            "Epoch 960/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4118 - accuracy: 0.8260 - val_loss: 0.4049 - val_accuracy: 0.8360\n",
            "Epoch 961/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4184 - accuracy: 0.8240 - val_loss: 0.4110 - val_accuracy: 0.8380\n",
            "Epoch 962/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4027 - accuracy: 0.8360 - val_loss: 0.3974 - val_accuracy: 0.8300\n",
            "Epoch 963/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4189 - accuracy: 0.8160 - val_loss: 0.4009 - val_accuracy: 0.8320\n",
            "Epoch 964/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4075 - accuracy: 0.8160 - val_loss: 0.4090 - val_accuracy: 0.8360\n",
            "Epoch 965/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4228 - accuracy: 0.8160 - val_loss: 0.3997 - val_accuracy: 0.8360\n",
            "Epoch 966/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4076 - accuracy: 0.8280 - val_loss: 0.3976 - val_accuracy: 0.8380\n",
            "Epoch 967/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3941 - accuracy: 0.8340 - val_loss: 0.3987 - val_accuracy: 0.8300\n",
            "Epoch 968/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3909 - accuracy: 0.8280 - val_loss: 0.4077 - val_accuracy: 0.8340\n",
            "Epoch 969/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4099 - accuracy: 0.8160 - val_loss: 0.3985 - val_accuracy: 0.8300\n",
            "Epoch 970/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4112 - accuracy: 0.8240 - val_loss: 0.4070 - val_accuracy: 0.8320\n",
            "Epoch 971/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4137 - accuracy: 0.8160 - val_loss: 0.4002 - val_accuracy: 0.8380\n",
            "Epoch 972/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4091 - accuracy: 0.8240 - val_loss: 0.3967 - val_accuracy: 0.8300\n",
            "Epoch 973/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4251 - accuracy: 0.8160 - val_loss: 0.4106 - val_accuracy: 0.8380\n",
            "Epoch 974/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4092 - accuracy: 0.8220 - val_loss: 0.4028 - val_accuracy: 0.8340\n",
            "Epoch 975/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4096 - accuracy: 0.8240 - val_loss: 0.3996 - val_accuracy: 0.8380\n",
            "Epoch 976/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3981 - accuracy: 0.8260 - val_loss: 0.4013 - val_accuracy: 0.8380\n",
            "Epoch 977/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4090 - accuracy: 0.8120 - val_loss: 0.4043 - val_accuracy: 0.8340\n",
            "Epoch 978/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4052 - accuracy: 0.8160 - val_loss: 0.3998 - val_accuracy: 0.8340\n",
            "Epoch 979/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3965 - accuracy: 0.8240 - val_loss: 0.4013 - val_accuracy: 0.8340\n",
            "Epoch 980/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4185 - accuracy: 0.8100 - val_loss: 0.4015 - val_accuracy: 0.8340\n",
            "Epoch 981/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3921 - accuracy: 0.8300 - val_loss: 0.4012 - val_accuracy: 0.8340\n",
            "Epoch 982/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4182 - accuracy: 0.8200 - val_loss: 0.4145 - val_accuracy: 0.8440\n",
            "Epoch 983/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4192 - accuracy: 0.8200 - val_loss: 0.4032 - val_accuracy: 0.8380\n",
            "Epoch 984/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4119 - accuracy: 0.8140 - val_loss: 0.4006 - val_accuracy: 0.8400\n",
            "Epoch 985/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4069 - accuracy: 0.8300 - val_loss: 0.4059 - val_accuracy: 0.8340\n",
            "Epoch 986/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4102 - accuracy: 0.8260 - val_loss: 0.4000 - val_accuracy: 0.8380\n",
            "Epoch 987/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4145 - accuracy: 0.8080 - val_loss: 0.4024 - val_accuracy: 0.8380\n",
            "Epoch 988/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4132 - accuracy: 0.8180 - val_loss: 0.4012 - val_accuracy: 0.8400\n",
            "Epoch 989/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4321 - accuracy: 0.7980 - val_loss: 0.3989 - val_accuracy: 0.8400\n",
            "Epoch 990/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4172 - accuracy: 0.8140 - val_loss: 0.4100 - val_accuracy: 0.8360\n",
            "Epoch 991/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4123 - accuracy: 0.8220 - val_loss: 0.3981 - val_accuracy: 0.8280\n",
            "Epoch 992/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4076 - accuracy: 0.8140 - val_loss: 0.3986 - val_accuracy: 0.8360\n",
            "Epoch 993/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4083 - accuracy: 0.8320 - val_loss: 0.4087 - val_accuracy: 0.8340\n",
            "Epoch 994/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3988 - accuracy: 0.8280 - val_loss: 0.3962 - val_accuracy: 0.8320\n",
            "Epoch 995/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4188 - accuracy: 0.8100 - val_loss: 0.3971 - val_accuracy: 0.8340\n",
            "Epoch 996/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4191 - accuracy: 0.8160 - val_loss: 0.4100 - val_accuracy: 0.8420\n",
            "Epoch 997/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4044 - accuracy: 0.8200 - val_loss: 0.3993 - val_accuracy: 0.8360\n",
            "Epoch 998/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4130 - accuracy: 0.8300 - val_loss: 0.3996 - val_accuracy: 0.8360\n",
            "Epoch 999/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4170 - accuracy: 0.8260 - val_loss: 0.4099 - val_accuracy: 0.8360\n",
            "Epoch 1000/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4050 - accuracy: 0.8280 - val_loss: 0.3994 - val_accuracy: 0.8400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "his = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=1000, verbose=1, batch_size = 128)\n"
      ],
      "metadata": {
        "id": "x6D89M3j5RGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = go.Scatter(y=his.history['loss'],\n",
        "                    mode=\"lines\",\n",
        "                    line=dict(\n",
        "                        width=2,\n",
        "                        color='blue'),\n",
        "                        name=\"loss\"\n",
        "                   )\n",
        "h2 = go.Scatter(y=his.history['val_loss'],\n",
        "                    mode=\"lines\",\n",
        "                    line=dict(\n",
        "                        width=2,\n",
        "                        color='red'),\n",
        "                        name=\"val_loss\"\n",
        "                   )\n",
        "\n",
        "data = [h1,h2]\n",
        "layout1 = go.Layout(title='Loss',\n",
        "                   xaxis=dict(title='epochs'),\n",
        "                   yaxis=dict(title=''))\n",
        "fig1 = go.Figure(data = data, layout=layout1)\n",
        "plotly.offline.iplot(fig1)"
      ],
      "metadata": {
        "id": "phM1POW35SK-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "2b259f5f-7eee-4b3e-bae1-f7d87f16c990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"5923b8ac-9cb9-4bf5-8230-202204bd98bd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5923b8ac-9cb9-4bf5-8230-202204bd98bd\")) {                    Plotly.newPlot(                        \"5923b8ac-9cb9-4bf5-8230-202204bd98bd\",                        [{\"line\":{\"color\":\"blue\",\"width\":2},\"mode\":\"lines\",\"name\":\"loss\",\"y\":[2.7527241706848145,2.2620627880096436,1.8595367670059204,1.4970074892044067,1.2654799222946167,1.1762170791625977,1.2825175523757935,1.542599081993103,1.415359616279602,1.2860454320907593,1.2512645721435547,1.0868357419967651,0.984653890132904,1.1413031816482544,0.9354051351547241,0.862758219242096,0.8103397488594055,0.7804500460624695,0.8379145264625549,0.7554816007614136,0.7075026631355286,0.6679283976554871,0.702763557434082,0.6382049322128296,0.6363083720207214,0.6123018860816956,0.644005537033081,0.5930144786834717,0.6786739230155945,0.6416978240013123,0.6328489184379578,0.5767987966537476,0.5954208374023438,0.5987709164619446,0.5806397199630737,0.5517376661300659,0.5838424563407898,0.5626022815704346,0.5616054534912109,0.5448850393295288,0.5425705313682556,0.5502561330795288,0.5733776688575745,0.5498978495597839,0.5465610027313232,0.5538632869720459,0.5442790985107422,0.5726946592330933,0.5331547856330872,0.5598594546318054,0.5391952395439148,0.5506409406661987,0.5357317328453064,0.5263554453849792,0.528843879699707,0.5405737161636353,0.5349348187446594,0.5275246500968933,0.5547553300857544,0.5222322940826416,0.5271987915039062,0.5170711874961853,0.5094911456108093,0.5111230611801147,0.51881343126297,0.5353493094444275,0.5397697687149048,0.5523179173469543,0.5613910555839539,0.5233663320541382,0.5185261964797974,0.5454722046852112,0.5243636965751648,0.5294729471206665,0.5199891328811646,0.5129095315933228,0.527457058429718,0.5176474452018738,0.6076412200927734,0.5770382285118103,0.5186560153961182,0.5211571455001831,0.5046767592430115,0.48672014474868774,0.49852946400642395,0.5148629546165466,0.49396848678588867,0.4889349639415741,0.4889003336429596,0.5004977583885193,0.5311575531959534,0.49425843358039856,0.5014348030090332,0.5184234976768494,0.4705095887184143,0.4935554265975952,0.4941948354244232,0.47733446955680847,0.49256569147109985,0.4945567548274994,0.4725792706012726,0.47301068902015686,0.46706146001815796,0.49222999811172485,0.5056618452072144,0.48627156019210815,0.4798785150051117,0.47503194212913513,0.48526647686958313,0.47761669754981995,0.46613091230392456,0.4692278504371643,0.45536819100379944,0.46477290987968445,0.46325263381004333,0.4386759102344513,0.4626041054725647,0.45406246185302734,0.4668876826763153,0.45818230509757996,0.464987188577652,0.46980419754981995,0.4855484068393707,0.5009099841117859,0.47809261083602905,0.4779437780380249,0.4536866545677185,0.4539489150047302,0.4537517726421356,0.4760913550853729,0.46793901920318604,0.47359123826026917,0.47469550371170044,0.45532140135765076,0.4549967646598816,0.4546860456466675,0.4473879039287567,0.46201708912849426,0.4423940181732178,0.4513549208641052,0.4787212610244751,0.45299869775772095,0.4430224597454071,0.46772605180740356,0.47638219594955444,0.46904340386390686,0.4538712501525879,0.480075478553772,0.4747741222381592,0.47660166025161743,0.458661288022995,0.45887747406959534,0.4247918128967285,0.4622035324573517,0.4486743211746216,0.45508021116256714,0.46432676911354065,0.46670857071876526,0.43803268671035767,0.45177483558654785,0.43177559971809387,0.4478767216205597,0.4435490071773529,0.4459911286830902,0.45612502098083496,0.4672059118747711,0.45471158623695374,0.4548611044883728,0.47459039092063904,0.48846709728240967,0.4715558588504791,0.43928244709968567,0.44914722442626953,0.45169174671173096,0.45612409710884094,0.4511006474494934,0.4599921405315399,0.44424647092819214,0.4607505202293396,0.4469168782234192,0.4490605592727661,0.44133323431015015,0.43942925333976746,0.45677781105041504,0.4511522650718689,0.47385743260383606,0.4811323583126068,0.49163714051246643,0.451389878988266,0.45734691619873047,0.4667327404022217,0.4883687198162079,0.45248594880104065,0.4608715772628784,0.4366053640842438,0.4575139582157135,0.4505566954612732,0.44003719091415405,0.44373849034309387,0.46492451429367065,0.4523124694824219,0.43505486845970154,0.43656688928604126,0.4325915575027466,0.4417059123516083,0.43259477615356445,0.4352996349334717,0.4539317786693573,0.44979327917099,0.4488198459148407,0.4522458612918854,0.44441989064216614,0.44635120034217834,0.4270782768726349,0.43445324897766113,0.43556469678878784,0.4381173849105835,0.43734461069107056,0.44167426228523254,0.4485987424850464,0.44237157702445984,0.42782050371170044,0.4459359645843506,0.43692368268966675,0.45594096183776855,0.43520256876945496,0.4373091757297516,0.4400876462459564,0.4423324167728424,0.43145987391471863,0.434055358171463,0.43205150961875916,0.44121024012565613,0.44552937150001526,0.4423321485519409,0.4355833828449249,0.43356096744537354,0.42788994312286377,0.43249326944351196,0.4482373595237732,0.4316847324371338,0.44082221388816833,0.4370397925376892,0.4181209206581116,0.43830394744873047,0.43238091468811035,0.43059971928596497,0.4292166531085968,0.4412718713283539,0.4321046471595764,0.44664037227630615,0.4414258599281311,0.43412232398986816,0.4439818561077118,0.45132067799568176,0.43215668201446533,0.43841931223869324,0.43271568417549133,0.42590898275375366,0.44233977794647217,0.4265731871128082,0.4360750913619995,0.43473559617996216,0.43602100014686584,0.4351945221424103,0.43841221928596497,0.43191027641296387,0.4562331438064575,0.44186931848526,0.4508804380893707,0.4546394944190979,0.43349871039390564,0.4427048861980438,0.4284754693508148,0.42365336418151855,0.4286971688270569,0.43027251958847046,0.43997979164123535,0.4411955773830414,0.4253808856010437,0.43134862184524536,0.4306086003780365,0.4323173463344574,0.42071208357810974,0.4407450258731842,0.4254814088344574,0.44195353984832764,0.41083410382270813,0.4328327476978302,0.4363379180431366,0.41353100538253784,0.42958229780197144,0.4375267028808594,0.42679888010025024,0.4368171989917755,0.4313744902610779,0.4257339537143707,0.4300529658794403,0.4368000626564026,0.4297739565372467,0.425749272108078,0.41633138060569763,0.44333764910697937,0.4301338791847229,0.4242061674594879,0.4200607240200043,0.4406364858150482,0.4240700900554657,0.4120619595050812,0.42198631167411804,0.42709362506866455,0.43331319093704224,0.4401402175426483,0.416933536529541,0.4181172549724579,0.455937922000885,0.4348503351211548,0.4305202066898346,0.4198612570762634,0.45362821221351624,0.4738791882991791,0.4505574405193329,0.43914300203323364,0.4376595616340637,0.425051748752594,0.42996513843536377,0.4256889820098877,0.42018142342567444,0.4250107407569885,0.4084624648094177,0.418219655752182,0.4244438409805298,0.41901543736457825,0.43558835983276367,0.430891752243042,0.4365496337413788,0.4222645163536072,0.4130779504776001,0.42770424485206604,0.426603764295578,0.423333078622818,0.42786723375320435,0.4171319901943207,0.4372546374797821,0.4206438958644867,0.42200496792793274,0.4227154552936554,0.4349444806575775,0.4264676570892334,0.42358776926994324,0.4314146339893341,0.43664905428886414,0.42875105142593384,0.42696520686149597,0.4291619658470154,0.42441120743751526,0.4191337525844574,0.4201825261116028,0.4417416751384735,0.42860621213912964,0.440225213766098,0.44892722368240356,0.4312843084335327,0.4186183214187622,0.4220949113368988,0.431769460439682,0.420233815908432,0.4253185987472534,0.4369393289089203,0.44504398107528687,0.42075204849243164,0.41964757442474365,0.4244495928287506,0.4199821352958679,0.4566499888896942,0.43160998821258545,0.42493966221809387,0.417985737323761,0.42940467596054077,0.4234747588634491,0.42228463292121887,0.41169533133506775,0.4165593087673187,0.416545033454895,0.42235657572746277,0.4201204180717468,0.4189595878124237,0.4276365041732788,0.42426517605781555,0.43162789940834045,0.43719589710235596,0.43401673436164856,0.463445782661438,0.4389418363571167,0.4305962920188904,0.42298829555511475,0.44966450333595276,0.42420029640197754,0.42292383313179016,0.4357728362083435,0.44388729333877563,0.4455339312553406,0.43173667788505554,0.44606274366378784,0.420052170753479,0.4117223620414734,0.4189842641353607,0.4216603636741638,0.4053962230682373,0.42439723014831543,0.4187960624694824,0.4337630569934845,0.4257528781890869,0.42338991165161133,0.4114612936973572,0.42188629508018494,0.4228949546813965,0.42276450991630554,0.4338175654411316,0.43295323848724365,0.4126676023006439,0.4228181540966034,0.41630375385284424,0.41040876507759094,0.42308497428894043,0.426168829202652,0.42003515362739563,0.42358630895614624,0.42872127890586853,0.4112866222858429,0.4397936463356018,0.42040637135505676,0.4288884699344635,0.42294588685035706,0.41519585251808167,0.4434998333454132,0.41685110330581665,0.42944952845573425,0.41372647881507874,0.4225582182407379,0.4307515323162079,0.41454753279685974,0.4258972704410553,0.4099489152431488,0.41435763239860535,0.4217624068260193,0.4204612374305725,0.4341960549354553,0.4206523299217224,0.44165387749671936,0.41734665632247925,0.4141339063644409,0.4089891016483307,0.4149511456489563,0.41995012760162354,0.41535520553588867,0.4176624119281769,0.43049156665802,0.42934417724609375,0.427625834941864,0.4099182188510895,0.41529756784439087,0.4132383465766907,0.41645029187202454,0.42047902941703796,0.43806886672973633,0.43384692072868347,0.4263749122619629,0.41829201579093933,0.44342225790023804,0.43411168456077576,0.434901624917984,0.41953402757644653,0.42047879099845886,0.42913684248924255,0.4053836166858673,0.42409616708755493,0.4266766309738159,0.4354337453842163,0.4182462692260742,0.40792980790138245,0.42657601833343506,0.4143833518028259,0.414994478225708,0.4102709889411926,0.4247414469718933,0.41187766194343567,0.42352214455604553,0.4335748553276062,0.42298004031181335,0.43097755312919617,0.4141328036785126,0.432039737701416,0.4273228645324707,0.408468633890152,0.42589470744132996,0.42327502369880676,0.41593530774116516,0.4051624834537506,0.4321134388446808,0.4361934959888458,0.43064385652542114,0.4081418514251709,0.4199696183204651,0.42660439014434814,0.4165145754814148,0.4091285467147827,0.4232526123523712,0.42234331369400024,0.42442482709884644,0.4031899571418762,0.41804563999176025,0.4166698157787323,0.414084792137146,0.40319857001304626,0.42360222339630127,0.40805351734161377,0.41399744153022766,0.4225291609764099,0.425051212310791,0.42621317505836487,0.4116757810115814,0.4223993122577667,0.43199414014816284,0.41487911343574524,0.4143601953983307,0.42502814531326294,0.4044096767902374,0.4296582341194153,0.4351601004600525,0.40873005986213684,0.4263143837451935,0.4264252185821533,0.4352817237377167,0.4240589439868927,0.4088936746120453,0.43276694416999817,0.42166846990585327,0.42666706442832947,0.4267752468585968,0.42189452052116394,0.4544856548309326,0.4318840801715851,0.42780667543411255,0.4317077100276947,0.4301455616950989,0.4275650978088379,0.4286048412322998,0.4133305549621582,0.41268041729927063,0.4188462197780609,0.43059229850769043,0.4223198890686035,0.4055454432964325,0.41591858863830566,0.4247846305370331,0.4101029932498932,0.410722941160202,0.4209791123867035,0.41524967551231384,0.42162781953811646,0.40435951948165894,0.4214991629123688,0.4375900626182556,0.43647629022598267,0.41198864579200745,0.41403496265411377,0.4190208613872528,0.42362114787101746,0.42038172483444214,0.42230138182640076,0.4170982241630554,0.4068293869495392,0.41075217723846436,0.4207545816898346,0.41518810391426086,0.4108608365058899,0.4077845811843872,0.4087753891944885,0.4187648594379425,0.41987186670303345,0.4271717667579651,0.4295010566711426,0.41934269666671753,0.4184718728065491,0.41669514775276184,0.4224332869052887,0.41838428378105164,0.4250061810016632,0.42101573944091797,0.4233176112174988,0.4137266278266907,0.4220236837863922,0.41635093092918396,0.4300084114074707,0.416976660490036,0.4125308692455292,0.4252534806728363,0.41317984461784363,0.43020427227020264,0.4109860956668854,0.43584102392196655,0.41629138588905334,0.431697279214859,0.43819841742515564,0.4247053861618042,0.41031429171562195,0.40582841634750366,0.40465086698532104,0.4297637939453125,0.4088069498538971,0.4166398346424103,0.4119299650192261,0.42798563838005066,0.42047473788261414,0.40916797518730164,0.4075641334056854,0.4060148596763611,0.4096914529800415,0.42621347308158875,0.40933793783187866,0.41759026050567627,0.43069425225257874,0.41042786836624146,0.40770819783210754,0.4085882902145386,0.41084179282188416,0.40918248891830444,0.4019694924354553,0.4015294909477234,0.4105421304702759,0.4196215569972992,0.41401001811027527,0.41227346658706665,0.4230685532093048,0.4026069939136505,0.4191342294216156,0.4139098823070526,0.41433122754096985,0.4066312909126282,0.42264246940612793,0.4005453586578369,0.4150933027267456,0.4207628071308136,0.40908440947532654,0.41127175092697144,0.41189736127853394,0.4076880216598511,0.39938271045684814,0.42006218433380127,0.410581111907959,0.41186121106147766,0.4060850143432617,0.407043993473053,0.4107089340686798,0.41492924094200134,0.4228774607181549,0.4201936423778534,0.4206986129283905,0.42620208859443665,0.4090951681137085,0.4198480248451233,0.4094507694244385,0.421626478433609,0.4101405739784241,0.4131544232368469,0.4261241555213928,0.4362788200378418,0.42554405331611633,0.40319275856018066,0.41684043407440186,0.40052905678749084,0.4165416955947876,0.4040622413158417,0.41543763875961304,0.4138108789920807,0.4056136906147003,0.4193049967288971,0.41735416650772095,0.4009746015071869,0.4050506353378296,0.4192321002483368,0.4160846471786499,0.41157451272010803,0.4138640761375427,0.4090219736099243,0.4202864170074463,0.40959081053733826,0.41031479835510254,0.419499933719635,0.4109981954097748,0.4177386164665222,0.4106734097003937,0.41556593775749207,0.4211243689060211,0.4161233603954315,0.41843748092651367,0.41977977752685547,0.4268058240413666,0.42360931634902954,0.42194366455078125,0.42698004841804504,0.4147059917449951,0.4127959907054901,0.42130711674690247,0.4153048098087311,0.41362664103507996,0.41284477710723877,0.42584967613220215,0.41540566086769104,0.4215720295906067,0.4188145399093628,0.4128829836845398,0.40154004096984863,0.4133434593677521,0.4215647578239441,0.4148404598236084,0.433027982711792,0.4111926257610321,0.4217184782028198,0.404325395822525,0.4173859655857086,0.41331860423088074,0.41850000619888306,0.4107169210910797,0.4054274260997772,0.40726420283317566,0.4116179347038269,0.4044926166534424,0.4181918203830719,0.4143409729003906,0.4162881672382355,0.4329538643360138,0.4260905683040619,0.41063424944877625,0.4120112359523773,0.41913238167762756,0.4178187847137451,0.4153841733932495,0.4172307848930359,0.4141197204589844,0.41139110922813416,0.4167671203613281,0.41262194514274597,0.4006824791431427,0.40295544266700745,0.404839426279068,0.4181383550167084,0.4102623760700226,0.40562933683395386,0.4060472846031189,0.4122776389122009,0.4306216537952423,0.4141513705253601,0.4149268865585327,0.41702425479888916,0.4133599102497101,0.41697385907173157,0.4156944453716278,0.40499168634414673,0.40074360370635986,0.4128938913345337,0.3927304744720459,0.413858562707901,0.40581074357032776,0.3994424641132355,0.40354594588279724,0.42232468724250793,0.41080209612846375,0.397098571062088,0.42333653569221497,0.4176745116710663,0.4116567373275757,0.402876615524292,0.41954120993614197,0.4144658148288727,0.4165744483470917,0.40589088201522827,0.4032716751098633,0.41224637627601624,0.41828396916389465,0.4130573868751526,0.41156724095344543,0.40944069623947144,0.4127189815044403,0.408531129360199,0.41660162806510925,0.4054119884967804,0.4099082052707672,0.4204369783401489,0.42604926228523254,0.4153085947036743,0.41319724917411804,0.41541826725006104,0.42190730571746826,0.4062005579471588,0.4160263240337372,0.41590359807014465,0.42173346877098083,0.41388875246047974,0.4132612645626068,0.41195398569107056,0.41180673241615295,0.42282378673553467,0.4103516936302185,0.41810277104377747,0.4122810661792755,0.4189121723175049,0.4086156189441681,0.40786468982696533,0.4256775379180908,0.41762831807136536,0.4059300124645233,0.4193926453590393,0.4016834795475006,0.40623292326927185,0.41584232449531555,0.40128156542778015,0.4144285023212433,0.4062507450580597,0.4307112395763397,0.40523940324783325,0.4173164963722229,0.42538055777549744,0.4191368520259857,0.417050838470459,0.39721882343292236,0.4008108377456665,0.4196648597717285,0.4122861325740814,0.4148767292499542,0.40712517499923706,0.3991115093231201,0.4031241536140442,0.3951303958892822,0.42320266366004944,0.4099839925765991,0.4173036813735962,0.4063161611557007,0.40213140845298767,0.41251957416534424,0.4079464375972748,0.4049137830734253,0.42566776275634766,0.4048590064048767,0.4158405661582947,0.41898205876350403,0.4141019284725189,0.41100212931632996,0.408407986164093,0.4079046845436096,0.4064924716949463,0.416497141122818,0.41642042994499207,0.4050845503807068,0.4049876630306244,0.4184759259223938,0.41475436091423035,0.4220103919506073,0.41912299394607544,0.40852829813957214,0.41591253876686096,0.4105830490589142,0.4067981541156769,0.4016476571559906,0.4080237150192261,0.4088032841682434,0.4076870083808899,0.41568779945373535,0.4136156141757965,0.3991173207759857,0.4166097044944763,0.38875827193260193,0.41154009103775024,0.4088532626628876,0.41574394702911377,0.4043734669685364,0.41841766238212585,0.41470202803611755,0.4062122106552124,0.4153608977794647,0.4011448919773102,0.40740829706192017,0.40904316306114197,0.40067097544670105,0.41107362508773804,0.40977251529693604,0.4070776700973511,0.41715073585510254,0.4268971383571625,0.41249004006385803,0.43774014711380005,0.40950897336006165,0.4131498634815216,0.4204205274581909,0.4142914116382599,0.40991005301475525,0.41254985332489014,0.4056112766265869,0.3890599310398102,0.4115139842033386,0.3950382173061371,0.41476285457611084,0.4159375727176666,0.4169047176837921,0.41436150670051575,0.40729451179504395,0.39248642325401306,0.410585880279541,0.4163586497306824,0.41652196645736694,0.41336846351623535,0.4218408763408661,0.402200847864151,0.411068856716156,0.4099802076816559,0.40816226601600647,0.41886013746261597,0.40598273277282715,0.413519024848938,0.41658201813697815,0.414226233959198,0.42607781291007996,0.3940248191356659,0.42172688245773315,0.4153018295764923,0.4207315444946289,0.41372451186180115,0.4200652539730072,0.41188767552375793,0.4068787097930908,0.4236046075820923,0.4066009521484375,0.4205808639526367,0.3986116945743561,0.40566286444664,0.4132643938064575,0.41244611144065857,0.42492473125457764,0.4079456031322479,0.4083012342453003,0.4162837266921997,0.4279884994029999,0.42825818061828613,0.42280855774879456,0.41077908873558044,0.4244789183139801,0.4103676378726959,0.4211317002773285,0.4249058961868286,0.40575942397117615,0.4248444736003876,0.40597206354141235,0.4119861423969269,0.4013267755508423,0.4050058424472809,0.4180845618247986,0.40701115131378174,0.4025770127773285,0.4118240773677826,0.4183746874332428,0.40265029668807983,0.4188902974128723,0.40754249691963196,0.4227558672428131,0.4075869917869568,0.39405256509780884,0.39088085293769836,0.40986987948417664,0.41124558448791504,0.4136998653411865,0.40906912088394165,0.4251454472541809,0.4092053771018982,0.4095597267150879,0.39809179306030273,0.40895411372184753,0.40518805384635925,0.39654576778411865,0.41852089762687683,0.3921011686325073,0.4181506931781769,0.41924166679382324,0.4118557572364807,0.40689602494239807,0.4101729393005371,0.41446325182914734,0.41324061155319214,0.4320920407772064,0.4172121584415436,0.4123232960700989,0.407572478055954,0.40825679898262024,0.3987504839897156,0.4187595844268799,0.41911470890045166,0.40442296862602234,0.41295793652534485,0.41704437136650085,0.40499603748321533],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\",\"width\":2},\"mode\":\"lines\",\"name\":\"val_loss\",\"y\":[1.9235409498214722,1.4683563709259033,1.1586312055587769,1.1887229681015015,0.8092191219329834,1.0130547285079956,0.9862538576126099,0.6862787008285522,1.336419701576233,0.8813263177871704,0.852601170539856,0.974809467792511,1.0413169860839844,0.631967306137085,0.8832938075065613,0.6862994432449341,0.7538416385650635,0.8182852864265442,0.6271910667419434,0.7002764344215393,0.6224094033241272,0.5947978496551514,0.5636168718338013,0.5850159525871277,0.5630611181259155,0.5663497447967529,0.5679481029510498,0.6387736797332764,0.5545987486839294,0.6541379690170288,0.5258501768112183,0.5516626834869385,0.549652636051178,0.5534138083457947,0.558690071105957,0.537850022315979,0.5351169109344482,0.5276378393173218,0.5086770057678223,0.5279101133346558,0.5151178240776062,0.5067378282546997,0.5431163907051086,0.5035297870635986,0.5081251263618469,0.5091757774353027,0.5236908197402954,0.5169948935508728,0.5312600135803223,0.4956287741661072,0.5062336921691895,0.5084049105644226,0.49482569098472595,0.4973675012588501,0.4966449439525604,0.4940739870071411,0.4894706904888153,0.5115512609481812,0.49227046966552734,0.5061346292495728,0.48529908061027527,0.49180328845977783,0.483230322599411,0.4840388298034668,0.48842576146125793,0.5368868112564087,0.49177688360214233,0.5421192049980164,0.4841890037059784,0.47287094593048096,0.5173315405845642,0.48361024260520935,0.47099950909614563,0.5009652972221375,0.4781459867954254,0.46887701749801636,0.5247036218643188,0.596413791179657,0.5600506067276001,0.4653010368347168,0.48014935851097107,0.4712679386138916,0.496005654335022,0.47293218970298767,0.49101221561431885,0.46735480427742004,0.4596133530139923,0.4609929919242859,0.46260693669319153,0.5168516635894775,0.4647911787033081,0.47298577427864075,0.48942920565605164,0.45579180121421814,0.45350220799446106,0.4584890305995941,0.45376232266426086,0.4485540986061096,0.4562305212020874,0.45516473054885864,0.45381537079811096,0.4482897222042084,0.45188647508621216,0.45261362195014954,0.4599372148513794,0.4656284749507904,0.46955448389053345,0.45751532912254333,0.46556517481803894,0.44601887464523315,0.4503161907196045,0.4455725848674774,0.4444684386253357,0.4481971561908722,0.4405934512615204,0.45024481415748596,0.44277533888816833,0.444388747215271,0.44067656993865967,0.4683307707309723,0.4482485353946686,0.46165814995765686,0.45372098684310913,0.44746434688568115,0.45746585726737976,0.4419686496257782,0.43862026929855347,0.43532440066337585,0.43442046642303467,0.4443187117576599,0.44058191776275635,0.44384437799453735,0.4507676959037781,0.43609699606895447,0.44295722246170044,0.4304133355617523,0.42837539315223694,0.431031733751297,0.4313616454601288,0.4312482178211212,0.43524953722953796,0.43280211091041565,0.43255603313446045,0.4325868487358093,0.4465334415435791,0.45320430397987366,0.43996426463127136,0.4705115854740143,0.4536842405796051,0.4561188519001007,0.4259004592895508,0.42458269000053406,0.4262278974056244,0.43303319811820984,0.43123334646224976,0.4343583285808563,0.42427858710289,0.429636150598526,0.43171846866607666,0.4286707043647766,0.42582064867019653,0.42454561591148376,0.4344910979270935,0.4220251441001892,0.42659252882003784,0.42708727717399597,0.42715057730674744,0.42409536242485046,0.4312655031681061,0.432736337184906,0.44245216250419617,0.4264172315597534,0.43146225810050964,0.4257097840309143,0.42089179158210754,0.43109625577926636,0.4234572649002075,0.43688517808914185,0.4205864369869232,0.4338228702545166,0.4218766987323761,0.431993693113327,0.43165966868400574,0.4433120787143707,0.43118876218795776,0.4300447404384613,0.4307405650615692,0.4302314817905426,0.42022961378097534,0.42403337359428406,0.43136242032051086,0.42243847250938416,0.41799452900886536,0.419816792011261,0.42257797718048096,0.4186075031757355,0.4247179329395294,0.4198651909828186,0.42191898822784424,0.41831833124160767,0.4173681437969208,0.41975682973861694,0.4209960699081421,0.4167473018169403,0.42665237188339233,0.42062923312187195,0.4357894957065582,0.42401885986328125,0.4278935492038727,0.4211670458316803,0.4282445013523102,0.4181272089481354,0.416498601436615,0.42013025283813477,0.4165816605091095,0.42079782485961914,0.41468560695648193,0.41803741455078125,0.41851329803466797,0.4235383868217468,0.41652271151542664,0.41470855474472046,0.42444300651550293,0.41719380021095276,0.416806697845459,0.41950279474258423,0.41876164078712463,0.42156216502189636,0.41523316502571106,0.41992703080177307,0.41887617111206055,0.4275759160518646,0.42024561762809753,0.4335290491580963,0.42040351033210754,0.41764482855796814,0.418131560087204,0.4138839542865753,0.4237039387226105,0.4158901274204254,0.4217339754104614,0.4145611524581909,0.41689538955688477,0.4149891436100006,0.42159712314605713,0.4121365249156952,0.42432159185409546,0.4133414924144745,0.41250067949295044,0.42874675989151,0.41453516483306885,0.42218202352523804,0.4149802327156067,0.42075803875923157,0.41711652278900146,0.41877734661102295,0.4151080846786499,0.4119172692298889,0.41660434007644653,0.41461941599845886,0.41621315479278564,0.41163820028305054,0.41409802436828613,0.4128694236278534,0.4094792306423187,0.4114565849304199,0.41137176752090454,0.4177558720111847,0.41448426246643066,0.41682863235473633,0.4127964377403259,0.4456789195537567,0.4157356023788452,0.4216125011444092,0.41130924224853516,0.41572266817092896,0.41286560893058777,0.41064342856407166,0.41751182079315186,0.40908339619636536,0.40940621495246887,0.4125850796699524,0.4128172695636749,0.4110115170478821,0.41600871086120605,0.4088596999645233,0.41288354992866516,0.41281068325042725,0.41126784682273865,0.4112168848514557,0.4110332131385803,0.4213641881942749,0.41166460514068604,0.41420966386795044,0.40896105766296387,0.4175178110599518,0.4110558331012726,0.4185040295124054,0.4105733036994934,0.41553714871406555,0.4114390015602112,0.41375306248664856,0.4128378629684448,0.4123699367046356,0.42090290784835815,0.41151589155197144,0.41803276538848877,0.4132649600505829,0.41534554958343506,0.41447290778160095,0.41222745180130005,0.4142496883869171,0.4157716929912567,0.40940359234809875,0.423852801322937,0.4107811152935028,0.43573319911956787,0.4131218194961548,0.41324853897094727,0.41457781195640564,0.4161156713962555,0.42257821559906006,0.4117012023925781,0.42302751541137695,0.4107896387577057,0.4170312285423279,0.41050586104393005,0.4132384657859802,0.4137314558029175,0.41122937202453613,0.41088393330574036,0.40784844756126404,0.41060671210289,0.41157835721969604,0.4090368449687958,0.4092179536819458,0.4174342155456543,0.4097228944301605,0.41054749488830566,0.41513708233833313,0.4156190752983093,0.4144924581050873,0.41261255741119385,0.4139910042285919,0.4101253151893616,0.41100963950157166,0.41307324171066284,0.4070603847503662,0.4062858521938324,0.414542019367218,0.4074711203575134,0.4121335744857788,0.4072239398956299,0.4162393808364868,0.4090271592140198,0.41077083349227905,0.4117559492588043,0.41112038493156433,0.41254034638404846,0.4100850224494934,0.4095708429813385,0.4122982919216156,0.4072064459323883,0.4187568426132202,0.40563899278640747,0.41216492652893066,0.4066084623336792,0.4094383716583252,0.40762650966644287,0.4081282913684845,0.4237288236618042,0.4069596230983734,0.40899229049682617,0.45515111088752747,0.4096364676952362,0.41378268599510193,0.4113995134830475,0.4106419086456299,0.4158858060836792,0.4081302583217621,0.41103094816207886,0.41494885087013245,0.409440815448761,0.4098697006702423,0.4122123122215271,0.4107913076877594,0.41126886010169983,0.40745094418525696,0.41109734773635864,0.4171052873134613,0.40827757120132446,0.40891140699386597,0.4396311044692993,0.41172510385513306,0.4264236390590668,0.40954795479774475,0.4086219072341919,0.4249325394630432,0.40580883622169495,0.40619364380836487,0.43240588903427124,0.41992393136024475,0.43970683217048645,0.406485915184021,0.41200947761535645,0.40660595893859863,0.4049524962902069,0.4101303815841675,0.403658390045166,0.4059498608112335,0.41774439811706543,0.4079035222530365,0.4180629551410675,0.4118324816226959,0.40798890590667725,0.4167167842388153,0.40632131695747375,0.4046512246131897,0.40331342816352844,0.405444860458374,0.4095248579978943,0.405471533536911,0.41053882241249084,0.4089450538158417,0.40538281202316284,0.4132646918296814,0.405401349067688,0.40515005588531494,0.40676820278167725,0.40696951746940613,0.40737295150756836,0.40385740995407104,0.40712982416152954,0.4068452715873718,0.4177808165550232,0.4029562175273895,0.41496965289115906,0.4041995406150818,0.4040442407131195,0.41712257266044617,0.40448522567749023,0.4028526246547699,0.4206547439098358,0.40241992473602295,0.40236738324165344,0.4164031445980072,0.40302208065986633,0.40767616033554077,0.40609538555145264,0.40574151277542114,0.40836432576179504,0.4055218994617462,0.4125153124332428,0.4063330888748169,0.4014054834842682,0.417447030544281,0.4042495787143707,0.40915605425834656,0.40922021865844727,0.4062044024467468,0.41476213932037354,0.40482887625694275,0.4056251645088196,0.41177329421043396,0.4056365489959717,0.40732887387275696,0.40983015298843384,0.4065049886703491,0.40587320923805237,0.40349718928337097,0.4143885672092438,0.40409862995147705,0.40714341402053833,0.4109992980957031,0.4017350971698761,0.412109911441803,0.4032858610153198,0.40459102392196655,0.4068496823310852,0.40137699246406555,0.4124358892440796,0.40665319561958313,0.403211772441864,0.40741321444511414,0.403474897146225,0.4135078489780426,0.40371838212013245,0.4076755940914154,0.4051951467990875,0.4168418049812317,0.40501245856285095,0.41595110297203064,0.40254414081573486,0.40934130549430847,0.4037731885910034,0.40533125400543213,0.4052797853946686,0.40240612626075745,0.40785694122314453,0.40053513646125793,0.41034337878227234,0.40383028984069824,0.4053489565849304,0.40900591015815735,0.4050474166870117,0.4090181589126587,0.4051092565059662,0.40678131580352783,0.4020174443721771,0.40617111325263977,0.40638816356658936,0.40264666080474854,0.409670352935791,0.40765050053596497,0.406435489654541,0.4084181487560272,0.4093611538410187,0.4040379822254181,0.4181750416755676,0.40322136878967285,0.409261554479599,0.4082036316394806,0.402441143989563,0.40856751799583435,0.4031168222427368,0.4044489562511444,0.4141259789466858,0.401896208524704,0.4080609381198883,0.4048941731452942,0.4013808071613312,0.4250583052635193,0.40177300572395325,0.4015646278858185,0.42431217432022095,0.4027566611766815,0.4071024954319,0.4024580419063568,0.4018422067165375,0.4295942783355713,0.4027842879295349,0.40507543087005615,0.4452452063560486,0.4084930121898651,0.40498998761177063,0.42349767684936523,0.40365931391716003,0.4116569757461548,0.40553632378578186,0.40082475543022156,0.40529167652130127,0.4041527807712555,0.4021313488483429,0.4033583402633667,0.40081965923309326,0.4039854109287262,0.4073077440261841,0.40255871415138245,0.4068077504634857,0.40289685130119324,0.40444865822792053,0.40059855580329895,0.4104512333869934,0.40229707956314087,0.4177248179912567,0.40205639600753784,0.40811705589294434,0.40708670020103455,0.4032522439956665,0.4173753261566162,0.4021630883216858,0.4041239321231842,0.40647590160369873,0.4062928557395935,0.4073726236820221,0.4178323745727539,0.4059789478778839,0.4035715162754059,0.4071522653102875,0.40439462661743164,0.40592530369758606,0.4038003087043762,0.42566847801208496,0.4031728506088257,0.40488120913505554,0.4104869067668915,0.40112870931625366,0.4104270339012146,0.40286627411842346,0.4019998610019684,0.4122811257839203,0.40149688720703125,0.4022185206413269,0.40369752049446106,0.4024609625339508,0.42758870124816895,0.4055570363998413,0.4053474962711334,0.4097747802734375,0.4056002199649811,0.41214147210121155,0.4085124135017395,0.4030798673629761,0.4161534607410431,0.40382444858551025,0.4027861952781677,0.4092269837856293,0.3994874358177185,0.4052508473396301,0.40751683712005615,0.4015916883945465,0.40620240569114685,0.41032537817955017,0.4033403694629669,0.4122602343559265,0.40418702363967896,0.4037318825721741,0.41108179092407227,0.40204060077667236,0.4021785855293274,0.41659244894981384,0.400427907705307,0.4022970497608185,0.4126984775066376,0.40144166350364685,0.403404176235199,0.404171884059906,0.40316691994667053,0.4072238504886627,0.4015856087207794,0.40437597036361694,0.41042783856391907,0.40080931782722473,0.41205283999443054,0.40230146050453186,0.4044255316257477,0.4049031138420105,0.39845559000968933,0.40180039405822754,0.40168431401252747,0.40179920196533203,0.4038153886795044,0.40321582555770874,0.40507689118385315,0.4031844139099121,0.4059911370277405,0.4013826549053192,0.4114522337913513,0.40182483196258545,0.40660780668258667,0.40154629945755005,0.40382909774780273,0.40445318818092346,0.40541717410087585,0.4073256552219391,0.4024646282196045,0.4111790657043457,0.4087236821651459,0.40229132771492004,0.41477635502815247,0.40156206488609314,0.4046710729598999,0.40879443287849426,0.40276041626930237,0.40654683113098145,0.40613964200019836,0.4010053277015686,0.41920867562294006,0.40225934982299805,0.40809065103530884,0.41246339678764343,0.40338853001594543,0.406715989112854,0.4060918092727661,0.40083709359169006,0.40805643796920776,0.4028574526309967,0.4009946286678314,0.40793219208717346,0.4021749794483185,0.40957117080688477,0.40825122594833374,0.40065330266952515,0.4025239944458008,0.40326085686683655,0.4024813175201416,0.41061902046203613,0.40764227509498596,0.40164563059806824,0.4126802086830139,0.4091443419456482,0.39962470531463623,0.402296245098114,0.4137900471687317,0.40113064646720886,0.4028365910053253,0.40582823753356934,0.4020676612854004,0.4013577103614807,0.41704943776130676,0.4015302360057831,0.4135100543498993,0.4013056755065918,0.4036450684070587,0.41358259320259094,0.40346962213516235,0.4088745713233948,0.40825963020324707,0.4019624590873718,0.40783771872520447,0.4029940664768219,0.4026256799697876,0.4092734754085541,0.40043413639068604,0.4122861325740814,0.40257978439331055,0.40172210335731506,0.4176499843597412,0.40089380741119385,0.403779536485672,0.4093858599662781,0.3996143043041229,0.4017481207847595,0.4107039272785187,0.40144699811935425,0.4019242823123932,0.40695908665657043,0.40436607599258423,0.40108978748321533,0.40402987599372864,0.40703877806663513,0.4002438187599182,0.4097697138786316,0.39836975932121277,0.41449329257011414,0.3994245231151581,0.4043237864971161,0.4067433476448059,0.4015578329563141,0.4048781394958496,0.4021978974342346,0.3992775082588196,0.4024062156677246,0.4053158760070801,0.3992152810096741,0.4064202904701233,0.40004703402519226,0.40013062953948975,0.4080204963684082,0.3991920053958893,0.40201810002326965,0.41201525926589966,0.40097126364707947,0.4007280170917511,0.4164385497570038,0.40105223655700684,0.40243279933929443,0.40906262397766113,0.40088051557540894,0.40177100896835327,0.41445133090019226,0.4001225233078003,0.40131843090057373,0.40600818395614624,0.40055128931999207,0.40242519974708557,0.40596461296081543,0.4020148515701294,0.40233156085014343,0.40229448676109314,0.40406543016433716,0.402037113904953,0.4020024240016937,0.4017200171947479,0.4018201231956482,0.4011000990867615,0.40307947993278503,0.3983391225337982,0.4052707552909851,0.4051600694656372,0.4011113941669464,0.40155312418937683,0.4010462164878845,0.40202176570892334,0.40335705876350403,0.4054305851459503,0.3998836874961853,0.4028142988681793,0.4039313495159149,0.4021797180175781,0.4098569452762604,0.40029653906822205,0.4083729386329651,0.4043031632900238,0.401947557926178,0.4143463969230652,0.40730199217796326,0.4031827747821808,0.41421791911125183,0.4060118496417999,0.4004991352558136,0.4080159366130829,0.406098335981369,0.4014193117618561,0.4075316786766052,0.40568166971206665,0.40168851613998413,0.40835902094841003,0.40325668454170227,0.402957558631897,0.403938353061676,0.40114346146583557,0.4142199456691742,0.40440496802330017,0.40543660521507263,0.40885865688323975,0.4108086824417114,0.3990826904773712,0.4043888747692108,0.4121941924095154,0.40088415145874023,0.41599079966545105,0.4020311236381531,0.40201520919799805,0.40451619029045105,0.3992365896701813,0.40287432074546814,0.40861719846725464,0.40397530794143677,0.40311846137046814,0.40703505277633667,0.4059402644634247,0.4034871459007263,0.40297675132751465,0.40714600682258606,0.4004332423210144,0.4025588929653168,0.4078337550163269,0.40086284279823303,0.40350720286369324,0.40484946966171265,0.4018765985965729,0.40152978897094727,0.40169477462768555,0.4038780629634857,0.3981574773788452,0.40603500604629517,0.40361860394477844,0.401650995016098,0.39931830763816833,0.4008196294307709,0.41158196330070496,0.3995523750782013,0.40186014771461487,0.4123380780220032,0.4000585675239563,0.4006684422492981,0.41022610664367676,0.4006381928920746,0.401563823223114,0.4155551791191101,0.4003661572933197,0.4031071066856384,0.408120334148407,0.4038647413253784,0.401640921831131,0.41976675391197205,0.4015478193759918,0.4031919538974762,0.4060518741607666,0.4042699635028839,0.40240147709846497,0.4035443365573883,0.4011959135532379,0.40187034010887146,0.4051702618598938,0.3998273015022278,0.40204963088035583,0.40814855694770813,0.3999482989311218,0.40410199761390686,0.4050883948802948,0.4005592465400696,0.40392619371414185,0.4009852409362793,0.4014718532562256,0.4047354459762573,0.4044327735900879,0.3991803228855133,0.4137609899044037,0.4053059220314026,0.4005364775657654,0.4089331030845642,0.39968034625053406,0.4016662836074829,0.4042777121067047,0.4009163975715637,0.4055859446525574,0.4042215049266815,0.40049058198928833,0.4043435752391815,0.4011785387992859,0.4040645956993103,0.4010140895843506,0.40419626235961914,0.4045851528644562,0.40232646465301514,0.40022459626197815,0.40053531527519226,0.4212287664413452,0.40067774057388306,0.40321075916290283,0.40866467356681824,0.40464717149734497,0.4003618061542511,0.41119280457496643,0.39990538358688354,0.4001641273498535,0.4018629491329193,0.3997335731983185,0.4036577343940735,0.4037962555885315,0.39959684014320374,0.4071701169013977,0.4031257629394531,0.4025301933288574,0.41431719064712524,0.4029688239097595,0.40280377864837646,0.4120025634765625,0.39859387278556824,0.4005974233150482,0.40877148509025574,0.4018545150756836,0.39991113543510437,0.40194037556648254,0.4032706320285797,0.402900755405426,0.39902129769325256,0.414832204580307,0.3988277316093445,0.3987846076488495,0.4162164330482483,0.4041420519351959,0.400176465511322,0.40465638041496277,0.4106824994087219,0.3995024561882019,0.40463370084762573,0.4181777238845825,0.39919766783714294,0.3990359604358673,0.4080441892147064,0.39871543645858765,0.39996811747550964,0.40021172165870667,0.4010556638240814,0.40728282928466797,0.39718347787857056,0.4048506021499634,0.41101372241973877,0.39744192361831665,0.400862455368042,0.4089791476726532,0.3996618688106537,0.3976362943649292,0.39867767691612244,0.4077117145061493,0.3984542191028595,0.4070207476615906,0.4002009630203247,0.39666613936424255,0.4105965197086334,0.4028143584728241,0.3996472656726837,0.4012829661369324,0.40426215529441833,0.39983606338500977,0.40129488706588745,0.4014686644077301,0.4011998176574707,0.4144807755947113,0.4032069742679596,0.40064582228660583,0.4059162735939026,0.39996016025543213,0.4024304449558258,0.40115174651145935,0.3989467918872833,0.40995916724205017,0.3981061577796936,0.3986116945743561,0.4087181091308594,0.3962280750274658,0.39705514907836914,0.410005658864975,0.39925262331962585,0.39962372183799744,0.4098690450191498,0.39941370487213135],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Loss\"},\"xaxis\":{\"title\":{\"text\":\"epochs\"}},\"yaxis\":{\"title\":{\"text\":\"\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5923b8ac-9cb9-4bf5-8230-202204bd98bd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Accuracy"
      ],
      "metadata": {
        "id": "APrQ-3DJ5TNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = go.Scatter(y=his.history['accuracy'],\n",
        "                    mode=\"lines\",\n",
        "                    line=dict(\n",
        "                        width=2,\n",
        "                        color='blue'),\n",
        "                        name=\"acc\"\n",
        "                   )\n",
        "h2 = go.Scatter(y=his.history['val_accuracy'],\n",
        "                    mode=\"lines\",\n",
        "                    line=dict(\n",
        "                        width=2,\n",
        "                        color='red'),\n",
        "                        name=\"val_acc\"\n",
        "                   )\n",
        "\n",
        "data = [h1,h2]\n",
        "layout1 = go.Layout(title='Accuracy',\n",
        "                   xaxis=dict(title='epochs'),\n",
        "                   yaxis=dict(title=''))\n",
        "fig1 = go.Figure(data = data, layout=layout1)\n",
        "plotly.offline.iplot(fig1)"
      ],
      "metadata": {
        "id": "rqlBrikD5UT3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "18b8baa0-0622-412a-ce84-da24e1c34ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"d8c89d59-f7da-4a93-9564-97d934c2898d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d8c89d59-f7da-4a93-9564-97d934c2898d\")) {                    Plotly.newPlot(                        \"d8c89d59-f7da-4a93-9564-97d934c2898d\",                        [{\"line\":{\"color\":\"blue\",\"width\":2},\"mode\":\"lines\",\"name\":\"acc\",\"y\":[0.4000000059604645,0.5,0.5860000252723694,0.6000000238418579,0.5640000104904175,0.550000011920929,0.5920000076293945,0.5920000076293945,0.5699999928474426,0.550000011920929,0.6119999885559082,0.6240000128746033,0.6060000061988831,0.5540000200271606,0.6259999871253967,0.6480000019073486,0.671999990940094,0.6399999856948853,0.6539999842643738,0.6779999732971191,0.671999990940094,0.7139999866485596,0.6880000233650208,0.7179999947547913,0.7179999947547913,0.7200000286102295,0.6959999799728394,0.7400000095367432,0.6919999718666077,0.7039999961853027,0.7239999771118164,0.7419999837875366,0.7120000123977661,0.7379999756813049,0.7360000014305115,0.7599999904632568,0.7400000095367432,0.7440000176429749,0.7519999742507935,0.7519999742507935,0.7699999809265137,0.7720000147819519,0.7419999837875366,0.7620000243186951,0.7739999890327454,0.7559999823570251,0.7760000228881836,0.7540000081062317,0.7419999837875366,0.7540000081062317,0.777999997138977,0.7559999823570251,0.7639999985694885,0.7799999713897705,0.7599999904632568,0.7739999890327454,0.7820000052452087,0.7620000243186951,0.7760000228881836,0.7839999794960022,0.7839999794960022,0.765999972820282,0.7960000038146973,0.777999997138977,0.7940000295639038,0.777999997138977,0.7760000228881836,0.7540000081062317,0.75,0.7620000243186951,0.7699999809265137,0.7540000081062317,0.7760000228881836,0.7839999794960022,0.7680000066757202,0.7839999794960022,0.7799999713897705,0.765999972820282,0.7179999947547913,0.7400000095367432,0.777999997138977,0.7760000228881836,0.7900000214576721,0.7900000214576721,0.7799999713897705,0.7739999890327454,0.7879999876022339,0.7940000295639038,0.7879999876022339,0.7739999890327454,0.7639999985694885,0.800000011920929,0.7699999809265137,0.7760000228881836,0.800000011920929,0.7879999876022339,0.7940000295639038,0.7960000038146973,0.7919999957084656,0.7879999876022339,0.7979999780654907,0.7860000133514404,0.800000011920929,0.7940000295639038,0.7799999713897705,0.7960000038146973,0.7960000038146973,0.7940000295639038,0.7879999876022339,0.7860000133514404,0.7960000038146973,0.8019999861717224,0.8100000023841858,0.7960000038146973,0.7960000038146973,0.8159999847412109,0.7940000295639038,0.800000011920929,0.8040000200271606,0.8220000267028809,0.8059999942779541,0.800000011920929,0.800000011920929,0.7720000147819519,0.7979999780654907,0.8019999861717224,0.8019999861717224,0.8140000104904175,0.8040000200271606,0.7860000133514404,0.800000011920929,0.7940000295639038,0.7960000038146973,0.7979999780654907,0.7940000295639038,0.8100000023841858,0.8059999942779541,0.7979999780654907,0.8159999847412109,0.8080000281333923,0.7919999957084656,0.8059999942779541,0.8040000200271606,0.7919999957084656,0.7979999780654907,0.800000011920929,0.8100000023841858,0.7919999957084656,0.7900000214576721,0.7940000295639038,0.7960000038146973,0.8059999942779541,0.8019999861717224,0.7900000214576721,0.8119999766349792,0.8100000023841858,0.800000011920929,0.8059999942779541,0.8140000104904175,0.8100000023841858,0.8080000281333923,0.7900000214576721,0.8119999766349792,0.7979999780654907,0.8119999766349792,0.8040000200271606,0.8100000023841858,0.800000011920929,0.7960000038146973,0.8019999861717224,0.800000011920929,0.7940000295639038,0.8040000200271606,0.7960000038146973,0.8040000200271606,0.8059999942779541,0.7960000038146973,0.8059999942779541,0.8100000023841858,0.8040000200271606,0.8259999752044678,0.8059999942779541,0.8019999861717224,0.8040000200271606,0.8080000281333923,0.8080000281333923,0.7839999794960022,0.7900000214576721,0.8040000200271606,0.7979999780654907,0.7860000133514404,0.7879999876022339,0.8040000200271606,0.7919999957084656,0.8240000009536743,0.8159999847412109,0.8019999861717224,0.8100000023841858,0.8199999928474426,0.8019999861717224,0.8040000200271606,0.8180000185966492,0.8040000200271606,0.8199999928474426,0.8180000185966492,0.8100000023841858,0.8140000104904175,0.8080000281333923,0.8019999861717224,0.8080000281333923,0.8119999766349792,0.8080000281333923,0.8059999942779541,0.8220000267028809,0.8159999847412109,0.8159999847412109,0.8199999928474426,0.8199999928474426,0.8019999861717224,0.8040000200271606,0.8059999942779541,0.8259999752044678,0.8180000185966492,0.8180000185966492,0.7940000295639038,0.8059999942779541,0.8180000185966492,0.8119999766349792,0.8059999942779541,0.8100000023841858,0.8199999928474426,0.8059999942779541,0.8100000023841858,0.8080000281333923,0.8019999861717224,0.8059999942779541,0.8080000281333923,0.8140000104904175,0.8140000104904175,0.7960000038146973,0.8140000104904175,0.8059999942779541,0.7979999780654907,0.8180000185966492,0.8159999847412109,0.8159999847412109,0.8159999847412109,0.8159999847412109,0.8180000185966492,0.8180000185966492,0.8040000200271606,0.8019999861717224,0.8180000185966492,0.8140000104904175,0.8119999766349792,0.8140000104904175,0.8140000104904175,0.8180000185966492,0.8119999766349792,0.8040000200271606,0.8140000104904175,0.8080000281333923,0.8180000185966492,0.8040000200271606,0.800000011920929,0.8159999847412109,0.8119999766349792,0.7979999780654907,0.8019999861717224,0.8040000200271606,0.8059999942779541,0.8019999861717224,0.8100000023841858,0.8240000009536743,0.8220000267028809,0.8059999942779541,0.8320000171661377,0.8119999766349792,0.7960000038146973,0.8100000023841858,0.8159999847412109,0.8299999833106995,0.8119999766349792,0.8220000267028809,0.800000011920929,0.8199999928474426,0.8100000023841858,0.8339999914169312,0.8059999942779541,0.8059999942779541,0.8119999766349792,0.8259999752044678,0.8100000023841858,0.8199999928474426,0.8059999942779541,0.8180000185966492,0.8119999766349792,0.8199999928474426,0.8180000185966492,0.8140000104904175,0.8159999847412109,0.8100000023841858,0.8080000281333923,0.8080000281333923,0.8140000104904175,0.8240000009536743,0.8100000023841858,0.8259999752044678,0.8140000104904175,0.8240000009536743,0.8159999847412109,0.8180000185966492,0.8140000104904175,0.8259999752044678,0.8240000009536743,0.8059999942779541,0.8040000200271606,0.8100000023841858,0.8040000200271606,0.7940000295639038,0.800000011920929,0.8059999942779541,0.8159999847412109,0.8159999847412109,0.8119999766349792,0.8140000104904175,0.8199999928474426,0.8299999833106995,0.8159999847412109,0.8159999847412109,0.8159999847412109,0.8259999752044678,0.8140000104904175,0.8119999766349792,0.8199999928474426,0.8019999861717224,0.8140000104904175,0.8140000104904175,0.8140000104904175,0.8220000267028809,0.8220000267028809,0.8080000281333923,0.8199999928474426,0.8119999766349792,0.8220000267028809,0.8240000009536743,0.8180000185966492,0.8259999752044678,0.8059999942779541,0.8159999847412109,0.8119999766349792,0.8100000023841858,0.8100000023841858,0.8140000104904175,0.8040000200271606,0.8140000104904175,0.8240000009536743,0.8119999766349792,0.8019999861717224,0.8180000185966492,0.8140000104904175,0.800000011920929,0.8199999928474426,0.8119999766349792,0.8259999752044678,0.8220000267028809,0.8199999928474426,0.8199999928474426,0.8199999928474426,0.800000011920929,0.8119999766349792,0.8199999928474426,0.8259999752044678,0.8299999833106995,0.8199999928474426,0.8119999766349792,0.8080000281333923,0.8339999914169312,0.8119999766349792,0.8140000104904175,0.8140000104904175,0.8240000009536743,0.8140000104904175,0.8159999847412109,0.8180000185966492,0.8299999833106995,0.8199999928474426,0.8119999766349792,0.8199999928474426,0.8140000104904175,0.8220000267028809,0.8259999752044678,0.8019999861717224,0.8080000281333923,0.8080000281333923,0.8140000104904175,0.7960000038146973,0.8240000009536743,0.8259999752044678,0.8080000281333923,0.8159999847412109,0.8140000104904175,0.8080000281333923,0.8180000185966492,0.8320000171661377,0.8199999928474426,0.8240000009536743,0.8259999752044678,0.8180000185966492,0.8119999766349792,0.8140000104904175,0.8119999766349792,0.8140000104904175,0.8220000267028809,0.8180000185966492,0.8240000009536743,0.8119999766349792,0.8220000267028809,0.8040000200271606,0.8199999928474426,0.8240000009536743,0.8140000104904175,0.8159999847412109,0.8240000009536743,0.8180000185966492,0.8180000185966492,0.8299999833106995,0.8199999928474426,0.8159999847412109,0.8159999847412109,0.8199999928474426,0.8140000104904175,0.7979999780654907,0.8140000104904175,0.8140000104904175,0.8180000185966492,0.8159999847412109,0.8100000023841858,0.8180000185966492,0.8180000185966492,0.8240000009536743,0.8379999995231628,0.8140000104904175,0.8259999752044678,0.8339999914169312,0.8159999847412109,0.8140000104904175,0.8220000267028809,0.8100000023841858,0.7979999780654907,0.8299999833106995,0.8159999847412109,0.8140000104904175,0.8180000185966492,0.8220000267028809,0.8240000009536743,0.828000009059906,0.8199999928474426,0.8180000185966492,0.8220000267028809,0.8199999928474426,0.828000009059906,0.8259999752044678,0.8140000104904175,0.828000009059906,0.8159999847412109,0.8199999928474426,0.8220000267028809,0.8080000281333923,0.800000011920929,0.8199999928474426,0.8140000104904175,0.828000009059906,0.8299999833106995,0.8119999766349792,0.8339999914169312,0.8140000104904175,0.8259999752044678,0.8119999766349792,0.8100000023841858,0.8259999752044678,0.8140000104904175,0.8259999752044678,0.8199999928474426,0.8220000267028809,0.8159999847412109,0.8240000009536743,0.8240000009536743,0.8180000185966492,0.8259999752044678,0.8140000104904175,0.8299999833106995,0.8220000267028809,0.8220000267028809,0.8159999847412109,0.8119999766349792,0.8100000023841858,0.8180000185966492,0.8220000267028809,0.8199999928474426,0.8119999766349792,0.8080000281333923,0.8320000171661377,0.8199999928474426,0.8059999942779541,0.8199999928474426,0.8199999928474426,0.8199999928474426,0.8100000023841858,0.8180000185966492,0.8259999752044678,0.8259999752044678,0.8199999928474426,0.8360000252723694,0.8299999833106995,0.8119999766349792,0.8140000104904175,0.828000009059906,0.8180000185966492,0.828000009059906,0.8059999942779541,0.8320000171661377,0.8159999847412109,0.7960000038146973,0.8159999847412109,0.8220000267028809,0.8059999942779541,0.8220000267028809,0.8119999766349792,0.8240000009536743,0.8180000185966492,0.8040000200271606,0.8119999766349792,0.8159999847412109,0.8159999847412109,0.8299999833106995,0.8180000185966492,0.800000011920929,0.8159999847412109,0.8159999847412109,0.8240000009536743,0.8119999766349792,0.8140000104904175,0.8140000104904175,0.8100000023841858,0.8040000200271606,0.8159999847412109,0.8220000267028809,0.8199999928474426,0.8199999928474426,0.8119999766349792,0.8240000009536743,0.8259999752044678,0.8339999914169312,0.8080000281333923,0.8259999752044678,0.8159999847412109,0.8159999847412109,0.8159999847412109,0.8199999928474426,0.8220000267028809,0.8259999752044678,0.8220000267028809,0.8180000185966492,0.8140000104904175,0.828000009059906,0.8199999928474426,0.8220000267028809,0.8159999847412109,0.8199999928474426,0.8100000023841858,0.8180000185966492,0.8259999752044678,0.8360000252723694,0.8180000185966492,0.8259999752044678,0.828000009059906,0.8180000185966492,0.8180000185966492,0.8119999766349792,0.8199999928474426,0.8199999928474426,0.8080000281333923,0.8159999847412109,0.8080000281333923,0.8199999928474426,0.8159999847412109,0.8100000023841858,0.8019999861717224,0.8199999928474426,0.828000009059906,0.8259999752044678,0.8119999766349792,0.8320000171661377,0.8240000009536743,0.8299999833106995,0.8240000009536743,0.8159999847412109,0.8240000009536743,0.8080000281333923,0.8100000023841858,0.8159999847412109,0.8180000185966492,0.8240000009536743,0.8080000281333923,0.8059999942779541,0.8159999847412109,0.8180000185966492,0.828000009059906,0.8240000009536743,0.8299999833106995,0.8220000267028809,0.8199999928474426,0.8220000267028809,0.8259999752044678,0.8259999752044678,0.8240000009536743,0.8259999752044678,0.8159999847412109,0.8059999942779541,0.8220000267028809,0.8220000267028809,0.8259999752044678,0.8259999752044678,0.8420000076293945,0.828000009059906,0.8240000009536743,0.8180000185966492,0.8259999752044678,0.8320000171661377,0.8420000076293945,0.8159999847412109,0.8140000104904175,0.8220000267028809,0.8119999766349792,0.8339999914169312,0.8140000104904175,0.8220000267028809,0.8180000185966492,0.8240000009536743,0.8180000185966492,0.8479999899864197,0.8240000009536743,0.8159999847412109,0.8180000185966492,0.8220000267028809,0.828000009059906,0.8379999995231628,0.8240000009536743,0.8339999914169312,0.8299999833106995,0.8140000104904175,0.8299999833106995,0.8259999752044678,0.8259999752044678,0.8240000009536743,0.8180000185966492,0.8220000267028809,0.8220000267028809,0.8119999766349792,0.8199999928474426,0.8199999928474426,0.8199999928474426,0.8159999847412109,0.8240000009536743,0.8199999928474426,0.8119999766349792,0.8240000009536743,0.8220000267028809,0.828000009059906,0.8180000185966492,0.8180000185966492,0.8299999833106995,0.828000009059906,0.8199999928474426,0.8180000185966492,0.8220000267028809,0.8100000023841858,0.8180000185966492,0.8140000104904175,0.8240000009536743,0.8299999833106995,0.8100000023841858,0.8299999833106995,0.8140000104904175,0.8220000267028809,0.8159999847412109,0.8180000185966492,0.8220000267028809,0.8199999928474426,0.8180000185966492,0.8220000267028809,0.8199999928474426,0.8080000281333923,0.8140000104904175,0.8320000171661377,0.8180000185966492,0.8240000009536743,0.8240000009536743,0.8040000200271606,0.8259999752044678,0.8199999928474426,0.8259999752044678,0.8360000252723694,0.8159999847412109,0.8140000104904175,0.8040000200271606,0.8299999833106995,0.8059999942779541,0.8259999752044678,0.8220000267028809,0.8240000009536743,0.828000009059906,0.8259999752044678,0.8240000009536743,0.8259999752044678,0.8220000267028809,0.8240000009536743,0.8140000104904175,0.8259999752044678,0.8360000252723694,0.8220000267028809,0.8199999928474426,0.8199999928474426,0.8199999928474426,0.828000009059906,0.8100000023841858,0.828000009059906,0.8220000267028809,0.8220000267028809,0.8180000185966492,0.8220000267028809,0.8100000023841858,0.8159999847412109,0.8199999928474426,0.8180000185966492,0.8159999847412109,0.8180000185966492,0.8159999847412109,0.8159999847412109,0.828000009059906,0.8240000009536743,0.8059999942779541,0.8159999847412109,0.8220000267028809,0.8259999752044678,0.8259999752044678,0.8080000281333923,0.8180000185966492,0.8159999847412109,0.8320000171661377,0.8339999914169312,0.8240000009536743,0.8220000267028809,0.828000009059906,0.8199999928474426,0.8199999928474426,0.8159999847412109,0.8140000104904175,0.828000009059906,0.8360000252723694,0.8240000009536743,0.8119999766349792,0.8140000104904175,0.8299999833106995,0.8240000009536743,0.8259999752044678,0.8159999847412109,0.8199999928474426,0.8299999833106995,0.8180000185966492,0.8059999942779541,0.828000009059906,0.8320000171661377,0.8080000281333923,0.8159999847412109,0.8199999928474426,0.8379999995231628,0.8199999928474426,0.8180000185966492,0.8180000185966492,0.8339999914169312,0.8159999847412109,0.8159999847412109,0.8119999766349792,0.828000009059906,0.8259999752044678,0.8199999928474426,0.8159999847412109,0.8199999928474426,0.8119999766349792,0.8220000267028809,0.8199999928474426,0.8180000185966492,0.8360000252723694,0.8379999995231628,0.8119999766349792,0.8059999942779541,0.8119999766349792,0.8220000267028809,0.8180000185966492,0.8199999928474426,0.8259999752044678,0.8220000267028809,0.8259999752044678,0.8119999766349792,0.8100000023841858,0.8140000104904175,0.8360000252723694,0.8220000267028809,0.8240000009536743,0.8080000281333923,0.8180000185966492,0.8259999752044678,0.8360000252723694,0.8100000023841858,0.8199999928474426,0.8119999766349792,0.8119999766349792,0.8320000171661377,0.8119999766349792,0.8080000281333923,0.8080000281333923,0.8220000267028809,0.8119999766349792,0.800000011920929,0.828000009059906,0.8360000252723694,0.8140000104904175,0.8199999928474426,0.8140000104904175,0.8199999928474426,0.8399999737739563,0.8259999752044678,0.8259999752044678,0.8159999847412109,0.8159999847412109,0.8339999914169312,0.8199999928474426,0.8420000076293945,0.8180000185966492,0.8240000009536743,0.8240000009536743,0.8180000185966492,0.8339999914169312,0.8140000104904175,0.8080000281333923,0.8240000009536743,0.8339999914169312,0.8080000281333923,0.8259999752044678,0.8159999847412109,0.8379999995231628,0.8159999847412109,0.8320000171661377,0.8259999752044678,0.8119999766349792,0.8199999928474426,0.8180000185966492,0.8180000185966492,0.8299999833106995,0.8259999752044678,0.8040000200271606,0.8059999942779541,0.8240000009536743,0.8199999928474426,0.8140000104904175,0.8220000267028809,0.8199999928474426,0.8199999928474426,0.828000009059906,0.8199999928474426,0.8259999752044678,0.8240000009536743,0.8159999847412109,0.8180000185966492,0.8379999995231628,0.8220000267028809,0.8159999847412109,0.8320000171661377,0.8299999833106995,0.8360000252723694,0.8119999766349792,0.8360000252723694,0.828000009059906,0.8140000104904175,0.8119999766349792,0.828000009059906,0.8259999752044678,0.8140000104904175,0.8199999928474426,0.8100000023841858,0.8180000185966492,0.828000009059906,0.8119999766349792,0.8159999847412109,0.8220000267028809,0.8220000267028809,0.828000009059906,0.828000009059906,0.8119999766349792,0.8159999847412109,0.8320000171661377,0.828000009059906,0.8220000267028809,0.8180000185966492,0.8360000252723694,0.8360000252723694,0.8320000171661377,0.8339999914169312,0.8180000185966492,0.8180000185966492,0.8320000171661377,0.8240000009536743,0.8320000171661377,0.8360000252723694,0.828000009059906,0.8100000023841858,0.8240000009536743,0.8100000023841858,0.8220000267028809,0.8180000185966492,0.8159999847412109,0.8379999995231628,0.8199999928474426,0.8140000104904175,0.8140000104904175,0.8180000185966492,0.8100000023841858,0.8199999928474426,0.828000009059906,0.8119999766349792,0.8080000281333923,0.8220000267028809,0.8199999928474426,0.828000009059906,0.8180000185966492,0.8180000185966492,0.8199999928474426,0.8299999833106995,0.8299999833106995,0.8180000185966492,0.8199999928474426,0.8159999847412109,0.8180000185966492,0.8180000185966492,0.8199999928474426,0.8199999928474426,0.8259999752044678,0.8119999766349792,0.8140000104904175,0.8080000281333923,0.8379999995231628,0.8159999847412109,0.8360000252723694,0.8339999914169312,0.8220000267028809,0.8240000009536743,0.8299999833106995,0.8259999752044678,0.8240000009536743,0.8360000252723694,0.8159999847412109,0.8159999847412109,0.8159999847412109,0.828000009059906,0.8339999914169312,0.828000009059906,0.8159999847412109,0.8240000009536743,0.8159999847412109,0.8240000009536743,0.8159999847412109,0.8220000267028809,0.8240000009536743,0.8259999752044678,0.8119999766349792,0.8159999847412109,0.8240000009536743,0.8100000023841858,0.8299999833106995,0.8199999928474426,0.8199999928474426,0.8140000104904175,0.8299999833106995,0.8259999752044678,0.8080000281333923,0.8180000185966492,0.7979999780654907,0.8140000104904175,0.8220000267028809,0.8140000104904175,0.8320000171661377,0.828000009059906,0.8100000023841858,0.8159999847412109,0.8199999928474426,0.8299999833106995,0.8259999752044678,0.828000009059906],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\",\"width\":2},\"mode\":\"lines\",\"name\":\"val_acc\",\"y\":[0.4259999990463257,0.6320000290870667,0.6579999923706055,0.5339999794960022,0.593999981880188,0.6639999747276306,0.6600000262260437,0.7080000042915344,0.5879999995231628,0.6480000019073486,0.7120000123977661,0.6320000290870667,0.46000000834465027,0.7120000123977661,0.656000018119812,0.7039999961853027,0.7099999785423279,0.6600000262260437,0.7319999933242798,0.7639999985694885,0.7059999704360962,0.722000002861023,0.765999972820282,0.8100000023841858,0.8080000281333923,0.8140000104904175,0.8019999861717224,0.7179999947547913,0.7599999904632568,0.7419999837875366,0.7820000052452087,0.7599999904632568,0.7480000257492065,0.8119999766349792,0.7540000081062317,0.765999972820282,0.7919999957084656,0.7979999780654907,0.7940000295639038,0.8119999766349792,0.8080000281333923,0.8019999861717224,0.7559999823570251,0.7940000295639038,0.8259999752044678,0.800000011920929,0.7639999985694885,0.7919999957084656,0.8299999833106995,0.7820000052452087,0.7979999780654907,0.7879999876022339,0.8100000023841858,0.8080000281333923,0.8119999766349792,0.8059999942779541,0.8080000281333923,0.7680000066757202,0.8159999847412109,0.8299999833106995,0.7919999957084656,0.8259999752044678,0.8100000023841858,0.8119999766349792,0.7960000038146973,0.8159999847412109,0.8100000023841858,0.7440000176429749,0.8420000076293945,0.8199999928474426,0.7699999809265137,0.8180000185966492,0.8159999847412109,0.777999997138977,0.8140000104904175,0.8199999928474426,0.7599999904632568,0.7620000243186951,0.7400000095367432,0.8159999847412109,0.8040000200271606,0.7979999780654907,0.8339999914169312,0.7960000038146973,0.8119999766349792,0.8059999942779541,0.8180000185966492,0.8140000104904175,0.7940000295639038,0.8159999847412109,0.8019999861717224,0.7919999957084656,0.8240000009536743,0.8100000023841858,0.8140000104904175,0.8199999928474426,0.8059999942779541,0.8159999847412109,0.8360000252723694,0.8040000200271606,0.8320000171661377,0.8119999766349792,0.8199999928474426,0.8240000009536743,0.828000009059906,0.8040000200271606,0.8299999833106995,0.7979999780654907,0.8379999995231628,0.8140000104904175,0.8379999995231628,0.8159999847412109,0.8040000200271606,0.8420000076293945,0.8180000185966492,0.8299999833106995,0.8180000185966492,0.8339999914169312,0.8080000281333923,0.8320000171661377,0.8040000200271606,0.8299999833106995,0.8119999766349792,0.8080000281333923,0.8299999833106995,0.8220000267028809,0.8299999833106995,0.8180000185966492,0.828000009059906,0.8259999752044678,0.8320000171661377,0.8059999942779541,0.8420000076293945,0.8100000023841858,0.8360000252723694,0.8299999833106995,0.8199999928474426,0.8259999752044678,0.8199999928474426,0.8220000267028809,0.8379999995231628,0.8119999766349792,0.8240000009536743,0.828000009059906,0.8059999942779541,0.8299999833106995,0.8159999847412109,0.828000009059906,0.8100000023841858,0.8360000252723694,0.8220000267028809,0.8199999928474426,0.8259999752044678,0.8420000076293945,0.8159999847412109,0.8399999737739563,0.8299999833106995,0.828000009059906,0.8320000171661377,0.8299999833106995,0.8240000009536743,0.8220000267028809,0.8360000252723694,0.8199999928474426,0.8360000252723694,0.8180000185966492,0.8240000009536743,0.8259999752044678,0.828000009059906,0.8140000104904175,0.8240000009536743,0.8220000267028809,0.8299999833106995,0.8399999737739563,0.8320000171661377,0.8360000252723694,0.8140000104904175,0.8379999995231628,0.8259999752044678,0.8339999914169312,0.828000009059906,0.8360000252723694,0.8119999766349792,0.8320000171661377,0.8140000104904175,0.8339999914169312,0.8199999928474426,0.8320000171661377,0.8220000267028809,0.8320000171661377,0.8159999847412109,0.8259999752044678,0.8180000185966492,0.8320000171661377,0.8379999995231628,0.8339999914169312,0.8339999914169312,0.828000009059906,0.8339999914169312,0.8240000009536743,0.8320000171661377,0.828000009059906,0.8360000252723694,0.8339999914169312,0.8360000252723694,0.8220000267028809,0.8379999995231628,0.8240000009536743,0.8339999914169312,0.8180000185966492,0.8320000171661377,0.8299999833106995,0.8299999833106995,0.8399999737739563,0.8320000171661377,0.8360000252723694,0.8299999833106995,0.8379999995231628,0.8259999752044678,0.8379999995231628,0.8240000009536743,0.8299999833106995,0.8379999995231628,0.8180000185966492,0.8360000252723694,0.8339999914169312,0.8299999833106995,0.8360000252723694,0.8240000009536743,0.8320000171661377,0.8339999914169312,0.8420000076293945,0.8259999752044678,0.8339999914169312,0.8339999914169312,0.8360000252723694,0.8299999833106995,0.8259999752044678,0.843999981880188,0.8220000267028809,0.8379999995231628,0.828000009059906,0.8339999914169312,0.8259999752044678,0.8399999737739563,0.8240000009536743,0.8420000076293945,0.8320000171661377,0.8339999914169312,0.8320000171661377,0.828000009059906,0.8420000076293945,0.8320000171661377,0.828000009059906,0.8299999833106995,0.843999981880188,0.8320000171661377,0.8339999914169312,0.8360000252723694,0.8320000171661377,0.8420000076293945,0.8360000252723694,0.8339999914169312,0.828000009059906,0.8259999752044678,0.8299999833106995,0.8299999833106995,0.8420000076293945,0.8240000009536743,0.8399999737739563,0.8360000252723694,0.8339999914169312,0.8199999928474426,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8360000252723694,0.8360000252723694,0.8399999737739563,0.8259999752044678,0.8360000252723694,0.8420000076293945,0.8420000076293945,0.8299999833106995,0.8360000252723694,0.8360000252723694,0.8399999737739563,0.8299999833106995,0.8339999914169312,0.8420000076293945,0.8320000171661377,0.8379999995231628,0.8379999995231628,0.8399999737739563,0.8320000171661377,0.8360000252723694,0.8339999914169312,0.8399999737739563,0.8399999737739563,0.8379999995231628,0.8339999914169312,0.8360000252723694,0.8320000171661377,0.8299999833106995,0.8399999737739563,0.8360000252723694,0.843999981880188,0.8379999995231628,0.8320000171661377,0.8339999914169312,0.8320000171661377,0.8399999737739563,0.8360000252723694,0.8320000171661377,0.8399999737739563,0.8339999914169312,0.8320000171661377,0.8299999833106995,0.8420000076293945,0.843999981880188,0.8240000009536743,0.8399999737739563,0.8339999914169312,0.8479999899864197,0.828000009059906,0.8399999737739563,0.8339999914169312,0.8479999899864197,0.8360000252723694,0.8360000252723694,0.8399999737739563,0.8360000252723694,0.8360000252723694,0.8360000252723694,0.8379999995231628,0.8320000171661377,0.8460000157356262,0.8360000252723694,0.8299999833106995,0.8379999995231628,0.8379999995231628,0.8360000252723694,0.8399999737739563,0.8460000157356262,0.8399999737739563,0.8360000252723694,0.8399999737739563,0.8339999914169312,0.8339999914169312,0.843999981880188,0.8339999914169312,0.8399999737739563,0.8320000171661377,0.8360000252723694,0.8339999914169312,0.8420000076293945,0.8420000076293945,0.8379999995231628,0.8420000076293945,0.8379999995231628,0.8379999995231628,0.8420000076293945,0.8360000252723694,0.843999981880188,0.8360000252723694,0.8379999995231628,0.8399999737739563,0.843999981880188,0.8379999995231628,0.8360000252723694,0.843999981880188,0.8339999914169312,0.8320000171661377,0.8320000171661377,0.828000009059906,0.8379999995231628,0.8399999737739563,0.828000009059906,0.8379999995231628,0.8320000171661377,0.8360000252723694,0.8420000076293945,0.8320000171661377,0.8399999737739563,0.8420000076293945,0.8399999737739563,0.8399999737739563,0.8339999914169312,0.8379999995231628,0.8360000252723694,0.8379999995231628,0.8360000252723694,0.8420000076293945,0.8299999833106995,0.828000009059906,0.843999981880188,0.843999981880188,0.8360000252723694,0.8339999914169312,0.8360000252723694,0.8379999995231628,0.8299999833106995,0.8379999995231628,0.8339999914169312,0.8420000076293945,0.8420000076293945,0.8379999995231628,0.8479999899864197,0.8339999914169312,0.8320000171661377,0.8360000252723694,0.8320000171661377,0.8479999899864197,0.8379999995231628,0.8320000171661377,0.8539999723434448,0.8379999995231628,0.8420000076293945,0.8399999737739563,0.8420000076293945,0.8479999899864197,0.8399999737739563,0.8379999995231628,0.8420000076293945,0.8399999737739563,0.8399999737739563,0.8420000076293945,0.8360000252723694,0.8460000157356262,0.8320000171661377,0.8379999995231628,0.8399999737739563,0.8399999737739563,0.8420000076293945,0.8420000076293945,0.8320000171661377,0.8479999899864197,0.8399999737739563,0.8339999914169312,0.843999981880188,0.8379999995231628,0.8339999914169312,0.843999981880188,0.8339999914169312,0.8399999737739563,0.8420000076293945,0.8360000252723694,0.8420000076293945,0.8420000076293945,0.8360000252723694,0.8420000076293945,0.8360000252723694,0.8420000076293945,0.8360000252723694,0.8320000171661377,0.843999981880188,0.8339999914169312,0.8379999995231628,0.8399999737739563,0.828000009059906,0.8379999995231628,0.8339999914169312,0.8339999914169312,0.8360000252723694,0.8339999914169312,0.8420000076293945,0.8399999737739563,0.8379999995231628,0.8420000076293945,0.8339999914169312,0.8379999995231628,0.8320000171661377,0.8399999737739563,0.8399999737739563,0.8320000171661377,0.8420000076293945,0.8379999995231628,0.8420000076293945,0.8399999737739563,0.8320000171661377,0.8379999995231628,0.8399999737739563,0.8320000171661377,0.8379999995231628,0.8339999914169312,0.8379999995231628,0.8360000252723694,0.8399999737739563,0.8379999995231628,0.8379999995231628,0.8360000252723694,0.8360000252723694,0.8339999914169312,0.8420000076293945,0.8420000076293945,0.843999981880188,0.8420000076293945,0.8320000171661377,0.8360000252723694,0.8320000171661377,0.8399999737739563,0.8320000171661377,0.8399999737739563,0.8379999995231628,0.8420000076293945,0.8399999737739563,0.8420000076293945,0.8379999995231628,0.8360000252723694,0.8399999737739563,0.8399999737739563,0.8299999833106995,0.8399999737739563,0.8420000076293945,0.8420000076293945,0.8399999737739563,0.8360000252723694,0.8299999833106995,0.8360000252723694,0.8379999995231628,0.8379999995231628,0.8399999737739563,0.8379999995231628,0.8360000252723694,0.8379999995231628,0.8399999737739563,0.8379999995231628,0.8320000171661377,0.8399999737739563,0.8399999737739563,0.8299999833106995,0.8379999995231628,0.8320000171661377,0.8360000252723694,0.8320000171661377,0.8339999914169312,0.8399999737739563,0.8399999737739563,0.8259999752044678,0.8399999737739563,0.8339999914169312,0.8240000009536743,0.828000009059906,0.8360000252723694,0.8399999737739563,0.8320000171661377,0.8299999833106995,0.843999981880188,0.8420000076293945,0.828000009059906,0.8379999995231628,0.8399999737739563,0.8399999737739563,0.8399999737739563,0.8360000252723694,0.8379999995231628,0.8379999995231628,0.8399999737739563,0.8399999737739563,0.843999981880188,0.8379999995231628,0.8259999752044678,0.8379999995231628,0.8320000171661377,0.8379999995231628,0.8259999752044678,0.8360000252723694,0.8399999737739563,0.8399999737739563,0.8379999995231628,0.8360000252723694,0.8399999737739563,0.8399999737739563,0.8379999995231628,0.8299999833106995,0.8399999737739563,0.8379999995231628,0.8360000252723694,0.8379999995231628,0.8420000076293945,0.843999981880188,0.8360000252723694,0.8379999995231628,0.8339999914169312,0.8379999995231628,0.8379999995231628,0.8360000252723694,0.8420000076293945,0.8379999995231628,0.828000009059906,0.8420000076293945,0.8399999737739563,0.8399999737739563,0.8339999914169312,0.8399999737739563,0.8320000171661377,0.8320000171661377,0.8339999914169312,0.8360000252723694,0.8320000171661377,0.8399999737739563,0.8399999737739563,0.8320000171661377,0.8360000252723694,0.8399999737739563,0.8399999737739563,0.8379999995231628,0.8299999833106995,0.8399999737739563,0.8379999995231628,0.8339999914169312,0.8420000076293945,0.8399999737739563,0.8299999833106995,0.8360000252723694,0.8420000076293945,0.8420000076293945,0.8379999995231628,0.8339999914169312,0.8399999737739563,0.8379999995231628,0.8299999833106995,0.8339999914169312,0.8379999995231628,0.8320000171661377,0.8420000076293945,0.8379999995231628,0.8420000076293945,0.8399999737739563,0.828000009059906,0.8339999914169312,0.8379999995231628,0.8299999833106995,0.8379999995231628,0.8399999737739563,0.8379999995231628,0.8360000252723694,0.8320000171661377,0.8339999914169312,0.8360000252723694,0.8399999737739563,0.8420000076293945,0.8360000252723694,0.8399999737739563,0.8399999737739563,0.8420000076293945,0.8420000076293945,0.8320000171661377,0.8420000076293945,0.8399999737739563,0.8379999995231628,0.8379999995231628,0.8399999737739563,0.8420000076293945,0.8399999737739563,0.8339999914169312,0.8399999737739563,0.8379999995231628,0.8320000171661377,0.8379999995231628,0.8320000171661377,0.8360000252723694,0.8420000076293945,0.8379999995231628,0.8399999737739563,0.8379999995231628,0.8299999833106995,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8399999737739563,0.8320000171661377,0.8399999737739563,0.8360000252723694,0.8299999833106995,0.8420000076293945,0.8360000252723694,0.8339999914169312,0.8339999914169312,0.8299999833106995,0.8360000252723694,0.843999981880188,0.8339999914169312,0.8339999914169312,0.8320000171661377,0.8379999995231628,0.8399999737739563,0.8360000252723694,0.828000009059906,0.8379999995231628,0.8399999737739563,0.8299999833106995,0.8360000252723694,0.8379999995231628,0.828000009059906,0.8320000171661377,0.8399999737739563,0.8420000076293945,0.8379999995231628,0.8379999995231628,0.8339999914169312,0.8379999995231628,0.8320000171661377,0.8299999833106995,0.8379999995231628,0.8360000252723694,0.8360000252723694,0.8379999995231628,0.8320000171661377,0.8379999995231628,0.8320000171661377,0.8360000252723694,0.8339999914169312,0.8299999833106995,0.8379999995231628,0.8339999914169312,0.8339999914169312,0.8379999995231628,0.8299999833106995,0.8420000076293945,0.843999981880188,0.8299999833106995,0.8299999833106995,0.8320000171661377,0.828000009059906,0.8360000252723694,0.8379999995231628,0.8379999995231628,0.8320000171661377,0.8379999995231628,0.8339999914169312,0.828000009059906,0.8379999995231628,0.8299999833106995,0.8379999995231628,0.8259999752044678,0.8299999833106995,0.8360000252723694,0.8379999995231628,0.8360000252723694,0.8360000252723694,0.828000009059906,0.8360000252723694,0.8360000252723694,0.8299999833106995,0.8379999995231628,0.8399999737739563,0.8420000076293945,0.8360000252723694,0.8339999914169312,0.8379999995231628,0.8379999995231628,0.828000009059906,0.8299999833106995,0.8399999737739563,0.8339999914169312,0.8360000252723694,0.8360000252723694,0.8320000171661377,0.8360000252723694,0.8420000076293945,0.8339999914169312,0.8379999995231628,0.8360000252723694,0.8360000252723694,0.8399999737739563,0.8399999737739563,0.8320000171661377,0.8379999995231628,0.8379999995231628,0.8339999914169312,0.8399999737739563,0.8399999737739563,0.8360000252723694,0.8360000252723694,0.8399999737739563,0.8399999737739563,0.8320000171661377,0.8399999737739563,0.8399999737739563,0.8399999737739563,0.8360000252723694,0.8360000252723694,0.8360000252723694,0.8399999737739563,0.8420000076293945,0.8320000171661377,0.8379999995231628,0.8379999995231628,0.8360000252723694,0.8420000076293945,0.8320000171661377,0.8339999914169312,0.8360000252723694,0.8339999914169312,0.8399999737739563,0.8379999995231628,0.8339999914169312,0.8339999914169312,0.8339999914169312,0.8320000171661377,0.8360000252723694,0.8399999737739563,0.8379999995231628,0.8360000252723694,0.8320000171661377,0.8320000171661377,0.8379999995231628,0.8420000076293945,0.8339999914169312,0.8360000252723694,0.8299999833106995,0.8379999995231628,0.8379999995231628,0.8299999833106995,0.8360000252723694,0.8360000252723694,0.8299999833106995,0.8360000252723694,0.8360000252723694,0.8320000171661377,0.8339999914169312,0.8299999833106995,0.8360000252723694,0.8360000252723694,0.8299999833106995,0.8379999995231628,0.8339999914169312,0.8360000252723694,0.8339999914169312,0.8339999914169312,0.8360000252723694,0.8399999737739563,0.8379999995231628,0.8399999737739563,0.8320000171661377,0.8399999737739563,0.8379999995231628,0.8320000171661377,0.8379999995231628,0.8360000252723694,0.8420000076293945,0.8379999995231628,0.8360000252723694,0.8339999914169312,0.828000009059906,0.8360000252723694,0.8399999737739563,0.8299999833106995,0.8299999833106995,0.8360000252723694,0.8360000252723694,0.8320000171661377,0.8339999914169312,0.8379999995231628,0.8360000252723694,0.8259999752044678,0.8360000252723694,0.8320000171661377,0.8379999995231628,0.8379999995231628,0.8320000171661377,0.8360000252723694,0.8360000252723694,0.8360000252723694,0.8379999995231628,0.8379999995231628,0.8320000171661377,0.8379999995231628,0.8360000252723694,0.8379999995231628,0.8320000171661377,0.8339999914169312,0.8379999995231628,0.8379999995231628,0.8339999914169312,0.8339999914169312,0.8379999995231628,0.8379999995231628,0.8299999833106995,0.8399999737739563,0.8399999737739563,0.8320000171661377,0.8360000252723694,0.8399999737739563,0.8360000252723694,0.8339999914169312,0.8379999995231628,0.8379999995231628,0.8420000076293945,0.8379999995231628,0.8320000171661377,0.8360000252723694,0.8320000171661377,0.8339999914169312,0.8360000252723694,0.8379999995231628,0.8399999737739563,0.8399999737739563,0.8360000252723694,0.8339999914169312,0.8379999995231628,0.8399999737739563,0.8299999833106995,0.8379999995231628,0.8379999995231628,0.8360000252723694,0.8299999833106995,0.8299999833106995,0.8399999737739563,0.8339999914169312,0.8360000252723694,0.8379999995231628,0.8399999737739563,0.8360000252723694,0.8360000252723694,0.828000009059906,0.8360000252723694,0.8420000076293945,0.8379999995231628,0.8339999914169312,0.8320000171661377,0.8320000171661377,0.8399999737739563,0.8399999737739563,0.8339999914169312,0.8399999737739563,0.8320000171661377,0.8360000252723694,0.8360000252723694,0.8360000252723694,0.8399999737739563,0.8360000252723694,0.8339999914169312,0.8379999995231628,0.8399999737739563,0.8360000252723694,0.8299999833106995,0.828000009059906,0.8339999914169312,0.8379999995231628,0.8339999914169312,0.8399999737739563,0.8360000252723694,0.8299999833106995,0.8379999995231628,0.8420000076293945,0.8320000171661377,0.8379999995231628,0.8420000076293945,0.8339999914169312,0.8360000252723694,0.8360000252723694,0.8360000252723694,0.8360000252723694,0.8360000252723694,0.8320000171661377,0.8339999914169312,0.8320000171661377,0.8360000252723694,0.8379999995231628,0.8299999833106995,0.8320000171661377,0.8360000252723694,0.8360000252723694,0.8379999995231628,0.8299999833106995,0.8339999914169312,0.8299999833106995,0.8320000171661377,0.8379999995231628,0.8299999833106995,0.8379999995231628,0.8339999914169312,0.8379999995231628,0.8379999995231628,0.8339999914169312,0.8339999914169312,0.8339999914169312,0.8339999914169312,0.8339999914169312,0.843999981880188,0.8379999995231628,0.8399999737739563,0.8339999914169312,0.8379999995231628,0.8379999995231628,0.8399999737739563,0.8399999737739563,0.8360000252723694,0.828000009059906,0.8360000252723694,0.8339999914169312,0.8320000171661377,0.8339999914169312,0.8420000076293945,0.8360000252723694,0.8360000252723694,0.8360000252723694,0.8399999737739563],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Accuracy\"},\"xaxis\":{\"title\":{\"text\":\"epochs\"}},\"yaxis\":{\"title\":{\"text\":\"\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d8c89d59-f7da-4a93-9564-97d934c2898d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Model"
      ],
      "metadata": {
        "id": "KI16cG935YUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
        "_, val_acc = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Train: %.4f, Validation: %.4f' % (train_acc, val_acc))"
      ],
      "metadata": {
        "id": "bV_qBb9o5ZSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef39a742-fdb4-4720-d8dc-4e368c3045eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.8300, Validation: 0.8400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.predict(x_train)\n",
        "\n",
        "print(np.round(res[:10],3))"
      ],
      "metadata": {
        "id": "5_YEiNDy5ciE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a3a64d3-1c19-4378-cabb-c03d0bd7d261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 1ms/step\n",
            "[[0.003 0.742 0.255]\n",
            " [0.001 0.809 0.189]\n",
            " [0.006 0.747 0.247]\n",
            " [0.999 0.    0.001]\n",
            " [0.    0.154 0.846]\n",
            " [0.013 0.677 0.311]\n",
            " [0.005 0.742 0.253]\n",
            " [0.    0.995 0.005]\n",
            " [0.999 0.    0.001]\n",
            " [0.99  0.    0.01 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "จากภาพด้านบน แสดงค่าความเชื่อมั่นในการทำนายของแต่ละ Class (Class 0, 1, 2) จาก Input Data 10 Record โดยค่าความเชื่อมั่นทุก Class รวมกันเท่ากับ 1.0"
      ],
      "metadata": {
        "id": "GQLPpAma5bSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(60, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(3, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "CTUxK3pNcT5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt =  tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFPJJ1C2cXTS",
        "outputId": "be0ea094-458d-4a5d-8f0e-46afdfa85dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "his = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=1000, verbose=1, batch_size = 128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-uVQdIacbeS",
        "outputId": "5f34283e-5556-4884-8ced-b8c5e67499ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "4/4 [==============================] - 1s 56ms/step - loss: 3.7105 - accuracy: 0.4060 - val_loss: 4.4116 - val_accuracy: 0.3680\n",
            "Epoch 2/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 4.0369 - accuracy: 0.4000 - val_loss: 2.7513 - val_accuracy: 0.4880\n",
            "Epoch 3/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2.5371 - accuracy: 0.5320 - val_loss: 1.6598 - val_accuracy: 0.5440\n",
            "Epoch 4/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.0584 - accuracy: 0.5440 - val_loss: 1.8084 - val_accuracy: 0.6440\n",
            "Epoch 5/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.0858 - accuracy: 0.6060 - val_loss: 1.4030 - val_accuracy: 0.6480\n",
            "Epoch 6/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.8020 - accuracy: 0.6000 - val_loss: 1.7984 - val_accuracy: 0.6120\n",
            "Epoch 7/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.7250 - accuracy: 0.5980 - val_loss: 1.2464 - val_accuracy: 0.6500\n",
            "Epoch 8/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.3172 - accuracy: 0.6120 - val_loss: 0.8514 - val_accuracy: 0.6940\n",
            "Epoch 9/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.0971 - accuracy: 0.6300 - val_loss: 0.9109 - val_accuracy: 0.6640\n",
            "Epoch 10/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.1088 - accuracy: 0.6280 - val_loss: 0.7707 - val_accuracy: 0.7100\n",
            "Epoch 11/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.9414 - accuracy: 0.6420 - val_loss: 0.7276 - val_accuracy: 0.6620\n",
            "Epoch 12/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.7887 - accuracy: 0.6520 - val_loss: 0.6116 - val_accuracy: 0.7140\n",
            "Epoch 13/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7712 - accuracy: 0.6720 - val_loss: 0.6036 - val_accuracy: 0.7280\n",
            "Epoch 14/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.7438 - accuracy: 0.6820 - val_loss: 0.7456 - val_accuracy: 0.6340\n",
            "Epoch 15/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.7000 - accuracy: 0.6760 - val_loss: 0.5718 - val_accuracy: 0.7180\n",
            "Epoch 16/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6623 - accuracy: 0.6940 - val_loss: 0.5690 - val_accuracy: 0.7960\n",
            "Epoch 17/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6683 - accuracy: 0.6860 - val_loss: 0.6426 - val_accuracy: 0.6660\n",
            "Epoch 18/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6573 - accuracy: 0.7260 - val_loss: 0.5696 - val_accuracy: 0.7300\n",
            "Epoch 19/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6326 - accuracy: 0.7080 - val_loss: 0.5618 - val_accuracy: 0.7900\n",
            "Epoch 20/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6590 - accuracy: 0.7120 - val_loss: 0.6118 - val_accuracy: 0.6760\n",
            "Epoch 21/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6423 - accuracy: 0.7120 - val_loss: 0.5500 - val_accuracy: 0.7340\n",
            "Epoch 22/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6132 - accuracy: 0.7340 - val_loss: 0.5416 - val_accuracy: 0.7820\n",
            "Epoch 23/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6079 - accuracy: 0.7280 - val_loss: 0.5587 - val_accuracy: 0.7580\n",
            "Epoch 24/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6075 - accuracy: 0.7420 - val_loss: 0.5526 - val_accuracy: 0.7400\n",
            "Epoch 25/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5975 - accuracy: 0.7440 - val_loss: 0.5496 - val_accuracy: 0.7960\n",
            "Epoch 26/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5794 - accuracy: 0.7580 - val_loss: 0.5532 - val_accuracy: 0.7420\n",
            "Epoch 27/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5919 - accuracy: 0.7580 - val_loss: 0.5423 - val_accuracy: 0.7560\n",
            "Epoch 28/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6089 - accuracy: 0.7220 - val_loss: 0.5470 - val_accuracy: 0.8000\n",
            "Epoch 29/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5736 - accuracy: 0.7600 - val_loss: 0.5601 - val_accuracy: 0.7360\n",
            "Epoch 30/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5769 - accuracy: 0.7340 - val_loss: 0.5616 - val_accuracy: 0.8180\n",
            "Epoch 31/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5941 - accuracy: 0.7620 - val_loss: 0.5577 - val_accuracy: 0.7240\n",
            "Epoch 32/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5726 - accuracy: 0.7460 - val_loss: 0.5513 - val_accuracy: 0.8320\n",
            "Epoch 33/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5736 - accuracy: 0.7400 - val_loss: 0.5590 - val_accuracy: 0.7380\n",
            "Epoch 34/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5693 - accuracy: 0.7500 - val_loss: 0.5261 - val_accuracy: 0.7940\n",
            "Epoch 35/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5769 - accuracy: 0.7620 - val_loss: 0.5239 - val_accuracy: 0.7980\n",
            "Epoch 36/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5689 - accuracy: 0.7560 - val_loss: 0.5150 - val_accuracy: 0.7880\n",
            "Epoch 37/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5409 - accuracy: 0.7920 - val_loss: 0.5155 - val_accuracy: 0.8040\n",
            "Epoch 38/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5685 - accuracy: 0.7560 - val_loss: 0.5275 - val_accuracy: 0.7840\n",
            "Epoch 39/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5548 - accuracy: 0.7780 - val_loss: 0.5143 - val_accuracy: 0.7820\n",
            "Epoch 40/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5550 - accuracy: 0.7620 - val_loss: 0.5235 - val_accuracy: 0.8160\n",
            "Epoch 41/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5559 - accuracy: 0.7680 - val_loss: 0.5281 - val_accuracy: 0.7860\n",
            "Epoch 42/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5418 - accuracy: 0.7700 - val_loss: 0.5079 - val_accuracy: 0.8160\n",
            "Epoch 43/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5427 - accuracy: 0.7860 - val_loss: 0.5212 - val_accuracy: 0.7680\n",
            "Epoch 44/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5760 - accuracy: 0.7680 - val_loss: 0.5432 - val_accuracy: 0.8180\n",
            "Epoch 45/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5515 - accuracy: 0.7720 - val_loss: 0.5219 - val_accuracy: 0.7820\n",
            "Epoch 46/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5535 - accuracy: 0.7740 - val_loss: 0.5325 - val_accuracy: 0.8320\n",
            "Epoch 47/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5621 - accuracy: 0.7460 - val_loss: 0.5127 - val_accuracy: 0.7920\n",
            "Epoch 48/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5467 - accuracy: 0.7880 - val_loss: 0.5052 - val_accuracy: 0.7880\n",
            "Epoch 49/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5377 - accuracy: 0.7720 - val_loss: 0.5113 - val_accuracy: 0.8120\n",
            "Epoch 50/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5413 - accuracy: 0.7660 - val_loss: 0.5160 - val_accuracy: 0.7800\n",
            "Epoch 51/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5330 - accuracy: 0.7740 - val_loss: 0.4964 - val_accuracy: 0.8320\n",
            "Epoch 52/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5272 - accuracy: 0.7780 - val_loss: 0.4923 - val_accuracy: 0.7980\n",
            "Epoch 53/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5211 - accuracy: 0.7800 - val_loss: 0.5043 - val_accuracy: 0.8120\n",
            "Epoch 54/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5267 - accuracy: 0.7720 - val_loss: 0.5008 - val_accuracy: 0.7880\n",
            "Epoch 55/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5181 - accuracy: 0.7940 - val_loss: 0.4890 - val_accuracy: 0.7960\n",
            "Epoch 56/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5216 - accuracy: 0.7780 - val_loss: 0.4944 - val_accuracy: 0.8320\n",
            "Epoch 57/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5094 - accuracy: 0.7920 - val_loss: 0.4893 - val_accuracy: 0.8040\n",
            "Epoch 58/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5236 - accuracy: 0.7740 - val_loss: 0.4850 - val_accuracy: 0.8140\n",
            "Epoch 59/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.5149 - accuracy: 0.7980 - val_loss: 0.4885 - val_accuracy: 0.8020\n",
            "Epoch 60/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5274 - accuracy: 0.7780 - val_loss: 0.4843 - val_accuracy: 0.8080\n",
            "Epoch 61/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5091 - accuracy: 0.7900 - val_loss: 0.4823 - val_accuracy: 0.8120\n",
            "Epoch 62/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5017 - accuracy: 0.7800 - val_loss: 0.4873 - val_accuracy: 0.8040\n",
            "Epoch 63/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.5181 - accuracy: 0.7860 - val_loss: 0.4826 - val_accuracy: 0.8040\n",
            "Epoch 64/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.5053 - accuracy: 0.7860 - val_loss: 0.4892 - val_accuracy: 0.8240\n",
            "Epoch 65/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.5065 - accuracy: 0.7880 - val_loss: 0.4796 - val_accuracy: 0.8060\n",
            "Epoch 66/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5058 - accuracy: 0.7920 - val_loss: 0.4839 - val_accuracy: 0.8120\n",
            "Epoch 67/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5074 - accuracy: 0.7820 - val_loss: 0.4809 - val_accuracy: 0.8220\n",
            "Epoch 68/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5079 - accuracy: 0.7880 - val_loss: 0.4725 - val_accuracy: 0.8140\n",
            "Epoch 69/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5136 - accuracy: 0.7900 - val_loss: 0.4853 - val_accuracy: 0.8200\n",
            "Epoch 70/1000\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.5075 - accuracy: 0.7840 - val_loss: 0.4741 - val_accuracy: 0.8180\n",
            "Epoch 71/1000\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5085 - accuracy: 0.8020 - val_loss: 0.4661 - val_accuracy: 0.8060\n",
            "Epoch 72/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.4932 - accuracy: 0.7840 - val_loss: 0.4706 - val_accuracy: 0.8180\n",
            "Epoch 73/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4980 - accuracy: 0.7980 - val_loss: 0.4831 - val_accuracy: 0.7980\n",
            "Epoch 74/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.4957 - accuracy: 0.7940 - val_loss: 0.4687 - val_accuracy: 0.8080\n",
            "Epoch 75/1000\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.5062 - accuracy: 0.7800 - val_loss: 0.4666 - val_accuracy: 0.8160\n",
            "Epoch 76/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.5059 - accuracy: 0.7900 - val_loss: 0.4677 - val_accuracy: 0.8300\n",
            "Epoch 77/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4969 - accuracy: 0.7820 - val_loss: 0.4678 - val_accuracy: 0.8120\n",
            "Epoch 78/1000\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.5034 - accuracy: 0.7920 - val_loss: 0.4652 - val_accuracy: 0.8280\n",
            "Epoch 79/1000\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.4845 - accuracy: 0.7920 - val_loss: 0.4604 - val_accuracy: 0.8140\n",
            "Epoch 80/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4938 - accuracy: 0.7860 - val_loss: 0.4622 - val_accuracy: 0.8260\n",
            "Epoch 81/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5074 - accuracy: 0.7780 - val_loss: 0.4639 - val_accuracy: 0.8080\n",
            "Epoch 82/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4864 - accuracy: 0.8000 - val_loss: 0.4696 - val_accuracy: 0.8220\n",
            "Epoch 83/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.5116 - accuracy: 0.7820 - val_loss: 0.4701 - val_accuracy: 0.8180\n",
            "Epoch 84/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5058 - accuracy: 0.7820 - val_loss: 0.4611 - val_accuracy: 0.8060\n",
            "Epoch 85/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4912 - accuracy: 0.7960 - val_loss: 0.4682 - val_accuracy: 0.8340\n",
            "Epoch 86/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4900 - accuracy: 0.8000 - val_loss: 0.4698 - val_accuracy: 0.8020\n",
            "Epoch 87/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4978 - accuracy: 0.7820 - val_loss: 0.4607 - val_accuracy: 0.8300\n",
            "Epoch 88/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4857 - accuracy: 0.7980 - val_loss: 0.4674 - val_accuracy: 0.8060\n",
            "Epoch 89/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4852 - accuracy: 0.8020 - val_loss: 0.4608 - val_accuracy: 0.8300\n",
            "Epoch 90/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4819 - accuracy: 0.8020 - val_loss: 0.4558 - val_accuracy: 0.8040\n",
            "Epoch 91/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4781 - accuracy: 0.8020 - val_loss: 0.4602 - val_accuracy: 0.8140\n",
            "Epoch 92/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4755 - accuracy: 0.7980 - val_loss: 0.4605 - val_accuracy: 0.8280\n",
            "Epoch 93/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4873 - accuracy: 0.7980 - val_loss: 0.4527 - val_accuracy: 0.8280\n",
            "Epoch 94/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4689 - accuracy: 0.8040 - val_loss: 0.4576 - val_accuracy: 0.8260\n",
            "Epoch 95/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4842 - accuracy: 0.7940 - val_loss: 0.4579 - val_accuracy: 0.8180\n",
            "Epoch 96/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4813 - accuracy: 0.8040 - val_loss: 0.4547 - val_accuracy: 0.8120\n",
            "Epoch 97/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4765 - accuracy: 0.8060 - val_loss: 0.4508 - val_accuracy: 0.8220\n",
            "Epoch 98/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4823 - accuracy: 0.7940 - val_loss: 0.4509 - val_accuracy: 0.8200\n",
            "Epoch 99/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4867 - accuracy: 0.7960 - val_loss: 0.4569 - val_accuracy: 0.8280\n",
            "Epoch 100/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4712 - accuracy: 0.8000 - val_loss: 0.4483 - val_accuracy: 0.8160\n",
            "Epoch 101/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4731 - accuracy: 0.8000 - val_loss: 0.4478 - val_accuracy: 0.8220\n",
            "Epoch 102/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4719 - accuracy: 0.8160 - val_loss: 0.4475 - val_accuracy: 0.8180\n",
            "Epoch 103/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4884 - accuracy: 0.7920 - val_loss: 0.4450 - val_accuracy: 0.8140\n",
            "Epoch 104/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4774 - accuracy: 0.8100 - val_loss: 0.4510 - val_accuracy: 0.8280\n",
            "Epoch 105/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4696 - accuracy: 0.7960 - val_loss: 0.4479 - val_accuracy: 0.8140\n",
            "Epoch 106/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4893 - accuracy: 0.8000 - val_loss: 0.4519 - val_accuracy: 0.8360\n",
            "Epoch 107/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4794 - accuracy: 0.8000 - val_loss: 0.4509 - val_accuracy: 0.8400\n",
            "Epoch 108/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4802 - accuracy: 0.7960 - val_loss: 0.4529 - val_accuracy: 0.8220\n",
            "Epoch 109/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4696 - accuracy: 0.8040 - val_loss: 0.4444 - val_accuracy: 0.8240\n",
            "Epoch 110/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4680 - accuracy: 0.8160 - val_loss: 0.4402 - val_accuracy: 0.8220\n",
            "Epoch 111/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4747 - accuracy: 0.7960 - val_loss: 0.4462 - val_accuracy: 0.8280\n",
            "Epoch 112/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4619 - accuracy: 0.8140 - val_loss: 0.4411 - val_accuracy: 0.8140\n",
            "Epoch 113/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4666 - accuracy: 0.8020 - val_loss: 0.4409 - val_accuracy: 0.8220\n",
            "Epoch 114/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4540 - accuracy: 0.8160 - val_loss: 0.4443 - val_accuracy: 0.8260\n",
            "Epoch 115/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4895 - accuracy: 0.8100 - val_loss: 0.4498 - val_accuracy: 0.8420\n",
            "Epoch 116/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4818 - accuracy: 0.7980 - val_loss: 0.4545 - val_accuracy: 0.8040\n",
            "Epoch 117/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4809 - accuracy: 0.7840 - val_loss: 0.4437 - val_accuracy: 0.8200\n",
            "Epoch 118/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4621 - accuracy: 0.8100 - val_loss: 0.4408 - val_accuracy: 0.8280\n",
            "Epoch 119/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4905 - accuracy: 0.7940 - val_loss: 0.4470 - val_accuracy: 0.8340\n",
            "Epoch 120/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4711 - accuracy: 0.8000 - val_loss: 0.4371 - val_accuracy: 0.8180\n",
            "Epoch 121/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4554 - accuracy: 0.8020 - val_loss: 0.4448 - val_accuracy: 0.8340\n",
            "Epoch 122/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4456 - accuracy: 0.8180 - val_loss: 0.4395 - val_accuracy: 0.8200\n",
            "Epoch 123/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4679 - accuracy: 0.7980 - val_loss: 0.4384 - val_accuracy: 0.8200\n",
            "Epoch 124/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4525 - accuracy: 0.8020 - val_loss: 0.4381 - val_accuracy: 0.8240\n",
            "Epoch 125/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4664 - accuracy: 0.7980 - val_loss: 0.4435 - val_accuracy: 0.8340\n",
            "Epoch 126/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4614 - accuracy: 0.7960 - val_loss: 0.4346 - val_accuracy: 0.8280\n",
            "Epoch 127/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4456 - accuracy: 0.8180 - val_loss: 0.4333 - val_accuracy: 0.8300\n",
            "Epoch 128/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4545 - accuracy: 0.8040 - val_loss: 0.4372 - val_accuracy: 0.8300\n",
            "Epoch 129/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4576 - accuracy: 0.8100 - val_loss: 0.4417 - val_accuracy: 0.8260\n",
            "Epoch 130/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4512 - accuracy: 0.8020 - val_loss: 0.4402 - val_accuracy: 0.8160\n",
            "Epoch 131/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4483 - accuracy: 0.8020 - val_loss: 0.4412 - val_accuracy: 0.8400\n",
            "Epoch 132/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4689 - accuracy: 0.8100 - val_loss: 0.4395 - val_accuracy: 0.8060\n",
            "Epoch 133/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4708 - accuracy: 0.7940 - val_loss: 0.4418 - val_accuracy: 0.8260\n",
            "Epoch 134/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4584 - accuracy: 0.8180 - val_loss: 0.4362 - val_accuracy: 0.8180\n",
            "Epoch 135/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4706 - accuracy: 0.7960 - val_loss: 0.4347 - val_accuracy: 0.8260\n",
            "Epoch 136/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4595 - accuracy: 0.8220 - val_loss: 0.4318 - val_accuracy: 0.8260\n",
            "Epoch 137/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4532 - accuracy: 0.8060 - val_loss: 0.4335 - val_accuracy: 0.8360\n",
            "Epoch 138/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4387 - accuracy: 0.8240 - val_loss: 0.4301 - val_accuracy: 0.8300\n",
            "Epoch 139/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4417 - accuracy: 0.8100 - val_loss: 0.4284 - val_accuracy: 0.8280\n",
            "Epoch 140/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4467 - accuracy: 0.8200 - val_loss: 0.4381 - val_accuracy: 0.8420\n",
            "Epoch 141/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4462 - accuracy: 0.8060 - val_loss: 0.4297 - val_accuracy: 0.8280\n",
            "Epoch 142/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4786 - accuracy: 0.7820 - val_loss: 0.4329 - val_accuracy: 0.8380\n",
            "Epoch 143/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4590 - accuracy: 0.8180 - val_loss: 0.4334 - val_accuracy: 0.8280\n",
            "Epoch 144/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4716 - accuracy: 0.7880 - val_loss: 0.4318 - val_accuracy: 0.8200\n",
            "Epoch 145/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4535 - accuracy: 0.7980 - val_loss: 0.4378 - val_accuracy: 0.8380\n",
            "Epoch 146/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4574 - accuracy: 0.8020 - val_loss: 0.4359 - val_accuracy: 0.8180\n",
            "Epoch 147/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4568 - accuracy: 0.8000 - val_loss: 0.4460 - val_accuracy: 0.8420\n",
            "Epoch 148/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4532 - accuracy: 0.8120 - val_loss: 0.4307 - val_accuracy: 0.8160\n",
            "Epoch 149/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4630 - accuracy: 0.7980 - val_loss: 0.4320 - val_accuracy: 0.8360\n",
            "Epoch 150/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4629 - accuracy: 0.8060 - val_loss: 0.4293 - val_accuracy: 0.8240\n",
            "Epoch 151/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4490 - accuracy: 0.8000 - val_loss: 0.4343 - val_accuracy: 0.8460\n",
            "Epoch 152/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4537 - accuracy: 0.8160 - val_loss: 0.4306 - val_accuracy: 0.8300\n",
            "Epoch 153/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4516 - accuracy: 0.8020 - val_loss: 0.4266 - val_accuracy: 0.8360\n",
            "Epoch 154/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4484 - accuracy: 0.8080 - val_loss: 0.4277 - val_accuracy: 0.8300\n",
            "Epoch 155/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4480 - accuracy: 0.8000 - val_loss: 0.4251 - val_accuracy: 0.8320\n",
            "Epoch 156/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4466 - accuracy: 0.8080 - val_loss: 0.4282 - val_accuracy: 0.8440\n",
            "Epoch 157/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4603 - accuracy: 0.8040 - val_loss: 0.4298 - val_accuracy: 0.8240\n",
            "Epoch 158/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4440 - accuracy: 0.8100 - val_loss: 0.4448 - val_accuracy: 0.8380\n",
            "Epoch 159/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4512 - accuracy: 0.8140 - val_loss: 0.4318 - val_accuracy: 0.8220\n",
            "Epoch 160/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4547 - accuracy: 0.7900 - val_loss: 0.4281 - val_accuracy: 0.8340\n",
            "Epoch 161/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4478 - accuracy: 0.8220 - val_loss: 0.4240 - val_accuracy: 0.8300\n",
            "Epoch 162/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4439 - accuracy: 0.8080 - val_loss: 0.4309 - val_accuracy: 0.8420\n",
            "Epoch 163/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4426 - accuracy: 0.8060 - val_loss: 0.4249 - val_accuracy: 0.8320\n",
            "Epoch 164/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4723 - accuracy: 0.7960 - val_loss: 0.4269 - val_accuracy: 0.8200\n",
            "Epoch 165/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4617 - accuracy: 0.7960 - val_loss: 0.4336 - val_accuracy: 0.8460\n",
            "Epoch 166/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4690 - accuracy: 0.8000 - val_loss: 0.4303 - val_accuracy: 0.8200\n",
            "Epoch 167/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4513 - accuracy: 0.8120 - val_loss: 0.4420 - val_accuracy: 0.8480\n",
            "Epoch 168/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4472 - accuracy: 0.8140 - val_loss: 0.4253 - val_accuracy: 0.8220\n",
            "Epoch 169/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4411 - accuracy: 0.8080 - val_loss: 0.4283 - val_accuracy: 0.8420\n",
            "Epoch 170/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4475 - accuracy: 0.8060 - val_loss: 0.4219 - val_accuracy: 0.8340\n",
            "Epoch 171/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4549 - accuracy: 0.8040 - val_loss: 0.4221 - val_accuracy: 0.8340\n",
            "Epoch 172/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4438 - accuracy: 0.8280 - val_loss: 0.4198 - val_accuracy: 0.8300\n",
            "Epoch 173/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4331 - accuracy: 0.8140 - val_loss: 0.4229 - val_accuracy: 0.8380\n",
            "Epoch 174/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4408 - accuracy: 0.8200 - val_loss: 0.4260 - val_accuracy: 0.8380\n",
            "Epoch 175/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4425 - accuracy: 0.8040 - val_loss: 0.4202 - val_accuracy: 0.8200\n",
            "Epoch 176/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4482 - accuracy: 0.8080 - val_loss: 0.4199 - val_accuracy: 0.8340\n",
            "Epoch 177/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4629 - accuracy: 0.8080 - val_loss: 0.4198 - val_accuracy: 0.8300\n",
            "Epoch 178/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4370 - accuracy: 0.8100 - val_loss: 0.4225 - val_accuracy: 0.8280\n",
            "Epoch 179/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4396 - accuracy: 0.8120 - val_loss: 0.4266 - val_accuracy: 0.8480\n",
            "Epoch 180/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4457 - accuracy: 0.8120 - val_loss: 0.4243 - val_accuracy: 0.8300\n",
            "Epoch 181/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4485 - accuracy: 0.8100 - val_loss: 0.4205 - val_accuracy: 0.8360\n",
            "Epoch 182/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4315 - accuracy: 0.8120 - val_loss: 0.4163 - val_accuracy: 0.8260\n",
            "Epoch 183/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4337 - accuracy: 0.8240 - val_loss: 0.4182 - val_accuracy: 0.8280\n",
            "Epoch 184/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4323 - accuracy: 0.8200 - val_loss: 0.4218 - val_accuracy: 0.8440\n",
            "Epoch 185/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4536 - accuracy: 0.8180 - val_loss: 0.4214 - val_accuracy: 0.8240\n",
            "Epoch 186/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4642 - accuracy: 0.8040 - val_loss: 0.4293 - val_accuracy: 0.8500\n",
            "Epoch 187/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4595 - accuracy: 0.8120 - val_loss: 0.4251 - val_accuracy: 0.8160\n",
            "Epoch 188/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4537 - accuracy: 0.8120 - val_loss: 0.4289 - val_accuracy: 0.8480\n",
            "Epoch 189/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4506 - accuracy: 0.8200 - val_loss: 0.4205 - val_accuracy: 0.8400\n",
            "Epoch 190/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4528 - accuracy: 0.8060 - val_loss: 0.4205 - val_accuracy: 0.8300\n",
            "Epoch 191/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4439 - accuracy: 0.8220 - val_loss: 0.4286 - val_accuracy: 0.8480\n",
            "Epoch 192/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4358 - accuracy: 0.8080 - val_loss: 0.4191 - val_accuracy: 0.8240\n",
            "Epoch 193/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4203 - accuracy: 0.8160 - val_loss: 0.4207 - val_accuracy: 0.8380\n",
            "Epoch 194/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4524 - accuracy: 0.7940 - val_loss: 0.4168 - val_accuracy: 0.8340\n",
            "Epoch 195/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4403 - accuracy: 0.8040 - val_loss: 0.4241 - val_accuracy: 0.8240\n",
            "Epoch 196/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4390 - accuracy: 0.8200 - val_loss: 0.4241 - val_accuracy: 0.8340\n",
            "Epoch 197/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4405 - accuracy: 0.8220 - val_loss: 0.4221 - val_accuracy: 0.8360\n",
            "Epoch 198/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4619 - accuracy: 0.7960 - val_loss: 0.4217 - val_accuracy: 0.8380\n",
            "Epoch 199/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4519 - accuracy: 0.8060 - val_loss: 0.4201 - val_accuracy: 0.8320\n",
            "Epoch 200/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4422 - accuracy: 0.7980 - val_loss: 0.4158 - val_accuracy: 0.8300\n",
            "Epoch 201/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4330 - accuracy: 0.8040 - val_loss: 0.4283 - val_accuracy: 0.8420\n",
            "Epoch 202/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4520 - accuracy: 0.8140 - val_loss: 0.4161 - val_accuracy: 0.8320\n",
            "Epoch 203/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4310 - accuracy: 0.8020 - val_loss: 0.4164 - val_accuracy: 0.8360\n",
            "Epoch 204/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4336 - accuracy: 0.8060 - val_loss: 0.4179 - val_accuracy: 0.8420\n",
            "Epoch 205/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4514 - accuracy: 0.8060 - val_loss: 0.4158 - val_accuracy: 0.8360\n",
            "Epoch 206/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4393 - accuracy: 0.8100 - val_loss: 0.4183 - val_accuracy: 0.8420\n",
            "Epoch 207/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4362 - accuracy: 0.8240 - val_loss: 0.4165 - val_accuracy: 0.8440\n",
            "Epoch 208/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4356 - accuracy: 0.8240 - val_loss: 0.4176 - val_accuracy: 0.8420\n",
            "Epoch 209/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4301 - accuracy: 0.8280 - val_loss: 0.4136 - val_accuracy: 0.8400\n",
            "Epoch 210/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4370 - accuracy: 0.8180 - val_loss: 0.4140 - val_accuracy: 0.8400\n",
            "Epoch 211/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4547 - accuracy: 0.8080 - val_loss: 0.4186 - val_accuracy: 0.8280\n",
            "Epoch 212/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4269 - accuracy: 0.8180 - val_loss: 0.4257 - val_accuracy: 0.8420\n",
            "Epoch 213/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4314 - accuracy: 0.8320 - val_loss: 0.4138 - val_accuracy: 0.8280\n",
            "Epoch 214/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4432 - accuracy: 0.8200 - val_loss: 0.4154 - val_accuracy: 0.8400\n",
            "Epoch 215/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4371 - accuracy: 0.8100 - val_loss: 0.4165 - val_accuracy: 0.8400\n",
            "Epoch 216/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4443 - accuracy: 0.8280 - val_loss: 0.4152 - val_accuracy: 0.8380\n",
            "Epoch 217/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4293 - accuracy: 0.8220 - val_loss: 0.4190 - val_accuracy: 0.8420\n",
            "Epoch 218/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4369 - accuracy: 0.8200 - val_loss: 0.4149 - val_accuracy: 0.8400\n",
            "Epoch 219/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4403 - accuracy: 0.7940 - val_loss: 0.4138 - val_accuracy: 0.8380\n",
            "Epoch 220/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4282 - accuracy: 0.8240 - val_loss: 0.4134 - val_accuracy: 0.8420\n",
            "Epoch 221/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4204 - accuracy: 0.8220 - val_loss: 0.4102 - val_accuracy: 0.8320\n",
            "Epoch 222/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4507 - accuracy: 0.8180 - val_loss: 0.4199 - val_accuracy: 0.8480\n",
            "Epoch 223/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4372 - accuracy: 0.7920 - val_loss: 0.4180 - val_accuracy: 0.8240\n",
            "Epoch 224/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4390 - accuracy: 0.8080 - val_loss: 0.4181 - val_accuracy: 0.8380\n",
            "Epoch 225/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4532 - accuracy: 0.8000 - val_loss: 0.4144 - val_accuracy: 0.8320\n",
            "Epoch 226/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4321 - accuracy: 0.8260 - val_loss: 0.4283 - val_accuracy: 0.8480\n",
            "Epoch 227/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4338 - accuracy: 0.8080 - val_loss: 0.4136 - val_accuracy: 0.8320\n",
            "Epoch 228/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4434 - accuracy: 0.8220 - val_loss: 0.4164 - val_accuracy: 0.8400\n",
            "Epoch 229/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4454 - accuracy: 0.8080 - val_loss: 0.4149 - val_accuracy: 0.8340\n",
            "Epoch 230/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4261 - accuracy: 0.8120 - val_loss: 0.4192 - val_accuracy: 0.8440\n",
            "Epoch 231/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4363 - accuracy: 0.8220 - val_loss: 0.4113 - val_accuracy: 0.8300\n",
            "Epoch 232/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4512 - accuracy: 0.7980 - val_loss: 0.4114 - val_accuracy: 0.8360\n",
            "Epoch 233/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4538 - accuracy: 0.7980 - val_loss: 0.4280 - val_accuracy: 0.8420\n",
            "Epoch 234/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4457 - accuracy: 0.8060 - val_loss: 0.4240 - val_accuracy: 0.8220\n",
            "Epoch 235/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4536 - accuracy: 0.7940 - val_loss: 0.4182 - val_accuracy: 0.8460\n",
            "Epoch 236/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4702 - accuracy: 0.7980 - val_loss: 0.4135 - val_accuracy: 0.8340\n",
            "Epoch 237/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4342 - accuracy: 0.8200 - val_loss: 0.4194 - val_accuracy: 0.8220\n",
            "Epoch 238/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4368 - accuracy: 0.8120 - val_loss: 0.4369 - val_accuracy: 0.8360\n",
            "Epoch 239/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4641 - accuracy: 0.8000 - val_loss: 0.4159 - val_accuracy: 0.8280\n",
            "Epoch 240/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4364 - accuracy: 0.8020 - val_loss: 0.4145 - val_accuracy: 0.8440\n",
            "Epoch 241/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4320 - accuracy: 0.8040 - val_loss: 0.4123 - val_accuracy: 0.8420\n",
            "Epoch 242/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4259 - accuracy: 0.8200 - val_loss: 0.4119 - val_accuracy: 0.8380\n",
            "Epoch 243/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4337 - accuracy: 0.8120 - val_loss: 0.4126 - val_accuracy: 0.8420\n",
            "Epoch 244/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4308 - accuracy: 0.8120 - val_loss: 0.4131 - val_accuracy: 0.8360\n",
            "Epoch 245/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4253 - accuracy: 0.8300 - val_loss: 0.4149 - val_accuracy: 0.8380\n",
            "Epoch 246/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4324 - accuracy: 0.8260 - val_loss: 0.4133 - val_accuracy: 0.8360\n",
            "Epoch 247/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4383 - accuracy: 0.8220 - val_loss: 0.4188 - val_accuracy: 0.8320\n",
            "Epoch 248/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4258 - accuracy: 0.8120 - val_loss: 0.4110 - val_accuracy: 0.8380\n",
            "Epoch 249/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4504 - accuracy: 0.8040 - val_loss: 0.4104 - val_accuracy: 0.8400\n",
            "Epoch 250/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4342 - accuracy: 0.8140 - val_loss: 0.4122 - val_accuracy: 0.8420\n",
            "Epoch 251/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4258 - accuracy: 0.8260 - val_loss: 0.4149 - val_accuracy: 0.8420\n",
            "Epoch 252/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4323 - accuracy: 0.8060 - val_loss: 0.4130 - val_accuracy: 0.8400\n",
            "Epoch 253/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4348 - accuracy: 0.8100 - val_loss: 0.4109 - val_accuracy: 0.8380\n",
            "Epoch 254/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4278 - accuracy: 0.8180 - val_loss: 0.4125 - val_accuracy: 0.8400\n",
            "Epoch 255/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4330 - accuracy: 0.8160 - val_loss: 0.4091 - val_accuracy: 0.8360\n",
            "Epoch 256/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4271 - accuracy: 0.8180 - val_loss: 0.4141 - val_accuracy: 0.8420\n",
            "Epoch 257/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4379 - accuracy: 0.8120 - val_loss: 0.4112 - val_accuracy: 0.8420\n",
            "Epoch 258/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4186 - accuracy: 0.8240 - val_loss: 0.4095 - val_accuracy: 0.8380\n",
            "Epoch 259/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4322 - accuracy: 0.7980 - val_loss: 0.4108 - val_accuracy: 0.8400\n",
            "Epoch 260/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4175 - accuracy: 0.8160 - val_loss: 0.4125 - val_accuracy: 0.8420\n",
            "Epoch 261/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4315 - accuracy: 0.8240 - val_loss: 0.4112 - val_accuracy: 0.8380\n",
            "Epoch 262/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4422 - accuracy: 0.7980 - val_loss: 0.4125 - val_accuracy: 0.8380\n",
            "Epoch 263/1000\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4408 - accuracy: 0.8280 - val_loss: 0.4144 - val_accuracy: 0.8420\n",
            "Epoch 264/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4334 - accuracy: 0.7960 - val_loss: 0.4115 - val_accuracy: 0.8360\n",
            "Epoch 265/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4256 - accuracy: 0.8360 - val_loss: 0.4256 - val_accuracy: 0.8480\n",
            "Epoch 266/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4363 - accuracy: 0.8140 - val_loss: 0.4130 - val_accuracy: 0.8300\n",
            "Epoch 267/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4315 - accuracy: 0.8060 - val_loss: 0.4134 - val_accuracy: 0.8400\n",
            "Epoch 268/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4294 - accuracy: 0.8200 - val_loss: 0.4154 - val_accuracy: 0.8420\n",
            "Epoch 269/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4414 - accuracy: 0.7940 - val_loss: 0.4112 - val_accuracy: 0.8360\n",
            "Epoch 270/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4259 - accuracy: 0.8140 - val_loss: 0.4086 - val_accuracy: 0.8360\n",
            "Epoch 271/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4175 - accuracy: 0.8180 - val_loss: 0.4152 - val_accuracy: 0.8400\n",
            "Epoch 272/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4451 - accuracy: 0.7980 - val_loss: 0.4101 - val_accuracy: 0.8380\n",
            "Epoch 273/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4272 - accuracy: 0.8220 - val_loss: 0.4137 - val_accuracy: 0.8440\n",
            "Epoch 274/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4368 - accuracy: 0.8080 - val_loss: 0.4089 - val_accuracy: 0.8320\n",
            "Epoch 275/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4273 - accuracy: 0.8100 - val_loss: 0.4102 - val_accuracy: 0.8420\n",
            "Epoch 276/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4251 - accuracy: 0.8140 - val_loss: 0.4104 - val_accuracy: 0.8400\n",
            "Epoch 277/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4326 - accuracy: 0.8220 - val_loss: 0.4107 - val_accuracy: 0.8420\n",
            "Epoch 278/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4121 - accuracy: 0.8160 - val_loss: 0.4104 - val_accuracy: 0.8400\n",
            "Epoch 279/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4250 - accuracy: 0.8140 - val_loss: 0.4122 - val_accuracy: 0.8440\n",
            "Epoch 280/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4260 - accuracy: 0.8160 - val_loss: 0.4106 - val_accuracy: 0.8420\n",
            "Epoch 281/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4305 - accuracy: 0.8100 - val_loss: 0.4098 - val_accuracy: 0.8380\n",
            "Epoch 282/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4233 - accuracy: 0.8160 - val_loss: 0.4117 - val_accuracy: 0.8400\n",
            "Epoch 283/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4399 - accuracy: 0.8020 - val_loss: 0.4106 - val_accuracy: 0.8420\n",
            "Epoch 284/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4344 - accuracy: 0.8120 - val_loss: 0.4072 - val_accuracy: 0.8420\n",
            "Epoch 285/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4257 - accuracy: 0.8220 - val_loss: 0.4090 - val_accuracy: 0.8400\n",
            "Epoch 286/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4241 - accuracy: 0.8140 - val_loss: 0.4098 - val_accuracy: 0.8460\n",
            "Epoch 287/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4357 - accuracy: 0.8080 - val_loss: 0.4090 - val_accuracy: 0.8380\n",
            "Epoch 288/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4318 - accuracy: 0.8120 - val_loss: 0.4127 - val_accuracy: 0.8340\n",
            "Epoch 289/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4293 - accuracy: 0.8100 - val_loss: 0.4079 - val_accuracy: 0.8300\n",
            "Epoch 290/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4296 - accuracy: 0.8080 - val_loss: 0.4147 - val_accuracy: 0.8400\n",
            "Epoch 291/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4290 - accuracy: 0.8180 - val_loss: 0.4092 - val_accuracy: 0.8400\n",
            "Epoch 292/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4373 - accuracy: 0.8260 - val_loss: 0.4105 - val_accuracy: 0.8380\n",
            "Epoch 293/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4332 - accuracy: 0.8000 - val_loss: 0.4068 - val_accuracy: 0.8320\n",
            "Epoch 294/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4220 - accuracy: 0.8160 - val_loss: 0.4111 - val_accuracy: 0.8380\n",
            "Epoch 295/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4207 - accuracy: 0.8180 - val_loss: 0.4095 - val_accuracy: 0.8400\n",
            "Epoch 296/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4093 - accuracy: 0.8260 - val_loss: 0.4084 - val_accuracy: 0.8440\n",
            "Epoch 297/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4348 - accuracy: 0.8080 - val_loss: 0.4049 - val_accuracy: 0.8420\n",
            "Epoch 298/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4321 - accuracy: 0.8040 - val_loss: 0.4127 - val_accuracy: 0.8420\n",
            "Epoch 299/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4186 - accuracy: 0.8400 - val_loss: 0.4073 - val_accuracy: 0.8260\n",
            "Epoch 300/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4307 - accuracy: 0.8060 - val_loss: 0.4148 - val_accuracy: 0.8360\n",
            "Epoch 301/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4260 - accuracy: 0.8160 - val_loss: 0.4073 - val_accuracy: 0.8440\n",
            "Epoch 302/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4184 - accuracy: 0.8200 - val_loss: 0.4090 - val_accuracy: 0.8380\n",
            "Epoch 303/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4262 - accuracy: 0.8240 - val_loss: 0.4085 - val_accuracy: 0.8360\n",
            "Epoch 304/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4176 - accuracy: 0.8220 - val_loss: 0.4101 - val_accuracy: 0.8400\n",
            "Epoch 305/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4253 - accuracy: 0.8160 - val_loss: 0.4100 - val_accuracy: 0.8400\n",
            "Epoch 306/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4148 - accuracy: 0.8140 - val_loss: 0.4089 - val_accuracy: 0.8300\n",
            "Epoch 307/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4312 - accuracy: 0.8160 - val_loss: 0.4094 - val_accuracy: 0.8380\n",
            "Epoch 308/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4337 - accuracy: 0.8160 - val_loss: 0.4080 - val_accuracy: 0.8380\n",
            "Epoch 309/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4298 - accuracy: 0.8120 - val_loss: 0.4074 - val_accuracy: 0.8400\n",
            "Epoch 310/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4285 - accuracy: 0.8100 - val_loss: 0.4078 - val_accuracy: 0.8380\n",
            "Epoch 311/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4302 - accuracy: 0.8120 - val_loss: 0.4081 - val_accuracy: 0.8400\n",
            "Epoch 312/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4311 - accuracy: 0.8180 - val_loss: 0.4111 - val_accuracy: 0.8380\n",
            "Epoch 313/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4173 - accuracy: 0.8160 - val_loss: 0.4080 - val_accuracy: 0.8420\n",
            "Epoch 314/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4303 - accuracy: 0.8200 - val_loss: 0.4093 - val_accuracy: 0.8380\n",
            "Epoch 315/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4341 - accuracy: 0.8120 - val_loss: 0.4084 - val_accuracy: 0.8480\n",
            "Epoch 316/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4265 - accuracy: 0.8180 - val_loss: 0.4041 - val_accuracy: 0.8300\n",
            "Epoch 317/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4152 - accuracy: 0.8140 - val_loss: 0.4091 - val_accuracy: 0.8400\n",
            "Epoch 318/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4289 - accuracy: 0.8200 - val_loss: 0.4053 - val_accuracy: 0.8340\n",
            "Epoch 319/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4349 - accuracy: 0.8040 - val_loss: 0.4067 - val_accuracy: 0.8420\n",
            "Epoch 320/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4212 - accuracy: 0.8260 - val_loss: 0.4096 - val_accuracy: 0.8460\n",
            "Epoch 321/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4296 - accuracy: 0.8140 - val_loss: 0.4092 - val_accuracy: 0.8380\n",
            "Epoch 322/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4223 - accuracy: 0.8160 - val_loss: 0.4042 - val_accuracy: 0.8400\n",
            "Epoch 323/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4244 - accuracy: 0.8180 - val_loss: 0.4073 - val_accuracy: 0.8420\n",
            "Epoch 324/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4148 - accuracy: 0.8180 - val_loss: 0.4032 - val_accuracy: 0.8340\n",
            "Epoch 325/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4276 - accuracy: 0.8180 - val_loss: 0.4038 - val_accuracy: 0.8360\n",
            "Epoch 326/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4179 - accuracy: 0.8240 - val_loss: 0.4074 - val_accuracy: 0.8460\n",
            "Epoch 327/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4300 - accuracy: 0.7980 - val_loss: 0.4067 - val_accuracy: 0.8400\n",
            "Epoch 328/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4116 - accuracy: 0.8240 - val_loss: 0.4049 - val_accuracy: 0.8420\n",
            "Epoch 329/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4175 - accuracy: 0.8260 - val_loss: 0.4067 - val_accuracy: 0.8420\n",
            "Epoch 330/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4299 - accuracy: 0.8120 - val_loss: 0.4093 - val_accuracy: 0.8420\n",
            "Epoch 331/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4264 - accuracy: 0.8160 - val_loss: 0.4081 - val_accuracy: 0.8380\n",
            "Epoch 332/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4237 - accuracy: 0.8100 - val_loss: 0.4113 - val_accuracy: 0.8380\n",
            "Epoch 333/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4274 - accuracy: 0.8180 - val_loss: 0.4092 - val_accuracy: 0.8360\n",
            "Epoch 334/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4382 - accuracy: 0.8160 - val_loss: 0.4065 - val_accuracy: 0.8320\n",
            "Epoch 335/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4109 - accuracy: 0.8300 - val_loss: 0.4114 - val_accuracy: 0.8380\n",
            "Epoch 336/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4253 - accuracy: 0.8200 - val_loss: 0.4081 - val_accuracy: 0.8420\n",
            "Epoch 337/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4220 - accuracy: 0.8180 - val_loss: 0.4088 - val_accuracy: 0.8380\n",
            "Epoch 338/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4333 - accuracy: 0.8140 - val_loss: 0.4159 - val_accuracy: 0.8420\n",
            "Epoch 339/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4157 - accuracy: 0.8200 - val_loss: 0.4068 - val_accuracy: 0.8360\n",
            "Epoch 340/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4356 - accuracy: 0.8060 - val_loss: 0.4109 - val_accuracy: 0.8380\n",
            "Epoch 341/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4301 - accuracy: 0.8240 - val_loss: 0.4070 - val_accuracy: 0.8300\n",
            "Epoch 342/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4273 - accuracy: 0.8180 - val_loss: 0.4057 - val_accuracy: 0.8380\n",
            "Epoch 343/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4246 - accuracy: 0.8260 - val_loss: 0.4089 - val_accuracy: 0.8400\n",
            "Epoch 344/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4216 - accuracy: 0.8280 - val_loss: 0.4054 - val_accuracy: 0.8400\n",
            "Epoch 345/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4145 - accuracy: 0.8160 - val_loss: 0.4054 - val_accuracy: 0.8380\n",
            "Epoch 346/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4399 - accuracy: 0.8040 - val_loss: 0.4095 - val_accuracy: 0.8440\n",
            "Epoch 347/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4140 - accuracy: 0.8160 - val_loss: 0.4057 - val_accuracy: 0.8400\n",
            "Epoch 348/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4217 - accuracy: 0.8140 - val_loss: 0.4144 - val_accuracy: 0.8360\n",
            "Epoch 349/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4401 - accuracy: 0.8080 - val_loss: 0.4059 - val_accuracy: 0.8400\n",
            "Epoch 350/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4521 - accuracy: 0.8020 - val_loss: 0.4132 - val_accuracy: 0.8280\n",
            "Epoch 351/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4325 - accuracy: 0.8080 - val_loss: 0.4332 - val_accuracy: 0.8400\n",
            "Epoch 352/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4211 - accuracy: 0.8300 - val_loss: 0.4071 - val_accuracy: 0.8300\n",
            "Epoch 353/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4437 - accuracy: 0.8060 - val_loss: 0.4025 - val_accuracy: 0.8300\n",
            "Epoch 354/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4178 - accuracy: 0.8240 - val_loss: 0.4257 - val_accuracy: 0.8460\n",
            "Epoch 355/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4359 - accuracy: 0.8080 - val_loss: 0.4059 - val_accuracy: 0.8320\n",
            "Epoch 356/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4167 - accuracy: 0.8120 - val_loss: 0.4080 - val_accuracy: 0.8440\n",
            "Epoch 357/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4237 - accuracy: 0.8040 - val_loss: 0.4069 - val_accuracy: 0.8400\n",
            "Epoch 358/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4288 - accuracy: 0.8160 - val_loss: 0.4055 - val_accuracy: 0.8360\n",
            "Epoch 359/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4257 - accuracy: 0.8180 - val_loss: 0.4104 - val_accuracy: 0.8440\n",
            "Epoch 360/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4255 - accuracy: 0.8140 - val_loss: 0.4050 - val_accuracy: 0.8380\n",
            "Epoch 361/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4180 - accuracy: 0.8160 - val_loss: 0.4072 - val_accuracy: 0.8420\n",
            "Epoch 362/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4277 - accuracy: 0.8220 - val_loss: 0.4074 - val_accuracy: 0.8420\n",
            "Epoch 363/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4091 - accuracy: 0.8220 - val_loss: 0.4054 - val_accuracy: 0.8400\n",
            "Epoch 364/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4174 - accuracy: 0.8120 - val_loss: 0.4045 - val_accuracy: 0.8380\n",
            "Epoch 365/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4211 - accuracy: 0.8080 - val_loss: 0.4093 - val_accuracy: 0.8400\n",
            "Epoch 366/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4300 - accuracy: 0.7960 - val_loss: 0.4045 - val_accuracy: 0.8400\n",
            "Epoch 367/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4181 - accuracy: 0.8160 - val_loss: 0.4062 - val_accuracy: 0.8360\n",
            "Epoch 368/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4236 - accuracy: 0.8140 - val_loss: 0.4066 - val_accuracy: 0.8360\n",
            "Epoch 369/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4248 - accuracy: 0.8160 - val_loss: 0.4058 - val_accuracy: 0.8380\n",
            "Epoch 370/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4437 - accuracy: 0.8140 - val_loss: 0.4039 - val_accuracy: 0.8320\n",
            "Epoch 371/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4279 - accuracy: 0.8220 - val_loss: 0.4160 - val_accuracy: 0.8460\n",
            "Epoch 372/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4284 - accuracy: 0.8140 - val_loss: 0.4052 - val_accuracy: 0.8380\n",
            "Epoch 373/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4217 - accuracy: 0.8060 - val_loss: 0.4063 - val_accuracy: 0.8400\n",
            "Epoch 374/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4226 - accuracy: 0.8080 - val_loss: 0.4069 - val_accuracy: 0.8360\n",
            "Epoch 375/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4169 - accuracy: 0.8240 - val_loss: 0.4103 - val_accuracy: 0.8360\n",
            "Epoch 376/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4319 - accuracy: 0.8080 - val_loss: 0.4071 - val_accuracy: 0.8420\n",
            "Epoch 377/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4267 - accuracy: 0.8180 - val_loss: 0.4073 - val_accuracy: 0.8400\n",
            "Epoch 378/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4231 - accuracy: 0.8120 - val_loss: 0.4060 - val_accuracy: 0.8400\n",
            "Epoch 379/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4262 - accuracy: 0.8140 - val_loss: 0.4070 - val_accuracy: 0.8400\n",
            "Epoch 380/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4137 - accuracy: 0.8180 - val_loss: 0.4050 - val_accuracy: 0.8320\n",
            "Epoch 381/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4372 - accuracy: 0.8020 - val_loss: 0.4112 - val_accuracy: 0.8420\n",
            "Epoch 382/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4205 - accuracy: 0.8080 - val_loss: 0.4058 - val_accuracy: 0.8380\n",
            "Epoch 383/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4153 - accuracy: 0.8260 - val_loss: 0.4045 - val_accuracy: 0.8400\n",
            "Epoch 384/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4358 - accuracy: 0.8020 - val_loss: 0.4092 - val_accuracy: 0.8460\n",
            "Epoch 385/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4249 - accuracy: 0.8020 - val_loss: 0.4022 - val_accuracy: 0.8400\n",
            "Epoch 386/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4175 - accuracy: 0.8060 - val_loss: 0.4034 - val_accuracy: 0.8400\n",
            "Epoch 387/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4225 - accuracy: 0.8160 - val_loss: 0.4059 - val_accuracy: 0.8380\n",
            "Epoch 388/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4294 - accuracy: 0.8160 - val_loss: 0.4028 - val_accuracy: 0.8420\n",
            "Epoch 389/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4282 - accuracy: 0.8180 - val_loss: 0.4028 - val_accuracy: 0.8400\n",
            "Epoch 390/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4153 - accuracy: 0.8080 - val_loss: 0.4032 - val_accuracy: 0.8420\n",
            "Epoch 391/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4126 - accuracy: 0.8120 - val_loss: 0.4072 - val_accuracy: 0.8420\n",
            "Epoch 392/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4169 - accuracy: 0.8280 - val_loss: 0.4029 - val_accuracy: 0.8380\n",
            "Epoch 393/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4153 - accuracy: 0.8080 - val_loss: 0.4035 - val_accuracy: 0.8380\n",
            "Epoch 394/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4270 - accuracy: 0.8040 - val_loss: 0.4102 - val_accuracy: 0.8420\n",
            "Epoch 395/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4227 - accuracy: 0.8140 - val_loss: 0.4018 - val_accuracy: 0.8340\n",
            "Epoch 396/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4133 - accuracy: 0.8240 - val_loss: 0.4121 - val_accuracy: 0.8400\n",
            "Epoch 397/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4141 - accuracy: 0.8300 - val_loss: 0.4022 - val_accuracy: 0.8440\n",
            "Epoch 398/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4393 - accuracy: 0.8200 - val_loss: 0.4021 - val_accuracy: 0.8380\n",
            "Epoch 399/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4344 - accuracy: 0.8100 - val_loss: 0.4219 - val_accuracy: 0.8460\n",
            "Epoch 400/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4367 - accuracy: 0.8140 - val_loss: 0.4055 - val_accuracy: 0.8300\n",
            "Epoch 401/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4476 - accuracy: 0.7980 - val_loss: 0.4127 - val_accuracy: 0.8520\n",
            "Epoch 402/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4229 - accuracy: 0.8220 - val_loss: 0.4007 - val_accuracy: 0.8420\n",
            "Epoch 403/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4061 - accuracy: 0.8280 - val_loss: 0.4053 - val_accuracy: 0.8380\n",
            "Epoch 404/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4199 - accuracy: 0.8120 - val_loss: 0.4058 - val_accuracy: 0.8380\n",
            "Epoch 405/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4233 - accuracy: 0.8240 - val_loss: 0.4076 - val_accuracy: 0.8460\n",
            "Epoch 406/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4318 - accuracy: 0.8220 - val_loss: 0.4028 - val_accuracy: 0.8440\n",
            "Epoch 407/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4250 - accuracy: 0.8000 - val_loss: 0.4099 - val_accuracy: 0.8380\n",
            "Epoch 408/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4433 - accuracy: 0.8260 - val_loss: 0.4039 - val_accuracy: 0.8360\n",
            "Epoch 409/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4154 - accuracy: 0.8180 - val_loss: 0.4052 - val_accuracy: 0.8400\n",
            "Epoch 410/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4294 - accuracy: 0.8200 - val_loss: 0.4013 - val_accuracy: 0.8400\n",
            "Epoch 411/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4203 - accuracy: 0.8320 - val_loss: 0.4134 - val_accuracy: 0.8360\n",
            "Epoch 412/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4334 - accuracy: 0.7900 - val_loss: 0.4002 - val_accuracy: 0.8400\n",
            "Epoch 413/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4225 - accuracy: 0.8320 - val_loss: 0.4035 - val_accuracy: 0.8440\n",
            "Epoch 414/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4265 - accuracy: 0.8060 - val_loss: 0.4088 - val_accuracy: 0.8380\n",
            "Epoch 415/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4266 - accuracy: 0.8100 - val_loss: 0.4060 - val_accuracy: 0.8300\n",
            "Epoch 416/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4125 - accuracy: 0.8280 - val_loss: 0.4089 - val_accuracy: 0.8440\n",
            "Epoch 417/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4353 - accuracy: 0.8160 - val_loss: 0.3982 - val_accuracy: 0.8360\n",
            "Epoch 418/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4324 - accuracy: 0.8000 - val_loss: 0.4029 - val_accuracy: 0.8300\n",
            "Epoch 419/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4155 - accuracy: 0.8060 - val_loss: 0.4186 - val_accuracy: 0.8480\n",
            "Epoch 420/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4259 - accuracy: 0.8020 - val_loss: 0.4030 - val_accuracy: 0.8400\n",
            "Epoch 421/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4162 - accuracy: 0.8020 - val_loss: 0.4012 - val_accuracy: 0.8380\n",
            "Epoch 422/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4289 - accuracy: 0.8060 - val_loss: 0.4105 - val_accuracy: 0.8420\n",
            "Epoch 423/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4268 - accuracy: 0.8120 - val_loss: 0.4029 - val_accuracy: 0.8380\n",
            "Epoch 424/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4311 - accuracy: 0.8220 - val_loss: 0.4025 - val_accuracy: 0.8400\n",
            "Epoch 425/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4290 - accuracy: 0.8080 - val_loss: 0.4056 - val_accuracy: 0.8420\n",
            "Epoch 426/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4295 - accuracy: 0.8080 - val_loss: 0.4025 - val_accuracy: 0.8420\n",
            "Epoch 427/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4214 - accuracy: 0.8180 - val_loss: 0.4023 - val_accuracy: 0.8420\n",
            "Epoch 428/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4277 - accuracy: 0.8040 - val_loss: 0.3996 - val_accuracy: 0.8320\n",
            "Epoch 429/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4312 - accuracy: 0.7900 - val_loss: 0.4056 - val_accuracy: 0.8360\n",
            "Epoch 430/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4177 - accuracy: 0.8200 - val_loss: 0.4017 - val_accuracy: 0.8400\n",
            "Epoch 431/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4173 - accuracy: 0.8120 - val_loss: 0.4005 - val_accuracy: 0.8400\n",
            "Epoch 432/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4249 - accuracy: 0.8240 - val_loss: 0.4050 - val_accuracy: 0.8400\n",
            "Epoch 433/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4169 - accuracy: 0.8300 - val_loss: 0.4048 - val_accuracy: 0.8380\n",
            "Epoch 434/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4264 - accuracy: 0.8060 - val_loss: 0.4009 - val_accuracy: 0.8360\n",
            "Epoch 435/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4241 - accuracy: 0.8180 - val_loss: 0.4042 - val_accuracy: 0.8400\n",
            "Epoch 436/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4137 - accuracy: 0.8300 - val_loss: 0.4043 - val_accuracy: 0.8420\n",
            "Epoch 437/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4364 - accuracy: 0.8100 - val_loss: 0.3995 - val_accuracy: 0.8380\n",
            "Epoch 438/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4144 - accuracy: 0.8240 - val_loss: 0.4122 - val_accuracy: 0.8400\n",
            "Epoch 439/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4200 - accuracy: 0.7980 - val_loss: 0.3995 - val_accuracy: 0.8380\n",
            "Epoch 440/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4235 - accuracy: 0.8160 - val_loss: 0.3998 - val_accuracy: 0.8400\n",
            "Epoch 441/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4230 - accuracy: 0.8060 - val_loss: 0.4042 - val_accuracy: 0.8400\n",
            "Epoch 442/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4139 - accuracy: 0.8280 - val_loss: 0.4048 - val_accuracy: 0.8380\n",
            "Epoch 443/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4127 - accuracy: 0.8120 - val_loss: 0.4001 - val_accuracy: 0.8360\n",
            "Epoch 444/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4161 - accuracy: 0.8220 - val_loss: 0.4129 - val_accuracy: 0.8380\n",
            "Epoch 445/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4327 - accuracy: 0.8180 - val_loss: 0.4010 - val_accuracy: 0.8360\n",
            "Epoch 446/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4245 - accuracy: 0.8240 - val_loss: 0.4030 - val_accuracy: 0.8360\n",
            "Epoch 447/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4416 - accuracy: 0.8000 - val_loss: 0.4150 - val_accuracy: 0.8400\n",
            "Epoch 448/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4452 - accuracy: 0.8120 - val_loss: 0.4075 - val_accuracy: 0.8280\n",
            "Epoch 449/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4352 - accuracy: 0.8060 - val_loss: 0.4222 - val_accuracy: 0.8400\n",
            "Epoch 450/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4258 - accuracy: 0.8280 - val_loss: 0.3994 - val_accuracy: 0.8340\n",
            "Epoch 451/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4329 - accuracy: 0.8120 - val_loss: 0.3998 - val_accuracy: 0.8320\n",
            "Epoch 452/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4290 - accuracy: 0.8040 - val_loss: 0.4114 - val_accuracy: 0.8420\n",
            "Epoch 453/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4268 - accuracy: 0.8100 - val_loss: 0.4004 - val_accuracy: 0.8400\n",
            "Epoch 454/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4271 - accuracy: 0.8080 - val_loss: 0.4007 - val_accuracy: 0.8400\n",
            "Epoch 455/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4205 - accuracy: 0.8160 - val_loss: 0.4115 - val_accuracy: 0.8400\n",
            "Epoch 456/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4216 - accuracy: 0.8160 - val_loss: 0.3994 - val_accuracy: 0.8300\n",
            "Epoch 457/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4206 - accuracy: 0.8220 - val_loss: 0.4010 - val_accuracy: 0.8440\n",
            "Epoch 458/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4185 - accuracy: 0.8080 - val_loss: 0.3986 - val_accuracy: 0.8380\n",
            "Epoch 459/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4177 - accuracy: 0.8160 - val_loss: 0.4002 - val_accuracy: 0.8360\n",
            "Epoch 460/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4166 - accuracy: 0.8120 - val_loss: 0.3983 - val_accuracy: 0.8420\n",
            "Epoch 461/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4221 - accuracy: 0.8240 - val_loss: 0.3982 - val_accuracy: 0.8420\n",
            "Epoch 462/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4024 - accuracy: 0.8260 - val_loss: 0.3975 - val_accuracy: 0.8400\n",
            "Epoch 463/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4089 - accuracy: 0.8220 - val_loss: 0.3976 - val_accuracy: 0.8360\n",
            "Epoch 464/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4168 - accuracy: 0.8160 - val_loss: 0.3966 - val_accuracy: 0.8400\n",
            "Epoch 465/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4125 - accuracy: 0.8100 - val_loss: 0.4005 - val_accuracy: 0.8420\n",
            "Epoch 466/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4129 - accuracy: 0.8120 - val_loss: 0.3958 - val_accuracy: 0.8360\n",
            "Epoch 467/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4226 - accuracy: 0.8200 - val_loss: 0.3988 - val_accuracy: 0.8340\n",
            "Epoch 468/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4133 - accuracy: 0.8140 - val_loss: 0.4053 - val_accuracy: 0.8360\n",
            "Epoch 469/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4180 - accuracy: 0.8160 - val_loss: 0.3991 - val_accuracy: 0.8400\n",
            "Epoch 470/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4134 - accuracy: 0.8140 - val_loss: 0.3981 - val_accuracy: 0.8400\n",
            "Epoch 471/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4288 - accuracy: 0.8140 - val_loss: 0.4043 - val_accuracy: 0.8360\n",
            "Epoch 472/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4279 - accuracy: 0.8140 - val_loss: 0.3969 - val_accuracy: 0.8340\n",
            "Epoch 473/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4148 - accuracy: 0.8200 - val_loss: 0.4068 - val_accuracy: 0.8420\n",
            "Epoch 474/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4250 - accuracy: 0.8140 - val_loss: 0.3979 - val_accuracy: 0.8420\n",
            "Epoch 475/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4144 - accuracy: 0.8160 - val_loss: 0.3977 - val_accuracy: 0.8400\n",
            "Epoch 476/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4093 - accuracy: 0.8220 - val_loss: 0.4003 - val_accuracy: 0.8380\n",
            "Epoch 477/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4156 - accuracy: 0.8220 - val_loss: 0.4026 - val_accuracy: 0.8400\n",
            "Epoch 478/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4300 - accuracy: 0.8140 - val_loss: 0.4006 - val_accuracy: 0.8340\n",
            "Epoch 479/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4162 - accuracy: 0.8200 - val_loss: 0.4052 - val_accuracy: 0.8380\n",
            "Epoch 480/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4216 - accuracy: 0.8180 - val_loss: 0.4028 - val_accuracy: 0.8400\n",
            "Epoch 481/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4167 - accuracy: 0.8200 - val_loss: 0.4002 - val_accuracy: 0.8400\n",
            "Epoch 482/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4228 - accuracy: 0.8040 - val_loss: 0.4004 - val_accuracy: 0.8400\n",
            "Epoch 483/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4271 - accuracy: 0.8120 - val_loss: 0.4069 - val_accuracy: 0.8380\n",
            "Epoch 484/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4148 - accuracy: 0.8100 - val_loss: 0.4044 - val_accuracy: 0.8300\n",
            "Epoch 485/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4196 - accuracy: 0.8220 - val_loss: 0.4127 - val_accuracy: 0.8480\n",
            "Epoch 486/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4286 - accuracy: 0.8000 - val_loss: 0.4012 - val_accuracy: 0.8380\n",
            "Epoch 487/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4237 - accuracy: 0.8100 - val_loss: 0.4058 - val_accuracy: 0.8400\n",
            "Epoch 488/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4191 - accuracy: 0.8100 - val_loss: 0.4026 - val_accuracy: 0.8400\n",
            "Epoch 489/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4166 - accuracy: 0.8260 - val_loss: 0.4047 - val_accuracy: 0.8420\n",
            "Epoch 490/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4237 - accuracy: 0.8180 - val_loss: 0.3976 - val_accuracy: 0.8340\n",
            "Epoch 491/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4160 - accuracy: 0.8200 - val_loss: 0.4014 - val_accuracy: 0.8400\n",
            "Epoch 492/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4303 - accuracy: 0.8160 - val_loss: 0.4000 - val_accuracy: 0.8420\n",
            "Epoch 493/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4188 - accuracy: 0.8220 - val_loss: 0.3988 - val_accuracy: 0.8420\n",
            "Epoch 494/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4128 - accuracy: 0.8140 - val_loss: 0.4016 - val_accuracy: 0.8400\n",
            "Epoch 495/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4113 - accuracy: 0.8360 - val_loss: 0.4002 - val_accuracy: 0.8420\n",
            "Epoch 496/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4127 - accuracy: 0.8240 - val_loss: 0.4061 - val_accuracy: 0.8420\n",
            "Epoch 497/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4128 - accuracy: 0.7980 - val_loss: 0.4000 - val_accuracy: 0.8380\n",
            "Epoch 498/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4207 - accuracy: 0.8040 - val_loss: 0.4012 - val_accuracy: 0.8400\n",
            "Epoch 499/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4068 - accuracy: 0.8220 - val_loss: 0.4022 - val_accuracy: 0.8380\n",
            "Epoch 500/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4036 - accuracy: 0.8300 - val_loss: 0.3997 - val_accuracy: 0.8420\n",
            "Epoch 501/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4250 - accuracy: 0.8120 - val_loss: 0.4032 - val_accuracy: 0.8400\n",
            "Epoch 502/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4147 - accuracy: 0.8400 - val_loss: 0.4030 - val_accuracy: 0.8420\n",
            "Epoch 503/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4097 - accuracy: 0.8260 - val_loss: 0.4037 - val_accuracy: 0.8380\n",
            "Epoch 504/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4134 - accuracy: 0.8200 - val_loss: 0.4032 - val_accuracy: 0.8380\n",
            "Epoch 505/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4223 - accuracy: 0.8260 - val_loss: 0.4001 - val_accuracy: 0.8380\n",
            "Epoch 506/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4380 - accuracy: 0.8060 - val_loss: 0.3998 - val_accuracy: 0.8380\n",
            "Epoch 507/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4166 - accuracy: 0.8200 - val_loss: 0.4049 - val_accuracy: 0.8400\n",
            "Epoch 508/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4168 - accuracy: 0.8180 - val_loss: 0.4015 - val_accuracy: 0.8380\n",
            "Epoch 509/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4192 - accuracy: 0.8200 - val_loss: 0.3973 - val_accuracy: 0.8320\n",
            "Epoch 510/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4173 - accuracy: 0.8080 - val_loss: 0.4031 - val_accuracy: 0.8400\n",
            "Epoch 511/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4140 - accuracy: 0.8060 - val_loss: 0.4021 - val_accuracy: 0.8380\n",
            "Epoch 512/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4098 - accuracy: 0.8220 - val_loss: 0.3968 - val_accuracy: 0.8300\n",
            "Epoch 513/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4060 - accuracy: 0.8240 - val_loss: 0.4007 - val_accuracy: 0.8400\n",
            "Epoch 514/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4100 - accuracy: 0.8160 - val_loss: 0.4031 - val_accuracy: 0.8420\n",
            "Epoch 515/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4210 - accuracy: 0.8080 - val_loss: 0.3998 - val_accuracy: 0.8400\n",
            "Epoch 516/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4138 - accuracy: 0.8200 - val_loss: 0.4004 - val_accuracy: 0.8380\n",
            "Epoch 517/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4250 - accuracy: 0.8100 - val_loss: 0.4013 - val_accuracy: 0.8400\n",
            "Epoch 518/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4096 - accuracy: 0.8140 - val_loss: 0.3983 - val_accuracy: 0.8380\n",
            "Epoch 519/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4239 - accuracy: 0.8180 - val_loss: 0.4046 - val_accuracy: 0.8360\n",
            "Epoch 520/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4186 - accuracy: 0.8280 - val_loss: 0.3985 - val_accuracy: 0.8360\n",
            "Epoch 521/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4163 - accuracy: 0.8200 - val_loss: 0.3987 - val_accuracy: 0.8400\n",
            "Epoch 522/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4138 - accuracy: 0.8080 - val_loss: 0.4005 - val_accuracy: 0.8380\n",
            "Epoch 523/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4119 - accuracy: 0.8260 - val_loss: 0.3996 - val_accuracy: 0.8420\n",
            "Epoch 524/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4207 - accuracy: 0.8220 - val_loss: 0.4003 - val_accuracy: 0.8400\n",
            "Epoch 525/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4179 - accuracy: 0.8180 - val_loss: 0.4060 - val_accuracy: 0.8400\n",
            "Epoch 526/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4185 - accuracy: 0.8120 - val_loss: 0.3981 - val_accuracy: 0.8320\n",
            "Epoch 527/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4203 - accuracy: 0.8200 - val_loss: 0.3977 - val_accuracy: 0.8320\n",
            "Epoch 528/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4132 - accuracy: 0.8140 - val_loss: 0.4049 - val_accuracy: 0.8380\n",
            "Epoch 529/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4216 - accuracy: 0.8160 - val_loss: 0.3996 - val_accuracy: 0.8400\n",
            "Epoch 530/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4085 - accuracy: 0.8220 - val_loss: 0.3983 - val_accuracy: 0.8420\n",
            "Epoch 531/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4061 - accuracy: 0.8280 - val_loss: 0.4002 - val_accuracy: 0.8400\n",
            "Epoch 532/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4229 - accuracy: 0.8100 - val_loss: 0.4025 - val_accuracy: 0.8380\n",
            "Epoch 533/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4155 - accuracy: 0.8160 - val_loss: 0.3981 - val_accuracy: 0.8340\n",
            "Epoch 534/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4058 - accuracy: 0.8340 - val_loss: 0.4004 - val_accuracy: 0.8380\n",
            "Epoch 535/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4235 - accuracy: 0.8180 - val_loss: 0.4003 - val_accuracy: 0.8380\n",
            "Epoch 536/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4053 - accuracy: 0.8320 - val_loss: 0.3986 - val_accuracy: 0.8380\n",
            "Epoch 537/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4028 - accuracy: 0.8220 - val_loss: 0.4056 - val_accuracy: 0.8380\n",
            "Epoch 538/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4232 - accuracy: 0.8360 - val_loss: 0.4005 - val_accuracy: 0.8340\n",
            "Epoch 539/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4274 - accuracy: 0.8080 - val_loss: 0.3971 - val_accuracy: 0.8320\n",
            "Epoch 540/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4150 - accuracy: 0.8160 - val_loss: 0.4073 - val_accuracy: 0.8380\n",
            "Epoch 541/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4137 - accuracy: 0.8160 - val_loss: 0.3999 - val_accuracy: 0.8420\n",
            "Epoch 542/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4309 - accuracy: 0.8020 - val_loss: 0.4000 - val_accuracy: 0.8420\n",
            "Epoch 543/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4197 - accuracy: 0.8200 - val_loss: 0.4029 - val_accuracy: 0.8420\n",
            "Epoch 544/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4175 - accuracy: 0.8080 - val_loss: 0.4010 - val_accuracy: 0.8400\n",
            "Epoch 545/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4022 - accuracy: 0.8260 - val_loss: 0.3996 - val_accuracy: 0.8380\n",
            "Epoch 546/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4355 - accuracy: 0.8220 - val_loss: 0.4023 - val_accuracy: 0.8400\n",
            "Epoch 547/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4185 - accuracy: 0.8080 - val_loss: 0.4002 - val_accuracy: 0.8400\n",
            "Epoch 548/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4361 - accuracy: 0.8040 - val_loss: 0.4015 - val_accuracy: 0.8400\n",
            "Epoch 549/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4257 - accuracy: 0.8120 - val_loss: 0.4048 - val_accuracy: 0.8460\n",
            "Epoch 550/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4129 - accuracy: 0.8120 - val_loss: 0.4023 - val_accuracy: 0.8440\n",
            "Epoch 551/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4065 - accuracy: 0.8180 - val_loss: 0.3978 - val_accuracy: 0.8380\n",
            "Epoch 552/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4211 - accuracy: 0.8060 - val_loss: 0.3990 - val_accuracy: 0.8360\n",
            "Epoch 553/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4205 - accuracy: 0.8120 - val_loss: 0.4023 - val_accuracy: 0.8320\n",
            "Epoch 554/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4069 - accuracy: 0.8280 - val_loss: 0.3959 - val_accuracy: 0.8360\n",
            "Epoch 555/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4042 - accuracy: 0.8200 - val_loss: 0.4017 - val_accuracy: 0.8420\n",
            "Epoch 556/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4041 - accuracy: 0.8260 - val_loss: 0.4032 - val_accuracy: 0.8420\n",
            "Epoch 557/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4159 - accuracy: 0.8120 - val_loss: 0.3984 - val_accuracy: 0.8420\n",
            "Epoch 558/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4107 - accuracy: 0.8160 - val_loss: 0.3984 - val_accuracy: 0.8360\n",
            "Epoch 559/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4093 - accuracy: 0.8260 - val_loss: 0.3998 - val_accuracy: 0.8360\n",
            "Epoch 560/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4113 - accuracy: 0.8300 - val_loss: 0.3979 - val_accuracy: 0.8360\n",
            "Epoch 561/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4171 - accuracy: 0.8040 - val_loss: 0.3988 - val_accuracy: 0.8360\n",
            "Epoch 562/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4119 - accuracy: 0.8100 - val_loss: 0.4044 - val_accuracy: 0.8380\n",
            "Epoch 563/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4145 - accuracy: 0.8120 - val_loss: 0.4013 - val_accuracy: 0.8420\n",
            "Epoch 564/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4217 - accuracy: 0.8120 - val_loss: 0.3996 - val_accuracy: 0.8380\n",
            "Epoch 565/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4150 - accuracy: 0.8120 - val_loss: 0.4056 - val_accuracy: 0.8360\n",
            "Epoch 566/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4075 - accuracy: 0.8200 - val_loss: 0.3991 - val_accuracy: 0.8320\n",
            "Epoch 567/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4183 - accuracy: 0.8260 - val_loss: 0.4043 - val_accuracy: 0.8340\n",
            "Epoch 568/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4112 - accuracy: 0.8200 - val_loss: 0.4032 - val_accuracy: 0.8360\n",
            "Epoch 569/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4191 - accuracy: 0.8060 - val_loss: 0.3972 - val_accuracy: 0.8380\n",
            "Epoch 570/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4067 - accuracy: 0.8140 - val_loss: 0.3976 - val_accuracy: 0.8400\n",
            "Epoch 571/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4158 - accuracy: 0.8160 - val_loss: 0.3960 - val_accuracy: 0.8360\n",
            "Epoch 572/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4253 - accuracy: 0.8120 - val_loss: 0.4006 - val_accuracy: 0.8400\n",
            "Epoch 573/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4113 - accuracy: 0.8160 - val_loss: 0.3982 - val_accuracy: 0.8400\n",
            "Epoch 574/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4011 - accuracy: 0.8200 - val_loss: 0.3972 - val_accuracy: 0.8420\n",
            "Epoch 575/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4051 - accuracy: 0.8300 - val_loss: 0.4000 - val_accuracy: 0.8380\n",
            "Epoch 576/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4003 - accuracy: 0.8080 - val_loss: 0.3981 - val_accuracy: 0.8400\n",
            "Epoch 577/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3986 - accuracy: 0.8320 - val_loss: 0.3994 - val_accuracy: 0.8400\n",
            "Epoch 578/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4308 - accuracy: 0.8060 - val_loss: 0.3986 - val_accuracy: 0.8420\n",
            "Epoch 579/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4153 - accuracy: 0.8140 - val_loss: 0.3967 - val_accuracy: 0.8340\n",
            "Epoch 580/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4108 - accuracy: 0.8140 - val_loss: 0.4039 - val_accuracy: 0.8400\n",
            "Epoch 581/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4181 - accuracy: 0.8120 - val_loss: 0.3976 - val_accuracy: 0.8400\n",
            "Epoch 582/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4018 - accuracy: 0.8140 - val_loss: 0.3997 - val_accuracy: 0.8340\n",
            "Epoch 583/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4250 - accuracy: 0.8120 - val_loss: 0.3985 - val_accuracy: 0.8380\n",
            "Epoch 584/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4176 - accuracy: 0.8120 - val_loss: 0.4034 - val_accuracy: 0.8340\n",
            "Epoch 585/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4180 - accuracy: 0.8260 - val_loss: 0.3982 - val_accuracy: 0.8400\n",
            "Epoch 586/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4069 - accuracy: 0.8240 - val_loss: 0.4063 - val_accuracy: 0.8360\n",
            "Epoch 587/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4164 - accuracy: 0.8220 - val_loss: 0.4039 - val_accuracy: 0.8360\n",
            "Epoch 588/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4161 - accuracy: 0.8120 - val_loss: 0.3966 - val_accuracy: 0.8360\n",
            "Epoch 589/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4119 - accuracy: 0.8160 - val_loss: 0.3968 - val_accuracy: 0.8400\n",
            "Epoch 590/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4215 - accuracy: 0.8220 - val_loss: 0.4006 - val_accuracy: 0.8340\n",
            "Epoch 591/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4108 - accuracy: 0.8280 - val_loss: 0.3938 - val_accuracy: 0.8300\n",
            "Epoch 592/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4195 - accuracy: 0.8200 - val_loss: 0.3950 - val_accuracy: 0.8360\n",
            "Epoch 593/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4232 - accuracy: 0.8220 - val_loss: 0.3991 - val_accuracy: 0.8400\n",
            "Epoch 594/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4171 - accuracy: 0.8200 - val_loss: 0.3960 - val_accuracy: 0.8420\n",
            "Epoch 595/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4095 - accuracy: 0.8160 - val_loss: 0.4104 - val_accuracy: 0.8420\n",
            "Epoch 596/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4140 - accuracy: 0.8220 - val_loss: 0.3983 - val_accuracy: 0.8340\n",
            "Epoch 597/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4194 - accuracy: 0.8080 - val_loss: 0.4014 - val_accuracy: 0.8380\n",
            "Epoch 598/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4215 - accuracy: 0.8180 - val_loss: 0.4130 - val_accuracy: 0.8340\n",
            "Epoch 599/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4134 - accuracy: 0.8200 - val_loss: 0.4003 - val_accuracy: 0.8320\n",
            "Epoch 600/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4254 - accuracy: 0.8020 - val_loss: 0.4017 - val_accuracy: 0.8420\n",
            "Epoch 601/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4186 - accuracy: 0.8100 - val_loss: 0.4203 - val_accuracy: 0.8340\n",
            "Epoch 602/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4087 - accuracy: 0.8100 - val_loss: 0.4017 - val_accuracy: 0.8400\n",
            "Epoch 603/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4137 - accuracy: 0.8220 - val_loss: 0.3964 - val_accuracy: 0.8340\n",
            "Epoch 604/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4163 - accuracy: 0.8180 - val_loss: 0.4036 - val_accuracy: 0.8400\n",
            "Epoch 605/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4245 - accuracy: 0.8200 - val_loss: 0.3966 - val_accuracy: 0.8360\n",
            "Epoch 606/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4054 - accuracy: 0.8300 - val_loss: 0.3956 - val_accuracy: 0.8380\n",
            "Epoch 607/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4070 - accuracy: 0.8280 - val_loss: 0.3969 - val_accuracy: 0.8420\n",
            "Epoch 608/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4090 - accuracy: 0.8140 - val_loss: 0.3988 - val_accuracy: 0.8400\n",
            "Epoch 609/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4128 - accuracy: 0.8180 - val_loss: 0.3960 - val_accuracy: 0.8300\n",
            "Epoch 610/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4271 - accuracy: 0.8060 - val_loss: 0.4143 - val_accuracy: 0.8440\n",
            "Epoch 611/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4312 - accuracy: 0.8000 - val_loss: 0.3998 - val_accuracy: 0.8380\n",
            "Epoch 612/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4180 - accuracy: 0.8080 - val_loss: 0.3984 - val_accuracy: 0.8420\n",
            "Epoch 613/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4218 - accuracy: 0.8200 - val_loss: 0.4157 - val_accuracy: 0.8500\n",
            "Epoch 614/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4151 - accuracy: 0.8260 - val_loss: 0.3965 - val_accuracy: 0.8380\n",
            "Epoch 615/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4199 - accuracy: 0.8120 - val_loss: 0.3985 - val_accuracy: 0.8380\n",
            "Epoch 616/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4175 - accuracy: 0.8060 - val_loss: 0.4026 - val_accuracy: 0.8380\n",
            "Epoch 617/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4162 - accuracy: 0.8240 - val_loss: 0.3964 - val_accuracy: 0.8380\n",
            "Epoch 618/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4012 - accuracy: 0.8260 - val_loss: 0.3981 - val_accuracy: 0.8420\n",
            "Epoch 619/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4177 - accuracy: 0.8260 - val_loss: 0.3988 - val_accuracy: 0.8400\n",
            "Epoch 620/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4225 - accuracy: 0.8120 - val_loss: 0.3985 - val_accuracy: 0.8360\n",
            "Epoch 621/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4272 - accuracy: 0.8220 - val_loss: 0.3985 - val_accuracy: 0.8360\n",
            "Epoch 622/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4104 - accuracy: 0.8260 - val_loss: 0.4065 - val_accuracy: 0.8340\n",
            "Epoch 623/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4081 - accuracy: 0.8140 - val_loss: 0.4000 - val_accuracy: 0.8420\n",
            "Epoch 624/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4181 - accuracy: 0.8060 - val_loss: 0.3980 - val_accuracy: 0.8440\n",
            "Epoch 625/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4126 - accuracy: 0.8160 - val_loss: 0.4017 - val_accuracy: 0.8460\n",
            "Epoch 626/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4254 - accuracy: 0.8260 - val_loss: 0.3976 - val_accuracy: 0.8380\n",
            "Epoch 627/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4170 - accuracy: 0.8180 - val_loss: 0.4017 - val_accuracy: 0.8280\n",
            "Epoch 628/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4263 - accuracy: 0.8160 - val_loss: 0.4083 - val_accuracy: 0.8340\n",
            "Epoch 629/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4292 - accuracy: 0.8180 - val_loss: 0.4009 - val_accuracy: 0.8440\n",
            "Epoch 630/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4122 - accuracy: 0.8140 - val_loss: 0.3975 - val_accuracy: 0.8340\n",
            "Epoch 631/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4066 - accuracy: 0.8200 - val_loss: 0.4025 - val_accuracy: 0.8400\n",
            "Epoch 632/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4131 - accuracy: 0.8200 - val_loss: 0.4001 - val_accuracy: 0.8380\n",
            "Epoch 633/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4116 - accuracy: 0.8180 - val_loss: 0.3976 - val_accuracy: 0.8380\n",
            "Epoch 634/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4093 - accuracy: 0.8160 - val_loss: 0.4079 - val_accuracy: 0.8380\n",
            "Epoch 635/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4210 - accuracy: 0.8160 - val_loss: 0.3973 - val_accuracy: 0.8380\n",
            "Epoch 636/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3972 - accuracy: 0.8220 - val_loss: 0.3955 - val_accuracy: 0.8340\n",
            "Epoch 637/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4107 - accuracy: 0.8180 - val_loss: 0.3993 - val_accuracy: 0.8360\n",
            "Epoch 638/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4103 - accuracy: 0.8220 - val_loss: 0.4031 - val_accuracy: 0.8360\n",
            "Epoch 639/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4128 - accuracy: 0.8180 - val_loss: 0.3975 - val_accuracy: 0.8380\n",
            "Epoch 640/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4143 - accuracy: 0.8200 - val_loss: 0.3979 - val_accuracy: 0.8360\n",
            "Epoch 641/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4105 - accuracy: 0.8120 - val_loss: 0.4053 - val_accuracy: 0.8420\n",
            "Epoch 642/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4111 - accuracy: 0.8140 - val_loss: 0.4007 - val_accuracy: 0.8400\n",
            "Epoch 643/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4017 - accuracy: 0.8080 - val_loss: 0.4024 - val_accuracy: 0.8400\n",
            "Epoch 644/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4167 - accuracy: 0.8140 - val_loss: 0.4006 - val_accuracy: 0.8360\n",
            "Epoch 645/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4213 - accuracy: 0.8120 - val_loss: 0.3997 - val_accuracy: 0.8420\n",
            "Epoch 646/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4074 - accuracy: 0.8220 - val_loss: 0.3991 - val_accuracy: 0.8400\n",
            "Epoch 647/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4097 - accuracy: 0.8220 - val_loss: 0.3967 - val_accuracy: 0.8360\n",
            "Epoch 648/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4134 - accuracy: 0.8120 - val_loss: 0.4015 - val_accuracy: 0.8380\n",
            "Epoch 649/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4198 - accuracy: 0.8100 - val_loss: 0.3960 - val_accuracy: 0.8360\n",
            "Epoch 650/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4132 - accuracy: 0.8160 - val_loss: 0.4022 - val_accuracy: 0.8360\n",
            "Epoch 651/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4156 - accuracy: 0.8120 - val_loss: 0.3978 - val_accuracy: 0.8380\n",
            "Epoch 652/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4125 - accuracy: 0.8180 - val_loss: 0.3986 - val_accuracy: 0.8360\n",
            "Epoch 653/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4093 - accuracy: 0.8240 - val_loss: 0.4010 - val_accuracy: 0.8420\n",
            "Epoch 654/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4084 - accuracy: 0.8120 - val_loss: 0.3949 - val_accuracy: 0.8360\n",
            "Epoch 655/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4181 - accuracy: 0.8220 - val_loss: 0.3985 - val_accuracy: 0.8380\n",
            "Epoch 656/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4192 - accuracy: 0.8200 - val_loss: 0.3995 - val_accuracy: 0.8360\n",
            "Epoch 657/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4120 - accuracy: 0.8140 - val_loss: 0.3965 - val_accuracy: 0.8400\n",
            "Epoch 658/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4169 - accuracy: 0.8280 - val_loss: 0.4033 - val_accuracy: 0.8420\n",
            "Epoch 659/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4089 - accuracy: 0.8160 - val_loss: 0.3999 - val_accuracy: 0.8360\n",
            "Epoch 660/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4053 - accuracy: 0.8100 - val_loss: 0.3996 - val_accuracy: 0.8360\n",
            "Epoch 661/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4095 - accuracy: 0.8200 - val_loss: 0.3998 - val_accuracy: 0.8300\n",
            "Epoch 662/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4108 - accuracy: 0.8180 - val_loss: 0.3977 - val_accuracy: 0.8380\n",
            "Epoch 663/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4110 - accuracy: 0.8160 - val_loss: 0.3981 - val_accuracy: 0.8380\n",
            "Epoch 664/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4085 - accuracy: 0.8220 - val_loss: 0.3982 - val_accuracy: 0.8400\n",
            "Epoch 665/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4104 - accuracy: 0.8300 - val_loss: 0.3960 - val_accuracy: 0.8400\n",
            "Epoch 666/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4034 - accuracy: 0.8280 - val_loss: 0.4046 - val_accuracy: 0.8340\n",
            "Epoch 667/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4105 - accuracy: 0.8240 - val_loss: 0.4020 - val_accuracy: 0.8360\n",
            "Epoch 668/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4126 - accuracy: 0.8120 - val_loss: 0.3980 - val_accuracy: 0.8400\n",
            "Epoch 669/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4171 - accuracy: 0.8160 - val_loss: 0.3987 - val_accuracy: 0.8440\n",
            "Epoch 670/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4118 - accuracy: 0.8220 - val_loss: 0.4075 - val_accuracy: 0.8340\n",
            "Epoch 671/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4175 - accuracy: 0.8220 - val_loss: 0.3979 - val_accuracy: 0.8400\n",
            "Epoch 672/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4135 - accuracy: 0.8140 - val_loss: 0.3975 - val_accuracy: 0.8400\n",
            "Epoch 673/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4032 - accuracy: 0.8220 - val_loss: 0.3973 - val_accuracy: 0.8400\n",
            "Epoch 674/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4363 - accuracy: 0.8000 - val_loss: 0.4024 - val_accuracy: 0.8360\n",
            "Epoch 675/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4087 - accuracy: 0.8120 - val_loss: 0.3972 - val_accuracy: 0.8340\n",
            "Epoch 676/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4137 - accuracy: 0.8220 - val_loss: 0.4030 - val_accuracy: 0.8400\n",
            "Epoch 677/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4098 - accuracy: 0.8120 - val_loss: 0.4012 - val_accuracy: 0.8360\n",
            "Epoch 678/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4122 - accuracy: 0.8100 - val_loss: 0.3968 - val_accuracy: 0.8400\n",
            "Epoch 679/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4042 - accuracy: 0.8260 - val_loss: 0.4000 - val_accuracy: 0.8380\n",
            "Epoch 680/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4031 - accuracy: 0.8300 - val_loss: 0.4063 - val_accuracy: 0.8380\n",
            "Epoch 681/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4065 - accuracy: 0.8020 - val_loss: 0.3983 - val_accuracy: 0.8360\n",
            "Epoch 682/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4287 - accuracy: 0.8000 - val_loss: 0.3980 - val_accuracy: 0.8380\n",
            "Epoch 683/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4288 - accuracy: 0.8100 - val_loss: 0.4036 - val_accuracy: 0.8360\n",
            "Epoch 684/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4093 - accuracy: 0.8200 - val_loss: 0.4029 - val_accuracy: 0.8360\n",
            "Epoch 685/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3910 - accuracy: 0.8200 - val_loss: 0.3997 - val_accuracy: 0.8380\n",
            "Epoch 686/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4115 - accuracy: 0.8200 - val_loss: 0.4005 - val_accuracy: 0.8360\n",
            "Epoch 687/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4189 - accuracy: 0.8180 - val_loss: 0.4050 - val_accuracy: 0.8340\n",
            "Epoch 688/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4125 - accuracy: 0.8000 - val_loss: 0.3976 - val_accuracy: 0.8340\n",
            "Epoch 689/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4220 - accuracy: 0.8120 - val_loss: 0.3975 - val_accuracy: 0.8380\n",
            "Epoch 690/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4097 - accuracy: 0.8220 - val_loss: 0.4153 - val_accuracy: 0.8380\n",
            "Epoch 691/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4110 - accuracy: 0.8200 - val_loss: 0.3998 - val_accuracy: 0.8380\n",
            "Epoch 692/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4149 - accuracy: 0.8240 - val_loss: 0.3994 - val_accuracy: 0.8340\n",
            "Epoch 693/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4130 - accuracy: 0.8180 - val_loss: 0.4015 - val_accuracy: 0.8380\n",
            "Epoch 694/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4143 - accuracy: 0.8180 - val_loss: 0.4058 - val_accuracy: 0.8320\n",
            "Epoch 695/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4204 - accuracy: 0.8100 - val_loss: 0.4052 - val_accuracy: 0.8340\n",
            "Epoch 696/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4258 - accuracy: 0.8040 - val_loss: 0.3995 - val_accuracy: 0.8340\n",
            "Epoch 697/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4012 - accuracy: 0.8200 - val_loss: 0.4112 - val_accuracy: 0.8320\n",
            "Epoch 698/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4101 - accuracy: 0.8220 - val_loss: 0.4081 - val_accuracy: 0.8360\n",
            "Epoch 699/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4229 - accuracy: 0.8120 - val_loss: 0.4011 - val_accuracy: 0.8380\n",
            "Epoch 700/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4168 - accuracy: 0.8240 - val_loss: 0.4051 - val_accuracy: 0.8380\n",
            "Epoch 701/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4147 - accuracy: 0.8240 - val_loss: 0.4013 - val_accuracy: 0.8380\n",
            "Epoch 702/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4067 - accuracy: 0.8220 - val_loss: 0.4006 - val_accuracy: 0.8380\n",
            "Epoch 703/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4192 - accuracy: 0.8140 - val_loss: 0.4057 - val_accuracy: 0.8460\n",
            "Epoch 704/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4046 - accuracy: 0.8200 - val_loss: 0.4004 - val_accuracy: 0.8360\n",
            "Epoch 705/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4111 - accuracy: 0.8180 - val_loss: 0.4039 - val_accuracy: 0.8380\n",
            "Epoch 706/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4058 - accuracy: 0.8200 - val_loss: 0.4019 - val_accuracy: 0.8300\n",
            "Epoch 707/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4156 - accuracy: 0.8200 - val_loss: 0.3979 - val_accuracy: 0.8320\n",
            "Epoch 708/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4091 - accuracy: 0.8160 - val_loss: 0.4039 - val_accuracy: 0.8340\n",
            "Epoch 709/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4034 - accuracy: 0.8240 - val_loss: 0.4002 - val_accuracy: 0.8340\n",
            "Epoch 710/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4122 - accuracy: 0.8080 - val_loss: 0.3994 - val_accuracy: 0.8360\n",
            "Epoch 711/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4092 - accuracy: 0.8120 - val_loss: 0.3996 - val_accuracy: 0.8360\n",
            "Epoch 712/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4139 - accuracy: 0.8200 - val_loss: 0.4043 - val_accuracy: 0.8360\n",
            "Epoch 713/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4089 - accuracy: 0.8200 - val_loss: 0.3988 - val_accuracy: 0.8380\n",
            "Epoch 714/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4153 - accuracy: 0.8120 - val_loss: 0.4018 - val_accuracy: 0.8360\n",
            "Epoch 715/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3937 - accuracy: 0.8280 - val_loss: 0.3966 - val_accuracy: 0.8400\n",
            "Epoch 716/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4136 - accuracy: 0.8180 - val_loss: 0.4004 - val_accuracy: 0.8380\n",
            "Epoch 717/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4253 - accuracy: 0.8220 - val_loss: 0.3981 - val_accuracy: 0.8400\n",
            "Epoch 718/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4096 - accuracy: 0.8220 - val_loss: 0.4006 - val_accuracy: 0.8400\n",
            "Epoch 719/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4084 - accuracy: 0.8240 - val_loss: 0.4001 - val_accuracy: 0.8380\n",
            "Epoch 720/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4220 - accuracy: 0.8080 - val_loss: 0.4020 - val_accuracy: 0.8360\n",
            "Epoch 721/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4006 - accuracy: 0.8120 - val_loss: 0.3975 - val_accuracy: 0.8380\n",
            "Epoch 722/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4033 - accuracy: 0.8260 - val_loss: 0.3990 - val_accuracy: 0.8300\n",
            "Epoch 723/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4082 - accuracy: 0.8300 - val_loss: 0.4085 - val_accuracy: 0.8320\n",
            "Epoch 724/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4192 - accuracy: 0.8160 - val_loss: 0.3984 - val_accuracy: 0.8360\n",
            "Epoch 725/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4150 - accuracy: 0.8060 - val_loss: 0.3996 - val_accuracy: 0.8380\n",
            "Epoch 726/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4090 - accuracy: 0.8180 - val_loss: 0.4054 - val_accuracy: 0.8360\n",
            "Epoch 727/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4215 - accuracy: 0.8160 - val_loss: 0.3973 - val_accuracy: 0.8380\n",
            "Epoch 728/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4121 - accuracy: 0.8100 - val_loss: 0.3981 - val_accuracy: 0.8380\n",
            "Epoch 729/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3998 - accuracy: 0.8220 - val_loss: 0.4043 - val_accuracy: 0.8320\n",
            "Epoch 730/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4057 - accuracy: 0.8260 - val_loss: 0.3970 - val_accuracy: 0.8380\n",
            "Epoch 731/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4113 - accuracy: 0.8100 - val_loss: 0.3978 - val_accuracy: 0.8320\n",
            "Epoch 732/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4007 - accuracy: 0.8360 - val_loss: 0.4055 - val_accuracy: 0.8320\n",
            "Epoch 733/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4195 - accuracy: 0.7980 - val_loss: 0.4023 - val_accuracy: 0.8420\n",
            "Epoch 734/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4161 - accuracy: 0.8140 - val_loss: 0.3971 - val_accuracy: 0.8380\n",
            "Epoch 735/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4208 - accuracy: 0.8120 - val_loss: 0.3988 - val_accuracy: 0.8400\n",
            "Epoch 736/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4325 - accuracy: 0.8120 - val_loss: 0.3969 - val_accuracy: 0.8420\n",
            "Epoch 737/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4229 - accuracy: 0.8180 - val_loss: 0.3977 - val_accuracy: 0.8400\n",
            "Epoch 738/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4103 - accuracy: 0.8320 - val_loss: 0.4007 - val_accuracy: 0.8380\n",
            "Epoch 739/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4027 - accuracy: 0.8180 - val_loss: 0.3963 - val_accuracy: 0.8380\n",
            "Epoch 740/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4185 - accuracy: 0.8040 - val_loss: 0.3956 - val_accuracy: 0.8360\n",
            "Epoch 741/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4115 - accuracy: 0.8180 - val_loss: 0.4063 - val_accuracy: 0.8360\n",
            "Epoch 742/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4202 - accuracy: 0.8180 - val_loss: 0.3994 - val_accuracy: 0.8400\n",
            "Epoch 743/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4235 - accuracy: 0.8020 - val_loss: 0.3976 - val_accuracy: 0.8340\n",
            "Epoch 744/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4338 - accuracy: 0.8040 - val_loss: 0.4103 - val_accuracy: 0.8360\n",
            "Epoch 745/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3971 - accuracy: 0.8220 - val_loss: 0.3980 - val_accuracy: 0.8400\n",
            "Epoch 746/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4089 - accuracy: 0.8080 - val_loss: 0.3976 - val_accuracy: 0.8380\n",
            "Epoch 747/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4164 - accuracy: 0.8080 - val_loss: 0.4032 - val_accuracy: 0.8340\n",
            "Epoch 748/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4191 - accuracy: 0.8160 - val_loss: 0.3963 - val_accuracy: 0.8340\n",
            "Epoch 749/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4044 - accuracy: 0.8100 - val_loss: 0.4018 - val_accuracy: 0.8400\n",
            "Epoch 750/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4282 - accuracy: 0.8080 - val_loss: 0.3984 - val_accuracy: 0.8340\n",
            "Epoch 751/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4223 - accuracy: 0.8200 - val_loss: 0.3985 - val_accuracy: 0.8380\n",
            "Epoch 752/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4197 - accuracy: 0.8060 - val_loss: 0.4066 - val_accuracy: 0.8300\n",
            "Epoch 753/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4109 - accuracy: 0.8240 - val_loss: 0.3983 - val_accuracy: 0.8300\n",
            "Epoch 754/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4093 - accuracy: 0.8240 - val_loss: 0.3988 - val_accuracy: 0.8340\n",
            "Epoch 755/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4137 - accuracy: 0.8160 - val_loss: 0.4004 - val_accuracy: 0.8260\n",
            "Epoch 756/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4153 - accuracy: 0.8080 - val_loss: 0.3978 - val_accuracy: 0.8340\n",
            "Epoch 757/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4080 - accuracy: 0.8160 - val_loss: 0.4010 - val_accuracy: 0.8380\n",
            "Epoch 758/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4100 - accuracy: 0.8200 - val_loss: 0.3981 - val_accuracy: 0.8400\n",
            "Epoch 759/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4089 - accuracy: 0.8180 - val_loss: 0.4027 - val_accuracy: 0.8360\n",
            "Epoch 760/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4054 - accuracy: 0.8220 - val_loss: 0.3962 - val_accuracy: 0.8380\n",
            "Epoch 761/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4225 - accuracy: 0.8140 - val_loss: 0.3998 - val_accuracy: 0.8340\n",
            "Epoch 762/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4042 - accuracy: 0.8240 - val_loss: 0.3982 - val_accuracy: 0.8340\n",
            "Epoch 763/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4176 - accuracy: 0.8180 - val_loss: 0.4000 - val_accuracy: 0.8380\n",
            "Epoch 764/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4222 - accuracy: 0.8200 - val_loss: 0.3959 - val_accuracy: 0.8320\n",
            "Epoch 765/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4153 - accuracy: 0.8180 - val_loss: 0.4019 - val_accuracy: 0.8340\n",
            "Epoch 766/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4186 - accuracy: 0.8200 - val_loss: 0.4051 - val_accuracy: 0.8320\n",
            "Epoch 767/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4134 - accuracy: 0.8160 - val_loss: 0.3984 - val_accuracy: 0.8320\n",
            "Epoch 768/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4155 - accuracy: 0.8120 - val_loss: 0.3985 - val_accuracy: 0.8260\n",
            "Epoch 769/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4037 - accuracy: 0.8160 - val_loss: 0.4089 - val_accuracy: 0.8360\n",
            "Epoch 770/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4205 - accuracy: 0.8060 - val_loss: 0.3991 - val_accuracy: 0.8280\n",
            "Epoch 771/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4237 - accuracy: 0.8060 - val_loss: 0.4007 - val_accuracy: 0.8400\n",
            "Epoch 772/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4209 - accuracy: 0.8060 - val_loss: 0.4052 - val_accuracy: 0.8360\n",
            "Epoch 773/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3948 - accuracy: 0.8300 - val_loss: 0.3980 - val_accuracy: 0.8400\n",
            "Epoch 774/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4106 - accuracy: 0.8200 - val_loss: 0.3977 - val_accuracy: 0.8280\n",
            "Epoch 775/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4150 - accuracy: 0.8160 - val_loss: 0.3991 - val_accuracy: 0.8300\n",
            "Epoch 776/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4127 - accuracy: 0.8000 - val_loss: 0.4018 - val_accuracy: 0.8300\n",
            "Epoch 777/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4016 - accuracy: 0.8160 - val_loss: 0.3998 - val_accuracy: 0.8320\n",
            "Epoch 778/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3940 - accuracy: 0.8220 - val_loss: 0.4005 - val_accuracy: 0.8320\n",
            "Epoch 779/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4023 - accuracy: 0.8100 - val_loss: 0.3966 - val_accuracy: 0.8280\n",
            "Epoch 780/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4170 - accuracy: 0.8140 - val_loss: 0.4000 - val_accuracy: 0.8380\n",
            "Epoch 781/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4019 - accuracy: 0.8120 - val_loss: 0.4028 - val_accuracy: 0.8380\n",
            "Epoch 782/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4203 - accuracy: 0.8220 - val_loss: 0.3985 - val_accuracy: 0.8360\n",
            "Epoch 783/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3979 - accuracy: 0.8240 - val_loss: 0.3962 - val_accuracy: 0.8340\n",
            "Epoch 784/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4253 - accuracy: 0.8200 - val_loss: 0.4071 - val_accuracy: 0.8340\n",
            "Epoch 785/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4092 - accuracy: 0.8240 - val_loss: 0.3995 - val_accuracy: 0.8380\n",
            "Epoch 786/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4302 - accuracy: 0.7920 - val_loss: 0.4009 - val_accuracy: 0.8400\n",
            "Epoch 787/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4178 - accuracy: 0.8200 - val_loss: 0.4084 - val_accuracy: 0.8360\n",
            "Epoch 788/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4075 - accuracy: 0.8340 - val_loss: 0.3994 - val_accuracy: 0.8380\n",
            "Epoch 789/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4077 - accuracy: 0.8200 - val_loss: 0.4008 - val_accuracy: 0.8400\n",
            "Epoch 790/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4107 - accuracy: 0.8180 - val_loss: 0.3991 - val_accuracy: 0.8400\n",
            "Epoch 791/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4105 - accuracy: 0.8160 - val_loss: 0.3983 - val_accuracy: 0.8360\n",
            "Epoch 792/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4251 - accuracy: 0.8040 - val_loss: 0.4043 - val_accuracy: 0.8340\n",
            "Epoch 793/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4019 - accuracy: 0.8220 - val_loss: 0.3988 - val_accuracy: 0.8360\n",
            "Epoch 794/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4348 - accuracy: 0.7980 - val_loss: 0.3976 - val_accuracy: 0.8340\n",
            "Epoch 795/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3935 - accuracy: 0.8320 - val_loss: 0.4049 - val_accuracy: 0.8340\n",
            "Epoch 796/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4199 - accuracy: 0.8140 - val_loss: 0.3973 - val_accuracy: 0.8260\n",
            "Epoch 797/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4039 - accuracy: 0.8240 - val_loss: 0.3968 - val_accuracy: 0.8340\n",
            "Epoch 798/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4078 - accuracy: 0.8240 - val_loss: 0.4002 - val_accuracy: 0.8360\n",
            "Epoch 799/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4123 - accuracy: 0.8200 - val_loss: 0.3968 - val_accuracy: 0.8380\n",
            "Epoch 800/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4116 - accuracy: 0.8280 - val_loss: 0.4022 - val_accuracy: 0.8340\n",
            "Epoch 801/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4133 - accuracy: 0.8280 - val_loss: 0.3980 - val_accuracy: 0.8400\n",
            "Epoch 802/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4241 - accuracy: 0.8100 - val_loss: 0.3963 - val_accuracy: 0.8380\n",
            "Epoch 803/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4004 - accuracy: 0.8240 - val_loss: 0.3988 - val_accuracy: 0.8400\n",
            "Epoch 804/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4208 - accuracy: 0.8080 - val_loss: 0.4049 - val_accuracy: 0.8360\n",
            "Epoch 805/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4186 - accuracy: 0.8060 - val_loss: 0.3997 - val_accuracy: 0.8340\n",
            "Epoch 806/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4097 - accuracy: 0.8180 - val_loss: 0.3999 - val_accuracy: 0.8340\n",
            "Epoch 807/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4070 - accuracy: 0.8200 - val_loss: 0.4019 - val_accuracy: 0.8360\n",
            "Epoch 808/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4134 - accuracy: 0.8180 - val_loss: 0.4038 - val_accuracy: 0.8340\n",
            "Epoch 809/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4088 - accuracy: 0.8240 - val_loss: 0.3948 - val_accuracy: 0.8320\n",
            "Epoch 810/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4070 - accuracy: 0.8040 - val_loss: 0.3967 - val_accuracy: 0.8360\n",
            "Epoch 811/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4109 - accuracy: 0.8160 - val_loss: 0.4007 - val_accuracy: 0.8340\n",
            "Epoch 812/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4009 - accuracy: 0.8200 - val_loss: 0.3988 - val_accuracy: 0.8320\n",
            "Epoch 813/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4080 - accuracy: 0.8300 - val_loss: 0.3951 - val_accuracy: 0.8400\n",
            "Epoch 814/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4141 - accuracy: 0.8220 - val_loss: 0.3969 - val_accuracy: 0.8400\n",
            "Epoch 815/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4119 - accuracy: 0.8240 - val_loss: 0.4029 - val_accuracy: 0.8340\n",
            "Epoch 816/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4129 - accuracy: 0.8280 - val_loss: 0.3955 - val_accuracy: 0.8300\n",
            "Epoch 817/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4041 - accuracy: 0.8280 - val_loss: 0.3980 - val_accuracy: 0.8400\n",
            "Epoch 818/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3985 - accuracy: 0.8280 - val_loss: 0.4012 - val_accuracy: 0.8380\n",
            "Epoch 819/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4095 - accuracy: 0.8120 - val_loss: 0.3983 - val_accuracy: 0.8400\n",
            "Epoch 820/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3971 - accuracy: 0.8220 - val_loss: 0.4002 - val_accuracy: 0.8360\n",
            "Epoch 821/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4163 - accuracy: 0.8200 - val_loss: 0.3998 - val_accuracy: 0.8360\n",
            "Epoch 822/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4065 - accuracy: 0.8240 - val_loss: 0.3971 - val_accuracy: 0.8260\n",
            "Epoch 823/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4110 - accuracy: 0.8220 - val_loss: 0.3982 - val_accuracy: 0.8360\n",
            "Epoch 824/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4030 - accuracy: 0.8440 - val_loss: 0.3977 - val_accuracy: 0.8360\n",
            "Epoch 825/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4157 - accuracy: 0.8180 - val_loss: 0.3978 - val_accuracy: 0.8380\n",
            "Epoch 826/1000\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.4018 - accuracy: 0.8260 - val_loss: 0.3965 - val_accuracy: 0.8360\n",
            "Epoch 827/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4003 - accuracy: 0.8220 - val_loss: 0.3972 - val_accuracy: 0.8340\n",
            "Epoch 828/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4052 - accuracy: 0.8160 - val_loss: 0.4015 - val_accuracy: 0.8340\n",
            "Epoch 829/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.4123 - accuracy: 0.8240 - val_loss: 0.3985 - val_accuracy: 0.8380\n",
            "Epoch 830/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4048 - accuracy: 0.8080 - val_loss: 0.3981 - val_accuracy: 0.8340\n",
            "Epoch 831/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4036 - accuracy: 0.8180 - val_loss: 0.3976 - val_accuracy: 0.8360\n",
            "Epoch 832/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4023 - accuracy: 0.8260 - val_loss: 0.4028 - val_accuracy: 0.8380\n",
            "Epoch 833/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4111 - accuracy: 0.8320 - val_loss: 0.4024 - val_accuracy: 0.8380\n",
            "Epoch 834/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4169 - accuracy: 0.8240 - val_loss: 0.3973 - val_accuracy: 0.8320\n",
            "Epoch 835/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4103 - accuracy: 0.8280 - val_loss: 0.4026 - val_accuracy: 0.8380\n",
            "Epoch 836/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4288 - accuracy: 0.8040 - val_loss: 0.4048 - val_accuracy: 0.8320\n",
            "Epoch 837/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4145 - accuracy: 0.8280 - val_loss: 0.3979 - val_accuracy: 0.8340\n",
            "Epoch 838/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3952 - accuracy: 0.8280 - val_loss: 0.4014 - val_accuracy: 0.8340\n",
            "Epoch 839/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4098 - accuracy: 0.8300 - val_loss: 0.3972 - val_accuracy: 0.8360\n",
            "Epoch 840/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4166 - accuracy: 0.8180 - val_loss: 0.3960 - val_accuracy: 0.8320\n",
            "Epoch 841/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4162 - accuracy: 0.8140 - val_loss: 0.4036 - val_accuracy: 0.8340\n",
            "Epoch 842/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4054 - accuracy: 0.8360 - val_loss: 0.4002 - val_accuracy: 0.8380\n",
            "Epoch 843/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4099 - accuracy: 0.8140 - val_loss: 0.3973 - val_accuracy: 0.8300\n",
            "Epoch 844/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4110 - accuracy: 0.8120 - val_loss: 0.4011 - val_accuracy: 0.8380\n",
            "Epoch 845/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4117 - accuracy: 0.8080 - val_loss: 0.4019 - val_accuracy: 0.8360\n",
            "Epoch 846/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3969 - accuracy: 0.8180 - val_loss: 0.3957 - val_accuracy: 0.8320\n",
            "Epoch 847/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4080 - accuracy: 0.8180 - val_loss: 0.3963 - val_accuracy: 0.8360\n",
            "Epoch 848/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4050 - accuracy: 0.8220 - val_loss: 0.4046 - val_accuracy: 0.8320\n",
            "Epoch 849/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4209 - accuracy: 0.8120 - val_loss: 0.3964 - val_accuracy: 0.8380\n",
            "Epoch 850/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4066 - accuracy: 0.8040 - val_loss: 0.3946 - val_accuracy: 0.8400\n",
            "Epoch 851/1000\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.4239 - accuracy: 0.8080 - val_loss: 0.4092 - val_accuracy: 0.8440\n",
            "Epoch 852/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4157 - accuracy: 0.8240 - val_loss: 0.3959 - val_accuracy: 0.8400\n",
            "Epoch 853/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4188 - accuracy: 0.8160 - val_loss: 0.3971 - val_accuracy: 0.8420\n",
            "Epoch 854/1000\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.4031 - accuracy: 0.8180 - val_loss: 0.4039 - val_accuracy: 0.8360\n",
            "Epoch 855/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4118 - accuracy: 0.8120 - val_loss: 0.3965 - val_accuracy: 0.8380\n",
            "Epoch 856/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4105 - accuracy: 0.8080 - val_loss: 0.3973 - val_accuracy: 0.8340\n",
            "Epoch 857/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4022 - accuracy: 0.8280 - val_loss: 0.3998 - val_accuracy: 0.8380\n",
            "Epoch 858/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4073 - accuracy: 0.8180 - val_loss: 0.3944 - val_accuracy: 0.8300\n",
            "Epoch 859/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.4160 - accuracy: 0.8320 - val_loss: 0.4016 - val_accuracy: 0.8300\n",
            "Epoch 860/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4089 - accuracy: 0.8180 - val_loss: 0.3983 - val_accuracy: 0.8380\n",
            "Epoch 861/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4029 - accuracy: 0.8280 - val_loss: 0.3963 - val_accuracy: 0.8380\n",
            "Epoch 862/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4115 - accuracy: 0.8140 - val_loss: 0.3995 - val_accuracy: 0.8380\n",
            "Epoch 863/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4068 - accuracy: 0.8300 - val_loss: 0.3971 - val_accuracy: 0.8380\n",
            "Epoch 864/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.4166 - accuracy: 0.8180 - val_loss: 0.3960 - val_accuracy: 0.8380\n",
            "Epoch 865/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4053 - accuracy: 0.8180 - val_loss: 0.4088 - val_accuracy: 0.8360\n",
            "Epoch 866/1000\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.4092 - accuracy: 0.8280 - val_loss: 0.3989 - val_accuracy: 0.8380\n",
            "Epoch 867/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.4255 - accuracy: 0.8040 - val_loss: 0.3973 - val_accuracy: 0.8300\n",
            "Epoch 868/1000\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4140 - accuracy: 0.8160 - val_loss: 0.4097 - val_accuracy: 0.8320\n",
            "Epoch 869/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4049 - accuracy: 0.8420 - val_loss: 0.3971 - val_accuracy: 0.8360\n",
            "Epoch 870/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4087 - accuracy: 0.8160 - val_loss: 0.3972 - val_accuracy: 0.8320\n",
            "Epoch 871/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4162 - accuracy: 0.8160 - val_loss: 0.4045 - val_accuracy: 0.8340\n",
            "Epoch 872/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.4263 - accuracy: 0.8220 - val_loss: 0.4069 - val_accuracy: 0.8380\n",
            "Epoch 873/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.4236 - accuracy: 0.8180 - val_loss: 0.3962 - val_accuracy: 0.8320\n",
            "Epoch 874/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4084 - accuracy: 0.8120 - val_loss: 0.3987 - val_accuracy: 0.8400\n",
            "Epoch 875/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4067 - accuracy: 0.8160 - val_loss: 0.4014 - val_accuracy: 0.8400\n",
            "Epoch 876/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4152 - accuracy: 0.8240 - val_loss: 0.3973 - val_accuracy: 0.8360\n",
            "Epoch 877/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.4224 - accuracy: 0.8080 - val_loss: 0.3963 - val_accuracy: 0.8340\n",
            "Epoch 878/1000\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4175 - accuracy: 0.8160 - val_loss: 0.4054 - val_accuracy: 0.8280\n",
            "Epoch 879/1000\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4083 - accuracy: 0.8180 - val_loss: 0.3981 - val_accuracy: 0.8300\n",
            "Epoch 880/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.4134 - accuracy: 0.8240 - val_loss: 0.3978 - val_accuracy: 0.8320\n",
            "Epoch 881/1000\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3978 - accuracy: 0.8200 - val_loss: 0.3992 - val_accuracy: 0.8360\n",
            "Epoch 882/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.4018 - accuracy: 0.8240 - val_loss: 0.4019 - val_accuracy: 0.8360\n",
            "Epoch 883/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.4078 - accuracy: 0.8140 - val_loss: 0.4020 - val_accuracy: 0.8380\n",
            "Epoch 884/1000\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.4009 - accuracy: 0.8140 - val_loss: 0.3986 - val_accuracy: 0.8380\n",
            "Epoch 885/1000\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.4137 - accuracy: 0.8360 - val_loss: 0.3992 - val_accuracy: 0.8380\n",
            "Epoch 886/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3876 - accuracy: 0.8340 - val_loss: 0.3986 - val_accuracy: 0.8380\n",
            "Epoch 887/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4062 - accuracy: 0.8220 - val_loss: 0.3960 - val_accuracy: 0.8300\n",
            "Epoch 888/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4175 - accuracy: 0.8140 - val_loss: 0.4019 - val_accuracy: 0.8340\n",
            "Epoch 889/1000\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4058 - accuracy: 0.8300 - val_loss: 0.3980 - val_accuracy: 0.8380\n",
            "Epoch 890/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.4125 - accuracy: 0.8100 - val_loss: 0.4054 - val_accuracy: 0.8420\n",
            "Epoch 891/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4006 - accuracy: 0.8200 - val_loss: 0.3993 - val_accuracy: 0.8400\n",
            "Epoch 892/1000\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.4072 - accuracy: 0.8320 - val_loss: 0.3995 - val_accuracy: 0.8400\n",
            "Epoch 893/1000\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.4136 - accuracy: 0.7960 - val_loss: 0.3979 - val_accuracy: 0.8360\n",
            "Epoch 894/1000\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.4075 - accuracy: 0.8180 - val_loss: 0.4088 - val_accuracy: 0.8340\n",
            "Epoch 895/1000\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.4095 - accuracy: 0.8180 - val_loss: 0.3962 - val_accuracy: 0.8320\n",
            "Epoch 896/1000\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.4344 - accuracy: 0.8000 - val_loss: 0.3980 - val_accuracy: 0.8320\n",
            "Epoch 897/1000\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.4171 - accuracy: 0.8080 - val_loss: 0.4173 - val_accuracy: 0.8340\n",
            "Epoch 898/1000\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.4113 - accuracy: 0.8280 - val_loss: 0.3971 - val_accuracy: 0.8360\n",
            "Epoch 899/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4149 - accuracy: 0.8100 - val_loss: 0.3956 - val_accuracy: 0.8280\n",
            "Epoch 900/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3937 - accuracy: 0.8240 - val_loss: 0.4006 - val_accuracy: 0.8340\n",
            "Epoch 901/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4228 - accuracy: 0.8160 - val_loss: 0.4075 - val_accuracy: 0.8320\n",
            "Epoch 902/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4043 - accuracy: 0.8220 - val_loss: 0.3958 - val_accuracy: 0.8320\n",
            "Epoch 903/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4218 - accuracy: 0.8140 - val_loss: 0.3971 - val_accuracy: 0.8380\n",
            "Epoch 904/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4213 - accuracy: 0.8100 - val_loss: 0.4098 - val_accuracy: 0.8340\n",
            "Epoch 905/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4093 - accuracy: 0.8200 - val_loss: 0.3983 - val_accuracy: 0.8340\n",
            "Epoch 906/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4060 - accuracy: 0.8020 - val_loss: 0.3954 - val_accuracy: 0.8300\n",
            "Epoch 907/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4234 - accuracy: 0.8160 - val_loss: 0.4106 - val_accuracy: 0.8380\n",
            "Epoch 908/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4187 - accuracy: 0.8140 - val_loss: 0.3974 - val_accuracy: 0.8400\n",
            "Epoch 909/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4117 - accuracy: 0.8080 - val_loss: 0.3957 - val_accuracy: 0.8360\n",
            "Epoch 910/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4126 - accuracy: 0.8060 - val_loss: 0.3965 - val_accuracy: 0.8360\n",
            "Epoch 911/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4119 - accuracy: 0.8180 - val_loss: 0.4024 - val_accuracy: 0.8360\n",
            "Epoch 912/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3971 - accuracy: 0.8100 - val_loss: 0.3971 - val_accuracy: 0.8380\n",
            "Epoch 913/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4113 - accuracy: 0.8120 - val_loss: 0.3947 - val_accuracy: 0.8380\n",
            "Epoch 914/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4131 - accuracy: 0.8200 - val_loss: 0.3987 - val_accuracy: 0.8380\n",
            "Epoch 915/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4126 - accuracy: 0.8060 - val_loss: 0.4034 - val_accuracy: 0.8340\n",
            "Epoch 916/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3957 - accuracy: 0.8260 - val_loss: 0.3973 - val_accuracy: 0.8400\n",
            "Epoch 917/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4091 - accuracy: 0.8100 - val_loss: 0.3977 - val_accuracy: 0.8360\n",
            "Epoch 918/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4125 - accuracy: 0.8220 - val_loss: 0.4095 - val_accuracy: 0.8340\n",
            "Epoch 919/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4159 - accuracy: 0.8240 - val_loss: 0.3974 - val_accuracy: 0.8340\n",
            "Epoch 920/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4046 - accuracy: 0.8220 - val_loss: 0.3977 - val_accuracy: 0.8340\n",
            "Epoch 921/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3812 - accuracy: 0.8240 - val_loss: 0.4012 - val_accuracy: 0.8380\n",
            "Epoch 922/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4168 - accuracy: 0.8220 - val_loss: 0.4031 - val_accuracy: 0.8360\n",
            "Epoch 923/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4109 - accuracy: 0.8200 - val_loss: 0.3944 - val_accuracy: 0.8280\n",
            "Epoch 924/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4155 - accuracy: 0.8140 - val_loss: 0.3953 - val_accuracy: 0.8280\n",
            "Epoch 925/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4022 - accuracy: 0.8200 - val_loss: 0.3962 - val_accuracy: 0.8260\n",
            "Epoch 926/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4036 - accuracy: 0.8200 - val_loss: 0.4031 - val_accuracy: 0.8380\n",
            "Epoch 927/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4064 - accuracy: 0.8240 - val_loss: 0.4056 - val_accuracy: 0.8360\n",
            "Epoch 928/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4155 - accuracy: 0.8080 - val_loss: 0.3976 - val_accuracy: 0.8360\n",
            "Epoch 929/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4169 - accuracy: 0.8160 - val_loss: 0.4078 - val_accuracy: 0.8380\n",
            "Epoch 930/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4165 - accuracy: 0.8140 - val_loss: 0.4040 - val_accuracy: 0.8380\n",
            "Epoch 931/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4278 - accuracy: 0.8080 - val_loss: 0.4001 - val_accuracy: 0.8260\n",
            "Epoch 932/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4056 - accuracy: 0.8240 - val_loss: 0.4098 - val_accuracy: 0.8320\n",
            "Epoch 933/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4200 - accuracy: 0.8080 - val_loss: 0.4011 - val_accuracy: 0.8380\n",
            "Epoch 934/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4074 - accuracy: 0.8200 - val_loss: 0.3980 - val_accuracy: 0.8340\n",
            "Epoch 935/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4153 - accuracy: 0.8000 - val_loss: 0.3985 - val_accuracy: 0.8340\n",
            "Epoch 936/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3983 - accuracy: 0.8220 - val_loss: 0.4143 - val_accuracy: 0.8440\n",
            "Epoch 937/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4079 - accuracy: 0.8340 - val_loss: 0.3966 - val_accuracy: 0.8380\n",
            "Epoch 938/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4227 - accuracy: 0.8120 - val_loss: 0.3965 - val_accuracy: 0.8300\n",
            "Epoch 939/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4242 - accuracy: 0.8180 - val_loss: 0.4013 - val_accuracy: 0.8360\n",
            "Epoch 940/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4084 - accuracy: 0.8200 - val_loss: 0.4009 - val_accuracy: 0.8340\n",
            "Epoch 941/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4091 - accuracy: 0.8200 - val_loss: 0.3943 - val_accuracy: 0.8360\n",
            "Epoch 942/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4060 - accuracy: 0.8340 - val_loss: 0.3979 - val_accuracy: 0.8360\n",
            "Epoch 943/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4021 - accuracy: 0.8260 - val_loss: 0.3974 - val_accuracy: 0.8380\n",
            "Epoch 944/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3933 - accuracy: 0.8200 - val_loss: 0.4003 - val_accuracy: 0.8380\n",
            "Epoch 945/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4101 - accuracy: 0.8220 - val_loss: 0.3992 - val_accuracy: 0.8360\n",
            "Epoch 946/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4004 - accuracy: 0.8240 - val_loss: 0.3982 - val_accuracy: 0.8400\n",
            "Epoch 947/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3965 - accuracy: 0.8320 - val_loss: 0.3976 - val_accuracy: 0.8360\n",
            "Epoch 948/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4250 - accuracy: 0.8060 - val_loss: 0.4007 - val_accuracy: 0.8360\n",
            "Epoch 949/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3984 - accuracy: 0.8260 - val_loss: 0.4018 - val_accuracy: 0.8340\n",
            "Epoch 950/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4235 - accuracy: 0.8160 - val_loss: 0.3978 - val_accuracy: 0.8360\n",
            "Epoch 951/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3995 - accuracy: 0.8280 - val_loss: 0.3990 - val_accuracy: 0.8340\n",
            "Epoch 952/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4140 - accuracy: 0.8240 - val_loss: 0.3973 - val_accuracy: 0.8380\n",
            "Epoch 953/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4016 - accuracy: 0.8260 - val_loss: 0.3979 - val_accuracy: 0.8380\n",
            "Epoch 954/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4040 - accuracy: 0.8320 - val_loss: 0.4029 - val_accuracy: 0.8380\n",
            "Epoch 955/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3942 - accuracy: 0.8160 - val_loss: 0.3995 - val_accuracy: 0.8360\n",
            "Epoch 956/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4123 - accuracy: 0.8160 - val_loss: 0.3986 - val_accuracy: 0.8340\n",
            "Epoch 957/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4056 - accuracy: 0.8240 - val_loss: 0.3991 - val_accuracy: 0.8340\n",
            "Epoch 958/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4005 - accuracy: 0.8200 - val_loss: 0.3963 - val_accuracy: 0.8360\n",
            "Epoch 959/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4002 - accuracy: 0.8240 - val_loss: 0.4023 - val_accuracy: 0.8340\n",
            "Epoch 960/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4223 - accuracy: 0.8100 - val_loss: 0.4053 - val_accuracy: 0.8380\n",
            "Epoch 961/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4201 - accuracy: 0.8040 - val_loss: 0.4031 - val_accuracy: 0.8320\n",
            "Epoch 962/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4040 - accuracy: 0.8140 - val_loss: 0.4008 - val_accuracy: 0.8340\n",
            "Epoch 963/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4044 - accuracy: 0.8140 - val_loss: 0.4018 - val_accuracy: 0.8280\n",
            "Epoch 964/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4143 - accuracy: 0.8280 - val_loss: 0.4005 - val_accuracy: 0.8300\n",
            "Epoch 965/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4039 - accuracy: 0.8300 - val_loss: 0.4021 - val_accuracy: 0.8340\n",
            "Epoch 966/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4113 - accuracy: 0.8140 - val_loss: 0.3986 - val_accuracy: 0.8420\n",
            "Epoch 967/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3970 - accuracy: 0.8280 - val_loss: 0.3988 - val_accuracy: 0.8400\n",
            "Epoch 968/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4028 - accuracy: 0.8120 - val_loss: 0.4025 - val_accuracy: 0.8320\n",
            "Epoch 969/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4127 - accuracy: 0.8160 - val_loss: 0.3959 - val_accuracy: 0.8320\n",
            "Epoch 970/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4023 - accuracy: 0.8180 - val_loss: 0.3969 - val_accuracy: 0.8360\n",
            "Epoch 971/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4032 - accuracy: 0.8100 - val_loss: 0.3977 - val_accuracy: 0.8360\n",
            "Epoch 972/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3971 - accuracy: 0.8340 - val_loss: 0.4015 - val_accuracy: 0.8360\n",
            "Epoch 973/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3984 - accuracy: 0.8180 - val_loss: 0.3990 - val_accuracy: 0.8380\n",
            "Epoch 974/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4036 - accuracy: 0.8220 - val_loss: 0.3975 - val_accuracy: 0.8340\n",
            "Epoch 975/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4171 - accuracy: 0.8020 - val_loss: 0.3982 - val_accuracy: 0.8340\n",
            "Epoch 976/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4089 - accuracy: 0.8220 - val_loss: 0.3974 - val_accuracy: 0.8360\n",
            "Epoch 977/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4190 - accuracy: 0.8140 - val_loss: 0.4015 - val_accuracy: 0.8340\n",
            "Epoch 978/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4042 - accuracy: 0.8240 - val_loss: 0.3961 - val_accuracy: 0.8360\n",
            "Epoch 979/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4124 - accuracy: 0.8220 - val_loss: 0.3986 - val_accuracy: 0.8360\n",
            "Epoch 980/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3943 - accuracy: 0.8200 - val_loss: 0.3982 - val_accuracy: 0.8380\n",
            "Epoch 981/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4124 - accuracy: 0.8040 - val_loss: 0.3970 - val_accuracy: 0.8340\n",
            "Epoch 982/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4159 - accuracy: 0.8020 - val_loss: 0.3986 - val_accuracy: 0.8340\n",
            "Epoch 983/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4103 - accuracy: 0.8140 - val_loss: 0.4094 - val_accuracy: 0.8320\n",
            "Epoch 984/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3964 - accuracy: 0.8200 - val_loss: 0.3981 - val_accuracy: 0.8360\n",
            "Epoch 985/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4044 - accuracy: 0.8080 - val_loss: 0.3962 - val_accuracy: 0.8380\n",
            "Epoch 986/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4077 - accuracy: 0.8180 - val_loss: 0.4046 - val_accuracy: 0.8360\n",
            "Epoch 987/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4165 - accuracy: 0.8160 - val_loss: 0.4003 - val_accuracy: 0.8340\n",
            "Epoch 988/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4136 - accuracy: 0.8200 - val_loss: 0.3953 - val_accuracy: 0.8240\n",
            "Epoch 989/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4065 - accuracy: 0.8180 - val_loss: 0.3982 - val_accuracy: 0.8340\n",
            "Epoch 990/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4057 - accuracy: 0.8160 - val_loss: 0.3974 - val_accuracy: 0.8400\n",
            "Epoch 991/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4013 - accuracy: 0.8220 - val_loss: 0.4000 - val_accuracy: 0.8360\n",
            "Epoch 992/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4058 - accuracy: 0.8180 - val_loss: 0.3958 - val_accuracy: 0.8280\n",
            "Epoch 993/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4035 - accuracy: 0.8140 - val_loss: 0.3983 - val_accuracy: 0.8340\n",
            "Epoch 994/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4193 - accuracy: 0.8220 - val_loss: 0.3982 - val_accuracy: 0.8340\n",
            "Epoch 995/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4245 - accuracy: 0.8120 - val_loss: 0.4054 - val_accuracy: 0.8380\n",
            "Epoch 996/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4090 - accuracy: 0.8240 - val_loss: 0.3971 - val_accuracy: 0.8360\n",
            "Epoch 997/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4138 - accuracy: 0.8260 - val_loss: 0.3960 - val_accuracy: 0.8340\n",
            "Epoch 998/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4075 - accuracy: 0.8180 - val_loss: 0.3997 - val_accuracy: 0.8340\n",
            "Epoch 999/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4150 - accuracy: 0.8200 - val_loss: 0.4019 - val_accuracy: 0.8340\n",
            "Epoch 1000/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3929 - accuracy: 0.8300 - val_loss: 0.3955 - val_accuracy: 0.8380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = go.Scatter(y=his.history['loss'],\n",
        "                    mode=\"lines\",\n",
        "                    line=dict(\n",
        "                        width=2,\n",
        "                        color='blue'),\n",
        "                        name=\"loss\"\n",
        "                   )\n",
        "h2 = go.Scatter(y=his.history['val_loss'],\n",
        "                    mode=\"lines\",\n",
        "                    line=dict(\n",
        "                        width=2,\n",
        "                        color='red'),\n",
        "                        name=\"val_loss\"\n",
        "                   )\n",
        "\n",
        "data = [h1,h2]\n",
        "layout1 = go.Layout(title='Loss',\n",
        "                   xaxis=dict(title='epochs'),\n",
        "                   yaxis=dict(title=''))\n",
        "fig1 = go.Figure(data = data, layout=layout1)\n",
        "plotly.offline.iplot(fig1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "_Ycum6QfcqHZ",
        "outputId": "a89a8638-5cd5-4506-9967-f5200a4d6171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"1a96ae47-36b2-4538-866d-760307415116\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1a96ae47-36b2-4538-866d-760307415116\")) {                    Plotly.newPlot(                        \"1a96ae47-36b2-4538-866d-760307415116\",                        [{\"line\":{\"color\":\"blue\",\"width\":2},\"mode\":\"lines\",\"name\":\"loss\",\"y\":[3.710503339767456,4.036915302276611,2.5371336936950684,2.05841326713562,2.0857818126678467,1.8020055294036865,1.724963665008545,1.3171770572662354,1.0971425771713257,1.10882568359375,0.9413647055625916,0.7886583805084229,0.7711997032165527,0.7438278794288635,0.6999725699424744,0.662341296672821,0.6682905554771423,0.6572786569595337,0.6326227188110352,0.6590057611465454,0.6422935724258423,0.6131771802902222,0.6078527569770813,0.607510507106781,0.5974611043930054,0.5794329047203064,0.5918691754341125,0.6088664531707764,0.5735796689987183,0.5769070386886597,0.5940772891044617,0.5726126432418823,0.5735817551612854,0.5693437457084656,0.5769123435020447,0.5688831806182861,0.54087233543396,0.568484365940094,0.5548050403594971,0.5550431609153748,0.555892288684845,0.5417664051055908,0.5426521897315979,0.5760495066642761,0.5515444874763489,0.5534839034080505,0.5621208548545837,0.5466927886009216,0.5376995205879211,0.5413094758987427,0.5330212116241455,0.5271949172019958,0.5210791826248169,0.5266518592834473,0.5180941820144653,0.5215757489204407,0.5093727707862854,0.5235810279846191,0.5149394273757935,0.5273792147636414,0.5091236233711243,0.5017166137695312,0.5180585980415344,0.505292534828186,0.5065084099769592,0.5057826638221741,0.507424533367157,0.5078855752944946,0.5135698318481445,0.5075005292892456,0.5084963440895081,0.4932023286819458,0.4979606866836548,0.4956774413585663,0.5061520934104919,0.5058745741844177,0.49685847759246826,0.5033959746360779,0.484520822763443,0.4938211739063263,0.5074469447135925,0.48643428087234497,0.5116267204284668,0.5057954788208008,0.4911879599094391,0.4899703860282898,0.4978092312812805,0.4857030212879181,0.48519495129585266,0.48194682598114014,0.47808632254600525,0.4754960834980011,0.48732906579971313,0.4688641130924225,0.4841610789299011,0.48126378655433655,0.4764605760574341,0.4823232889175415,0.48668986558914185,0.47121307253837585,0.47308680415153503,0.47190985083580017,0.4883511960506439,0.47741198539733887,0.46960151195526123,0.4892595112323761,0.47937917709350586,0.4802430272102356,0.4696148633956909,0.4680096209049225,0.47469380497932434,0.4618738293647766,0.466621458530426,0.4540194571018219,0.48953869938850403,0.48183080554008484,0.4809141159057617,0.462134450674057,0.4904949963092804,0.47106245160102844,0.4553799033164978,0.44557538628578186,0.4678932726383209,0.45245644450187683,0.46644389629364014,0.4614099860191345,0.44563087821006775,0.4544607102870941,0.45757630467414856,0.4512366056442261,0.44831788539886475,0.4688635766506195,0.4708486497402191,0.4584349989891052,0.4706226885318756,0.4595358073711395,0.4531857669353485,0.438668817281723,0.44165682792663574,0.4466555118560791,0.4462488293647766,0.47862541675567627,0.4590395390987396,0.47158342599868774,0.45352062582969666,0.45740002393722534,0.4567509889602661,0.45323681831359863,0.46297186613082886,0.46294984221458435,0.44895365834236145,0.45371213555336,0.45157548785209656,0.4483652114868164,0.44795361161231995,0.4465985596179962,0.4603295624256134,0.44404298067092896,0.4511944055557251,0.4547007977962494,0.4477923810482025,0.44392937421798706,0.44257935881614685,0.47228363156318665,0.4616619646549225,0.4689665734767914,0.4513058066368103,0.44717684388160706,0.4410645067691803,0.4475480616092682,0.4548953175544739,0.4437870979309082,0.4331132173538208,0.4408075511455536,0.4425380825996399,0.4482109844684601,0.46285906434059143,0.43702176213264465,0.4396224617958069,0.44574519991874695,0.44852960109710693,0.43145477771759033,0.43372276425361633,0.4322923719882965,0.45356059074401855,0.46424877643585205,0.45947596430778503,0.45369455218315125,0.4505573809146881,0.452786922454834,0.4439246356487274,0.43580982089042664,0.4203047454357147,0.45235106348991394,0.4403093457221985,0.43899816274642944,0.4405348002910614,0.46194615960121155,0.45190513134002686,0.44222643971443176,0.43302011489868164,0.45202651619911194,0.4310302734375,0.4335602819919586,0.45143797993659973,0.43927136063575745,0.4362107813358307,0.43560877442359924,0.43014344573020935,0.4369896948337555,0.4546809196472168,0.42689967155456543,0.43137067556381226,0.44324570894241333,0.43707144260406494,0.444274365901947,0.4292813837528229,0.43693530559539795,0.4402742087841034,0.4282113313674927,0.4203880727291107,0.4507216811180115,0.4372224509716034,0.4390426576137543,0.45322030782699585,0.43213123083114624,0.4338122606277466,0.4433649182319641,0.44541987776756287,0.42614486813545227,0.4362935423851013,0.45122313499450684,0.45383331179618835,0.4456823766231537,0.4536341428756714,0.4701886475086212,0.43418335914611816,0.4367509186267853,0.4640883505344391,0.43644586205482483,0.4319858253002167,0.4258580207824707,0.43371525406837463,0.43083927035331726,0.4253195822238922,0.43242624402046204,0.4382941722869873,0.42583197355270386,0.45038703083992004,0.43424373865127563,0.4258405864238739,0.43234506249427795,0.43480461835861206,0.4278348386287689,0.43295592069625854,0.42708954215049744,0.4378601610660553,0.41859865188598633,0.43224456906318665,0.4175342619419098,0.4314565658569336,0.44224444031715393,0.44075775146484375,0.43344905972480774,0.42557695508003235,0.43629300594329834,0.43147793412208557,0.4293990135192871,0.4413658082485199,0.4259309470653534,0.41745421290397644,0.44513842463493347,0.42720210552215576,0.43675556778907776,0.427280992269516,0.4251307249069214,0.4326286017894745,0.4121147692203522,0.42503437399864197,0.4260208010673523,0.4305178225040436,0.42326194047927856,0.43989887833595276,0.4344407916069031,0.42566901445388794,0.4240727126598358,0.43574807047843933,0.4317711591720581,0.42934489250183105,0.4295802414417267,0.428957998752594,0.43731439113616943,0.43316102027893066,0.42201992869377136,0.42069947719573975,0.4092714488506317,0.43484780192375183,0.43210569024086,0.4186428487300873,0.4307122528553009,0.4260272681713104,0.4183990955352783,0.42622023820877075,0.4176059067249298,0.42530322074890137,0.414818674325943,0.4312252104282379,0.43367645144462585,0.42984476685523987,0.4285230040550232,0.43021655082702637,0.4310683608055115,0.4173107445240021,0.4303168058395386,0.43406397104263306,0.4264679253101349,0.415231317281723,0.4289160668849945,0.43488043546676636,0.4211602807044983,0.42957258224487305,0.422341912984848,0.4243622422218323,0.4147755205631256,0.42761993408203125,0.4179496169090271,0.42996543645858765,0.41155683994293213,0.4174950122833252,0.42987188696861267,0.4264136850833893,0.4236517548561096,0.4274084270000458,0.4381885230541229,0.41085389256477356,0.4252914488315582,0.4220474064350128,0.4332861602306366,0.41570156812667847,0.43563762307167053,0.4301355481147766,0.4273417592048645,0.42461028695106506,0.42157861590385437,0.41452285647392273,0.4399115741252899,0.4139523208141327,0.421739786863327,0.44013819098472595,0.4521193206310272,0.43250852823257446,0.42105716466903687,0.4436647295951843,0.41776514053344727,0.43586528301239014,0.41668474674224854,0.4236610233783722,0.4288003146648407,0.4256936013698578,0.425545871257782,0.41798827052116394,0.4276764392852783,0.4091322720050812,0.4173572063446045,0.42105865478515625,0.43003109097480774,0.4180637300014496,0.4235863983631134,0.4248243272304535,0.4436724781990051,0.4279337227344513,0.4283756613731384,0.4217444360256195,0.42261913418769836,0.41691136360168457,0.43188878893852234,0.4267440438270569,0.4230860471725464,0.42620304226875305,0.4136802852153778,0.43718212842941284,0.4205329716205597,0.415309876203537,0.4358464479446411,0.42488813400268555,0.41754528880119324,0.42247000336647034,0.429379403591156,0.42819857597351074,0.41531720757484436,0.41264039278030396,0.4168857932090759,0.4152642786502838,0.42704761028289795,0.42272186279296875,0.41327768564224243,0.4140895903110504,0.4392969310283661,0.43442976474761963,0.4367372989654541,0.4475971758365631,0.4229026734828949,0.4060983657836914,0.4198620617389679,0.42333608865737915,0.4317511320114136,0.42495059967041016,0.4432567358016968,0.41536614298820496,0.4293787181377411,0.42034393548965454,0.4334496557712555,0.42247670888900757,0.4265351891517639,0.4265654981136322,0.41250938177108765,0.4352664351463318,0.43241336941719055,0.4155167043209076,0.4259291887283325,0.4161844551563263,0.4289425015449524,0.4267708659172058,0.43113577365875244,0.4289826452732086,0.42950886487960815,0.4213837683200836,0.4276834726333618,0.4311518669128418,0.4176754057407379,0.4173203408718109,0.4249318540096283,0.4168870747089386,0.4263606667518616,0.42406779527664185,0.4136505722999573,0.4364403486251831,0.4144308567047119,0.4199833869934082,0.42353004217147827,0.4229640066623688,0.4139378070831299,0.4126877188682556,0.4161028563976288,0.4327274262905121,0.42448297142982483,0.441649854183197,0.4451819062232971,0.43515753746032715,0.4258342981338501,0.43291839957237244,0.4289846122264862,0.4267904758453369,0.4271351099014282,0.4204568564891815,0.4216475486755371,0.4205523729324341,0.4185100793838501,0.41772133111953735,0.41662082076072693,0.4221203327178955,0.4024122953414917,0.40889865159988403,0.4167580008506775,0.4124511182308197,0.41289111971855164,0.42260533571243286,0.4132688641548157,0.4179683327674866,0.4133809208869934,0.42884689569473267,0.4278707802295685,0.4148370623588562,0.4250175356864929,0.41443800926208496,0.40927934646606445,0.41562771797180176,0.4300203025341034,0.4161912500858307,0.42159920930862427,0.41666871309280396,0.4227633774280548,0.42710986733436584,0.41480568051338196,0.4195818305015564,0.42859959602355957,0.42368918657302856,0.41910579800605774,0.41661444306373596,0.42371296882629395,0.4159635007381439,0.43031585216522217,0.4188345670700073,0.412833034992218,0.4113342761993408,0.4127058684825897,0.4128067195415497,0.420681893825531,0.4067862331867218,0.4035815894603729,0.42500144243240356,0.41472911834716797,0.4097360372543335,0.4133891463279724,0.42227011919021606,0.43795645236968994,0.41656285524368286,0.41679999232292175,0.41921478509902954,0.41725537180900574,0.41395923495292664,0.4097942113876343,0.40603888034820557,0.40995192527770996,0.4210202693939209,0.41381511092185974,0.42496734857559204,0.4096392095088959,0.4238697290420532,0.4185970425605774,0.4163070321083069,0.413790762424469,0.41193321347236633,0.4206998348236084,0.41786879301071167,0.4185464680194855,0.42029473185539246,0.4132252335548401,0.421599805355072,0.40854474902153015,0.40613842010498047,0.4229084849357605,0.4155145585536957,0.4057750105857849,0.42351967096328735,0.4053102433681488,0.40282750129699707,0.4231977164745331,0.427435964345932,0.41502049565315247,0.4136713743209839,0.4309096038341522,0.41967540979385376,0.4174630641937256,0.40224510431289673,0.4354894459247589,0.41845983266830444,0.43609732389450073,0.4256882965564728,0.41289564967155457,0.40653595328330994,0.4210800528526306,0.4205275774002075,0.4069392681121826,0.4041602313518524,0.4040582776069641,0.4159354865550995,0.4106587767601013,0.4092912971973419,0.41129612922668457,0.4171214997768402,0.411869615316391,0.41452544927597046,0.42166414856910706,0.4149540662765503,0.4075222909450531,0.41828250885009766,0.41123849153518677,0.41909122467041016,0.4066506028175354,0.41579368710517883,0.4253380596637726,0.4112623333930969,0.4010939300060272,0.4051063060760498,0.40029317140579224,0.3985831141471863,0.43081438541412354,0.4152960479259491,0.4108176827430725,0.41809412837028503,0.40177613496780396,0.42496174573898315,0.4175930321216583,0.4179563820362091,0.4069024622440338,0.41638079285621643,0.4160657227039337,0.41186755895614624,0.42150193452835083,0.41075047850608826,0.4194776713848114,0.4231555163860321,0.4171367883682251,0.4094580113887787,0.4140468239784241,0.41942620277404785,0.42148032784461975,0.41335344314575195,0.42542919516563416,0.41857534646987915,0.4086762070655823,0.4136754274368286,0.41630756855010986,0.4244798719882965,0.40540361404418945,0.4069942533969879,0.40903082489967346,0.4127595126628876,0.4270634949207306,0.4311577081680298,0.41802114248275757,0.4217905104160309,0.41508451104164124,0.4199327826499939,0.41752517223358154,0.41622141003608704,0.4011648893356323,0.417693555355072,0.42254525423049927,0.42722663283348083,0.41043439507484436,0.4080708920955658,0.4180998206138611,0.41264012455940247,0.42541879415512085,0.41701740026474,0.4263492524623871,0.4292371869087219,0.41222184896469116,0.4065529406070709,0.41308385133743286,0.4115522503852844,0.409296452999115,0.4210369884967804,0.3972219228744507,0.41066938638687134,0.4103221297264099,0.41279760003089905,0.41432201862335205,0.41046345233917236,0.4110809862613678,0.40173816680908203,0.41669565439224243,0.42133599519729614,0.40735673904418945,0.40970519185066223,0.41336578130722046,0.4197852313518524,0.4132150411605835,0.41559740900993347,0.41249358654022217,0.4093270003795624,0.4084143042564392,0.41809073090553284,0.4191715121269226,0.41198089718818665,0.4168851375579834,0.40885674953460693,0.4053400158882141,0.4094531834125519,0.4108157157897949,0.4109671711921692,0.40850377082824707,0.4103620648384094,0.4033738374710083,0.4105054438114166,0.4125746488571167,0.4171399772167206,0.41182002425193787,0.41752922534942627,0.4134748876094818,0.4032295048236847,0.4363265633583069,0.40869414806365967,0.41368505358695984,0.4097668528556824,0.41215765476226807,0.40424519777297974,0.4031018316745758,0.40647435188293457,0.42869871854782104,0.42880573868751526,0.40925613045692444,0.39103707671165466,0.41147124767303467,0.41886937618255615,0.4125220477581024,0.4220287501811981,0.4097115695476532,0.4110092222690582,0.4148898124694824,0.4129703938961029,0.4143492579460144,0.4204173684120178,0.4257895350456238,0.401231586933136,0.4100939929485321,0.42292407155036926,0.4167998135089874,0.41472941637039185,0.4066687524318695,0.41920706629753113,0.4045543074607849,0.4111158549785614,0.4057500958442688,0.41561511158943176,0.40905633568763733,0.4034295380115509,0.41223400831222534,0.40923744440078735,0.41388601064682007,0.4088929295539856,0.41531819105148315,0.39369142055511475,0.4136265218257904,0.4253472089767456,0.40963536500930786,0.4084167778491974,0.42204341292381287,0.4006073474884033,0.4033188819885254,0.40821734070777893,0.4192420542240143,0.41497716307640076,0.409049928188324,0.4214688837528229,0.4120982587337494,0.399807870388031,0.4057277739048004,0.4112844169139862,0.40074455738067627,0.4194815754890442,0.416128009557724,0.42078128457069397,0.4325251579284668,0.42287328839302063,0.41031694412231445,0.40274733304977417,0.4185258448123932,0.41146737337112427,0.420160710811615,0.4235091507434845,0.43375152349472046,0.39712920784950256,0.4088894724845886,0.41636279225349426,0.41906633973121643,0.4043934643268585,0.4282289445400238,0.42229315638542175,0.41971009969711304,0.41094452142715454,0.40934550762176514,0.4137098491191864,0.41525620222091675,0.4080035984516144,0.4099828600883484,0.40889424085617065,0.40535521507263184,0.422456294298172,0.40424734354019165,0.4175669550895691,0.4221981167793274,0.4153079390525818,0.4185590147972107,0.41340625286102295,0.415489137172699,0.4036860167980194,0.42054522037506104,0.4237478971481323,0.420901894569397,0.39483126997947693,0.41063472628593445,0.414951890707016,0.4126860499382019,0.40159180760383606,0.39401939511299133,0.4023289680480957,0.4169524610042572,0.4018716812133789,0.4202515184879303,0.39787307381629944,0.4253459870815277,0.4092130661010742,0.4301722049713135,0.41783517599105835,0.4075111746788025,0.40767228603363037,0.41071978211402893,0.4105168581008911,0.4251185953617096,0.40189018845558167,0.43484237790107727,0.39352089166641235,0.4199222922325134,0.4038712680339813,0.40777692198753357,0.41228851675987244,0.4116438627243042,0.4132855236530304,0.4241107702255249,0.4003819227218628,0.4207853376865387,0.41860851645469666,0.40971386432647705,0.406997948884964,0.4134238660335541,0.4088440239429474,0.40698108077049255,0.4109216332435608,0.40091291069984436,0.408038854598999,0.41410908102989197,0.41187718510627747,0.4129173159599304,0.4040879011154175,0.39849087595939636,0.40953612327575684,0.39713844656944275,0.41633355617523193,0.40649834275245667,0.4109920263290405,0.4030258059501648,0.4157402217388153,0.40177926421165466,0.4002740681171417,0.405242383480072,0.4123293161392212,0.4048311412334442,0.40355169773101807,0.4023243188858032,0.4111124277114868,0.41687002778053284,0.4102669656276703,0.4287715256214142,0.4145432114601135,0.3952256143093109,0.4097925126552582,0.4166433811187744,0.4162142872810364,0.4053742587566376,0.4098586440086365,0.411038875579834,0.41170528531074524,0.3969278037548065,0.4080151915550232,0.40498146414756775,0.42089688777923584,0.4066150486469269,0.42386674880981445,0.4157177805900574,0.41880562901496887,0.4030573070049286,0.411813884973526,0.41054999828338623,0.4021933972835541,0.40728065371513367,0.4160136282444,0.4089353680610657,0.40290385484695435,0.41153547167778015,0.40682220458984375,0.4165878891944885,0.4052944481372833,0.40917351841926575,0.4254705011844635,0.41398656368255615,0.40494611859321594,0.4086543321609497,0.41623249650001526,0.42633748054504395,0.42362427711486816,0.40837275981903076,0.40666088461875916,0.41523241996765137,0.42236998677253723,0.4174928367137909,0.4082951247692108,0.4134257137775421,0.3977876603603363,0.40181615948677063,0.40777361392974854,0.40090930461883545,0.41371673345565796,0.3876020610332489,0.40618789196014404,0.41748717427253723,0.405788391828537,0.4125167429447174,0.40063267946243286,0.4072091579437256,0.4135635197162628,0.4074537456035614,0.40947213768959045,0.43435215950012207,0.4171324372291565,0.41131702065467834,0.4149091839790344,0.3937183916568756,0.4228375256061554,0.404310017824173,0.42181703448295593,0.42127951979637146,0.4093122184276581,0.40599149465560913,0.42342671751976013,0.4186563789844513,0.411724328994751,0.41258296370506287,0.41187584400177,0.39710119366645813,0.411298930644989,0.41311565041542053,0.41256552934646606,0.39572590589523315,0.4091185927391052,0.4125341773033142,0.4159473180770874,0.4045867919921875,0.3812265992164612,0.4167966842651367,0.4108584225177765,0.4154822528362274,0.4022407829761505,0.4036245346069336,0.40644219517707825,0.4154810309410095,0.4168764650821686,0.41652411222457886,0.42780420184135437,0.4056492745876312,0.42001578211784363,0.4074426293373108,0.41527697443962097,0.39833375811576843,0.40792280435562134,0.4227055013179779,0.42424386739730835,0.40844017267227173,0.4091411530971527,0.4060007631778717,0.4021308422088623,0.39334186911582947,0.41012924909591675,0.4003767967224121,0.3964863121509552,0.4249776303768158,0.3983798921108246,0.4234720468521118,0.3995084762573242,0.4140462577342987,0.40160873532295227,0.40401726961135864,0.3942345380783081,0.4123486280441284,0.4055720269680023,0.40054386854171753,0.4002262055873871,0.4222889840602875,0.4200837314128876,0.40400615334510803,0.40435200929641724,0.41434580087661743,0.4039042294025421,0.4113350510597229,0.39697468280792236,0.4028432071208954,0.41274935007095337,0.4022570550441742,0.403194397687912,0.3970714211463928,0.3984065651893616,0.40360042452812195,0.41706135869026184,0.40890806913375854,0.4189916253089905,0.4042235016822815,0.41235777735710144,0.3942872881889343,0.4123919904232025,0.4158983528614044,0.4103029668331146,0.3964105248451233,0.4044497311115265,0.4077349603176117,0.4164917767047882,0.4136445224285126,0.40649837255477905,0.4057346284389496,0.4012823700904846,0.40582823753356934,0.4035114645957947,0.4192523658275604,0.4244541525840759,0.4090210497379303,0.4137958884239197,0.4075019657611847,0.4150359034538269,0.39285796880722046],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\",\"width\":2},\"mode\":\"lines\",\"name\":\"val_loss\",\"y\":[4.411563396453857,2.7512667179107666,1.6597516536712646,1.8083970546722412,1.4030365943908691,1.798384189605713,1.2463877201080322,0.8513606190681458,0.9108916521072388,0.7707376480102539,0.7276450991630554,0.6115832924842834,0.6035955548286438,0.7455680966377258,0.5718408823013306,0.5690416097640991,0.6426113247871399,0.5695877075195312,0.5617762804031372,0.6118033528327942,0.5499964356422424,0.541628897190094,0.558708667755127,0.5525694489479065,0.5495797991752625,0.5531506538391113,0.5422788858413696,0.547027051448822,0.5600684285163879,0.5616310834884644,0.5577098727226257,0.5512890219688416,0.5590237379074097,0.5260865688323975,0.5238878130912781,0.5149891972541809,0.5154637098312378,0.5274649262428284,0.5143453478813171,0.523513913154602,0.5281122326850891,0.5078562498092651,0.5211666226387024,0.543229877948761,0.5218502879142761,0.532534122467041,0.5127031207084656,0.5052298307418823,0.5113273859024048,0.5159531235694885,0.49642643332481384,0.4923231899738312,0.5043009519577026,0.5007501244544983,0.48901572823524475,0.4944145381450653,0.48932552337646484,0.4850027859210968,0.48854029178619385,0.48428019881248474,0.4823310673236847,0.48731616139411926,0.48260945081710815,0.4892428517341614,0.47960254549980164,0.48387712240219116,0.4809427261352539,0.4725276827812195,0.4852754473686218,0.47412797808647156,0.46610021591186523,0.47055134177207947,0.483063668012619,0.4687010645866394,0.46657395362854004,0.46774590015411377,0.4677603840827942,0.46516716480255127,0.46035236120224,0.46220171451568604,0.46394646167755127,0.469573438167572,0.4700915217399597,0.46105071902275085,0.4681791365146637,0.46979108452796936,0.46067705750465393,0.4674411118030548,0.4607662260532379,0.45578649640083313,0.4602409601211548,0.4604717493057251,0.452721506357193,0.45760253071784973,0.45785215497016907,0.45470336079597473,0.45084500312805176,0.4509443938732147,0.45694053173065186,0.44829627871513367,0.4478284418582916,0.4474705159664154,0.44499364495277405,0.4510498046875,0.44786399602890015,0.4518551230430603,0.4509122371673584,0.45286691188812256,0.4443794786930084,0.44017156958580017,0.4462415277957916,0.44108086824417114,0.44090473651885986,0.44425642490386963,0.44978511333465576,0.4544543921947479,0.4437083899974823,0.44080427289009094,0.44699862599372864,0.4371430575847626,0.4447900950908661,0.4394678473472595,0.4383557438850403,0.43808236718177795,0.44352903962135315,0.4346254765987396,0.4332711398601532,0.43721628189086914,0.4416741728782654,0.4402448832988739,0.44116851687431335,0.43952521681785583,0.44180646538734436,0.4362281262874603,0.4347257912158966,0.4317934513092041,0.4335181713104248,0.4300781190395355,0.42843544483184814,0.4380580484867096,0.42974475026130676,0.43291571736335754,0.4333592355251312,0.43181678652763367,0.4378218948841095,0.435860276222229,0.44600456953048706,0.4307112991809845,0.4319726526737213,0.42932775616645813,0.43428146839141846,0.4306353032588959,0.4266286790370941,0.4277181625366211,0.42505916953086853,0.428158700466156,0.4298495650291443,0.4447711706161499,0.4318341016769409,0.42811593413352966,0.4239918887615204,0.43094977736473083,0.42489972710609436,0.42690491676330566,0.43364208936691284,0.430330753326416,0.4420328438282013,0.42530742287635803,0.4283483326435089,0.4219111204147339,0.4221206605434418,0.4198346436023712,0.4228929281234741,0.4260319173336029,0.42021775245666504,0.41991955041885376,0.41981828212738037,0.42245370149612427,0.42655012011528015,0.42432326078414917,0.42049670219421387,0.41630393266677856,0.4181945323944092,0.42181679606437683,0.4214465320110321,0.4293157160282135,0.42507609724998474,0.42890679836273193,0.4205455183982849,0.4205261766910553,0.42855826020240784,0.41909322142601013,0.420674204826355,0.4168086647987366,0.42406919598579407,0.4240931272506714,0.4221211075782776,0.421658992767334,0.4200964570045471,0.4158039689064026,0.4282623827457428,0.416141539812088,0.41640767455101013,0.4178723096847534,0.41583138704299927,0.41825705766677856,0.4165298044681549,0.41759344935417175,0.41364386677742004,0.4140399098396301,0.4185502231121063,0.42572304606437683,0.4138071835041046,0.4153975248336792,0.41652634739875793,0.41521379351615906,0.4189724326133728,0.41488194465637207,0.4137766361236572,0.4133530259132385,0.41019031405448914,0.41987890005111694,0.41801953315734863,0.41813451051712036,0.4144333302974701,0.4283452033996582,0.4135923683643341,0.41635650396347046,0.41490039229393005,0.4191988706588745,0.4113258123397827,0.4114411473274231,0.4279642403125763,0.42401424050331116,0.4182014763355255,0.413471519947052,0.41937997937202454,0.4369426965713501,0.4158545732498169,0.41451483964920044,0.4123014509677887,0.41186851263046265,0.41260358691215515,0.41308653354644775,0.4148661196231842,0.4132673442363739,0.4187503457069397,0.4110319912433624,0.41039299964904785,0.4121641218662262,0.41486015915870667,0.41300976276397705,0.41086432337760925,0.41251832246780396,0.4091426730155945,0.4140987992286682,0.4112376570701599,0.40948328375816345,0.41084960103034973,0.4124632477760315,0.4112163782119751,0.4124862551689148,0.41438028216362,0.4115191102027893,0.42562445998191833,0.4129992127418518,0.41338518261909485,0.4154033958911896,0.4112049639225006,0.4086453914642334,0.41520848870277405,0.41010427474975586,0.41366344690322876,0.4088801145553589,0.41019517183303833,0.4103509187698364,0.41068035364151,0.41038578748703003,0.4122263789176941,0.4105706214904785,0.40983033180236816,0.41168537735939026,0.4106334149837494,0.40722933411598206,0.40900182723999023,0.40982919931411743,0.4090246558189392,0.4127248525619507,0.40786802768707275,0.41467994451522827,0.4091872572898865,0.410544216632843,0.4068108797073364,0.4110690951347351,0.40947869420051575,0.4084368944168091,0.40487024188041687,0.4126942753791809,0.40726834535598755,0.4147818982601166,0.4072660505771637,0.40897509455680847,0.40846195816993713,0.41014987230300903,0.41000431776046753,0.4088796377182007,0.409440279006958,0.4079923629760742,0.40737903118133545,0.4078357517719269,0.40814849734306335,0.4110632836818695,0.4080442488193512,0.4093077778816223,0.4083591401576996,0.404084712266922,0.40906456112861633,0.4053311347961426,0.4066671133041382,0.40963107347488403,0.4092386066913605,0.4041730463504791,0.4072561264038086,0.4031526446342468,0.403845876455307,0.40738165378570557,0.406706303358078,0.40486085414886475,0.40666234493255615,0.40925249457359314,0.40812817215919495,0.4112549126148224,0.40921318531036377,0.406459778547287,0.41141417622566223,0.40813958644866943,0.4087584912776947,0.41589057445526123,0.4068327844142914,0.4109240770339966,0.40695610642433167,0.4057466387748718,0.4089395999908447,0.405391663312912,0.4053974747657776,0.4095170795917511,0.4056628942489624,0.41435572504997253,0.4059273600578308,0.41318005323410034,0.4331694543361664,0.4071177840232849,0.4025440812110901,0.4257121980190277,0.4059220254421234,0.40800243616104126,0.40691444277763367,0.40550416707992554,0.41044509410858154,0.40503424406051636,0.40715348720550537,0.4073718786239624,0.40539291501045227,0.40450653433799744,0.409325510263443,0.40450698137283325,0.4061519205570221,0.4065779447555542,0.40583181381225586,0.4039275646209717,0.41604217886924744,0.4052300453186035,0.40628141164779663,0.40685969591140747,0.41028979420661926,0.4071231186389923,0.4072864353656769,0.4060460031032562,0.4069681465625763,0.40497684478759766,0.41124415397644043,0.40575140714645386,0.4045070707798004,0.40917912125587463,0.40218254923820496,0.4034484326839447,0.40591660141944885,0.4027891159057617,0.4028022885322571,0.4031928777694702,0.40722981095314026,0.40286368131637573,0.4035244882106781,0.4101789593696594,0.4017910659313202,0.4120965898036957,0.40222007036209106,0.40210020542144775,0.42193955183029175,0.40551435947418213,0.412689745426178,0.40070641040802,0.4052893817424774,0.4057748019695282,0.40764355659484863,0.40278923511505127,0.4098539650440216,0.40391644835472107,0.4052309989929199,0.4013170599937439,0.41338586807250977,0.4001520872116089,0.40353673696517944,0.40880468487739563,0.4059823751449585,0.4089420437812805,0.39817795157432556,0.4028559923171997,0.41860753297805786,0.4029780924320221,0.40116673707962036,0.4104522168636322,0.4028635025024414,0.4025372266769409,0.40559470653533936,0.4024546146392822,0.40233033895492554,0.39955639839172363,0.4056170880794525,0.4016571640968323,0.40045392513275146,0.4050437808036804,0.40482622385025024,0.4009360373020172,0.4041728675365448,0.40431827306747437,0.399539589881897,0.41221287846565247,0.3994832932949066,0.39980432391166687,0.40416592359542847,0.40476587414741516,0.40005257725715637,0.41292649507522583,0.40099743008613586,0.4030495584011078,0.41497617959976196,0.4075276255607605,0.42223504185676575,0.3994109034538269,0.399787962436676,0.4113578498363495,0.4004421532154083,0.40070173144340515,0.41154560446739197,0.3994142413139343,0.400967001914978,0.3985712230205536,0.4001721143722534,0.39834344387054443,0.39819812774658203,0.3975107967853546,0.3976178765296936,0.3965851366519928,0.40054479241371155,0.3957583010196686,0.3988167345523834,0.40534764528274536,0.3991362452507019,0.3981150984764099,0.4043287932872772,0.39687907695770264,0.4068434536457062,0.3978878855705261,0.3976552188396454,0.40028300881385803,0.4025736153125763,0.40061691403388977,0.40519896149635315,0.4028032422065735,0.40022924542427063,0.40036335587501526,0.4068761467933655,0.40442943572998047,0.41270631551742554,0.4012387692928314,0.40576183795928955,0.40256068110466003,0.4046637713909149,0.3975779414176941,0.40138256549835205,0.399976521730423,0.398817777633667,0.401589035987854,0.40019476413726807,0.4061490297317505,0.39995965361595154,0.4011797606945038,0.4021875262260437,0.3997234106063843,0.4032045006752014,0.40296924114227295,0.403658002614975,0.4031865894794464,0.4001018702983856,0.3998042643070221,0.4048541486263275,0.40146979689598083,0.3973183333873749,0.40306657552719116,0.40212592482566833,0.39677760004997253,0.40065184235572815,0.40308842062950134,0.3998290002346039,0.40041619539260864,0.40132442116737366,0.3983106017112732,0.40455031394958496,0.3984987437725067,0.39868611097335815,0.4004906415939331,0.39956948161125183,0.4002728760242462,0.4059707522392273,0.3981119692325592,0.39765021204948425,0.4049243628978729,0.39959338307380676,0.3983004093170166,0.40018346905708313,0.40247297286987305,0.3981207013130188,0.40037181973457336,0.40031349658966064,0.39856886863708496,0.40560972690582275,0.4005110263824463,0.39708930253982544,0.407250314950943,0.39986157417297363,0.4000387191772461,0.40286126732826233,0.4009975492954254,0.3995664715766907,0.40226811170578003,0.40017443895339966,0.40149301290512085,0.4047852158546448,0.4022575914859772,0.3977958858013153,0.399006187915802,0.4022957682609558,0.3958853781223297,0.40172290802001953,0.4031949043273926,0.3983803987503052,0.3983652591705322,0.39978939294815063,0.39785876870155334,0.39882394671440125,0.4043620526790619,0.40134838223457336,0.399623841047287,0.40561529994010925,0.39906153082847595,0.40429338812828064,0.40318939089775085,0.3972034156322479,0.39758312702178955,0.395958811044693,0.40058135986328125,0.3982241153717041,0.3972149193286896,0.40004828572273254,0.3980894386768341,0.3993925154209137,0.398642361164093,0.3966514468193054,0.4038620591163635,0.3975750803947449,0.39972320199012756,0.39852094650268555,0.4033956527709961,0.3981556296348572,0.40627285838127136,0.40388455986976624,0.39664384722709656,0.39678192138671875,0.4005717635154724,0.3938409388065338,0.39499950408935547,0.39913180470466614,0.3960200548171997,0.4103521704673767,0.39829644560813904,0.40144848823547363,0.41296663880348206,0.40029090642929077,0.4017171859741211,0.42028895020484924,0.40165650844573975,0.3964086174964905,0.403574138879776,0.39663147926330566,0.395616352558136,0.3969219923019409,0.39879631996154785,0.39597734808921814,0.4142542779445648,0.3997941017150879,0.3984243869781494,0.415744811296463,0.3964781165122986,0.39847275614738464,0.4025660455226898,0.39643093943595886,0.39810803532600403,0.3987588584423065,0.39845043420791626,0.3984755277633667,0.40650543570518494,0.4000462293624878,0.3979811370372772,0.40167802572250366,0.3976266384124756,0.40171948075294495,0.4082861840724945,0.40094372630119324,0.3974820375442505,0.40245020389556885,0.4000578224658966,0.3975736200809479,0.4078601598739624,0.39733216166496277,0.39546066522598267,0.39927318692207336,0.4030783772468567,0.39748719334602356,0.3979285955429077,0.4052695631980896,0.40066152811050415,0.40240004658699036,0.40063589811325073,0.399680495262146,0.3991484045982361,0.3966989517211914,0.40146324038505554,0.3959546387195587,0.4022023677825928,0.3978479504585266,0.3986464738845825,0.40101614594459534,0.39491063356399536,0.3984585404396057,0.3995249569416046,0.3964512348175049,0.40327227115631104,0.39991047978401184,0.3995787501335144,0.3997507393360138,0.3976742625236511,0.39812976121902466,0.39823195338249207,0.3959726393222809,0.40458592772483826,0.4020474851131439,0.3980346918106079,0.3987084627151489,0.4075222909450531,0.39793893694877625,0.39751267433166504,0.3973309397697449,0.4023910462856293,0.39718398451805115,0.4030469059944153,0.40117374062538147,0.396796315908432,0.4000018835067749,0.4062635004520416,0.39829689264297485,0.39801648259162903,0.40358349680900574,0.40286198258399963,0.3996840715408325,0.4005242586135864,0.4050133526325226,0.3975938856601715,0.3974960744380951,0.4153156876564026,0.3998200297355652,0.399391770362854,0.40152740478515625,0.4057556986808777,0.4052233397960663,0.3994862735271454,0.41122522950172424,0.4081196188926697,0.4011029899120331,0.40510326623916626,0.40130501985549927,0.40061047673225403,0.4056984484195709,0.4004114866256714,0.4038920998573303,0.40189656615257263,0.39794090390205383,0.40387022495269775,0.40020743012428284,0.39939185976982117,0.39955341815948486,0.4043150246143341,0.39884889125823975,0.4017753005027771,0.39655542373657227,0.40044400095939636,0.3981473445892334,0.40064746141433716,0.400057852268219,0.40200841426849365,0.3974655270576477,0.3989580571651459,0.40846776962280273,0.3983984887599945,0.39956822991371155,0.4054439961910248,0.39730727672576904,0.39805901050567627,0.40432068705558777,0.3969634771347046,0.3977581858634949,0.4055244028568268,0.4022510051727295,0.3971394896507263,0.398755818605423,0.39692652225494385,0.3977417051792145,0.40067553520202637,0.3962860405445099,0.3955923318862915,0.40634551644325256,0.3994452655315399,0.3976461887359619,0.41032788157463074,0.3979600667953491,0.397553414106369,0.4031597077846527,0.39626482129096985,0.4018198251724243,0.3983761668205261,0.3985002338886261,0.4065587818622589,0.39830827713012695,0.39879149198532104,0.4004102349281311,0.3978119194507599,0.40104085206985474,0.3981474041938782,0.40274831652641296,0.39616015553474426,0.39983752369880676,0.39816632866859436,0.40001118183135986,0.39586591720581055,0.4019271731376648,0.4050943851470947,0.39844000339508057,0.39846470952033997,0.40894803404808044,0.39907872676849365,0.4006974399089813,0.40517404675483704,0.397972047328949,0.39774763584136963,0.39906832575798035,0.40184837579727173,0.39982250332832336,0.40052422881126404,0.3966338336467743,0.40003466606140137,0.40284645557403564,0.3985483944416046,0.396200567483902,0.40708473324775696,0.39952653646469116,0.400869756937027,0.4083746671676636,0.39943280816078186,0.4007892310619354,0.39905980229377747,0.398330956697464,0.40434589982032776,0.3987572491168976,0.3975600004196167,0.4048807621002197,0.39730197191238403,0.3968134820461273,0.4002475440502167,0.3968040645122528,0.40217629075050354,0.39797937870025635,0.3963037133216858,0.39884519577026367,0.4048602283000946,0.39968183636665344,0.39990079402923584,0.401949405670166,0.40376636385917664,0.3947642743587494,0.39668527245521545,0.40070831775665283,0.3988332152366638,0.3950754404067993,0.3968566358089447,0.4028880000114441,0.39549681544303894,0.39804160594940186,0.4011576473712921,0.3983086049556732,0.4001625180244446,0.3998187482357025,0.39710015058517456,0.39822089672088623,0.39770713448524475,0.3977517783641815,0.39645805954933167,0.3972420394420624,0.4015038311481476,0.39853039383888245,0.39813441038131714,0.3975599408149719,0.4028109908103943,0.40241923928260803,0.3973437547683716,0.40260306000709534,0.4048168361186981,0.3978655934333801,0.40144428610801697,0.39721760153770447,0.3960486948490143,0.40364184975624084,0.40018901228904724,0.3973364531993866,0.40109241008758545,0.4019337594509125,0.3956606984138489,0.39631107449531555,0.40455862879753113,0.3964395821094513,0.3945835530757904,0.40919575095176697,0.3958973288536072,0.39714697003364563,0.4038528501987457,0.39648592472076416,0.3973366320133209,0.3997863531112671,0.3943619132041931,0.401559442281723,0.3983273208141327,0.39626678824424744,0.39947330951690674,0.3970680832862854,0.3960016965866089,0.4088427722454071,0.39887934923171997,0.39732062816619873,0.4096662700176239,0.3971306383609772,0.39720240235328674,0.40447163581848145,0.4068666696548462,0.39618542790412903,0.39870327711105347,0.40140682458877563,0.39728039503097534,0.39633193612098694,0.4053514301776886,0.3980781137943268,0.39780253171920776,0.39915332198143005,0.4018571674823761,0.40202662348747253,0.39859336614608765,0.3992457389831543,0.3986392021179199,0.3959818184375763,0.4018646776676178,0.39804765582084656,0.4053545892238617,0.3993060290813446,0.39954400062561035,0.39785200357437134,0.40882453322410583,0.396218866109848,0.39799532294273376,0.4173315763473511,0.3970506191253662,0.3955720067024231,0.40060269832611084,0.40751582384109497,0.39581337571144104,0.3971337378025055,0.4098484218120575,0.39832818508148193,0.3954056203365326,0.41059011220932007,0.397411584854126,0.39567261934280396,0.3965076506137848,0.40239477157592773,0.397090882062912,0.39472222328186035,0.39873364567756653,0.40341299772262573,0.3973056375980377,0.39769110083580017,0.4094967842102051,0.3974390923976898,0.39765113592147827,0.4011983573436737,0.4031405448913574,0.3943791687488556,0.39528366923332214,0.39618396759033203,0.4031263291835785,0.4056222438812256,0.3976438641548157,0.4078441560268402,0.403998464345932,0.40013447403907776,0.4097954332828522,0.4011338949203491,0.3980107605457306,0.39853379130363464,0.4143294095993042,0.39662402868270874,0.3965238332748413,0.4013064205646515,0.40094587206840515,0.39425402879714966,0.39792174100875854,0.3973782956600189,0.4003361165523529,0.3992106318473816,0.3982466459274292,0.3976447880268097,0.40066877007484436,0.40175893902778625,0.3978460133075714,0.39903613924980164,0.39726966619491577,0.39790481328964233,0.4029366374015808,0.3994521498680115,0.398634672164917,0.3990572988986969,0.39627644419670105,0.4022844731807709,0.40533769130706787,0.40305981040000916,0.4008283019065857,0.4018188416957855,0.4004569351673126,0.4020863175392151,0.39856216311454773,0.39880743622779846,0.4025056064128876,0.39585572481155396,0.3969069719314575,0.3976771831512451,0.4014672338962555,0.3989557921886444,0.39754271507263184,0.39822590351104736,0.39740750193595886,0.40148288011550903,0.39605531096458435,0.39858368039131165,0.39823785424232483,0.39696890115737915,0.3986090421676636,0.4093758463859558,0.3981401324272156,0.39622578024864197,0.4045616090297699,0.400256872177124,0.3952891230583191,0.39823001623153687,0.3974364101886749,0.399961918592453,0.39576512575149536,0.3982965648174286,0.3982200622558594,0.40535131096839905,0.3971031606197357,0.3960300385951996,0.3996710181236267,0.4018661379814148,0.39554157853126526],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Loss\"},\"xaxis\":{\"title\":{\"text\":\"epochs\"}},\"yaxis\":{\"title\":{\"text\":\"\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1a96ae47-36b2-4538-866d-760307415116');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = go.Scatter(y=his.history['accuracy'],\n",
        "                    mode=\"lines\",\n",
        "                    line=dict(\n",
        "                        width=2,\n",
        "                        color='blue'),\n",
        "                        name=\"acc\"\n",
        "                   )\n",
        "h2 = go.Scatter(y=his.history['val_accuracy'],\n",
        "                    mode=\"lines\",\n",
        "                    line=dict(\n",
        "                        width=2,\n",
        "                        color='red'),\n",
        "                        name=\"val_acc\"\n",
        "                   )\n",
        "\n",
        "data = [h1,h2]\n",
        "layout1 = go.Layout(title='Accuracy',\n",
        "                   xaxis=dict(title='epochs'),\n",
        "                   yaxis=dict(title=''))\n",
        "fig1 = go.Figure(data = data, layout=layout1)\n",
        "plotly.offline.iplot(fig1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "ZOLDlSqgcvZS",
        "outputId": "b70484fa-dcd5-4fab-c84f-9da40e1940de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"60f44d70-2474-4c17-8a67-877e5f73745f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"60f44d70-2474-4c17-8a67-877e5f73745f\")) {                    Plotly.newPlot(                        \"60f44d70-2474-4c17-8a67-877e5f73745f\",                        [{\"line\":{\"color\":\"blue\",\"width\":2},\"mode\":\"lines\",\"name\":\"acc\",\"y\":[0.4059999883174896,0.4000000059604645,0.5320000052452087,0.5440000295639038,0.6060000061988831,0.6000000238418579,0.5979999899864197,0.6119999885559082,0.6299999952316284,0.628000020980835,0.6420000195503235,0.6520000100135803,0.671999990940094,0.6819999814033508,0.6759999990463257,0.6940000057220459,0.6859999895095825,0.7260000109672546,0.7080000042915344,0.7120000123977661,0.7120000123977661,0.734000027179718,0.7279999852180481,0.7419999837875366,0.7440000176429749,0.7580000162124634,0.7580000162124634,0.722000002861023,0.7599999904632568,0.734000027179718,0.7620000243186951,0.7459999918937683,0.7400000095367432,0.75,0.7620000243186951,0.7559999823570251,0.7919999957084656,0.7559999823570251,0.777999997138977,0.7620000243186951,0.7680000066757202,0.7699999809265137,0.7860000133514404,0.7680000066757202,0.7720000147819519,0.7739999890327454,0.7459999918937683,0.7879999876022339,0.7720000147819519,0.765999972820282,0.7739999890327454,0.777999997138977,0.7799999713897705,0.7720000147819519,0.7940000295639038,0.777999997138977,0.7919999957084656,0.7739999890327454,0.7979999780654907,0.777999997138977,0.7900000214576721,0.7799999713897705,0.7860000133514404,0.7860000133514404,0.7879999876022339,0.7919999957084656,0.7820000052452087,0.7879999876022339,0.7900000214576721,0.7839999794960022,0.8019999861717224,0.7839999794960022,0.7979999780654907,0.7940000295639038,0.7799999713897705,0.7900000214576721,0.7820000052452087,0.7919999957084656,0.7919999957084656,0.7860000133514404,0.777999997138977,0.800000011920929,0.7820000052452087,0.7820000052452087,0.7960000038146973,0.800000011920929,0.7820000052452087,0.7979999780654907,0.8019999861717224,0.8019999861717224,0.8019999861717224,0.7979999780654907,0.7979999780654907,0.8040000200271606,0.7940000295639038,0.8040000200271606,0.8059999942779541,0.7940000295639038,0.7960000038146973,0.800000011920929,0.800000011920929,0.8159999847412109,0.7919999957084656,0.8100000023841858,0.7960000038146973,0.800000011920929,0.800000011920929,0.7960000038146973,0.8040000200271606,0.8159999847412109,0.7960000038146973,0.8140000104904175,0.8019999861717224,0.8159999847412109,0.8100000023841858,0.7979999780654907,0.7839999794960022,0.8100000023841858,0.7940000295639038,0.800000011920929,0.8019999861717224,0.8180000185966492,0.7979999780654907,0.8019999861717224,0.7979999780654907,0.7960000038146973,0.8180000185966492,0.8040000200271606,0.8100000023841858,0.8019999861717224,0.8019999861717224,0.8100000023841858,0.7940000295639038,0.8180000185966492,0.7960000038146973,0.8220000267028809,0.8059999942779541,0.8240000009536743,0.8100000023841858,0.8199999928474426,0.8059999942779541,0.7820000052452087,0.8180000185966492,0.7879999876022339,0.7979999780654907,0.8019999861717224,0.800000011920929,0.8119999766349792,0.7979999780654907,0.8059999942779541,0.800000011920929,0.8159999847412109,0.8019999861717224,0.8080000281333923,0.800000011920929,0.8080000281333923,0.8040000200271606,0.8100000023841858,0.8140000104904175,0.7900000214576721,0.8220000267028809,0.8080000281333923,0.8059999942779541,0.7960000038146973,0.7960000038146973,0.800000011920929,0.8119999766349792,0.8140000104904175,0.8080000281333923,0.8059999942779541,0.8040000200271606,0.828000009059906,0.8140000104904175,0.8199999928474426,0.8040000200271606,0.8080000281333923,0.8080000281333923,0.8100000023841858,0.8119999766349792,0.8119999766349792,0.8100000023841858,0.8119999766349792,0.8240000009536743,0.8199999928474426,0.8180000185966492,0.8040000200271606,0.8119999766349792,0.8119999766349792,0.8199999928474426,0.8059999942779541,0.8220000267028809,0.8080000281333923,0.8159999847412109,0.7940000295639038,0.8040000200271606,0.8199999928474426,0.8220000267028809,0.7960000038146973,0.8059999942779541,0.7979999780654907,0.8040000200271606,0.8140000104904175,0.8019999861717224,0.8059999942779541,0.8059999942779541,0.8100000023841858,0.8240000009536743,0.8240000009536743,0.828000009059906,0.8180000185966492,0.8080000281333923,0.8180000185966492,0.8320000171661377,0.8199999928474426,0.8100000023841858,0.828000009059906,0.8220000267028809,0.8199999928474426,0.7940000295639038,0.8240000009536743,0.8220000267028809,0.8180000185966492,0.7919999957084656,0.8080000281333923,0.800000011920929,0.8259999752044678,0.8080000281333923,0.8220000267028809,0.8080000281333923,0.8119999766349792,0.8220000267028809,0.7979999780654907,0.7979999780654907,0.8059999942779541,0.7940000295639038,0.7979999780654907,0.8199999928474426,0.8119999766349792,0.800000011920929,0.8019999861717224,0.8040000200271606,0.8199999928474426,0.8119999766349792,0.8119999766349792,0.8299999833106995,0.8259999752044678,0.8220000267028809,0.8119999766349792,0.8040000200271606,0.8140000104904175,0.8259999752044678,0.8059999942779541,0.8100000023841858,0.8180000185966492,0.8159999847412109,0.8180000185966492,0.8119999766349792,0.8240000009536743,0.7979999780654907,0.8159999847412109,0.8240000009536743,0.7979999780654907,0.828000009059906,0.7960000038146973,0.8360000252723694,0.8140000104904175,0.8059999942779541,0.8199999928474426,0.7940000295639038,0.8140000104904175,0.8180000185966492,0.7979999780654907,0.8220000267028809,0.8080000281333923,0.8100000023841858,0.8140000104904175,0.8220000267028809,0.8159999847412109,0.8140000104904175,0.8159999847412109,0.8100000023841858,0.8159999847412109,0.8019999861717224,0.8119999766349792,0.8220000267028809,0.8140000104904175,0.8080000281333923,0.8119999766349792,0.8100000023841858,0.8080000281333923,0.8180000185966492,0.8259999752044678,0.800000011920929,0.8159999847412109,0.8180000185966492,0.8259999752044678,0.8080000281333923,0.8040000200271606,0.8399999737739563,0.8059999942779541,0.8159999847412109,0.8199999928474426,0.8240000009536743,0.8220000267028809,0.8159999847412109,0.8140000104904175,0.8159999847412109,0.8159999847412109,0.8119999766349792,0.8100000023841858,0.8119999766349792,0.8180000185966492,0.8159999847412109,0.8199999928474426,0.8119999766349792,0.8180000185966492,0.8140000104904175,0.8199999928474426,0.8040000200271606,0.8259999752044678,0.8140000104904175,0.8159999847412109,0.8180000185966492,0.8180000185966492,0.8180000185966492,0.8240000009536743,0.7979999780654907,0.8240000009536743,0.8259999752044678,0.8119999766349792,0.8159999847412109,0.8100000023841858,0.8180000185966492,0.8159999847412109,0.8299999833106995,0.8199999928474426,0.8180000185966492,0.8140000104904175,0.8199999928474426,0.8059999942779541,0.8240000009536743,0.8180000185966492,0.8259999752044678,0.828000009059906,0.8159999847412109,0.8040000200271606,0.8159999847412109,0.8140000104904175,0.8080000281333923,0.8019999861717224,0.8080000281333923,0.8299999833106995,0.8059999942779541,0.8240000009536743,0.8080000281333923,0.8119999766349792,0.8040000200271606,0.8159999847412109,0.8180000185966492,0.8140000104904175,0.8159999847412109,0.8220000267028809,0.8220000267028809,0.8119999766349792,0.8080000281333923,0.7960000038146973,0.8159999847412109,0.8140000104904175,0.8159999847412109,0.8140000104904175,0.8220000267028809,0.8140000104904175,0.8059999942779541,0.8080000281333923,0.8240000009536743,0.8080000281333923,0.8180000185966492,0.8119999766349792,0.8140000104904175,0.8180000185966492,0.8019999861717224,0.8080000281333923,0.8259999752044678,0.8019999861717224,0.8019999861717224,0.8059999942779541,0.8159999847412109,0.8159999847412109,0.8180000185966492,0.8080000281333923,0.8119999766349792,0.828000009059906,0.8080000281333923,0.8040000200271606,0.8140000104904175,0.8240000009536743,0.8299999833106995,0.8199999928474426,0.8100000023841858,0.8140000104904175,0.7979999780654907,0.8220000267028809,0.828000009059906,0.8119999766349792,0.8240000009536743,0.8220000267028809,0.800000011920929,0.8259999752044678,0.8180000185966492,0.8199999928474426,0.8320000171661377,0.7900000214576721,0.8320000171661377,0.8059999942779541,0.8100000023841858,0.828000009059906,0.8159999847412109,0.800000011920929,0.8059999942779541,0.8019999861717224,0.8019999861717224,0.8059999942779541,0.8119999766349792,0.8220000267028809,0.8080000281333923,0.8080000281333923,0.8180000185966492,0.8040000200271606,0.7900000214576721,0.8199999928474426,0.8119999766349792,0.8240000009536743,0.8299999833106995,0.8059999942779541,0.8180000185966492,0.8299999833106995,0.8100000023841858,0.8240000009536743,0.7979999780654907,0.8159999847412109,0.8059999942779541,0.828000009059906,0.8119999766349792,0.8220000267028809,0.8180000185966492,0.8240000009536743,0.800000011920929,0.8119999766349792,0.8059999942779541,0.828000009059906,0.8119999766349792,0.8040000200271606,0.8100000023841858,0.8080000281333923,0.8159999847412109,0.8159999847412109,0.8220000267028809,0.8080000281333923,0.8159999847412109,0.8119999766349792,0.8240000009536743,0.8259999752044678,0.8220000267028809,0.8159999847412109,0.8100000023841858,0.8119999766349792,0.8199999928474426,0.8140000104904175,0.8159999847412109,0.8140000104904175,0.8140000104904175,0.8140000104904175,0.8199999928474426,0.8140000104904175,0.8159999847412109,0.8220000267028809,0.8220000267028809,0.8140000104904175,0.8199999928474426,0.8180000185966492,0.8199999928474426,0.8040000200271606,0.8119999766349792,0.8100000023841858,0.8220000267028809,0.800000011920929,0.8100000023841858,0.8100000023841858,0.8259999752044678,0.8180000185966492,0.8199999928474426,0.8159999847412109,0.8220000267028809,0.8140000104904175,0.8360000252723694,0.8240000009536743,0.7979999780654907,0.8040000200271606,0.8220000267028809,0.8299999833106995,0.8119999766349792,0.8399999737739563,0.8259999752044678,0.8199999928474426,0.8259999752044678,0.8059999942779541,0.8199999928474426,0.8180000185966492,0.8199999928474426,0.8080000281333923,0.8059999942779541,0.8220000267028809,0.8240000009536743,0.8159999847412109,0.8080000281333923,0.8199999928474426,0.8100000023841858,0.8140000104904175,0.8180000185966492,0.828000009059906,0.8199999928474426,0.8080000281333923,0.8259999752044678,0.8220000267028809,0.8180000185966492,0.8119999766349792,0.8199999928474426,0.8140000104904175,0.8159999847412109,0.8220000267028809,0.828000009059906,0.8100000023841858,0.8159999847412109,0.8339999914169312,0.8180000185966492,0.8320000171661377,0.8220000267028809,0.8360000252723694,0.8080000281333923,0.8159999847412109,0.8159999847412109,0.8019999861717224,0.8199999928474426,0.8080000281333923,0.8259999752044678,0.8220000267028809,0.8080000281333923,0.8040000200271606,0.8119999766349792,0.8119999766349792,0.8180000185966492,0.8059999942779541,0.8119999766349792,0.828000009059906,0.8199999928474426,0.8259999752044678,0.8119999766349792,0.8159999847412109,0.8259999752044678,0.8299999833106995,0.8040000200271606,0.8100000023841858,0.8119999766349792,0.8119999766349792,0.8119999766349792,0.8199999928474426,0.8259999752044678,0.8199999928474426,0.8059999942779541,0.8140000104904175,0.8159999847412109,0.8119999766349792,0.8159999847412109,0.8199999928474426,0.8299999833106995,0.8080000281333923,0.8320000171661377,0.8059999942779541,0.8140000104904175,0.8140000104904175,0.8119999766349792,0.8140000104904175,0.8119999766349792,0.8119999766349792,0.8259999752044678,0.8240000009536743,0.8220000267028809,0.8119999766349792,0.8159999847412109,0.8220000267028809,0.828000009059906,0.8199999928474426,0.8220000267028809,0.8199999928474426,0.8159999847412109,0.8220000267028809,0.8080000281333923,0.8180000185966492,0.8199999928474426,0.8019999861717224,0.8100000023841858,0.8100000023841858,0.8220000267028809,0.8180000185966492,0.8199999928474426,0.8299999833106995,0.828000009059906,0.8140000104904175,0.8180000185966492,0.8059999942779541,0.800000011920929,0.8080000281333923,0.8199999928474426,0.8259999752044678,0.8119999766349792,0.8059999942779541,0.8240000009536743,0.8259999752044678,0.8259999752044678,0.8119999766349792,0.8220000267028809,0.8259999752044678,0.8140000104904175,0.8059999942779541,0.8159999847412109,0.8259999752044678,0.8180000185966492,0.8159999847412109,0.8180000185966492,0.8140000104904175,0.8199999928474426,0.8199999928474426,0.8180000185966492,0.8159999847412109,0.8159999847412109,0.8220000267028809,0.8180000185966492,0.8220000267028809,0.8180000185966492,0.8199999928474426,0.8119999766349792,0.8140000104904175,0.8080000281333923,0.8140000104904175,0.8119999766349792,0.8220000267028809,0.8220000267028809,0.8119999766349792,0.8100000023841858,0.8159999847412109,0.8119999766349792,0.8180000185966492,0.8240000009536743,0.8119999766349792,0.8220000267028809,0.8199999928474426,0.8140000104904175,0.828000009059906,0.8159999847412109,0.8100000023841858,0.8199999928474426,0.8180000185966492,0.8159999847412109,0.8220000267028809,0.8299999833106995,0.828000009059906,0.8240000009536743,0.8119999766349792,0.8159999847412109,0.8220000267028809,0.8220000267028809,0.8140000104904175,0.8220000267028809,0.800000011920929,0.8119999766349792,0.8220000267028809,0.8119999766349792,0.8100000023841858,0.8259999752044678,0.8299999833106995,0.8019999861717224,0.800000011920929,0.8100000023841858,0.8199999928474426,0.8199999928474426,0.8199999928474426,0.8180000185966492,0.800000011920929,0.8119999766349792,0.8220000267028809,0.8199999928474426,0.8240000009536743,0.8180000185966492,0.8180000185966492,0.8100000023841858,0.8040000200271606,0.8199999928474426,0.8220000267028809,0.8119999766349792,0.8240000009536743,0.8240000009536743,0.8220000267028809,0.8140000104904175,0.8199999928474426,0.8180000185966492,0.8199999928474426,0.8199999928474426,0.8159999847412109,0.8240000009536743,0.8080000281333923,0.8119999766349792,0.8199999928474426,0.8199999928474426,0.8119999766349792,0.828000009059906,0.8180000185966492,0.8220000267028809,0.8220000267028809,0.8240000009536743,0.8080000281333923,0.8119999766349792,0.8259999752044678,0.8299999833106995,0.8159999847412109,0.8059999942779541,0.8180000185966492,0.8159999847412109,0.8100000023841858,0.8220000267028809,0.8259999752044678,0.8100000023841858,0.8360000252723694,0.7979999780654907,0.8140000104904175,0.8119999766349792,0.8119999766349792,0.8180000185966492,0.8320000171661377,0.8180000185966492,0.8040000200271606,0.8180000185966492,0.8180000185966492,0.8019999861717224,0.8040000200271606,0.8220000267028809,0.8080000281333923,0.8080000281333923,0.8159999847412109,0.8100000023841858,0.8080000281333923,0.8199999928474426,0.8059999942779541,0.8240000009536743,0.8240000009536743,0.8159999847412109,0.8080000281333923,0.8159999847412109,0.8199999928474426,0.8180000185966492,0.8220000267028809,0.8140000104904175,0.8240000009536743,0.8180000185966492,0.8199999928474426,0.8180000185966492,0.8199999928474426,0.8159999847412109,0.8119999766349792,0.8159999847412109,0.8059999942779541,0.8059999942779541,0.8059999942779541,0.8299999833106995,0.8199999928474426,0.8159999847412109,0.800000011920929,0.8159999847412109,0.8220000267028809,0.8100000023841858,0.8140000104904175,0.8119999766349792,0.8220000267028809,0.8240000009536743,0.8199999928474426,0.8240000009536743,0.7919999957084656,0.8199999928474426,0.8339999914169312,0.8199999928474426,0.8180000185966492,0.8159999847412109,0.8040000200271606,0.8220000267028809,0.7979999780654907,0.8320000171661377,0.8140000104904175,0.8240000009536743,0.8240000009536743,0.8199999928474426,0.828000009059906,0.828000009059906,0.8100000023841858,0.8240000009536743,0.8080000281333923,0.8059999942779541,0.8180000185966492,0.8199999928474426,0.8180000185966492,0.8240000009536743,0.8040000200271606,0.8159999847412109,0.8199999928474426,0.8299999833106995,0.8220000267028809,0.8240000009536743,0.828000009059906,0.828000009059906,0.828000009059906,0.8119999766349792,0.8220000267028809,0.8199999928474426,0.8240000009536743,0.8220000267028809,0.843999981880188,0.8180000185966492,0.8259999752044678,0.8220000267028809,0.8159999847412109,0.8240000009536743,0.8080000281333923,0.8180000185966492,0.8259999752044678,0.8320000171661377,0.8240000009536743,0.828000009059906,0.8040000200271606,0.828000009059906,0.828000009059906,0.8299999833106995,0.8180000185966492,0.8140000104904175,0.8360000252723694,0.8140000104904175,0.8119999766349792,0.8080000281333923,0.8180000185966492,0.8180000185966492,0.8220000267028809,0.8119999766349792,0.8040000200271606,0.8080000281333923,0.8240000009536743,0.8159999847412109,0.8180000185966492,0.8119999766349792,0.8080000281333923,0.828000009059906,0.8180000185966492,0.8320000171661377,0.8180000185966492,0.828000009059906,0.8140000104904175,0.8299999833106995,0.8180000185966492,0.8180000185966492,0.828000009059906,0.8040000200271606,0.8159999847412109,0.8420000076293945,0.8159999847412109,0.8159999847412109,0.8220000267028809,0.8180000185966492,0.8119999766349792,0.8159999847412109,0.8240000009536743,0.8080000281333923,0.8159999847412109,0.8180000185966492,0.8240000009536743,0.8199999928474426,0.8240000009536743,0.8140000104904175,0.8140000104904175,0.8360000252723694,0.8339999914169312,0.8220000267028809,0.8140000104904175,0.8299999833106995,0.8100000023841858,0.8199999928474426,0.8320000171661377,0.7960000038146973,0.8180000185966492,0.8180000185966492,0.800000011920929,0.8080000281333923,0.828000009059906,0.8100000023841858,0.8240000009536743,0.8159999847412109,0.8220000267028809,0.8140000104904175,0.8100000023841858,0.8199999928474426,0.8019999861717224,0.8159999847412109,0.8140000104904175,0.8080000281333923,0.8059999942779541,0.8180000185966492,0.8100000023841858,0.8119999766349792,0.8199999928474426,0.8059999942779541,0.8259999752044678,0.8100000023841858,0.8220000267028809,0.8240000009536743,0.8220000267028809,0.8240000009536743,0.8220000267028809,0.8199999928474426,0.8140000104904175,0.8199999928474426,0.8199999928474426,0.8240000009536743,0.8080000281333923,0.8159999847412109,0.8140000104904175,0.8080000281333923,0.8240000009536743,0.8080000281333923,0.8199999928474426,0.800000011920929,0.8220000267028809,0.8339999914169312,0.8119999766349792,0.8180000185966492,0.8199999928474426,0.8199999928474426,0.8339999914169312,0.8259999752044678,0.8199999928474426,0.8220000267028809,0.8240000009536743,0.8320000171661377,0.8059999942779541,0.8259999752044678,0.8159999847412109,0.828000009059906,0.8240000009536743,0.8259999752044678,0.8320000171661377,0.8159999847412109,0.8159999847412109,0.8240000009536743,0.8199999928474426,0.8240000009536743,0.8100000023841858,0.8040000200271606,0.8140000104904175,0.8140000104904175,0.828000009059906,0.8299999833106995,0.8140000104904175,0.828000009059906,0.8119999766349792,0.8159999847412109,0.8180000185966492,0.8100000023841858,0.8339999914169312,0.8180000185966492,0.8220000267028809,0.8019999861717224,0.8220000267028809,0.8140000104904175,0.8240000009536743,0.8220000267028809,0.8199999928474426,0.8040000200271606,0.8019999861717224,0.8140000104904175,0.8199999928474426,0.8080000281333923,0.8180000185966492,0.8159999847412109,0.8199999928474426,0.8180000185966492,0.8159999847412109,0.8220000267028809,0.8180000185966492,0.8140000104904175,0.8220000267028809,0.8119999766349792,0.8240000009536743,0.8259999752044678,0.8180000185966492,0.8199999928474426,0.8299999833106995],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\",\"width\":2},\"mode\":\"lines\",\"name\":\"val_acc\",\"y\":[0.36800000071525574,0.4880000054836273,0.5440000295639038,0.6439999938011169,0.6480000019073486,0.6119999885559082,0.6499999761581421,0.6940000057220459,0.6639999747276306,0.7099999785423279,0.6620000004768372,0.7139999866485596,0.7279999852180481,0.6340000033378601,0.7179999947547913,0.7960000038146973,0.6660000085830688,0.7300000190734863,0.7900000214576721,0.6759999990463257,0.734000027179718,0.7820000052452087,0.7580000162124634,0.7400000095367432,0.7960000038146973,0.7419999837875366,0.7559999823570251,0.800000011920929,0.7360000014305115,0.8180000185966492,0.7239999771118164,0.8320000171661377,0.7379999756813049,0.7940000295639038,0.7979999780654907,0.7879999876022339,0.8040000200271606,0.7839999794960022,0.7820000052452087,0.8159999847412109,0.7860000133514404,0.8159999847412109,0.7680000066757202,0.8180000185966492,0.7820000052452087,0.8320000171661377,0.7919999957084656,0.7879999876022339,0.8119999766349792,0.7799999713897705,0.8320000171661377,0.7979999780654907,0.8119999766349792,0.7879999876022339,0.7960000038146973,0.8320000171661377,0.8040000200271606,0.8140000104904175,0.8019999861717224,0.8080000281333923,0.8119999766349792,0.8040000200271606,0.8040000200271606,0.8240000009536743,0.8059999942779541,0.8119999766349792,0.8220000267028809,0.8140000104904175,0.8199999928474426,0.8180000185966492,0.8059999942779541,0.8180000185966492,0.7979999780654907,0.8080000281333923,0.8159999847412109,0.8299999833106995,0.8119999766349792,0.828000009059906,0.8140000104904175,0.8259999752044678,0.8080000281333923,0.8220000267028809,0.8180000185966492,0.8059999942779541,0.8339999914169312,0.8019999861717224,0.8299999833106995,0.8059999942779541,0.8299999833106995,0.8040000200271606,0.8140000104904175,0.828000009059906,0.828000009059906,0.8259999752044678,0.8180000185966492,0.8119999766349792,0.8220000267028809,0.8199999928474426,0.828000009059906,0.8159999847412109,0.8220000267028809,0.8180000185966492,0.8140000104904175,0.828000009059906,0.8140000104904175,0.8360000252723694,0.8399999737739563,0.8220000267028809,0.8240000009536743,0.8220000267028809,0.828000009059906,0.8140000104904175,0.8220000267028809,0.8259999752044678,0.8420000076293945,0.8040000200271606,0.8199999928474426,0.828000009059906,0.8339999914169312,0.8180000185966492,0.8339999914169312,0.8199999928474426,0.8199999928474426,0.8240000009536743,0.8339999914169312,0.828000009059906,0.8299999833106995,0.8299999833106995,0.8259999752044678,0.8159999847412109,0.8399999737739563,0.8059999942779541,0.8259999752044678,0.8180000185966492,0.8259999752044678,0.8259999752044678,0.8360000252723694,0.8299999833106995,0.828000009059906,0.8420000076293945,0.828000009059906,0.8379999995231628,0.828000009059906,0.8199999928474426,0.8379999995231628,0.8180000185966492,0.8420000076293945,0.8159999847412109,0.8360000252723694,0.8240000009536743,0.8460000157356262,0.8299999833106995,0.8360000252723694,0.8299999833106995,0.8320000171661377,0.843999981880188,0.8240000009536743,0.8379999995231628,0.8220000267028809,0.8339999914169312,0.8299999833106995,0.8420000076293945,0.8320000171661377,0.8199999928474426,0.8460000157356262,0.8199999928474426,0.8479999899864197,0.8220000267028809,0.8420000076293945,0.8339999914169312,0.8339999914169312,0.8299999833106995,0.8379999995231628,0.8379999995231628,0.8199999928474426,0.8339999914169312,0.8299999833106995,0.828000009059906,0.8479999899864197,0.8299999833106995,0.8360000252723694,0.8259999752044678,0.828000009059906,0.843999981880188,0.8240000009536743,0.8500000238418579,0.8159999847412109,0.8479999899864197,0.8399999737739563,0.8299999833106995,0.8479999899864197,0.8240000009536743,0.8379999995231628,0.8339999914169312,0.8240000009536743,0.8339999914169312,0.8360000252723694,0.8379999995231628,0.8320000171661377,0.8299999833106995,0.8420000076293945,0.8320000171661377,0.8360000252723694,0.8420000076293945,0.8360000252723694,0.8420000076293945,0.843999981880188,0.8420000076293945,0.8399999737739563,0.8399999737739563,0.828000009059906,0.8420000076293945,0.828000009059906,0.8399999737739563,0.8399999737739563,0.8379999995231628,0.8420000076293945,0.8399999737739563,0.8379999995231628,0.8420000076293945,0.8320000171661377,0.8479999899864197,0.8240000009536743,0.8379999995231628,0.8320000171661377,0.8479999899864197,0.8320000171661377,0.8399999737739563,0.8339999914169312,0.843999981880188,0.8299999833106995,0.8360000252723694,0.8420000076293945,0.8220000267028809,0.8460000157356262,0.8339999914169312,0.8220000267028809,0.8360000252723694,0.828000009059906,0.843999981880188,0.8420000076293945,0.8379999995231628,0.8420000076293945,0.8360000252723694,0.8379999995231628,0.8360000252723694,0.8320000171661377,0.8379999995231628,0.8399999737739563,0.8420000076293945,0.8420000076293945,0.8399999737739563,0.8379999995231628,0.8399999737739563,0.8360000252723694,0.8420000076293945,0.8420000076293945,0.8379999995231628,0.8399999737739563,0.8420000076293945,0.8379999995231628,0.8379999995231628,0.8420000076293945,0.8360000252723694,0.8479999899864197,0.8299999833106995,0.8399999737739563,0.8420000076293945,0.8360000252723694,0.8360000252723694,0.8399999737739563,0.8379999995231628,0.843999981880188,0.8320000171661377,0.8420000076293945,0.8399999737739563,0.8420000076293945,0.8399999737739563,0.843999981880188,0.8420000076293945,0.8379999995231628,0.8399999737739563,0.8420000076293945,0.8420000076293945,0.8399999737739563,0.8460000157356262,0.8379999995231628,0.8339999914169312,0.8299999833106995,0.8399999737739563,0.8399999737739563,0.8379999995231628,0.8320000171661377,0.8379999995231628,0.8399999737739563,0.843999981880188,0.8420000076293945,0.8420000076293945,0.8259999752044678,0.8360000252723694,0.843999981880188,0.8379999995231628,0.8360000252723694,0.8399999737739563,0.8399999737739563,0.8299999833106995,0.8379999995231628,0.8379999995231628,0.8399999737739563,0.8379999995231628,0.8399999737739563,0.8379999995231628,0.8420000076293945,0.8379999995231628,0.8479999899864197,0.8299999833106995,0.8399999737739563,0.8339999914169312,0.8420000076293945,0.8460000157356262,0.8379999995231628,0.8399999737739563,0.8420000076293945,0.8339999914169312,0.8360000252723694,0.8460000157356262,0.8399999737739563,0.8420000076293945,0.8420000076293945,0.8420000076293945,0.8379999995231628,0.8379999995231628,0.8360000252723694,0.8320000171661377,0.8379999995231628,0.8420000076293945,0.8379999995231628,0.8420000076293945,0.8360000252723694,0.8379999995231628,0.8299999833106995,0.8379999995231628,0.8399999737739563,0.8399999737739563,0.8379999995231628,0.843999981880188,0.8399999737739563,0.8360000252723694,0.8399999737739563,0.828000009059906,0.8399999737739563,0.8299999833106995,0.8299999833106995,0.8460000157356262,0.8320000171661377,0.843999981880188,0.8399999737739563,0.8360000252723694,0.843999981880188,0.8379999995231628,0.8420000076293945,0.8420000076293945,0.8399999737739563,0.8379999995231628,0.8399999737739563,0.8399999737739563,0.8360000252723694,0.8360000252723694,0.8379999995231628,0.8320000171661377,0.8460000157356262,0.8379999995231628,0.8399999737739563,0.8360000252723694,0.8360000252723694,0.8420000076293945,0.8399999737739563,0.8399999737739563,0.8399999737739563,0.8320000171661377,0.8420000076293945,0.8379999995231628,0.8399999737739563,0.8460000157356262,0.8399999737739563,0.8399999737739563,0.8379999995231628,0.8420000076293945,0.8399999737739563,0.8420000076293945,0.8420000076293945,0.8379999995231628,0.8379999995231628,0.8420000076293945,0.8339999914169312,0.8399999737739563,0.843999981880188,0.8379999995231628,0.8460000157356262,0.8299999833106995,0.8519999980926514,0.8420000076293945,0.8379999995231628,0.8379999995231628,0.8460000157356262,0.843999981880188,0.8379999995231628,0.8360000252723694,0.8399999737739563,0.8399999737739563,0.8360000252723694,0.8399999737739563,0.843999981880188,0.8379999995231628,0.8299999833106995,0.843999981880188,0.8360000252723694,0.8299999833106995,0.8479999899864197,0.8399999737739563,0.8379999995231628,0.8420000076293945,0.8379999995231628,0.8399999737739563,0.8420000076293945,0.8420000076293945,0.8420000076293945,0.8320000171661377,0.8360000252723694,0.8399999737739563,0.8399999737739563,0.8399999737739563,0.8379999995231628,0.8360000252723694,0.8399999737739563,0.8420000076293945,0.8379999995231628,0.8399999737739563,0.8379999995231628,0.8399999737739563,0.8399999737739563,0.8379999995231628,0.8360000252723694,0.8379999995231628,0.8360000252723694,0.8360000252723694,0.8399999737739563,0.828000009059906,0.8399999737739563,0.8339999914169312,0.8320000171661377,0.8420000076293945,0.8399999737739563,0.8399999737739563,0.8399999737739563,0.8299999833106995,0.843999981880188,0.8379999995231628,0.8360000252723694,0.8420000076293945,0.8420000076293945,0.8399999737739563,0.8360000252723694,0.8399999737739563,0.8420000076293945,0.8360000252723694,0.8339999914169312,0.8360000252723694,0.8399999737739563,0.8399999737739563,0.8360000252723694,0.8339999914169312,0.8420000076293945,0.8420000076293945,0.8399999737739563,0.8379999995231628,0.8399999737739563,0.8339999914169312,0.8379999995231628,0.8399999737739563,0.8399999737739563,0.8399999737739563,0.8379999995231628,0.8299999833106995,0.8479999899864197,0.8379999995231628,0.8399999737739563,0.8399999737739563,0.8420000076293945,0.8339999914169312,0.8399999737739563,0.8420000076293945,0.8420000076293945,0.8399999737739563,0.8420000076293945,0.8420000076293945,0.8379999995231628,0.8399999737739563,0.8379999995231628,0.8420000076293945,0.8399999737739563,0.8420000076293945,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8399999737739563,0.8379999995231628,0.8320000171661377,0.8399999737739563,0.8379999995231628,0.8299999833106995,0.8399999737739563,0.8420000076293945,0.8399999737739563,0.8379999995231628,0.8399999737739563,0.8379999995231628,0.8360000252723694,0.8360000252723694,0.8399999737739563,0.8379999995231628,0.8420000076293945,0.8399999737739563,0.8399999737739563,0.8320000171661377,0.8320000171661377,0.8379999995231628,0.8399999737739563,0.8420000076293945,0.8399999737739563,0.8379999995231628,0.8339999914169312,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8339999914169312,0.8320000171661377,0.8379999995231628,0.8420000076293945,0.8420000076293945,0.8420000076293945,0.8399999737739563,0.8379999995231628,0.8399999737739563,0.8399999737739563,0.8399999737739563,0.8460000157356262,0.843999981880188,0.8379999995231628,0.8360000252723694,0.8320000171661377,0.8360000252723694,0.8420000076293945,0.8420000076293945,0.8420000076293945,0.8360000252723694,0.8360000252723694,0.8360000252723694,0.8360000252723694,0.8379999995231628,0.8420000076293945,0.8379999995231628,0.8360000252723694,0.8320000171661377,0.8339999914169312,0.8360000252723694,0.8379999995231628,0.8399999737739563,0.8360000252723694,0.8399999737739563,0.8399999737739563,0.8420000076293945,0.8379999995231628,0.8399999737739563,0.8399999737739563,0.8420000076293945,0.8339999914169312,0.8399999737739563,0.8399999737739563,0.8339999914169312,0.8379999995231628,0.8339999914169312,0.8399999737739563,0.8360000252723694,0.8360000252723694,0.8360000252723694,0.8399999737739563,0.8339999914169312,0.8299999833106995,0.8360000252723694,0.8399999737739563,0.8420000076293945,0.8420000076293945,0.8339999914169312,0.8379999995231628,0.8339999914169312,0.8320000171661377,0.8420000076293945,0.8339999914169312,0.8399999737739563,0.8339999914169312,0.8399999737739563,0.8360000252723694,0.8379999995231628,0.8420000076293945,0.8399999737739563,0.8299999833106995,0.843999981880188,0.8379999995231628,0.8420000076293945,0.8500000238418579,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8420000076293945,0.8399999737739563,0.8360000252723694,0.8360000252723694,0.8339999914169312,0.8420000076293945,0.843999981880188,0.8460000157356262,0.8379999995231628,0.828000009059906,0.8339999914169312,0.843999981880188,0.8339999914169312,0.8399999737739563,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8339999914169312,0.8360000252723694,0.8360000252723694,0.8379999995231628,0.8360000252723694,0.8420000076293945,0.8399999737739563,0.8399999737739563,0.8360000252723694,0.8420000076293945,0.8399999737739563,0.8360000252723694,0.8379999995231628,0.8360000252723694,0.8360000252723694,0.8379999995231628,0.8360000252723694,0.8420000076293945,0.8360000252723694,0.8379999995231628,0.8360000252723694,0.8399999737739563,0.8420000076293945,0.8360000252723694,0.8360000252723694,0.8299999833106995,0.8379999995231628,0.8379999995231628,0.8399999737739563,0.8399999737739563,0.8339999914169312,0.8360000252723694,0.8399999737739563,0.843999981880188,0.8339999914169312,0.8399999737739563,0.8399999737739563,0.8399999737739563,0.8360000252723694,0.8339999914169312,0.8399999737739563,0.8360000252723694,0.8399999737739563,0.8379999995231628,0.8379999995231628,0.8360000252723694,0.8379999995231628,0.8360000252723694,0.8360000252723694,0.8379999995231628,0.8360000252723694,0.8339999914169312,0.8339999914169312,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8339999914169312,0.8379999995231628,0.8320000171661377,0.8339999914169312,0.8339999914169312,0.8320000171661377,0.8360000252723694,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8460000157356262,0.8360000252723694,0.8379999995231628,0.8299999833106995,0.8320000171661377,0.8339999914169312,0.8339999914169312,0.8360000252723694,0.8360000252723694,0.8360000252723694,0.8379999995231628,0.8360000252723694,0.8399999737739563,0.8379999995231628,0.8399999737739563,0.8399999737739563,0.8379999995231628,0.8360000252723694,0.8379999995231628,0.8299999833106995,0.8320000171661377,0.8360000252723694,0.8379999995231628,0.8360000252723694,0.8379999995231628,0.8379999995231628,0.8320000171661377,0.8379999995231628,0.8320000171661377,0.8320000171661377,0.8420000076293945,0.8379999995231628,0.8399999737739563,0.8420000076293945,0.8399999737739563,0.8379999995231628,0.8379999995231628,0.8360000252723694,0.8360000252723694,0.8399999737739563,0.8339999914169312,0.8360000252723694,0.8399999737739563,0.8379999995231628,0.8339999914169312,0.8339999914169312,0.8399999737739563,0.8339999914169312,0.8379999995231628,0.8299999833106995,0.8299999833106995,0.8339999914169312,0.8259999752044678,0.8339999914169312,0.8379999995231628,0.8399999737739563,0.8360000252723694,0.8379999995231628,0.8339999914169312,0.8339999914169312,0.8379999995231628,0.8320000171661377,0.8339999914169312,0.8320000171661377,0.8320000171661377,0.8259999752044678,0.8360000252723694,0.828000009059906,0.8399999737739563,0.8360000252723694,0.8399999737739563,0.828000009059906,0.8299999833106995,0.8299999833106995,0.8320000171661377,0.8320000171661377,0.828000009059906,0.8379999995231628,0.8379999995231628,0.8360000252723694,0.8339999914169312,0.8339999914169312,0.8379999995231628,0.8399999737739563,0.8360000252723694,0.8379999995231628,0.8399999737739563,0.8399999737739563,0.8360000252723694,0.8339999914169312,0.8360000252723694,0.8339999914169312,0.8339999914169312,0.8259999752044678,0.8339999914169312,0.8360000252723694,0.8379999995231628,0.8339999914169312,0.8399999737739563,0.8379999995231628,0.8399999737739563,0.8360000252723694,0.8339999914169312,0.8339999914169312,0.8360000252723694,0.8339999914169312,0.8320000171661377,0.8360000252723694,0.8339999914169312,0.8320000171661377,0.8399999737739563,0.8399999737739563,0.8339999914169312,0.8299999833106995,0.8399999737739563,0.8379999995231628,0.8399999737739563,0.8360000252723694,0.8360000252723694,0.8259999752044678,0.8360000252723694,0.8360000252723694,0.8379999995231628,0.8360000252723694,0.8339999914169312,0.8339999914169312,0.8379999995231628,0.8339999914169312,0.8360000252723694,0.8379999995231628,0.8379999995231628,0.8320000171661377,0.8379999995231628,0.8320000171661377,0.8339999914169312,0.8339999914169312,0.8360000252723694,0.8320000171661377,0.8339999914169312,0.8379999995231628,0.8299999833106995,0.8379999995231628,0.8360000252723694,0.8320000171661377,0.8360000252723694,0.8320000171661377,0.8379999995231628,0.8399999737739563,0.843999981880188,0.8399999737739563,0.8420000076293945,0.8360000252723694,0.8379999995231628,0.8339999914169312,0.8379999995231628,0.8299999833106995,0.8299999833106995,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8360000252723694,0.8379999995231628,0.8299999833106995,0.8320000171661377,0.8360000252723694,0.8320000171661377,0.8339999914169312,0.8379999995231628,0.8320000171661377,0.8399999737739563,0.8399999737739563,0.8360000252723694,0.8339999914169312,0.828000009059906,0.8299999833106995,0.8320000171661377,0.8360000252723694,0.8360000252723694,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8299999833106995,0.8339999914169312,0.8379999995231628,0.8420000076293945,0.8399999737739563,0.8399999737739563,0.8360000252723694,0.8339999914169312,0.8320000171661377,0.8320000171661377,0.8339999914169312,0.8360000252723694,0.828000009059906,0.8339999914169312,0.8320000171661377,0.8320000171661377,0.8379999995231628,0.8339999914169312,0.8339999914169312,0.8299999833106995,0.8379999995231628,0.8399999737739563,0.8360000252723694,0.8360000252723694,0.8360000252723694,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8339999914169312,0.8399999737739563,0.8360000252723694,0.8339999914169312,0.8339999914169312,0.8339999914169312,0.8379999995231628,0.8360000252723694,0.828000009059906,0.828000009059906,0.8259999752044678,0.8379999995231628,0.8360000252723694,0.8360000252723694,0.8379999995231628,0.8379999995231628,0.8259999752044678,0.8320000171661377,0.8379999995231628,0.8339999914169312,0.8339999914169312,0.843999981880188,0.8379999995231628,0.8299999833106995,0.8360000252723694,0.8339999914169312,0.8360000252723694,0.8360000252723694,0.8379999995231628,0.8379999995231628,0.8360000252723694,0.8399999737739563,0.8360000252723694,0.8360000252723694,0.8339999914169312,0.8360000252723694,0.8339999914169312,0.8379999995231628,0.8379999995231628,0.8379999995231628,0.8360000252723694,0.8339999914169312,0.8339999914169312,0.8360000252723694,0.8339999914169312,0.8379999995231628,0.8320000171661377,0.8339999914169312,0.828000009059906,0.8299999833106995,0.8339999914169312,0.8420000076293945,0.8399999737739563,0.8320000171661377,0.8320000171661377,0.8360000252723694,0.8360000252723694,0.8360000252723694,0.8379999995231628,0.8339999914169312,0.8339999914169312,0.8360000252723694,0.8339999914169312,0.8360000252723694,0.8360000252723694,0.8379999995231628,0.8339999914169312,0.8339999914169312,0.8320000171661377,0.8360000252723694,0.8379999995231628,0.8360000252723694,0.8339999914169312,0.8240000009536743,0.8339999914169312,0.8399999737739563,0.8360000252723694,0.828000009059906,0.8339999914169312,0.8339999914169312,0.8379999995231628,0.8360000252723694,0.8339999914169312,0.8339999914169312,0.8339999914169312,0.8379999995231628],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Accuracy\"},\"xaxis\":{\"title\":{\"text\":\"epochs\"}},\"yaxis\":{\"title\":{\"text\":\"\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('60f44d70-2474-4c17-8a67-877e5f73745f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
        "_, val_acc = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Train: %.4f, Validation: %.4f' % (train_acc, val_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulON2-xeczQd",
        "outputId": "0709d88f-6130-41e1-e741-0e302db22211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.8220, Validation: 0.8380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.predict(x_train)\n",
        "\n",
        "print(np.round(res[:10],3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF6pLHAHc1tI",
        "outputId": "d82fad01-e305-448e-da14-47988bb8ddf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 1ms/step\n",
            "[[0.002 0.744 0.254]\n",
            " [0.002 0.894 0.104]\n",
            " [0.004 0.764 0.232]\n",
            " [0.999 0.    0.001]\n",
            " [0.    0.113 0.886]\n",
            " [0.009 0.713 0.278]\n",
            " [0.003 0.759 0.238]\n",
            " [0.    0.996 0.004]\n",
            " [0.998 0.    0.002]\n",
            " [0.982 0.    0.018]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sparse Categorical Crossentropy Loss"
      ],
      "metadata": {
        "id": "FP1Ah_DR5fLP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "โดย Default แล้ว ในการสร้าง Model แบบ Multi-Class Classification เราจะคอนฟิก Loss Function เป็น Categorical Crossentropy Loss แต่สำหรับปัญหาบางปัญหาที่มีผลเฉลย (Label) จำนวนมากๆ การเข้ารหัสผลเฉลยแบบ One-hot Encoding เพื่อสร้างการแจกแจงความน่าจะเป็นแบบที่เราอยากได้ (Actual Probability Distribution) จะทำให้สิ้นเปลือง Memory\n",
        "\n",
        "Sparse Categorical Crossentropy สามารถแก้ปัญหานี้ได้โดยไม่ต้องสร้างผลเฉลยแบบ One-hot Encoding แต่ยังคงมีการคำนวนค่า Cross-entropy ได้เหมือนเดิม ซึ่งในการคอนฟิก Model ให้ใช้งาน Sparse Categorical Crossentropy Loss เรายังคงใช้ Activate Function เป็น Softmax ที่ Output Layer เช่นเดิม"
      ],
      "metadata": {
        "id": "fNfOt8E65g_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Example"
      ],
      "metadata": {
        "id": "t17fVsWy5ilV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "เราจะทดลอง Train Model แบบ Multi-Class Classification จากข้อมูลที่ Make ขึ้นมาด้วยฟังก์ชัน make_blobs ตามขั้นตอนต่อไปนี้"
      ],
      "metadata": {
        "id": "iLUSqwcq5nRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "สร้าง Dataset แบบ 20 Class โดยใช้ Function make_blobs ของ Sklearn"
      ],
      "metadata": {
        "id": "V0NQftj15mk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = make_blobs(n_samples=10000, centers=20, n_features=2, cluster_std=0.1, random_state=2)"
      ],
      "metadata": {
        "id": "3gRHuHvc5o1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "one hot encoder"
      ],
      "metadata": {
        "id": "8_0r5Jyheirg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y)\n",
        "\n",
        "y[:10]"
      ],
      "metadata": {
        "id": "yYxCCDdYelf_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd0c4dc3-4015-4621-cb64-c6eabe7584c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "แบ่งข้อมูลสำหรับ Train และ Test โดยการสุ่มในสัดส่วน 50:50"
      ],
      "metadata": {
        "id": "xfaEsOGg5qDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.5, shuffle= True)\n",
        "\n",
        "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
      ],
      "metadata": {
        "id": "skxyy-rx5rJV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "399137df-f5e9-4974-eeec-4697d627b413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5000, 2), (5000, 2), (5000, 20), (5000, 20))"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNZ4eMhggRVt",
        "outputId": "07e008a6-a146-4252-b580-aa635ef23a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "นำ Dataset ส่วนที่ Train มาแปลงเป็น DataFrame โดยเปลี่ยนชนิดข้อมูลใน Column \"class\" เป็น String เพื่อทำให้สามารถแสดงสีแบบไม่ต่อเนื่องได้ แล้วนำไป Plot"
      ],
      "metadata": {
        "id": "Kbz60iuJ5sKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train_pd = pd.DataFrame(x_train, columns=['x', 'y'])\n",
        "# y_train_pd = pd.DataFrame(y_train, columns=['class'], dtype='str')\n",
        "\n",
        "# df = pd.concat([x_train_pd, y_train_pd], axis=1)"
      ],
      "metadata": {
        "id": "1DIyIDoo5tZ1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "c436b1a5-92b6-4969-f857-3c37cfe6d8bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-b0767f291ee4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_train_pd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_train_pd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'str'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train_pd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_pd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 )\n\u001b[1;32m    721\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m                 mgr = ndarray_to_mgr(\n\u001b[0m\u001b[1;32m    723\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    347\u001b[0m     )\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (5000, 20), indices imply (5000, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "DT_WHG4Zd44q",
        "outputId": "4a4e1b7a-6edd-4184-ac5f-5e7708cd9caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             x         y class\n",
              "0    -0.507467 -6.049266    15\n",
              "1     5.917439  1.652530    18\n",
              "2    -5.637819 -2.970164    14\n",
              "3     6.904881 -0.143321     8\n",
              "4    -1.373689 -9.407934     0\n",
              "...        ...       ...   ...\n",
              "4995  2.592110  0.721797     5\n",
              "4996 -5.440291 -7.957742    13\n",
              "4997 -7.015918  3.915422    19\n",
              "4998  7.149018 -0.120999     8\n",
              "4999  0.094972 -2.203637    17\n",
              "\n",
              "[5000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0167667f-cc6c-4c78-9409-ee345989c7d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.507467</td>\n",
              "      <td>-6.049266</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.917439</td>\n",
              "      <td>1.652530</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-5.637819</td>\n",
              "      <td>-2.970164</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.904881</td>\n",
              "      <td>-0.143321</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.373689</td>\n",
              "      <td>-9.407934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>2.592110</td>\n",
              "      <td>0.721797</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>-5.440291</td>\n",
              "      <td>-7.957742</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>-7.015918</td>\n",
              "      <td>3.915422</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>7.149018</td>\n",
              "      <td>-0.120999</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>0.094972</td>\n",
              "      <td>-2.203637</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0167667f-cc6c-4c78-9409-ee345989c7d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0167667f-cc6c-4c78-9409-ee345989c7d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0167667f-cc6c-4c78-9409-ee345989c7d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPSRVv-4eE5r",
        "outputId": "263bbe1d-295c-479d-d74e-486e6ef1e084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(df, x=\"x\", y=\"y\", color=\"class\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "mo5Vn_jN5uOl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "c6428e55-4367-487f-86b5-3d1f5b31080f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"dd26d6a1-f85c-4266-8fdb-9c03e0366f6a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"dd26d6a1-f85c-4266-8fdb-9c03e0366f6a\")) {                    Plotly.newPlot(                        \"dd26d6a1-f85c-4266-8fdb-9c03e0366f6a\",                        [{\"hovertemplate\":\"class=15<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"15\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"15\",\"showlegend\":true,\"x\":[-0.5074673172786159,-0.5752001420892171,-0.7347701365771796,-0.6771773934092888,-0.5674356580693652,-0.5287772884136538,-0.5483285136826024,-0.49946994982500914,-0.614927897982205,-0.3443047627360319,-0.771263289229766,-0.41712409498917424,-0.7107414834589457,-0.5225132192693971,-0.5148903354502993,-0.6370250042104262,-0.5834801322714359,-0.6080323251006634,-0.6570373005384214,-0.7520569523852938,-0.7063291842890579,-0.8144987764053804,-0.664005504365549,-0.5313637106604796,-0.7554357086675761,-0.7920621605885863,-0.6387745022784678,-0.6321833771585627,-0.7925115544176198,-0.7120352611581524,-0.6465076706643107,-0.5552991686612193,-0.5746666227154933,-0.865414028638799,-0.5812206279932061,-0.6518191465642105,-0.7071906864136301,-0.7094153345534914,-0.6255169757728604,-0.6965989993197671,-0.5174057026570249,-0.7071429133071109,-0.5957840690683105,-0.500650181013306,-0.7411849142200118,-0.5842413912721139,-0.7056367342003969,-0.7797559430452,-0.7303687185193046,-0.5011166769810252,-0.41589535880978307,-0.7815584430371922,-0.8120578002974408,-0.6641747169682604,-0.724511175979672,-0.4432656939402607,-0.6152263318375444,-0.7973163780535376,-0.507264548927078,-0.3936148572818652,-0.5453304526404694,-0.7750208486449635,-0.6415310926847778,-0.7021307170189326,-0.5829806317432655,-0.7134851849990778,-0.5311174172284276,-0.5146178922659993,-0.5929773902513077,-0.5372164670994614,-0.8277542359879603,-0.6668232531535006,-0.605478383811221,-0.695894556995897,-0.6396894920841695,-0.6245963652532053,-0.7029768764703956,-0.7356343499202886,-0.6572316629594519,-0.6400072919863775,-0.7276652554655552,-0.6085519804570351,-0.5986915540154492,-0.4820553313469909,-0.4842215472917971,-0.5963662566423624,-0.68030474746896,-0.7004642647036271,-0.7484824491572567,-0.5947659337620741,-0.6243112072101745,-0.4950561967069186,-0.5354618205860862,-0.5519147457880114,-0.6148931139429111,-0.701397090634674,-0.5048469523014818,-0.751971109431081,-0.5121368155037105,-0.5994731306915189,-0.3651108153227286,-0.5236720665201875,-0.6942258146180899,-0.63887070920156,-0.8251022992080439,-0.6304946772970423,-0.6098666376769298,-0.5991677966273307,-0.649637501805329,-0.836394065290115,-0.6567023270882325,-0.698303013242249,-0.5892158547591385,-0.6726584282192185,-0.6945477549792431,-0.7385532558809187,-0.6279357404122022,-0.6451301884406264,-0.683199628375419,-0.6707702872637092,-0.980966930717412,-0.7550880433061885,-0.6341541930858234,-0.6676459750626337,-0.5922812111292154,-0.7500538306162712,-0.8005345209662309,-0.5305657796734562,-0.6131399864639546,-0.4662617380415156,-0.6769659364993901,-0.7227152731831364,-0.5463535447553036,-0.6316834663477549,-0.5983909869014444,-0.5521970313602304,-0.4787937712578638,-0.6254231426435899,-0.6224739251904623,-0.7725723549618381,-0.7270417747462848,-0.5065163799265037,-0.6262874194040225,-0.6567350114983855,-0.5193959459878202,-0.5266692928957984,-0.45931205357195815,-0.6250995293744325,-0.7180896435242446,-0.5270197049278326,-0.7115717177292598,-0.5317379644331003,-0.8473823482686906,-0.6070672085110014,-0.42554319690225173,-0.41596720453843233,-0.5541437117901651,-0.7065858487170134,-0.7082257723951887,-0.6399027166750237,-0.6541621115366177,-0.5849580053313072,-0.6612296170674969,-0.8748470010339648,-0.4881609358365975,-0.5693896822706302,-0.6437387519417256,-0.6849822170054433,-0.6971639722171428,-0.5973769269836524,-0.6301434333934064,-0.8382284990402755,-0.4040497070634078,-0.7251669135652197,-0.7254802839490041,-0.6978635756709813,-0.44699311627380467,-0.7782492135591602,-0.5589702549719591,-0.7317022110737387,-0.5279331697285039,-0.6381471633872252,-0.6068974668002945,-0.7877995894469763,-0.545627648296217,-0.747035371992919,-0.5937461657356327,-0.6920160888392012,-0.6848311028966252,-0.7599865464982439,-0.5832874841622073,-0.6557261306305306,-0.6777586991841099,-0.6764302008663697,-0.5800337400943874,-0.5670154408170667,-0.62852640260314,-0.6218908648490307,-0.6466339537390325,-0.539439740298844,-0.7080328710533108,-0.6084420553914544,-0.5374061522545158,-0.6908174259196666,-0.595134458836651,-0.5349167942420321,-0.726678153882402,-0.6444247833916046,-0.583299535299018,-0.6044211465961169,-0.6867623583334271,-0.6963742732028323,-0.6267776930298068,-0.6886049348960454,-0.640708256560347,-0.727186808617332,-0.7090564645165672,-0.654118567244819,-0.5945914973613896,-0.5831160358850596,-0.6285876985049268,-0.39387135079999297,-0.556944591010464,-0.8018727133627996,-0.6019232590400113,-0.575830516297407,-0.6805388781872357,-0.762603349927851,-0.5717554002630492,-0.850353325936142,-0.6312597963301783,-0.9213339122189541,-0.748990205535684,-0.8021747243392853,-0.6239885753743959,-0.5624005709354517,-0.6127623721280108,-0.6695524535184723,-0.716163044946232,-0.5974092952746052,-0.7605194908002778,-0.6417997000856356,-0.7264782365483156,-0.7578036486198734,-0.5727330142189121,-0.6196115195930192,-0.6884332596036457,-0.7224045524038245,-0.631306558709502,-0.6007755154405767,-0.4261711765310687,-0.5460773845716489,-0.7557967094637278,-0.5741416528638152,-0.5985799612420957,-0.7142273426717377,-0.5576538305279878,-0.37989514347030223,-0.6952829367140461],\"xaxis\":\"x\",\"y\":[-6.049265823833714,-5.981051755304205,-5.981161403742855,-6.110713215744734,-5.951079095751208,-5.948893918270601,-5.808823587803891,-5.886738749827315,-6.024123132078476,-6.03571550118929,-6.099130466351508,-5.978252237738048,-6.04466992972912,-6.012798419501256,-5.9232579871123585,-5.999015044280654,-5.834118110906472,-6.035029553552455,-6.084488201828492,-6.002914173444822,-6.053007064981761,-5.993649628592776,-6.179713489077064,-5.933414194279345,-5.856311853015245,-5.958501780897181,-6.066918759207387,-5.933624296371829,-5.952426987015853,-6.052574093706516,-5.970100133595337,-5.817939681868388,-6.04636601705159,-6.038734041908523,-6.110170327416622,-6.19834075423375,-5.921720070881944,-6.067441496965005,-5.871438798032914,-5.831731597297631,-6.068320642687945,-5.8330138883678435,-6.043488234941387,-5.981966421321766,-5.796275749240827,-5.991241568044081,-5.926523312380921,-6.0016953860067295,-5.958399410429233,-5.92407346008687,-5.883987511630469,-5.997214206749783,-5.848243692555414,-6.097717582865425,-5.9773031030095956,-6.004964710640542,-6.068597254890171,-5.8421090196406285,-6.084947624656438,-6.095279371552095,-5.815822952323048,-6.050923004911014,-5.9436276768919285,-5.979508557995079,-6.032931295575168,-5.995463622891494,-6.004504407439847,-5.874127003237426,-5.98881782282972,-6.025039976436448,-5.915525124675865,-5.882022671890879,-6.012518542797983,-5.748724111561524,-6.075962197401715,-6.067724655092516,-5.964171073022772,-6.04688057761124,-5.97688592930177,-5.967636122577487,-5.8093458571912935,-5.81006439747974,-5.865573790689299,-6.113698241360766,-6.037869156674599,-5.908006773542348,-5.826728920310124,-5.946410323568459,-5.928799935187834,-5.926884118193943,-5.873958095860502,-5.898882645228733,-5.9898287295794885,-5.77633533746701,-6.081302626415579,-5.948350416726819,-5.824561011801579,-5.908270612023571,-6.040030061539428,-6.0394560558520425,-6.060319626511253,-5.826537462650312,-5.823985266165541,-5.969257022215419,-6.111098242867296,-6.051862890668427,-6.139014253782884,-6.034485998570793,-5.818276419759507,-5.685884986216899,-5.891179697576387,-5.894735166419056,-5.8863152768685385,-6.199222587973426,-6.102254563311975,-5.917900744249841,-5.801465518927944,-5.839174029701817,-5.840356404944106,-6.1232873397117284,-6.024543817484385,-5.7385745992412565,-5.90129192216955,-6.037371209294647,-5.82889049393744,-6.077963979754016,-6.031425258757107,-5.990708109778485,-5.898976753418533,-5.78922673002218,-5.9978601283841,-5.993953838353739,-6.193434210706914,-6.030713922474125,-5.910545066334357,-5.919618189741457,-6.056603716269363,-5.967397511817707,-6.024714579688345,-6.041047786660853,-5.914190028071806,-5.976551401058311,-6.004338037080423,-5.971257468484959,-5.934775521391196,-6.084335581271962,-6.06763256842449,-5.940402808253877,-6.100960705992128,-6.021170071099991,-6.044270194758455,-6.098558527403022,-6.103690752251536,-5.692649378000806,-6.019411291917725,-5.911671854174687,-6.0100637342189005,-5.944425747266809,-5.723089129227628,-6.023145022958952,-5.818245821660903,-5.994320675435442,-5.952376160575523,-6.000587257077103,-5.97938099890102,-6.019578508308601,-6.09211995329839,-6.00859950615481,-6.086335312448523,-6.024954553321602,-5.83672312518933,-5.8459726430182855,-6.071991154700894,-5.977156250956845,-5.863790825773881,-5.947604071673157,-5.750447003788201,-5.872401174598352,-5.917501746908884,-5.948375744729575,-6.083537762691085,-5.951517945212404,-6.119979789975586,-5.925467320792894,-6.088661494270903,-6.07401263365119,-5.84199457363394,-5.903273562215736,-5.862062269428748,-6.058593955333431,-5.919250792271653,-6.062602027245421,-6.085011366135271,-5.928145146894062,-6.21639338603247,-6.062454282790448,-6.013584021925142,-5.969877036045766,-5.941473984372453,-6.008983399329027,-5.820797757065019,-5.969721221770725,-6.015382081673226,-6.061802990819535,-5.8950776632646065,-6.074251154834994,-6.042149792070622,-5.9352203731394715,-6.0002310040460864,-6.127443237949463,-6.074955917124023,-5.9236711883024,-6.062056883855048,-5.91317119631416,-6.162109404200185,-5.995289584442669,-5.930560465083336,-5.938913540443589,-5.926055869088572,-6.015141649193025,-5.84033714324877,-5.898385275910238,-5.960455228783141,-6.109992674196256,-5.807654811255009,-6.039413629484593,-5.932875435117231,-5.9923859833397914,-5.969355472178897,-6.06153892007571,-5.8459149033659275,-6.0458477346547586,-5.95228095801504,-5.8858523588788945,-6.051303291482909,-5.96304185037048,-6.053441471247353,-6.00620757023358,-5.912066421284376,-6.019742447103142,-5.994853937155216,-5.8087228295996,-5.9635766830357895,-5.969343671629602,-5.81375044434823,-5.914813296963175,-6.109821283853918,-5.913677803772413,-5.937674927276115,-6.007351707428165,-5.939768450024689,-6.102287976574505,-6.132498333965016,-5.898127653935916,-5.764356228383824,-5.869254191254146,-5.787446796311507,-5.812998885516993,-5.893590402447425],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=18<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"18\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"18\",\"showlegend\":true,\"x\":[5.917439172184606,5.736025987684721,5.920417427465437,5.958461984456417,5.787072499890616,5.902365353344095,5.805801162641559,6.003239651150919,5.7752066349102025,5.7914792944737075,5.9391321262426535,6.048958781200605,5.897818391178348,5.943258270368136,6.079440248560844,5.973126487280426,5.833302991207249,5.660639057199061,6.0375554464916465,5.7328537610862655,5.865770494157126,5.906409442590739,5.885366952095015,5.8918752135843855,5.808032090350832,5.8600552681982885,5.816956435199439,5.8928788638358105,5.73659113077802,5.912131008572599,5.764680457425146,5.759429655459177,5.961094603790334,5.981996360369095,5.777078892676153,5.948241495682998,5.921696695317803,5.817637934934864,5.802167091855478,5.958430617574973,5.775722369648349,5.822400396478036,5.900539625787876,5.741562502064571,6.062933477682289,5.823010307777405,5.857648364042273,5.794012730192224,5.8493829019805705,5.8684726653600965,5.919174946601317,5.9645968650053796,5.816406849427422,5.869689732385223,5.86807892632307,5.719584944825174,5.7816870519181,5.8554610704903,5.968719987647029,5.942304054043035,5.85471592346333,5.918746369940755,5.88876512072598,5.709508489063764,6.0111899248268905,5.910288518416203,5.896585148942884,5.918168052605457,5.793770851448171,5.888912034766882,5.992183984749029,5.961186609919768,5.841768194151597,5.81246962987986,5.898547798916278,5.909902206807542,5.803613868313325,5.692875381928988,5.857187713343486,5.81183657848555,5.774693643880606,5.787592500070092,5.8817575692601824,5.752211340321599,5.859447648858786,5.731260094759258,5.6203708802363055,5.802474332517112,5.825961867538851,5.729394086386906,5.723402705454871,5.830560654751829,5.827462430272477,5.846163606695276,5.7336192550548635,6.001252978467557,5.757158792025271,5.966041844730875,5.762808847407561,5.884565728107659,5.972600442611642,5.896489439355388,5.858137408070069,5.708587170339628,5.9204035153708325,5.65540916849516,5.8906660081514,6.0664180180114045,6.036207751555819,5.780514559381393,5.866339444268142,5.944837749530339,5.7219438569801,5.901679489336852,5.956516537126266,5.973777162893999,5.8711457423894515,5.881958324278894,5.826044942507186,6.0863425715912465,5.9937395633896475,5.840310836640656,5.956994040425413,5.897485921378679,5.755826448850363,5.836788368860392,6.019168019920132,5.808275152817568,5.8990914747672125,5.881899214848619,5.824123640963893,5.877165044772304,5.984325325772912,5.823248073100917,5.978431615738122,5.878424998513067,5.830224453326096,5.883224271956076,5.64542626371283,5.833897548587925,5.868396343836851,5.9921185818747515,5.930274968849163,5.882331576372195,5.842326193088184,5.88437350402239,5.750680244442712,5.858629200545013,5.799328568225309,5.967848548337194,5.970547314246794,6.002567535936435,5.735939159505557,5.741550134922691,5.787619384618099,5.735709767682296,5.678974721804852,5.884575430552948,5.869521790284205,5.850926291117673,5.9558932609682875,5.881540996513715,5.90552797730378,5.896618193650427,5.9629461683534135,5.644386876899047,5.9245164717149175,5.767355101628086,5.617155070828266,5.805455062993717,5.719670332098963,6.077278529862091,5.915315389476183,5.940466393349709,5.716296743391517,5.863889357035291,5.7066105679148444,6.099538064351947,6.000607194044132,5.858035144218136,5.8957399845975615,5.702215348989859,5.919742182375753,5.930218219851964,5.903798183367291,6.000740573187095,5.908966394093986,5.851168623822016,5.966845830185095,5.9742906611606506,5.966922129401894,5.677656509452125,6.014559749430676,5.763969997846742,5.8061889694093844,5.667161508553631,5.807788388568703,5.776784880680406,5.819984797188357,5.973315911861684,5.925082856503446,5.923035095729423,5.813659526262276,5.93786701116996,5.92159674677208,5.788597520828815,5.861779732586549,5.8279536948910495,5.788669993677889,5.848916175827614,5.810933604057575,5.9081950669615075,6.076473798547239,6.000764029507606,5.823934577121028,5.865718508840058,5.89303188131117,5.947923438114372,5.897915806974586,6.0069490044288845,6.068589379542028,5.66035607797875,5.864642629915887,5.964128500548634,5.768561654071948,5.852471499603453,5.785355900338081,6.002424534864131,5.86982895365825,5.809068882871619,5.835906761943141,5.802365810178945,5.666196705326001,6.000760117700402,5.932266314587748,5.85633220801635,6.0209991228749535,5.997929630222991,5.858490797139783,5.81061491723804,5.8565881661194705,5.614950582830106,5.908691605600036,5.885882465571861,5.820629705554678,5.845421723504753,5.789167008752518,5.958772792112174,5.82021319902305,5.894970460206751,6.134946906402681,5.878497061720997,5.7807894679768355,5.757869061575918,5.767381091982727,5.9735676013713315,5.859057022865955,5.8693317465267505,5.737712965449981,5.859540524605035,5.949527903292237],\"xaxis\":\"x\",\"y\":[1.6525300108792997,1.6059075609697002,1.6856398111102018,1.5689565140464548,1.7236216145974772,1.633186031364567,1.512628425475937,1.5612034327180977,1.6380812142835008,1.504912942548282,1.4297321318113663,1.4224853951192657,1.5063099001132363,1.7615948282095784,1.5330249704639465,1.4890220444397217,1.592617354357913,1.6484682146449463,1.5998540648035868,1.6771488516318174,1.7327363308041959,1.6473217572475671,1.6401985871846043,1.5380857243917363,1.3038809583146989,1.7064969435939787,1.5967865003480928,1.6099939253408815,1.4628014944085335,1.7830134022248094,1.560747618465649,1.3962045401399854,1.4401464754654782,1.5652609911383293,1.6670304161076233,1.8141215549915177,1.655459798555623,1.4955651676289814,1.6481003235022487,1.5457897545093728,1.7580871320841975,1.5616792522625291,1.5853148435428142,1.573970418290915,1.5515038455793664,1.659481400710086,1.5363303890617177,1.6529748782750344,1.5098288256135444,1.6461800481600484,1.5247158597576498,1.5842670404765404,1.6635662951966979,1.6448113020922357,1.7269119893313913,1.6857992239703077,1.69565927836827,1.6737879849277593,1.6656470792969882,1.6455236644897966,1.6268689634543605,1.8019681991349128,1.6068339463085646,1.5460028598216913,1.5661836877685498,1.5175296300873449,1.635360257699381,1.4874856473006095,1.6882141321375437,1.5045779847475942,1.5174419300538795,1.6757946254361396,1.7542333945552342,1.5297816030165754,1.6319705724493607,1.5881990132815667,1.6527476767268807,1.5272414670194956,1.4091906997259431,1.620282547273916,1.7045691149010473,1.4741713817631825,1.4929871927592613,1.9913411969317738,1.6717895943725332,1.540462450459991,1.4388144468030026,1.7697023958143994,1.512889869334694,1.668219142006846,1.523248396429497,1.508858093576725,1.731840573235758,1.6142660492360643,1.5444754705757595,1.426603101797836,1.7155508798071364,1.5952381179747206,1.7401515553476932,1.4796802389811856,1.3535994724265503,1.741041258409979,1.7500578802769982,1.5873786968281889,1.6037136183943996,1.6520862663012588,1.695018739676264,1.6348849048721057,1.5117901398945823,1.501243416182334,1.662583994096644,1.7744311504442365,1.6372851712024348,1.5762824699723492,1.5664167275919485,1.62306525926887,1.685939494966659,1.6531344826137724,1.595914112606521,1.497674326984288,1.5611521879319274,1.586393398705909,1.4174094346223012,1.575319623971356,1.4253432077845285,1.4588522776659532,1.639283840542974,1.6816513346054462,1.621206256049828,1.5110397550349401,1.6893503172042361,1.5385208250152818,1.703273010865941,1.5560478696833715,1.5395127005137743,1.7569195575053582,1.7013891666071996,1.7321864044306936,1.6271179844280506,1.588192754549022,1.6781091232010232,1.6482877526396917,1.74537042107557,1.6192984454571024,1.6917250112745266,1.582714724680051,1.6252576769820226,1.5115890868771413,1.7195860493213995,1.659282192646305,1.6439184532949078,1.5684529569857681,1.6629010160900797,1.4925245651180505,1.530768471887645,1.503221339190151,1.6502606640463466,1.5291867928943035,1.632415689110494,1.5924817847743078,1.5914172133308775,1.876195236471265,1.5867431567575634,1.4921857445207505,1.7667880722876959,1.716286474492667,1.5533914956071624,1.6053235514721538,1.5824486968495577,1.566139256522505,1.6848283566445732,1.4846251836737014,1.5793862330255808,1.7423984818808793,1.4820156330807805,1.4213004106149951,1.6669052448196273,1.5652873604623398,1.608853028613622,1.3786146956274932,1.6679349168990913,1.6121711767831153,1.7154175903722542,1.5907036882024512,1.4723667438509354,1.5031735447822705,1.6163335401585657,1.6629279528428675,1.4623247010306297,1.4109112566689308,1.5724480261454983,1.414088923986422,1.617373867858364,1.558062386960553,1.4427672969430552,1.5128092025909927,1.6565809366922295,1.6681951894932916,1.422000223899934,1.5807683609266936,1.766226659203493,1.5822752483676248,1.7857117578824653,1.6340256136017102,1.5876244392260386,1.6874084081657097,1.4670484286488923,1.581070393584684,1.5022785813185338,1.5155337561670608,1.7041415621357006,1.5145308983395,1.6552877180655412,1.3960706900314968,1.5463136874846706,1.5797284485274552,1.4042549309192995,1.9151890671349312,1.591033602180814,1.6437766622319234,1.650601208774683,1.7612638113773076,1.5846537912624543,1.6416668048202019,1.4863393882279428,1.633842132767754,1.4251064061615262,1.49682420963182,1.6690073733015751,1.5885984267639521,1.5688949637146516,1.6966096230314351,1.523211766379092,1.5601307857412419,1.7311509864534305,1.3905453569357975,1.6848975511580757,1.675396304263407,1.5388750154536293,1.5570096613392326,1.468249244506455,1.6372935847718655,1.6832083970967047,1.7099849717246376,1.4920044186998034,1.5971883476241922,1.4492641604381251,1.5400697335264077,1.5034165807366409,1.5140226090124462,1.5375376303038075,1.6797176373125167,1.6444186614087346,1.7200095235092945,1.6653048651059987,1.7723472745300648,1.49832738823159,1.6766998615892235,1.5899313450823405,1.608198873828271,1.6943256862312273],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=14<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"14\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"14\",\"showlegend\":true,\"x\":[-5.637818908872534,-5.4266020656016085,-5.750508995271026,-5.6674605471679635,-5.513647469946318,-5.563485214826058,-5.545936508541736,-5.649834025852166,-5.669769116237543,-5.494956563949767,-5.687298977485475,-5.426662694752731,-5.488792822508125,-5.7141631529348285,-5.7067299535461125,-5.639467035696846,-5.544559637768627,-5.756891859414746,-5.647098483057992,-5.660405187861322,-5.545029660098047,-5.741503582002463,-5.588612532915215,-5.504072912389065,-5.458082940247644,-5.585071190722025,-5.65407882258258,-5.271427652241438,-5.6560468090601494,-5.640736231981945,-5.680335853889782,-5.7195688703571985,-5.3795251174147936,-5.583051917194698,-5.528280307211169,-5.485728407818484,-5.6721262431917285,-5.56528978133338,-5.877107898214733,-5.364231051029141,-5.636387033597273,-5.685737436381499,-5.610838140997669,-5.723264365855777,-5.739428400410212,-5.516390714290665,-5.616079219837897,-5.459112233600728,-5.411054889771618,-5.6409090756300015,-5.773600501607648,-5.41107579879751,-5.617680495202136,-5.781287684537081,-5.403254643586244,-5.552254659418571,-5.609022233457999,-5.666005617185707,-5.646118594405592,-5.63797344571856,-5.64741791608461,-5.76000026195607,-5.527233881493194,-5.570066018843462,-5.42410259675517,-5.614928572153614,-5.639798691593652,-5.507755373442691,-5.595191048318095,-5.404811724701979,-5.47678477601482,-5.688460284891845,-5.478090018509685,-5.626056528624159,-5.545773135284786,-5.566223577620442,-5.4400594790986565,-5.4800402761972835,-5.545711049457901,-5.513686680293588,-5.586642294826333,-5.479167931100363,-5.535551356006189,-5.6183429409018,-5.666832674906062,-5.601853988245883,-5.7323127143024175,-5.591018613568155,-5.528536761485131,-5.56922994741039,-5.567627750460619,-5.656293214881446,-5.691493265597165,-5.651112957963551,-5.605482234191573,-5.695872760382467,-5.488944872654359,-5.586695213397505,-5.7669745724653385,-5.438146835418527,-5.5122118500743476,-5.483335113709807,-5.578314367896575,-5.589373510426321,-5.750032182499729,-5.600728774160103,-5.637504627051954,-5.407687983060275,-5.7428596921606685,-5.492689001965332,-5.570632518438531,-5.587738784069805,-5.539263926433246,-5.515832879827862,-5.543651824822516,-5.522875027099156,-5.637706247118998,-5.556741573575767,-5.6233083963366495,-5.75936555780067,-5.543392448092409,-5.557186405059701,-5.438591331284037,-5.709562115100942,-5.408122095325663,-5.558446807676091,-5.496357326980538,-5.554291459492577,-5.516317975003247,-5.824440900435942,-5.806631516872729,-5.503094792551276,-5.579640913628894,-5.608988758722603,-5.513071784739394,-5.555253808444557,-5.597001151708369,-5.468860346567338,-5.506207885582327,-5.568292882351679,-5.663456890811459,-5.5793988362491955,-5.4566760519407795,-5.615916847660806,-5.4341367344909655,-5.549976815206751,-5.6492913018888045,-5.694053335174316,-5.625179838617798,-5.816637256425119,-5.6821561804341885,-5.637510480998217,-5.724953095398124,-5.579676779737824,-5.678099977909106,-5.659240734267561,-5.669108778305753,-5.820919561054883,-5.55794453143664,-5.547969214418098,-5.577535045909256,-5.665828970911186,-5.714126886385771,-5.820477501329401,-5.439586895509492,-5.5148493989779785,-5.583903897977694,-5.4812151904851465,-5.630762387988526,-5.805950998100388,-5.564809956398579,-5.601361395442914,-5.360195042377407,-5.623628374732974,-5.716441684110676,-5.711653953741276,-5.518296870196815,-5.63930618688391,-5.580328904724162,-5.687836426541813,-5.5088493495243025,-5.522005880471738,-5.712988917141085,-5.512914802468024,-5.5181132219003795,-5.502441067391367,-5.58539821325171,-5.688609434370219,-5.84100496727162,-5.584533889132836,-5.5583925259891185,-5.679439408818084,-5.645487711725325,-5.685487131767173,-5.728733985196401,-5.475614972001493,-5.542448594443844,-5.684367441805249,-5.821341744926185,-5.571011679084249,-5.581506481299951,-5.570105531551796,-5.5806592983580146,-5.7882115558861855,-5.473726508171378,-5.630351986141572,-5.625219158101536,-5.573091084428661,-5.64815258616501,-5.608883800513497,-5.6890046523349,-5.55947415069789,-5.6091731216287455,-5.620112733986948,-5.675217911915273,-5.620627535751755,-5.719883400739531,-5.707049082804069,-5.623872829657222,-5.634471850458826,-5.67738641031227,-5.565806218488604,-5.475926938342545,-5.615669599659963,-5.586680104335194,-5.415854362956647,-5.587295151118446,-5.590872357479385,-5.472181464455487,-5.579722596345571,-5.74053258877088,-5.684407276332944,-5.64014081766636,-5.662475776466186,-5.594986209343997,-5.627154923805532,-5.67646276853403,-5.633929984702645,-5.434209186702557,-5.686278129995273,-5.491417298276923,-5.574865499920859,-5.6784735471069725],\"xaxis\":\"x\",\"y\":[-2.9701635495550045,-3.0093779368645786,-2.9758287414561795,-2.961060287299776,-2.816369454434353,-2.905332202927845,-2.7859301676160473,-3.138205081950882,-3.1120724295033697,-3.0413638504119627,-2.82862814989449,-2.972512408471511,-3.0401598405734367,-3.1793282452103986,-2.994890292978536,-3.033807248618699,-2.811381788156789,-3.0773995912320173,-2.9510036029054136,-2.9687655882508817,-3.0687590880972384,-2.9299395616423,-3.133803629707206,-3.0926676396768715,-2.88168194393558,-3.0037343468487565,-3.0167897467264484,-2.948425121862542,-2.9696231017414276,-3.136494730763189,-2.9779369772788793,-3.046876480382401,-3.0077585114410175,-3.0308774592217262,-2.9440362522384045,-2.9297768087215323,-2.9058495640977076,-2.8446741778101616,-2.9941935180384625,-2.9994011603375275,-2.972581014989863,-3.2422905987996673,-3.0748599823761835,-3.0611126757887397,-2.9492984775874107,-2.91399994256773,-2.9220879869261025,-2.9181265907149267,-2.951454744570469,-3.105164378403842,-3.041877799470891,-2.9357860624233054,-2.8970747653703546,-2.942257335917066,-2.994498502368685,-3.031369128731031,-3.159395877298233,-3.0077372232715494,-3.127976014324997,-2.940484141857579,-3.0725396653217696,-2.968816020477033,-3.0610041240621464,-3.016752464124437,-3.0035510485779247,-2.9647809995707357,-3.000286116841278,-2.9977311599268037,-3.1042783733110446,-2.9566940637946746,-2.9659027760301457,-3.169307822183311,-3.0410095970604587,-2.8875934497515328,-3.055222962601116,-2.9609646579315467,-3.2336419144355038,-3.0961933646723985,-2.8548138271251644,-3.0640718824629314,-2.932351056891552,-3.016645115092899,-3.0280142037272455,-2.983792118515519,-3.0352920723620316,-2.9230223757911142,-2.87317989415204,-2.8621728544625338,-3.0166298791592974,-2.9455825564180707,-2.8924697068631615,-2.993358202152441,-3.034528332732642,-3.0023103406273086,-2.9370210620465493,-3.228211047843469,-3.106717314233593,-2.968944593670025,-3.168719707409577,-3.0737151390391366,-3.0897506874378577,-3.0317993646332875,-2.8722310698962286,-3.018929779273411,-3.091171485728613,-3.0662130188138503,-3.0264605043602755,-3.0651272788151314,-2.9022887486825937,-3.153815576363623,-3.131329855305579,-2.9235902404161624,-2.92650441877707,-3.0747336183371266,-3.0441620175903674,-3.113266972087363,-3.023955921672433,-2.951223590701502,-3.0149484172826537,-2.920339202533434,-3.0411279379978158,-3.1154794423569467,-3.155932886187746,-3.033256783319302,-3.132779029988811,-3.0908623208241015,-2.946830361851778,-2.855653527993076,-2.9149674933482057,-3.0081945193815947,-2.8738216855681005,-2.951543538570638,-2.9179378037832993,-3.2713606351563262,-3.0285905313387227,-2.87885645354541,-3.073412898214967,-2.871898320522408,-2.934360968253138,-2.889230622804207,-3.009865808743875,-3.0552517150979632,-2.901488937702012,-2.9432176322566033,-3.0555200639029088,-3.0048624667426904,-3.0669620333172625,-3.077504191757889,-2.9079162577818924,-2.9649073168506948,-3.088370067253339,-3.1396095729506217,-3.065842421363694,-2.971751409529246,-3.102598382079552,-2.828604973962081,-3.3139709500208783,-3.0166067863531825,-3.044035088050905,-3.011498162579918,-2.9748085478586512,-2.8934042044519575,-3.0186704873851262,-2.8732356283482647,-3.124899114401582,-3.099252160002991,-3.08470252562209,-3.1120473006088876,-3.08595005118515,-3.142284001676314,-3.121821732652821,-3.011375498713324,-2.912804265313928,-2.9391861590620536,-2.865735439255022,-2.9419314953997575,-3.091691923346766,-3.04653946034041,-3.0123332914775283,-3.057630844699088,-3.0506594047464137,-3.0883942411525402,-2.9699854866704833,-3.0132838173616125,-3.022982358102659,-2.8216454908240323,-2.9798600128308057,-2.981367949156354,-3.025858064299744,-3.010050919791971,-3.0056553947358964,-3.1543710365620954,-2.9367046208927,-3.023591461614662,-3.0118701509230292,-3.0695740377909844,-3.065112596926645,-2.9129329987902834,-2.933047794472214,-3.0271142607877373,-3.0828703211144535,-3.169492786433729,-2.985033073158505,-3.139506515502129,-2.9246979760276686,-2.9668780978235882,-2.830606276885823,-2.929223812828298,-2.987314885420449,-2.99275676984084,-2.9005774565988953,-3.0330712523176024,-3.1574371121560016,-2.873878791222001,-2.9251261610833206,-2.9267483156295775,-2.938787618945149,-3.1485414946844412,-2.958631999477415,-2.922416960480955,-2.940422368631172,-2.974341800114254,-3.026771501290266,-2.976581881341064,-2.8609831576753844,-2.9321654079895576,-3.245596321253189,-3.090502086129016,-2.967107934355657,-2.9984093067251765,-2.983090465917984,-2.9715537323392063,-3.0622692800847604,-2.983885226142176,-2.9803064124099796,-2.978964643994836,-3.070370695514246,-2.8463174585938242,-2.961244389138672,-3.0818561398615243,-2.9042503131039576,-3.0512200322930596,-3.013644416932109],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=8<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"8\",\"marker\":{\"color\":\"#ab63fa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"8\",\"showlegend\":true,\"x\":[6.90488092102235,7.014349617170877,6.897962213686846,6.955286790140684,6.88304640382028,7.066557344864514,7.0045409148507,6.967727843289599,7.0712032562375,7.088711502692321,6.986519011999285,7.063175801710737,7.256446075007488,7.033268869737363,7.224066404924305,7.1101392231022125,7.135736997761784,7.096678021669256,7.202318419712239,7.086277113856263,7.103928141188934,7.140774153849344,7.0706456406976885,7.105522046296431,7.1478241184981925,6.961184372318544,7.128280803640942,6.985903302504807,7.250405167867808,6.981812316450378,7.038838525839667,6.98229793311491,7.038194384901116,7.022160767357146,7.041977476951017,7.150130355644601,6.983147133791664,6.934399452642307,7.146464432588802,7.099791807383269,7.156078882420356,6.961277105602114,7.075652233529757,7.061702131846408,7.011346856141927,7.133653674720528,7.096640680077386,7.135274021219748,7.121829526174405,7.05207218060097,7.168671756274865,7.046690681752982,7.0404156747409194,7.061127251209057,7.0470074246859475,7.1005138869503055,7.181872832337163,7.211159980776533,7.10048417635483,7.078244585013121,6.930955053426409,7.041845067316079,7.144861199814915,7.198628914118476,7.152046018721835,7.231026268501022,7.057242454972225,7.064113517619653,6.992204890249133,6.942622631702722,7.120382635248626,6.9622755137329495,7.16690927553891,7.091837019389272,7.326999027306341,7.186339026690704,6.95907861866445,6.966062898800184,6.9756424174152185,7.113887347504677,6.7411028964938104,7.08248516944298,7.030855109594177,7.112964321597935,6.8298131889470195,7.0040872606983715,7.078413718607701,7.260096441260118,7.099157640687024,7.2113641569575915,7.050192567072208,7.062194125318692,7.047328304022352,7.219466235986544,7.17780509117247,6.940178663199336,7.035965698468165,7.058276516543648,7.128271429019072,6.936503458405287,7.116823548999299,6.996122074861325,7.039078379769771,7.078637805828201,7.080681702788958,7.17344100190481,7.1648220118656525,7.164725473586403,7.095336159230976,6.959748855990903,7.175534937501605,7.249449801101716,7.168308821165059,7.145368792068047,7.122878732302157,7.21572901330046,7.150264410102067,7.09877311500669,7.172872357764881,7.019000475369721,7.201788410319582,6.899846031644606,7.1350724424119205,7.093390038510755,7.235756253166529,7.179238965050986,7.130748931060113,6.765598834579632,6.985699601718781,7.2163344717440205,7.080220086592436,7.125700089601945,6.9861869610741,6.988203600239247,7.065965871650563,7.155482884214165,6.884722909131607,7.151641857541867,7.095839247721334,7.0356818001954196,7.12831910888879,7.188957962927795,6.943267890179487,7.125917605196237,7.119749908218461,7.010033421735181,7.12763008217695,7.125052662645058,7.143145233522787,7.086839551199441,7.139782482131634,7.114979884766175,7.0669129061224165,7.131993739254484,7.037358174005744,6.895030709317564,7.047183650016204,7.216176911477103,7.215507433012539,6.960962643500811,6.790834078689168,6.977447687499046,7.240133965565428,7.046624680063026,7.065915038798534,6.894160411689699,7.049063471981625,7.119368258951918,7.20750566883568,7.003606068250489,7.094579065856568,7.0599479911218435,7.000078254285818,7.106335341133201,7.111434593343599,6.9450739243064765,7.091642743487833,7.03471078023316,7.218330313693374,7.072721838077095,7.156399442197409,7.1692942782761655,7.184937953767958,7.160210491553593,7.1443953854411255,7.0259587673875785,7.068385796870452,7.096470449681062,6.862439825961519,7.128963202222499,7.0955094485666645,7.107107648202898,7.046457673178242,6.838215222337582,6.969670822995699,7.137121961734147,7.086489544167781,7.200537247083808,7.2600705804583034,6.967194315440285,7.142343103921811,7.158031500743689,7.008326911825633,7.201434456053409,7.097272110757952,7.09550778544917,7.008906203489799,7.1466212823292725,7.023927351516211,7.119276344113894,7.2160213666114625,7.007486659575822,6.899575690977281,7.11507710214757,6.9462966042762115,7.0655378748106346,6.937163557967595,6.995358821541852,7.0906382207999235,7.112096802893785,7.008126605631992,7.123376343181674,7.147774679868743,7.062343634430561,7.137108870507356,6.996570012754026,7.12806704740848,7.017899119990481,7.193073264099872,7.028190758027389,7.122334896212551,6.957958741372939,6.920192032904632,7.002836706065511,7.159601940900327,7.066370656419143,7.052493103103329,6.900299433069136,7.016289686736562,7.061063495328393,7.270507600772714,7.066400270966744,7.088143972059487,7.047345855539428,7.047954821376192,7.100973487423084,7.034229350141978,7.1022147410688214,7.197899700105472,7.264178421273243,7.04733297109959,6.781917760245774,7.053889566293417,7.061036794250335,7.083054183350257,7.108683775869497,7.149018474242231],\"xaxis\":\"x\",\"y\":[-0.14332091550390508,-0.023671078423999625,-0.02392310720143033,-0.04678391563982483,-0.11583641959600109,-0.1228102346205649,-0.1735723922655734,-0.15855750696298404,-0.1452274875943522,-0.21713970690398704,-0.1792594321904066,-0.17658801254448206,-0.08001330927943792,0.0337772296427592,-0.051126532782877834,-0.20728726747681325,-0.17564989931241695,-0.11505944516519057,-0.10794291825819347,-0.15702864975876313,-0.21121653028990608,-0.07620299480904551,-0.1164706866521273,-0.014290249267731814,-0.22704407349188574,-0.17196772886111492,-0.22328937913801855,-0.18427811775764646,-0.0654871040311453,-0.1298720149936134,-0.16476760912533078,-0.23528948312454107,-0.24471189492341425,-0.20412509320798217,-0.09303707476754691,-0.03552079577613715,-0.19752971138428366,-0.20239914663565234,-0.12626628653189167,-0.07150252457732473,-0.07716543806154007,-0.26007421691143684,-0.10874999259836313,0.07941392667188837,-0.2568330343577663,-0.17793046341471114,-0.05111393520913028,-0.10710739953244158,-0.018829926900527358,-0.048689014497528535,-0.165171158874467,-0.21967553229373754,0.034022184299454306,-0.008969901280062267,-0.17201026635139477,-0.18752186001601628,-0.10211794038945743,-0.03823875690728551,-0.1949004500866249,-0.18148668976762317,-0.28700908942065423,-0.02186974142470649,-0.17830100697699425,-0.13605342123464137,-0.07320370215380888,-0.10974760890022205,-0.025778801183040254,-0.1698848548313949,-0.3139422503676661,-0.14623095395147034,0.0009247880847289836,-0.11447166915901257,0.030808279955528123,-0.10211927904283492,-0.20526977322772483,0.022582713924415687,-0.13260183756800112,-0.0019540201529549828,-0.38490527974768146,-0.11102189501058404,-0.3123776952166645,-0.13154260822046213,-0.038814315237986105,-0.10516965509200155,-0.11763064896824571,-0.06500943810825198,-0.05362715922842552,-0.06863961558502839,0.007463295706992695,-0.08434982150575929,-0.07633056886409381,-0.13289314374880995,-0.2646992410953746,-0.05379673723488867,-0.146147935638346,-0.1509605537370131,-0.23871194692289122,-0.2541107379967168,-0.1384256386718942,-0.1317763862189631,-0.2234108376209069,-0.17984209311413696,-0.022086814369607355,-0.077733960341269,-0.1773907784714323,-0.2635525055648781,-0.1803661416951784,-0.057804806008434906,-0.11968678200571271,-0.06754121683311651,-0.0847810180335744,0.10386947990855466,-0.07234580569561204,-0.19099055987675273,-0.050577664072768994,-0.13669016011185423,-0.2577975195418153,-0.2871236945453369,-0.0508820750247206,-0.08783571154820867,-0.028012645659737448,0.03456792810612297,-0.03812692201299772,-0.22895480249275352,0.022841638688297833,-0.1517296332228631,-0.03706642600145239,-0.1931739718480401,-0.08054356150012651,0.09043208673998837,-0.3087938855863446,-0.11134117951855946,-0.12042653429844025,-0.10123324647433667,-0.21292453451188312,-0.11044730829382482,0.11026796036328293,-0.028324660643669064,0.04124388843368523,-0.08965281886066274,0.055022081069856926,-0.17087908095116713,-0.2508146731738392,-0.05416817502548279,-0.33857990374469576,-0.03281819916557624,-0.02956641375883423,-0.11633679460267074,-0.12028965796698451,-0.12137143247318573,0.13101348515272077,-0.10696157460655413,-0.3145876579371525,-0.1499851186808735,-0.13421747808335321,-0.023003544798246553,-0.3328500973229944,0.002304099833511819,-0.15484840416098017,-0.1618578630344128,-0.1259343331352003,-0.1479410714823723,-0.039576745010382164,-0.07072903800476445,-0.029775546903772723,-0.18054524464378857,0.06287910569980348,-0.15413415044968104,-0.03087211073928882,-0.18292713814307743,-0.07832892026292154,-0.12228073263930975,-0.2413111214176162,-0.1740923767176393,-0.06696558991837898,-0.12381551998502811,-0.11986412692181968,-0.24280473342153874,-0.19179131080804715,0.0013278169652284622,0.021832392815183593,0.16510187504806745,-0.21661396399594285,0.009372130016494576,-0.07986213422399274,-0.02947157980550605,-0.1243302399518714,-0.1621938841526781,-0.2688443543133575,-0.07523034794934165,0.026934204226395447,-0.14986574162372807,-0.01851856317135893,-0.09478682224558854,-0.1932099045616747,-0.015319315607821238,0.01845936224834585,-0.252144553687373,-0.06149299204746613,-0.059459941601491456,-0.25915003427867345,-0.04397694583245994,-0.1321991920968916,-0.15526868112451453,0.06296386970575205,-0.2160369165600477,-0.02630176918063376,-0.15373718166313022,-0.05998914051130594,-0.032190459369507485,-0.23454090410853878,-0.26040566470728754,-0.14503251461372094,-0.14935805649795658,-0.062049111479360715,-0.09427039913862496,-0.03575933971565588,-0.03729008605173138,0.0692467032289423,-0.09253537820371546,-0.08570617225318276,-0.0522215335081055,-0.12320328715404943,-0.07510695741338563,0.06337629072224885,-0.19319510503505283,-0.13110241569967987,-0.05712311491725938,-0.004635401253479693,-0.15741758216171184,0.16733701853073762,-0.06879239548848254,-0.19441236824739183,0.04252578302555848,-0.05077732305680137,-0.049805415073096215,-0.08220121819993906,-0.18962258378625574,-0.11076607512754211,-0.05526194207974136,-0.08737373718621431,-0.12893224217887755,-0.13080889310110097,-0.05383199344047546,-0.10374766002539482,-0.2223312977516806,-0.12253587809980337,-0.13659994039396542,0.0004883156954541418,-0.11146929780752346,-0.2027989974079115,-0.05258431953618542,-0.16605726931265494,-0.02419857350628997,-0.26649679512254687,-0.09113606476214162,-0.12099894543457451],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=0<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#FFA15A\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"0\",\"showlegend\":true,\"x\":[-1.3736888485926233,-1.3494245169608265,-1.2232293978013145,-1.3331158979864892,-1.1465453403258525,-1.3077199063849987,-1.4835470801382216,-1.4135378150709375,-1.2840589811292853,-1.202026521557657,-1.5320598867968127,-1.3294004828450445,-1.3454561015633795,-1.2620952886664034,-1.2961282130432232,-1.247395253358051,-1.1981134455064866,-1.3372401179482492,-1.2167308762589206,-1.2224109853793066,-1.1755541583960742,-1.2976350350357808,-1.0197319903746895,-1.359720096643314,-1.4056446789945107,-1.205342062981998,-1.393415284527623,-1.1603839736164132,-1.4302059661406783,-1.2367523241522678,-1.274128861829781,-1.3398676830225684,-1.1179926593926142,-1.3499609521535636,-1.2369030590673304,-1.183991525898167,-1.03138349962676,-1.2276723141588899,-1.331895389575282,-1.4721767298699593,-1.276590933397416,-1.1528774945843607,-1.381568225467102,-1.2955429533957363,-1.1981812737889488,-1.2424473660565207,-1.249266331000607,-1.3067040635747038,-1.1752630913187125,-1.1262283577672045,-1.3009723200711762,-1.2410723121788485,-1.1712161105657841,-1.2875022546473334,-1.3450224731161131,-1.2845070999345567,-1.2990063623065,-1.3899758518595304,-1.3182536053364333,-1.2406066351219596,-1.0474628670478066,-1.2734893154764746,-1.3822434302121314,-1.2523297754692644,-1.280322601700891,-1.3723463200268398,-1.1512250164737372,-1.1931421374054303,-1.5306477703673642,-1.3815482635119412,-1.2046858598857222,-1.3088723281226975,-1.3147960103393546,-1.3064407648649736,-1.2441886239805444,-1.499398627430672,-1.320204646604202,-1.1611491434694914,-1.3478695148927289,-1.2374002114043772,-1.2295654675786118,-1.1639498080858475,-1.1962306586091185,-1.1976316566162266,-1.2417815108139183,-1.2206710414558268,-1.2835704937600463,-1.3260154499933277,-1.2343831050781047,-1.2386915823664901,-1.386808669538257,-1.4254383921256037,-1.364968557269991,-1.3111002746476865,-1.2983517194874927,-1.0420535111167837,-1.2862654656221297,-1.1980455239368422,-1.4134423559393767,-1.3889181140400515,-1.2620609764687702,-1.2306983700663991,-1.2715655138176598,-1.3887567724483256,-1.4118586841353284,-1.332367466162346,-1.1800653685048552,-1.2282094647436865,-1.2603269657920129,-1.2435966055158407,-1.2991944136254543,-1.2190875485192592,-1.2497785138690516,-1.3116712781902022,-1.2287768127289915,-1.2977875460381754,-1.103272213985409,-1.302234051433054,-1.4178777503095343,-1.4330410927095465,-1.313899172096368,-1.2509785561598603,-1.3058144540823566,-1.2479683775819166,-1.4275647528065678,-1.16682734956659,-1.4841342620327964,-1.2915440868629369,-1.4474655557055103,-1.2596811592685135,-1.285388431099967,-1.1963403777633226,-1.344143848122617,-1.3016443722738058,-1.2049054722384367,-1.2808620710012544,-1.2088958344173395,-1.316563457439768,-1.3220336053751938,-1.2866429251938323,-1.341311432176706,-1.3951237242737118,-1.2946983982539335,-1.2883264946632378,-1.2485743489759409,-1.4985197135850545,-1.3244531034092213,-1.3037342962620238,-1.4904577914192478,-1.3114527768592656,-1.340993376739614,-1.3599368300649053,-1.180935928267849,-1.3595892016162183,-1.343569887677861,-1.2990488836311629,-1.16918762902376,-1.2584903565335566,-1.2720748953289445,-1.3764984784929033,-1.2801009810127653,-1.2768524853378165,-1.1653919629187306,-1.3344902952969078,-1.470484071454218,-1.2984396306655779,-1.2587860893653398,-1.2614498051613234,-1.3258328400009982,-1.300718982350129,-1.317668899467824,-1.391432088388807,-1.08386499252758,-1.37110852142218,-1.2238314684483873,-1.223835049346989,-1.318764535248696,-1.0988934044470715,-1.3165498663211908,-1.201799948425901,-1.2718197091287793,-1.349919056918214,-1.3131695415086826,-1.215947955240654,-1.2253757768088436,-1.165616419559864,-1.3204911840937188,-1.4048492003210589,-1.3520273413025925,-1.2116259602650339,-1.2047361642223928,-1.210465842092339,-1.344476447175606,-1.1847842171303402,-1.451508698269528,-1.22389784340091,-1.3369714708875822,-1.3097428142802334,-1.2521585815054377,-1.2649822396282318,-1.298427614537883,-1.1123475507557348,-1.3772351777654994,-1.366622953581591,-1.3483643172286925,-1.2676195925213403,-1.3663550657725894,-1.2655179498455427,-1.2360812775317882,-1.1799548241547386,-1.1767990505671626,-1.224835587599505,-1.4283485049421918,-1.1724189922069062,-1.1743385001169142,-1.378758923652809,-1.1433784147672124,-1.370326563966975,-1.3366138955235767,-1.4076132125482008,-1.4219830122747783,-1.1224129393458755,-1.2376218528796121,-1.2028315831771295,-1.246511117648989,-1.3588769111918548,-1.0885340689476917,-1.3394775154481855,-1.496963807050252,-1.2347317798521613,-1.4538979075983816,-1.1925330641421794,-1.1763454665139748,-1.2377198610969742,-1.2881325163636712,-1.258282379903333,-1.4170658244225516,-1.418818898492681,-1.191666057270413,-1.3855935245949156,-1.1883799093919771,-1.3045368681571594,-1.3694628780679352,-1.246155979997405,-1.4930888776403584,-1.3305787945718304,-1.2950610924247146,-1.340416036375724,-1.245707684755712],\"xaxis\":\"x\",\"y\":[-9.407934317296027,-9.31668784630607,-9.504923630254632,-9.607396064978513,-9.451212429824364,-9.533163752815433,-9.40532685559039,-9.413183226380543,-9.448875020103475,-9.587059327298755,-9.342359120700236,-9.491083609093147,-9.340591965045926,-9.488168467841826,-9.476172715166184,-9.627011307939998,-9.544587231700683,-9.45223215670918,-9.578325339300429,-9.409694793929551,-9.344573761002078,-9.506444622579265,-9.387883748446308,-9.398387510006485,-9.387658996314759,-9.504765063547051,-9.438166107976505,-9.460296645666045,-9.733019309056592,-9.353637440414987,-9.581107878924604,-9.44768170244597,-9.410207036094224,-9.574364555894556,-9.58326163634813,-9.369823764417896,-9.526611468877238,-9.407947405835653,-9.42334673943724,-9.52620373523199,-9.461796836445204,-9.621660676157612,-9.356847190211358,-9.656404243823403,-9.607056584959842,-9.495023339872493,-9.553704168948613,-9.579368428511984,-9.448199111129762,-9.562271862103342,-9.467713564311678,-9.383924422219318,-9.347944188259042,-9.580124999839638,-9.724300709228869,-9.55953700251466,-9.526408223513807,-9.323026657802606,-9.47482646252756,-9.601856710386647,-9.54488067620582,-9.427919528383816,-9.438235793344214,-9.5895428908632,-9.495404551719036,-9.533372831962994,-9.46798281722508,-9.590184420926418,-9.298875917728706,-9.593001759745936,-9.477882835196663,-9.478469357856689,-9.440331011808336,-9.549211412616481,-9.419253321995381,-9.421528801899282,-9.433077117080533,-9.479355208656461,-9.625419266116035,-9.440776588530964,-9.407610179832856,-9.442867558681815,-9.466492568437832,-9.35665407138247,-9.523174778329706,-9.48928609718075,-9.411855988198473,-9.390300576910601,-9.498545518553893,-9.58377418536012,-9.546768477956002,-9.515277141177796,-9.448321398631485,-9.58680856455957,-9.664301997393565,-9.569033496448018,-9.576765078654839,-9.530391063568237,-9.52845943111755,-9.55726091876412,-9.426158936026393,-9.326847598855409,-9.414941935649951,-9.504567113170284,-9.684034722625633,-9.524376589777187,-9.51958461519371,-9.530774854587628,-9.447791749819034,-9.404067160101704,-9.544000715253361,-9.439125673397886,-9.564462847913214,-9.616475573708728,-9.514959775987945,-9.213510939957173,-9.519823881752185,-9.598790925586453,-9.362870495873537,-9.512274137117,-9.447154090222519,-9.501208458254647,-9.49517319305101,-9.576120049872765,-9.377783581378036,-9.444444879167449,-9.476849811128004,-9.531292782834349,-9.431556927687412,-9.340805739276037,-9.475176095897295,-9.494643603767358,-9.490707692386199,-9.525920840582874,-9.580851461754033,-9.574858429583863,-9.661546967520765,-9.64523680180684,-9.494708253285848,-9.404863773088664,-9.51660160955145,-9.41291358880928,-9.575905191012344,-9.511942021927139,-9.294854542915873,-9.633095839540374,-9.640988803328046,-9.324674863201235,-9.55661284761642,-9.404374189635233,-9.5026947772648,-9.480909583729032,-9.40217629164285,-9.522003990124096,-9.43063573917383,-9.489197229977469,-9.657967136269749,-9.667336602054524,-9.402122903856101,-9.553913104388515,-9.427240106227272,-9.560893159805541,-9.471919664990986,-9.463045189502338,-9.601289401273881,-9.597456053069834,-9.326224020074758,-9.497318285861018,-9.555039415726524,-9.475538603978743,-9.488922439731573,-9.45567506098168,-9.341461680006446,-9.363829944173855,-9.539682439187596,-9.49792686917152,-9.569933133771508,-9.687101937515878,-9.569073311208713,-9.522181668123554,-9.590214843115742,-9.457480243614885,-9.452754543226165,-9.555468550422477,-9.508107150280917,-9.496687132122256,-9.61992723009576,-9.489229988405029,-9.539816822900075,-9.652229268497283,-9.416511745623374,-9.548717405535841,-9.682353816186914,-9.515999559941068,-9.489139319841911,-9.513084766225614,-9.519928696896061,-9.422939353571575,-9.663698490286258,-9.404968415345927,-9.37948989050525,-9.614591536278276,-9.382460095228508,-9.306293547295061,-9.423213980321997,-9.405825149136918,-9.655762653866425,-9.52148596908989,-9.25720901630985,-9.362024347148509,-9.514375606912244,-9.565519664691324,-9.396844174257966,-9.437734340256094,-9.397238428942261,-9.327121729531816,-9.359686800136545,-9.540572590989118,-9.424963189990983,-9.571525394831276,-9.506652775279155,-9.622145321933536,-9.390124815082222,-9.375243432073193,-9.291037772524149,-9.438999996214644,-9.64751584752038,-9.366525306670376,-9.54799338005059,-9.519591825394262,-9.3773929681031,-9.482552927626566,-9.483494697299054,-9.462579263935432,-9.610697744560337,-9.48566840624033,-9.214441638962205,-9.50914199977978,-9.466586744559452,-9.599751083873656,-9.353892673360292,-9.629652518148545,-9.406285127925141,-9.397136062697017,-9.568187913911924,-9.576444251494147,-9.505719423455345,-9.477279600522474,-9.497675698948228],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=2<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"2\",\"marker\":{\"color\":\"#19d3f3\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"2\",\"showlegend\":true,\"x\":[-1.5175224398050664,-1.5724477060664803,-1.4874198646523416,-1.5697940768472174,-1.5451122323806388,-1.3813724617366534,-1.487719038704833,-1.485164437218698,-1.526134519811722,-1.6804561637218902,-1.5671985651210434,-1.5931405917243333,-1.6255513771501857,-1.5917059329972767,-1.6447934305975223,-1.5415971973321916,-1.552538515414927,-1.8100176909346606,-1.7963809678804363,-1.5863380145007915,-1.7039797461298616,-1.691792842637065,-1.4906304394912633,-1.3743621638627221,-1.6521980691665188,-1.555486009235158,-1.7830365567237203,-1.6520682252502963,-1.666605222577197,-1.5655194889066517,-1.6686907760113585,-1.8154865620001186,-1.566047796260508,-1.657821145585574,-1.5546646731030869,-1.7670766207862123,-1.6414521304038057,-1.5855970827309136,-1.670620431010719,-1.6015001782363412,-1.5340963142493846,-1.563852120334587,-1.5538161259448076,-1.3078932454156091,-1.5810719574043732,-1.5969007990172888,-1.4823420346791967,-1.5121784287415037,-1.5990917743269473,-1.6004658825237164,-1.6504207589768465,-1.4683135412063961,-1.4685520539044918,-1.40476846298475,-1.6678755126343339,-1.6359155691830967,-1.7249404296129074,-1.5749858017263303,-1.7012001930704161,-1.6719986546866012,-1.6159073467701042,-1.5662376311258275,-1.480701332145765,-1.243456265012864,-1.6418933941507416,-1.6590743241538946,-1.6043484793889746,-1.593518820237831,-1.4599027508386289,-1.8026631274546816,-1.4783473849873696,-1.4761012193437004,-1.609516490851378,-1.4705496254001573,-1.7344692290004704,-1.5376320118202431,-1.698542791585474,-1.4819292039631737,-1.33798632091622,-1.5726593133271567,-1.7836074022779018,-1.6407049937031972,-1.7605002035246344,-1.7422281925078063,-1.4755871330382009,-1.4704670975603609,-1.7013672464091472,-1.7870520532400735,-1.5198681171030808,-1.732321481123097,-1.5292030472365674,-1.4936247359025265,-1.6533428539453212,-1.600598480390674,-1.5201971913546783,-1.3890685498384938,-1.5203566304387617,-1.5558396661255418,-1.4308729645650438,-1.6185936745611647,-1.6802632038836323,-1.5977196955563207,-1.4605448445029592,-1.5028860459080555,-1.642582878968477,-1.648175295743187,-1.5652756546710171,-1.5103591946415582,-1.5140798805987077,-1.513244319786301,-1.5103599815640947,-1.5338386870282417,-1.234947127326971,-1.5858528212370395,-1.568042594449539,-1.6078760514809787,-1.7061917177109303,-1.5984543456980234,-1.5995835561869947,-1.5687665188355977,-1.6573473527036753,-1.4447787305845923,-1.5977759989341622,-1.4751009740681802,-1.5720177647490936,-1.464030132954796,-1.5969467126229306,-1.5616626708441186,-1.526605758487333,-1.6935636684193491,-1.4785162419402222,-1.4587099903787997,-1.4444670777203088,-1.7359727163330458,-1.665869207668673,-1.4026490655151098,-1.5940530729974,-1.6254642523559415,-1.5653073303785252,-1.4677183796633877,-1.7034762410566573,-1.5030966058512782,-1.6989527965486082,-1.6122038170239326,-1.5643824163104678,-1.767140777468748,-1.5532274538047435,-1.6290622832534676,-1.6737488765271773,-1.4335779696984003,-1.4868177439856893,-1.6768970045251836,-1.7220134277481403,-1.367675273458236,-1.5830150431810843,-1.535678985479011,-1.5285181875815175,-1.5629956357972972,-1.6753581327731484,-1.631493273205906,-1.7568566783454491,-1.634746252543495,-1.4551683482928588,-1.5211351410588578,-1.578856463958282,-1.6474416477285152,-1.5558157840932751,-1.6499934481077982,-1.6032186606668615,-1.4998630227206393,-1.5658154935989064,-1.5214630078007378,-1.7268310706919916,-1.440156750594727,-1.5793044438289177,-1.747247430683442,-1.5325430263244801,-1.349587579009183,-1.6879708623017433,-1.3946759876969328,-1.6605611476157973,-1.5596422775941223,-1.7860757828215341,-1.578542060921903,-1.8602466329307776,-1.578805886146483,-1.4827552690825336,-1.6132221519826173,-1.6200510428851382,-1.5256530720706343,-1.7190414571476884,-1.5317864009037727,-1.525961396537333,-1.7219536553485315,-1.5155246883613889,-1.4590922849556305,-1.757581499777804,-1.6280063961105953,-1.494854500750384,-1.592644492380901,-1.6328127771550727,-1.4501526245221203,-1.5726065363919357,-1.537197602360492,-1.5398410722010254,-1.5622468704412698,-1.610561551707664,-1.510122448623188,-1.4577735836335106,-1.528365965419586,-1.4492861072955006,-1.3512346617825879,-1.5350384300730693,-1.4922392640393012,-1.4107549191841273,-1.6421440466897723,-1.577404196492871,-1.6831966142619723,-1.567782919838492,-1.6302773674502138,-1.6489028740922964,-1.5282880509877885,-1.4577794391285162,-1.6791752997556835,-1.6131936495780868,-1.6904525628147942,-1.4267776065241935,-1.6562483439975368,-1.477255094186887,-1.6470523515263498,-1.6229287064573918,-1.7086460624791127,-1.5731280329860666,-1.4912512018864854,-1.683816420349883,-1.5427256507564318,-1.5674521294461032,-1.5198121762304113,-1.5191824547930384,-1.7725704577944,-1.6344375006273117,-1.4581872356825603,-1.4999736300176645,-1.3175907218967953,-1.7339252063676218,-1.5877415336571963,-1.6524095418661386,-1.70212457127343,-1.5900404455084702,-1.6172988798368215,-1.6548115581045544,-1.5093420993458277,-1.4221558919080028,-1.5653132380405512],\"xaxis\":\"x\",\"y\":[-3.452778110026129,-3.6169082330620728,-3.2222340412399175,-3.4247221909743666,-3.501662881488122,-3.6740492905830897,-3.281509345235734,-3.3575438645474245,-3.589564047552754,-3.342009570687256,-3.5910519918592203,-3.5744365958939,-3.2824557765051194,-3.17476136213693,-3.442536221823826,-3.436154458991328,-3.3426442087201735,-3.3490442953874044,-3.2641021984261647,-3.370753434962383,-3.5932066288061657,-3.4428246032150556,-3.471094350411339,-3.3643466548418353,-3.4259902417032735,-3.258902341311446,-3.6797253128435425,-3.4849571964800696,-3.541119535911479,-3.431525178424695,-3.2581728475411893,-3.5290844078126185,-3.4140661961787058,-3.3901386359577312,-3.40569503396243,-3.2165736116296064,-3.4274084511414293,-3.563599152238402,-3.3632862292703822,-3.4948144488730293,-3.1999354260449757,-3.4811284229020836,-3.3950432221098055,-3.4049122192647525,-3.342907610407755,-3.3622742934369505,-3.434433728175226,-3.453063059951519,-3.3404179349196146,-3.3089843478447185,-3.3041307309476866,-3.3164788124548865,-3.2695959399264476,-3.3067532219979143,-3.4688138634857335,-3.413051427226573,-3.5763434053211887,-3.3683920713852094,-3.4432045887694662,-3.5381451524613903,-3.4067502804345384,-3.3419274022136283,-3.430124284098476,-3.4542075403472827,-3.4477265752174633,-3.4220140668487145,-3.369231959207042,-3.5044700906224464,-3.4773645879912416,-3.343186419764085,-3.6088973042875856,-3.3731008534207296,-3.3325288760163536,-3.5730560243839644,-3.5598944532086234,-3.572579673254995,-3.6064670902570035,-3.4344600747688894,-3.314800261848842,-3.4006718426830163,-3.4332657291211794,-3.283195692657731,-3.510036581777149,-3.3672943445967425,-3.3632501318798433,-3.5766098752969975,-3.261472059128606,-3.4203427899431147,-3.4389505104694407,-3.3668916915981386,-3.2507789459928573,-3.5429504495498456,-3.537872907247321,-3.269240617992872,-3.4471774545397094,-3.654996271075099,-3.500475941059196,-3.347275247036979,-3.3538540309715286,-3.3202324849465006,-3.391647739118598,-3.483750083741823,-3.4371338564461156,-3.523821399981759,-3.343267829493861,-3.4687738977824196,-3.553460572789544,-3.616231728423178,-3.4308815100446504,-3.368644928841404,-3.3228264023100937,-3.2240992271033733,-3.391443505660586,-3.442232897249041,-3.296431713263469,-3.3877382252142083,-3.4919846448978675,-3.366388208647285,-3.4519441467560115,-3.368366336451903,-3.30430531629353,-3.411345571650533,-3.2700145189877934,-3.2713380343948733,-3.4262011603326465,-3.490383594972586,-3.428707760580359,-3.4678410773803217,-3.398619457491004,-3.5586236596131893,-3.253826940874245,-3.418237747125526,-3.5061955260141446,-3.3331601388756917,-3.432508580738403,-3.265157163965608,-3.428282318729465,-3.43652631810558,-3.3773101564152217,-3.2726224724631994,-3.4063209856182914,-3.406410665502264,-3.3400948272386963,-3.2535235381098473,-3.2272057228610787,-3.374896166693836,-3.3975964940673555,-3.3233323782270436,-3.4826983573554644,-3.35304077268333,-3.3998647543764804,-3.3810436620124986,-3.3966001128876684,-3.3314117868131117,-3.369661631347916,-3.4525990391322865,-3.2556729138719187,-3.3482098084950525,-3.2732475432235244,-3.4927009619782488,-3.5086162811194233,-3.4974881377845066,-3.299854423208491,-3.2157863652287726,-3.46080988200896,-3.2613504434090315,-3.476133151106949,-3.3302704070085336,-3.322505317516179,-3.276330418106613,-3.347837757634653,-3.3914448301160363,-3.316725107671459,-3.4816849409023622,-3.4102920744219287,-3.1892341061445064,-3.475271586529955,-3.3962315231591957,-3.408259434645176,-3.2797822862127926,-3.2567906453367677,-3.3186707835477414,-3.50806777215309,-3.166646447065108,-3.4895193215337477,-3.3061646714846753,-3.3799985945667035,-3.592607054380454,-3.352463055415922,-3.373581606832008,-3.539206515234343,-3.4501440777553665,-3.511987911647042,-3.457646200532843,-3.4047812751227973,-3.421699660069654,-3.254982468848469,-3.3991242537340485,-3.435356028383499,-3.415464537777508,-3.466050673170399,-3.2931054597246985,-3.5044022658607683,-3.3247266544562706,-3.5608583580110795,-3.40344723255605,-3.5044841519795957,-3.1899700355906786,-3.386641459410623,-3.473246487058726,-3.519170184383889,-3.4342689806844873,-3.2948885151716563,-3.3878452625009996,-3.3655340261018285,-3.41999588678854,-3.551679007239851,-3.396992951996809,-3.3038806791502098,-3.2289416185208433,-3.3756491591645483,-3.3902699890599957,-3.2630963581761763,-3.457375596622179,-3.370668879296392,-3.234615180151007,-3.4003471472794677,-3.3171771680901943,-3.310078535566337,-3.557415359465123,-3.350399804303419,-3.388704408439691,-3.2808976060554444,-3.4790086610693325,-3.306787388857281,-3.426778502263638,-3.582192325674917,-3.452160538084072,-3.5366300899202052,-3.17226120065329,-3.5815570333124476,-3.49567558388573,-3.4644103865197877,-3.247189379700481,-3.34196472085634,-3.3657856613118597,-3.390754040509417,-3.2247632811043645,-3.329041225648396,-3.3721839941888527,-3.2923015071473984,-3.244164608332075,-3.5051009313974357,-3.4088036301785385],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=5<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"5\",\"marker\":{\"color\":\"#FF6692\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"5\",\"showlegend\":true,\"x\":[2.51528757433582,2.4133800022695233,2.2167485309710764,2.433482071358483,2.2794965636177915,2.4231549112195854,2.4194028734075905,2.3252884482324925,2.336607940462335,2.355917289038483,2.349348213203503,2.613938173892957,2.3301253381438793,2.47726334130113,2.536898243915525,2.3421888201910845,2.500790849219765,2.5449128754461765,2.392357168657522,2.495017837722591,2.268338158128657,2.237281957102184,2.3992459029761846,2.4821675611706913,2.5641861526683605,2.3581071491252272,2.3860813958563907,2.3639909946871174,2.359935065560017,2.298991159101407,2.426802301875099,2.3067789138058705,2.400644703640267,2.506047967205818,2.514203072103716,2.4117250676460884,2.4621027612031905,2.2775347841399087,2.493891715193496,2.434764169210151,2.5068960106991214,2.3184635417802335,2.399036450203663,2.337834502623182,2.3633054771014352,2.650529231525934,2.32803784617299,2.469856694780211,2.5416287276579235,2.4030291900253586,2.257900070033878,2.4497018600643825,2.283731090660741,2.4229418117113926,2.463326031576575,2.4225145942201936,2.2067196827043007,2.3350125743397383,2.4973964196985894,2.188622265021304,2.3865507220630846,2.3232768851313925,2.3676066770832134,2.277950959368889,2.394239856097642,2.429547451195534,2.4635264457516777,2.324295231321328,2.5107094505780396,2.396588884848013,2.442187559655049,2.405309878757339,2.53591678388301,2.5411618627969945,2.466627274542282,2.382519583824348,2.418178801582816,2.2853281562930445,2.4805793903457056,2.5333108488128606,2.2282004697756768,2.4156905240979345,2.499775767809462,2.4414297559739206,2.3024971085052157,2.3803293829117513,2.4366599111339085,2.3645541079406502,2.4470415408919037,2.574109577511958,2.3277748957713804,2.2770082734306087,2.298693043930928,2.5172624229654548,2.459408041802613,2.382799382566419,2.3176117623977124,2.4472555889928973,2.4103570235118883,2.60192578071688,2.4067307604496415,2.3325333725228417,2.4230447321137305,2.3874719503318715,2.3322175624542973,2.388565661820323,2.450464492929034,2.2864041916748503,2.3554492286769606,2.46649821887877,2.4900922882188783,2.405343611661925,2.35734116192464,2.4082269890766312,2.3169168735052885,2.400154435478052,2.473094385906319,2.2481984848426078,2.27474458653718,2.3357938571292842,2.360319973066793,2.446050900524982,2.370485823706736,2.3087199706974912,2.284156090123112,2.317328775951265,2.4865667175697586,2.44529067511112,2.358247214935173,2.458251671361788,2.5041182218693625,2.362198116923267,2.2961857702947737,2.271827772733718,2.064440804124836,2.4860960905848506,2.3332881299149064,2.4581686850248228,2.4645361464697073,2.372974078193835,2.323694946571459,2.179974397594171,2.4648119657727188,2.3384436870857988,2.514995675536965,2.503670289035071,2.3921591548592698,2.342109656512692,2.478664579971854,2.349294940348339,2.4811065351677315,2.5297637690062436,2.4807107949323983,2.5720958597983627,2.5728235358618865,2.450835609749741,2.3854219316837715,2.4525062815154013,2.2047678090427176,2.3825217702539256,2.320242021237635,2.4903768623183167,2.4909228760920272,2.3842011716036295,2.118110503657668,2.6225228014869724,2.5028526214271176,2.3420968899939814,2.6574206295200438,2.5115684308177664,2.4056063365803415,2.3462270927737716,2.5688206584302624,2.379946335220194,2.2839355777671724,2.3964436619157046,2.5009755209659015,2.4177353959706784,2.272352046399402,2.3554212388682734,2.4858079677416383,2.4383420448422575,2.62984074917496,2.4885963761859564,2.3955525483739124,2.4733193494982015,2.3576116574678014,2.2831252486241715,2.403558279277756,2.541649551893849,2.400317350692866,2.455745816107063,2.439522654971703,2.4472700991492564,2.466362219838657,2.51148733876567,2.5347425412594538,2.498812466633982,2.4159264113486802,2.3803374090708274,2.1963448707723026,2.393292518311909,2.286430357272419,2.3449134154749847,2.471071920095282,2.5852376864380275,2.4511618426129353,2.355085973345559,2.484532376018937,2.441298987355827,2.2810061968308406,2.55392503241807,2.4656066752160704,2.5263624695334035,2.4287260940443676,2.5753564343803683,2.2992285044236493,2.6698826683255246,2.3485962111767202,2.4490202232155323,2.4312904933457054,2.3941909484219948,2.3804779587004226,2.4644166878348526,2.3040104068274423,2.473952162373844,2.505854582126698,2.480351832633416,2.387095762888597,2.3168427151983897,2.2833763951640127,2.2697345442204298,2.4582814822344132,2.507258427277891,2.479214439226244,2.4992266159480367,2.3523558052097546,2.59211018932914],\"xaxis\":\"x\",\"y\":[0.5679190592692371,0.4706920055357592,0.7471829698601802,0.4471200391393705,0.5747048212332564,0.6843715143926399,0.6874918971430557,0.6970543074935026,0.5893413412852762,0.533614794487352,0.36031293977847917,0.642691996892392,0.48295332655811946,0.6590082768475755,0.5551480988386753,0.6857022916032715,0.5294345043171377,0.5438606274427193,0.5197883718731234,0.5913061268114802,0.8534152185859081,0.6387929296032029,0.513057889417553,0.7130620184200445,0.7248878055104312,0.5472670162411574,0.5423769321384063,0.7264429256534525,0.5900802969944153,0.550521755288096,0.41231441060594837,0.6570128913431801,0.5549297642011277,0.6768841800386354,0.7897508306356636,0.6722957033726795,0.5153101463010799,0.5004132687553152,0.6315816659388098,0.39596650959528334,0.6699281700141388,0.7516789702809135,0.4709448987128486,0.3202945373972598,0.5532981055880277,0.5860876453980152,0.6100657410222073,0.6441694779559805,0.8374508095002209,0.6306964020117063,0.600167878295538,0.5000062089712268,0.5144926665584248,0.5713690401926464,0.6307712975582256,0.6401239880907439,0.5598957856398928,0.6049953816178018,0.5983635398882077,0.4693314261750362,0.48925567754319876,0.6993819920815891,0.475873687838113,0.38339499667454907,0.6525152302410857,0.5562661584112509,0.4808094449235808,0.5855609489318093,0.5448834753217178,0.5580946326430005,0.6215782235066261,0.427681090059461,0.5878947314851505,0.6701261410152004,0.5328082598999423,0.5166381337277889,0.5723832349094374,0.3681995363526025,0.7361796671061094,0.7410010730709523,0.6400582707866258,0.41713665033250913,0.5366992551628559,0.7377339154695444,0.4424180532746245,0.6239959759867452,0.5010289632687406,0.49369721404162903,0.59623640568855,0.7445249097089309,0.6685228008630238,0.6064311367048627,0.6229958806408183,0.46346750551519833,0.5388255843413903,0.6800733058955988,0.6762551079830742,0.7702238056892261,0.8409332757755456,0.4732575327934903,0.5801115236818241,0.48203695839695904,0.5586221147821543,0.6375293970469679,0.6797684835563673,0.5987479912108087,0.6261700932262956,0.7119449749153737,0.5341937142096382,0.4499008925674584,0.583314393749131,0.5504521174779324,0.69709801807716,0.4989754774173599,0.627268592949044,0.4894746897454222,0.4991223540335977,0.5980495204094276,0.6801774744486353,0.4950233357899122,0.5600240046321598,0.7090433787083982,0.5270387412288364,0.5891748536853947,0.5500233935412431,0.6258799175126486,0.4899382281890018,0.6235714745918692,0.4937904487558872,0.6017253951456715,0.6870563397103012,0.6332762109626684,0.590333621074095,0.41393257465868816,0.4715309672712656,0.553569092259755,0.4532562820594801,0.6579644107255969,0.7584435119288034,0.4687705261682313,0.4091428865232426,0.6352447458964209,0.684485374023497,0.45700452728160457,0.7953626617867303,0.7599789443061049,0.516518398351872,0.6779194869116387,0.5178374680923126,0.8067619791919324,0.45170196366003706,0.7713853128338866,0.6494789317941772,0.5274150900364243,0.4483577507868258,0.4664152463976712,0.6050057133482813,0.41698759627796195,0.5139508516485339,0.7013114703255976,0.7149554861942056,0.536420331707509,0.6965139050977996,0.5887288819546858,0.5460084902265561,0.49758387344310734,0.557733742840525,0.4622763647185123,0.6683542202220489,0.5427779937173135,0.6117729429916612,0.45172996974733787,0.612731470668741,0.5812908169849863,0.5910998975892298,0.563988015125485,0.621358822112907,0.5907762932536467,0.5616071110715279,0.44743066459828473,0.6413995371111114,0.537632271991659,0.6705410165718703,0.5500629440280952,0.6751501780881382,0.48293205094873726,0.6203454338020404,0.6177884562172921,0.6109407271839689,0.6184120169795456,0.5062214653673724,0.593870489029886,0.6029571881687747,0.5813468312783744,0.5602189354100946,0.5374293740920913,0.4669206532582576,0.5320123342157733,0.7454381424394408,0.6579068591597244,0.6421863830699283,0.5963864458249416,0.6007237222314836,0.5305023722689083,0.7695991529413481,0.46436173732144426,0.5288912363445316,0.7082709621926171,0.582682631363237,0.6721430547919727,0.6057387654785084,0.5779161732263767,0.5358694452991898,0.509928957819094,0.6122283089163569,0.658899065946025,0.5928619255546691,0.37128579602273837,0.6281191022314399,0.7240093755730455,0.629910204955505,0.5395579523310762,0.5381554926058502,0.6552687549375129,0.5594583770739663,0.6792948360137772,0.5818733729801132,0.612374778917206,0.5239158244860048,0.4237879805678936,0.6925791210848182,0.6292116875927352,0.5619976997021748,0.504001729702946,0.5935491487076315,0.6070874078317274,0.6500485482791377,0.7217966812859686],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=16<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"16\",\"marker\":{\"color\":\"#B6E880\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"16\",\"showlegend\":true,\"x\":[2.836763586274268,2.8829892529455012,2.79303257437105,2.848418422573593,2.460007434982191,2.731966664833222,2.7845603629308697,2.8290148283004184,2.903256175871629,2.774079607466055,2.770857873252544,2.8988806855507177,2.702802521130885,2.7241699777521804,2.6969607955187924,2.71532205973998,3.011787665516233,3.017541507702693,2.817607880363594,2.843372658644247,2.671655783916398,2.670964160199672,2.9475596203633545,2.7924033844610925,2.7381344921248947,2.930575693353951,2.8741816178609767,3.1590779324476315,2.77885754339411,2.827103545475078,2.811555071909799,2.8129820150550398,2.804448017433154,2.825036139858393,2.91748832253171,2.792127009160433,2.7541874259655423,2.9248655115887727,2.9058027164051943,2.8780846265029942,2.872100882570975,2.881925784366098,2.7562975090112576,2.8863956389749617,2.8092682664069177,2.843559856052527,2.7619251609883535,2.8128587318014433,2.914046827261857,2.709158598832605,2.845631015917671,2.799042397498508,2.949332513297585,2.9047825472380757,2.6446922406705786,2.631786572761395,2.9605350922831635,2.791865013139557,2.74503487087639,2.8369795012974732,2.821542580084253,2.7718644005200046,2.622396238248895,2.8370429938685526,2.7110409457641715,2.864778347172454,2.7155495371057983,2.8981235943150137,2.8470478111483692,2.6744135575154546,2.823055199459606,2.887239235027731,2.84367844516153,2.6926902377063127,2.677089574397693,2.866124097679136,2.837863556329901,2.697805682445254,2.9068795716184987,2.8579485852629745,2.8220867193725687,2.8428432459628326,2.762101088191517,2.7359536574734316,2.8971692223999455,2.770814525269666,2.699687515341619,2.8269255856357147,2.82370431707365,2.9517010208832133,2.6956854093476195,2.7280319517840352,2.8206346222912684,2.8307359337798204,2.8694426228192227,2.6019847710069413,2.8904689217251907,2.8521231473575157,2.8079718169479144,2.918402664156575,2.694280329451748,2.9776904308368772,2.9868677823993024,2.703299105790638,2.587929990761621,2.6761458749132245,2.8461279013227436,2.720975668036055,2.8868955999171364,2.708815593878555,2.826077610932837,2.8287515544636364,2.884897993270692,2.7720835976259663,2.937517256539885,3.0145074466273183,2.7014495177208357,2.727429485124024,2.8047677298527023,2.7882858869057103,2.99368234871905,2.675726799770916,2.8592259812740988,2.906385425543716,2.699457878047696,2.8565075869582888,2.916432217788897,2.8519546097972244,2.8966898191458266,2.816586531853966,2.909481422498829,2.770560598825803,2.6440606696741855,3.00896259441246,2.82315143635104,2.9122256760231875,2.808621864723232,2.802661421720351,2.8457902107256725,2.8103020556651064,2.84455058596265,2.837536719728258,2.8611318602382836,2.7471765989690673,2.7029438422851055,2.875084800999914,2.6678047779283802,2.6425642710642885,2.840595340932708,2.684225511994258,2.7889638437537294,2.7864671699384647,3.0373022989239953,2.983679686930125,2.6470015329511676,2.7660304740964414,2.7905425766089853,2.614057841624814,2.791267653599696,2.976500883853455,2.651887751385914,2.8922014290935065,2.699667022258933,2.6418540462661446,2.827665576455431,2.82171851610639,3.0041185986734744,2.8162163407693694,2.892198152668747,2.9334049668981903,2.7221723331320375,2.8441080836189,2.784774515985906,2.7874546662376387,2.9516492452858,2.72088959685918,2.7186509373940684,2.928800534085633,2.7812126646991664,2.789149760791909,2.8415301972442997,2.713316562877689,2.807321045051158,2.719592186039319,2.705365044408845,2.8132510322541524,2.7234318573045146,2.925181194423826,2.8518626588841482,2.7968688075735693,2.9278971603796435,2.71902916285747,2.7334724361564477,2.638386847680741,2.65682168102437,2.9077829986814123,2.7940518147445976,2.7289953164881147,2.6272127537074024,3.0188474775292753,2.88706959092025,2.829332347411747,2.758347573976045,2.9244125229952074,2.797574261729241,2.728631810130481,2.939242194958903,2.9242257411828074,2.942658437841173,2.941053957500035,2.7719495325573553,2.865160728474767,2.9442567054747584,2.7793642334294675,2.8001965938732174,2.6436514952555323,2.86580681643738,2.8276584232661,2.9252176397116694,2.5750163464596802,2.760573560660408,2.925135744546664,3.149212039759055,2.754097931730111,2.7084411932901795,2.861290380434988,2.8682840400610146,2.4999349226728453,2.906342376466363,2.84933159923877,2.7600087130438853,2.8733656822010656,2.7218451418734784,2.749485644169074,2.9441638371546746,2.713459691379408,2.723069037717459,2.8183485989456423,2.7745693209977387,2.9882748411658198,2.785248129068238,2.6133156651113167,2.879361716711036,2.7926647718226603,2.7705291405176733,2.767749454599893,2.818140191575462,2.9225568330591134,2.7857586463499286,2.847406914916942,2.79018599411952,2.8137160661169474,2.7914296398536913,2.943713541023091,2.771642733905383,2.620096785175385,2.6898428824153893,2.8328532500272154,2.8920292942705212,2.8240345088040995,2.773676574731965,2.6425290888392845,2.790537580671895,2.7182581120002345,2.8471632489560235],\"xaxis\":\"x\",\"y\":[-0.505067660129911,-0.3073616435365451,-0.3585303919792849,-0.2490583330883468,-0.27355980781826866,-0.33628245272293905,-0.43641534316383424,-0.5335651676623461,-0.28948227031581253,-0.29443320024531827,-0.594627618246889,-0.4033304108743462,-0.42356549470115407,-0.24118462840515636,-0.18591038873240506,-0.40951406531288426,-0.4791722171064767,-0.27429119405055225,-0.11699958867870455,-0.3733002540210363,-0.10525653387700606,-0.27413707994625425,-0.32103601088700373,-0.4020856777950692,-0.3448570220889518,-0.42947221603958585,-0.4548130981942542,-0.2716579558309001,-0.44662797198158216,-0.4627299368902984,-0.37233358468730876,-0.4067606870863826,-0.4091258606431387,-0.3060899696810674,-0.3420794417769901,-0.2496938672090473,-0.03198288781447395,-0.3567861548781043,-0.23072896617691024,-0.3334772154316334,-0.34492666353238705,-0.27668330114760364,-0.39311637474518185,-0.2876903218254209,-0.30367980281891827,-0.19785722290751775,-0.4704504511443546,-0.4329203005059822,-0.37254742219218717,-0.4114874262247078,-0.43853324555698936,-0.43660967746230517,-0.32578128575803267,-0.27166616299399327,-0.32646785793939187,-0.3810433025658419,-0.34544668715157006,-0.43049538070551263,-0.2934489082016448,-0.3875509010544972,-0.261452854035289,-0.48903737688151755,-0.23074477501315804,-0.3224459938176378,-0.27268782238849126,-0.3871341172923549,-0.32642307869984055,-0.5018948247701718,-0.1866101783038685,-0.39969035382959534,-0.3285895137954707,-0.4609631106299643,-0.3617701780306139,-0.28663632174353476,-0.25312948357353626,-0.30314697578913724,-0.394497829039152,-0.4300933636689601,-0.2973758906305405,-0.18720735611254402,-0.3583239985396465,-0.2382525787033966,-0.3424367730790941,-0.3497262072893724,-0.48271330480318536,-0.3670188121662348,-0.3106709424685592,-0.23760755204037232,-0.32116737054204864,-0.3294421864370691,-0.25361564121287383,-0.41892464143010777,-0.34228867049779227,-0.4267849577381656,-0.41075437445367313,-0.43324696977487936,-0.32971433024325764,-0.4189976583685718,-0.44443845964314627,-0.1827263846687224,-0.25003428800005967,-0.3640946645002138,-0.3295960754576176,-0.29542219562746036,-0.49363535336308395,-0.40699602633281007,-0.3583859926469541,-0.5262434542256527,-0.2977758746717283,-0.46218051416706274,-0.3373769879907247,-0.33487366122141554,-0.20571714329852545,-0.2987518103247495,-0.3509050840524453,-0.4323536491116293,-0.2534771519351852,-0.3672965455613301,-0.2839792456350606,-0.35422387326907606,-0.2423393913011596,-0.3577689953166033,-0.32906808581775615,-0.4678281312060759,-0.2054064467867072,-0.4567365928708873,-0.3284852672382726,-0.32558386903805825,-0.4364607501933802,-0.37958753639339854,-0.3561267744928598,-0.27747955526546375,-0.346524178153839,-0.606694831761935,-0.36241144472308867,-0.16484364314005484,-0.1595491595200828,-0.3668063857954662,-0.21329755559536887,-0.3627559966046826,-0.3373753432371659,-0.2796319627065342,-0.31299405295521937,-0.3791025151946623,-0.40752505876044626,-0.21229959265470724,-0.33731117007946854,-0.2519215668354643,-0.1934062577064359,-0.4668850020512599,-0.3150191233841275,-0.18422960942377706,-0.25591528893073245,-0.29092258133493454,-0.2147342574298196,-0.36992733343191175,-0.3555479666768141,-0.34860951273220114,-0.3792482421371597,-0.10268910271362552,-0.39749031294163034,-0.31581753121522693,-0.23132868925911337,-0.4851413562521456,-0.31787332093552745,-0.22646329589789327,-0.40863368997322,-0.3581841210691542,-0.4130419472090546,-0.13271800931291333,-0.44273243175990584,-0.121558123074605,-0.22895373737708058,-0.2120557334926537,-0.1759019630529039,-0.3505056872350225,-0.33700420865113395,-0.2322182514668754,-0.29847467052570276,-0.48948800678599724,-0.3945463639709618,-0.3797076412481225,-0.4932406255332743,-0.33381304437177167,-0.4110683064595423,-0.2759529319825263,-0.3096095436441045,-0.40662361102895705,-0.2784044286161669,-0.23570778967866265,-0.4227479523765126,-0.24945292330504287,-0.36321066628693804,-0.41214084652459726,-0.4198421205943165,-0.3785280787635212,-0.47745663928729143,-0.2264453932874937,-0.3612928494236924,-0.33193955271270864,-0.1392661629695081,-0.3534166822845514,-0.3157950168014405,-0.3114677148811813,-0.42963784989382525,-0.4485257137251028,-0.3015504853580376,-0.2852529053967247,-0.33990437094124604,-0.48483602239696766,-0.22984313226433684,-0.4608067401606865,-0.43443423974349454,-0.2661840351012453,-0.518058747342191,-0.2190229820807531,-0.428477801881742,-0.31004188627972123,-0.3334539325306996,-0.49856174962205946,-0.21293326123458262,-0.26168508041102106,-0.407311597269562,-0.359591027916929,-0.4181499141045565,-0.2716382753661295,-0.43375259750575723,-0.4760078257091698,-0.30760102286054897,-0.44309095580864477,-0.5454992540437074,-0.4293718714481415,-0.3514402541577844,-0.4289003356791068,-0.18714246846284555,-0.26385537925196234,-0.2192224085095268,-0.3752012471827377,-0.3147815061455168,-0.2715540712058063,-0.3871109439609498,-0.3070264535229421,-0.31807131698245816,-0.2437583940874301,-0.19292772737837285,-0.37202252220119564,-0.2994230582624908,-0.4250057217084233,-0.16977492610281728,-0.2440021293326371,-0.3077413497863936,-0.28390643306175817,-0.4461968041117691,-0.5143387527980872,-0.33462780484221577,-0.3886405567581487,-0.2812125934428563,-0.3675122183525571,-0.2853767686078083,-0.35088186010686767,-0.31629493740235287,-0.27458482750584867,-0.27121135190841267,-0.382363473127932,-0.1977195631957148],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=4<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"4\",\"marker\":{\"color\":\"#FF97FF\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"4\",\"showlegend\":true,\"x\":[-3.890798950053017,-3.9117275979212,-3.9775382001828845,-4.116593685855455,-3.9270489942063755,-3.9585782842788584,-4.0841621394372,-4.103507142897442,-4.054654611153987,-3.958738458825389,-4.001522435247836,-4.010562644755611,-4.047006410275614,-3.996601714414442,-3.9497417700184982,-3.873672998440856,-4.057546957043916,-4.126462207271089,-3.890422688013373,-4.072952545300189,-4.012975875315865,-4.002771499922375,-3.8594793889463195,-3.972932015382771,-3.936815362950657,-3.958581236099843,-3.8712710661378003,-4.085618441247892,-3.887530588734853,-4.156192119293096,-3.96916944867341,-3.933118864607598,-4.021852279813417,-4.104986328218781,-3.856825642671645,-4.038649918226177,-3.8175364159945606,-4.060375048905303,-4.036823568617024,-3.9037188343087244,-4.1462657538093834,-3.938886223458509,-4.0447212892547375,-4.112932036435489,-4.160843452322906,-3.936568994875839,-4.085895291359524,-3.9659828881521335,-3.9593451168899376,-4.032863913145434,-3.811361628997652,-4.107079547590838,-3.9246198937414247,-4.100977983843898,-4.1295226236127505,-4.046973980146579,-4.06487423065496,-3.8524301286854072,-4.005527808330929,-4.110878945653935,-3.955445669232133,-4.018685187985811,-4.005997239185883,-3.9453374039135367,-4.166351569813926,-3.8742324221881104,-4.182319408193593,-4.077255994866344,-4.0225896018403935,-4.136135535753973,-3.8672483513324196,-3.9335148131734012,-4.096378949452601,-3.9944326870449673,-4.085575971496422,-3.978819831654318,-3.8474834649228984,-3.9283757683574976,-3.900454796141328,-3.790787594962013,-3.951269284141697,-4.122166377851101,-3.924816861697625,-3.755928156037842,-3.9895215616716366,-4.03074154771676,-4.172374085091792,-3.944409369114224,-4.001739919553507,-3.8020367929300933,-3.87719222384565,-4.085661895105535,-3.8613209141699105,-4.2323584340848255,-3.99606996159068,-3.8645337422533874,-4.093694037249777,-3.9884556328038965,-4.050814566719678,-3.990041508557959,-3.8706598891192425,-4.227432845940061,-4.170338473066457,-4.124034071932188,-3.8540408472598386,-3.959279716432973,-3.88352196579013,-3.986300517468147,-4.138871641186074,-4.16700618302025,-3.963809494301156,-3.9956481512340947,-4.361252952832948,-4.021039306168902,-4.0586760921544585,-3.917653246801243,-4.1441152950865945,-3.9583726364012204,-3.7629644251073495,-4.11952541380044,-4.073435176833236,-4.049865860455921,-3.987293722607812,-3.948461805579123,-4.022035213110685,-4.014396839982307,-4.058946853663008,-4.107018113688689,-3.974360402601635,-3.9492256065099265,-4.093148215890026,-3.787565981599145,-4.117955715702795,-3.974156662275087,-4.100210952176127,-4.008313865679064,-3.886932308618169,-3.973635063591923,-4.103969301326591,-4.11568677088226,-4.075262707470692,-3.898752711545945,-3.7837487441692437,-4.077017113470299,-4.048474845593151,-3.926711242863025,-3.938868885567033,-4.0157602270445505,-3.845845610317135,-4.0228817078105,-3.997221578393272,-3.823078895190771,-4.052204388504049,-3.878483428884246,-4.087724878974582,-4.079051870864508,-4.076734320697603,-3.9946713207163707,-3.9402466789745523,-4.091600063794827,-4.03133363545206,-4.0742847922575525,-4.1279319774023415,-3.8216695872204003,-3.9901470913210457,-3.91243132070287,-3.9858317532472562,-3.891610608360306,-4.110377908664609,-4.056038321233433,-3.953610878958065,-3.901457819345997,-3.805045864937765,-3.9783109111389443,-4.078372734070817,-4.088338678750863,-3.880354110378189,-3.9590884631301875,-3.9188471869547024,-3.9349889669144895,-3.8364866658466537,-3.9761546735387614,-4.13738738313392,-3.8440707511472096,-4.0203979982310845,-3.9227750832621844,-3.9320639807839286,-4.288203662787199,-4.093596555416209,-4.083109753269968,-3.9157349895274614,-3.9805594707377705,-4.125985367485083,-3.9837821452993096,-3.9842601098605845,-4.039432362315568,-3.9178566762130465,-4.047475193391463,-3.943011335390033,-3.951238228513304,-3.9580704988665856,-3.902818672915326,-4.047044497143443,-3.968716830257337,-4.002868859769975,-3.9705261027046315,-3.9208681405968755,-4.100664116014672,-3.9892819212215285,-3.931030598249156,-4.063775558818628,-4.0733433100953595,-4.016414200239637,-4.091438668193465,-3.92848447874688,-4.035562635361776,-4.139916336960276,-4.0503260143434465,-3.9934585384420096,-3.9006928812225956,-3.8406715448154283,-4.089666082173103,-3.9554639670576632,-4.116911523629853,-4.109608189931752,-3.9984801195445097,-4.039503108030416,-4.102413221318324,-4.1623910614174795,-4.190883933969348,-4.022063064935194,-4.062022262903309,-3.934029489988168,-3.971496782797992,-4.085710308918769,-3.983140174638446,-3.9316627919916627,-4.054482923650816,-3.913903653147682,-4.03010131812845,-4.060573117634002,-4.1136690825039315,-3.9150219626321263,-4.07305853842874,-4.039148586544026,-3.998649132149429,-4.113689987218294,-3.8224207924915987],\"xaxis\":\"x\",\"y\":[-4.762818876344073,-4.570756535255091,-4.636006560858073,-4.689458764218871,-4.513152650314167,-4.748098165135759,-4.581408348473039,-4.646484071724343,-4.613648148478953,-4.647714767554349,-4.474823222556551,-4.613063216410308,-4.64974589386947,-4.728670892394586,-4.8902906475507235,-4.935928061966677,-4.594330365690658,-4.52060840722645,-4.7822346681842784,-4.8214530048949475,-4.722354010107666,-4.693936799648775,-4.637233286763426,-4.653493333513861,-4.669974734021646,-4.49336332436957,-4.931283046966018,-4.603988308671944,-4.604905307958106,-4.829315601406297,-4.698311543108688,-4.657349203415862,-4.399333002397407,-4.70674890082858,-4.743725765985677,-4.572928134473742,-4.574304375860405,-4.662905978082107,-4.643425311912966,-4.763089276353507,-4.735486324536983,-4.702876724137169,-4.77423506839813,-4.541171776083954,-4.789406758008026,-4.616621167692436,-4.72620773701462,-4.641535120553412,-4.6353687698922545,-4.690530287486335,-4.855246388634476,-4.794230040862706,-4.641160171432788,-4.585910668711939,-4.647033722510051,-4.8001713644372055,-4.673678783641713,-4.768924151063353,-4.765610374236925,-4.628824778744589,-4.593117019749703,-4.693316698215899,-4.553101599421581,-4.673758108927426,-4.655812996564762,-4.68015894914784,-4.538983306773541,-4.791945707381917,-4.676497752698264,-4.547129403527368,-4.78919789054541,-4.67505977779454,-4.53842895433763,-4.845865551461219,-4.433689134908881,-4.803972795391545,-4.603149436937589,-4.620472563795331,-4.615965528175129,-4.529372030249018,-4.706417723966651,-4.711276598495461,-4.720057443297697,-4.580646106067664,-4.635664640682903,-4.697005622358118,-4.7454512508175,-4.740729950957849,-4.738377577883926,-4.728188037627378,-4.6299528430851336,-4.789861847320295,-4.647624102901118,-4.58464446182726,-4.748449639138988,-4.695120120549027,-4.620849689523015,-4.633613002598479,-4.71732835319216,-4.635246086716347,-4.764045911530425,-4.6577800740833855,-4.694113419824753,-4.654129948088711,-4.8847975408656525,-4.817263875912236,-4.655795071647953,-4.6862608816897815,-4.776334161179653,-4.718420080484009,-4.654601135053271,-4.617248587502065,-4.684150071331428,-4.516427153727589,-4.7422396666724245,-4.749649059013613,-4.629188465636993,-4.795647811114383,-4.741947423411405,-4.719020451152707,-4.738506501380299,-4.63722629562868,-4.732356228777408,-4.5457934093388435,-4.65276559958345,-4.570863695509173,-4.578837216818926,-4.695549533591402,-4.64071154718573,-4.648603459669559,-4.6819062740150095,-4.6022445690648315,-4.695208622545029,-4.607127122916207,-4.64602194017822,-4.781708016806226,-4.629562973675148,-4.750004721739777,-4.658603598127527,-4.628499482558774,-4.811397761927845,-4.616805875799079,-4.81952810818728,-4.752060421494037,-4.820371784655751,-4.706104699633299,-4.725693406699799,-4.6754159749783835,-4.758016697614448,-4.525697025157616,-4.678111169055112,-4.423547324640328,-4.654811489708506,-4.437107759172552,-4.6906034894693,-4.605165127381841,-4.626494958395857,-4.695859735049521,-4.732060175772577,-4.5386287449698735,-4.55259967415248,-4.676354043435248,-4.706275989844163,-4.782384092788522,-4.6017463436250265,-4.655023570141051,-4.736464813656826,-4.62588861486185,-4.728393536958573,-4.8189141459511,-4.593634849448947,-4.766483687258103,-4.612449138788066,-4.666198018060208,-4.760869744793183,-4.737760777841775,-4.799429418135172,-4.609257370729316,-4.641901272852877,-4.810415502018653,-4.604843563578337,-4.802115733902418,-4.784972542326787,-4.661387429722605,-4.6239911124118525,-4.563888677705186,-4.685994638730461,-4.763749169419725,-4.742652832165158,-4.6379965522601525,-4.660824939567197,-4.812190898821666,-4.581702906532864,-4.63706000701069,-4.61098929488131,-4.8550975259450615,-4.7753231737000235,-4.583595437893432,-4.696811296225346,-4.745243738392233,-4.565378368031171,-4.644062609098836,-4.738979387830508,-4.60698532534217,-4.677984229365252,-4.682305155072177,-4.650920918598457,-4.708687965120743,-4.71935839663604,-4.675920154101795,-4.764060109006362,-4.627006452332504,-4.753181600192684,-4.542904733160203,-4.731583075930109,-4.625045170751285,-4.644751496230857,-4.487830529058073,-4.659924656663733,-4.512300701913917,-4.490378009118706,-4.975729549027825,-4.730944458969552,-4.469405827538026,-4.620719330383078,-4.67233765580068,-4.563885782198364,-4.660222599277095,-4.683936451953979,-4.712284335769445,-4.710739992000018,-4.595686477368294,-4.7038148767442705,-4.752030245201452,-4.810956522842349,-4.571500114065748,-4.666532124508487,-4.634391422806335,-4.6805968748510445,-4.8156724717319035,-4.733873279613412,-4.710933368526173,-4.696132375145176,-4.649243866562546,-4.665300169259816,-4.885650319374374,-4.5832077849372945,-4.622804347127296],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=9<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"9\",\"marker\":{\"color\":\"#FECB52\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"9\",\"showlegend\":true,\"x\":[6.9928740874625,6.91413678055739,6.904731155959622,6.888976622823119,6.852681549875931,6.700720637148796,6.9898345796119585,7.0930955345898195,6.943922193941522,6.894657437963748,6.8257816279463555,6.893909644327573,7.101830347980702,6.953606162428113,6.955068811674982,6.9236060195416975,6.816972893845069,6.870473692811504,6.95773854090191,6.916107120423838,7.111439332523172,6.99582991432401,6.914085880917073,7.037554992337155,6.974136097272979,6.86287367083183,6.8536513566991335,6.888464329092154,6.983736214621999,6.810297831082859,7.014228740487741,7.059025415764483,7.215417033245447,6.835684590229801,6.9185711602598,6.975302247976498,6.817919946439385,6.926418334170561,6.8590341069378145,7.046655390251612,6.9898895718612835,6.817578593006235,6.86722928903633,6.763642455203163,6.9044166166683505,6.867857716980763,7.032387019285405,6.907872721400104,6.964212750080926,6.945295053018668,7.0270616367726255,6.997312018940919,7.088702368377576,6.871625703974916,6.957320968119437,6.889989879760336,6.858369683443802,6.971917141811687,6.975319653326796,6.998596740541671,6.831784129370282,6.815008986919777,6.879239441107758,7.019788861634658,6.916191395200007,6.815160028122945,6.858128387051353,7.130114724044577,6.804349673365086,6.994915587947224,7.0499668065718835,6.870281315804514,6.979692246805406,6.811054148669618,6.997869567905007,6.927373168155769,7.0437230409220195,6.873635915168447,6.938437390855329,6.872073701754351,7.005994570997851,6.817574095396582,7.038709882647367,6.952149979311551,6.8903630355280905,6.860864624725092,6.9564234138471495,6.848170803508714,6.737162953348508,6.902353599252894,6.931743981990505,6.808439697932293,7.172133820683665,6.815161083605312,7.083299937797276,6.807929318962981,6.685061981855185,6.843604608899667,6.822528371511777,6.856047844720601,6.888790873675984,6.9030427487717025,6.809049432948209,6.937698615742938,6.974940600279544,7.071195635828014,7.088281608346975,6.953745005487624,6.995689385475302,6.928950931384023,6.85466617982544,6.919170858082649,6.956292259349821,7.082306257764537,7.044241994796513,6.912752006517596,6.820773337541955,7.046947248328547,6.960605242393368,6.760739833368527,6.923344083254763,7.078880337063562,6.900082933754152,6.95748077495652,7.008130041383829,6.810759564205155,6.973116243518831,6.90742084296542,7.01302568170355,6.956096666713948,6.9231573375470425,6.934417653144624,6.986490804914587,6.795397193349424,6.992645295932825,6.814166185180529,6.924174608126436,6.888877171449166,6.9621721696765215,6.77480187528958,6.993853161791534,6.888597138640381,6.83400146028559,7.120874532691447,6.9996835523213985,6.905720580783718,6.9126485135448466,7.026914820805317,7.126757779123025,6.801611079571829,6.909443452829452,6.914811540803017,6.946603489381871,6.924549476775,6.924234280408877,7.08361115407872,6.924083285452171,6.944263447780556,6.875464507776057,6.846903370514294,6.9563325583906295,6.9054699897259235,7.174797783121681,6.860013360081764,7.028739676282655,6.78083324125666,6.894083964795524,6.949551364400771,6.944982177956577,6.934820872853532,7.104859827979246,6.841355423149507,6.926192789081991,6.815462643561392,6.978688995027803,6.842603925233327,7.104809991800292,6.950064959068264,6.857848906023565,6.962827155427386,6.906564598328903,6.944761421736509,6.825569060304354,6.9323188548171775,6.831370354453413,6.893673561334487,7.1182253033969225,6.966248421222088,7.023210019135614,6.945213809376611,6.844322644446397,6.770059142145409,6.75125763297587,6.981240337702075,6.794991848004958,6.760660509131954,6.9569944668545824,6.96152295788354,7.109884564913678,6.779111451612379,7.023406591323579,6.860124448112629,7.080040705826598,6.946564656009554,6.937031163958888,6.860324844737052,6.97886875269647,6.904276435776002,6.799512246262013,6.960393646381748,6.880822868452241,7.0721230016096,6.970821558752055,6.877759040640749,6.998010440743214,6.671245220446744,6.9153140645815325,7.138054821727117,6.649308328584049,6.825317247146056,6.888867358580107,6.7621833744124755,7.024404246657692,6.877126872169483,6.920273012358263,6.861285250747016,6.914183838279801,6.88464473345674,6.72858104787674,6.910251479907215,6.892163787418438,6.947969210188646,6.909677166787867,6.91074240430039],\"xaxis\":\"x\",\"y\":[-8.476408314430216,-8.609954245627426,-8.515553803871772,-8.424835330311973,-8.386013737980106,-8.39051245389708,-8.38471404986004,-8.414498258555561,-8.651208534717036,-8.372211309211055,-8.457369215190296,-8.408480582157358,-8.302426152811957,-8.50787653948541,-8.324916178228637,-8.483626576664859,-8.428001899753234,-8.465747315822366,-8.358236384582218,-8.472262157640682,-8.48728173946862,-8.445442144052894,-8.330006239176479,-8.403009409701664,-8.510917729230068,-8.422281306712346,-8.401742832049926,-8.51001498114263,-8.349916656784302,-8.393775093178125,-8.63569306159436,-8.315088106954397,-8.456820242343417,-8.450542211765297,-8.33630070920582,-8.342155397247442,-8.323097496043166,-8.368318621821928,-8.506122508004102,-8.471189296579789,-8.441954196850238,-8.562298087761516,-8.405329745280582,-8.246170128145,-8.438654714851234,-8.384147922954153,-8.395415002073987,-8.343769259093229,-8.296614227060571,-8.301663599868117,-8.454639828969261,-8.420328847716496,-8.467406007390721,-8.49462456313354,-8.446453915430263,-8.39509775124855,-8.415577838449881,-8.370262821727733,-8.37790083992392,-8.376768555056756,-8.470259505150604,-8.488834881511416,-8.239001410210905,-8.424433468534243,-8.378059527501206,-8.496307104072857,-8.346035982617368,-8.483196705687345,-8.503661839861511,-8.340018777297699,-8.266676484416546,-8.456289222894144,-8.487211069640624,-8.415351668813885,-8.341671380977811,-8.27285059065321,-8.520085804435372,-8.504634588734428,-8.419542741167577,-8.355364205038772,-8.295887023941004,-8.187806151014248,-8.593457748573353,-8.50376069520135,-8.370423637291442,-8.384055081339078,-8.460409611418886,-8.379709874311407,-8.368576575964402,-8.437128828199867,-8.359219825642773,-8.112211714774041,-8.403813835599209,-8.508026468282921,-8.311098343507913,-8.475844097211835,-8.444272238191987,-8.46276206219886,-8.401301827572661,-8.402362505149464,-8.229155947289167,-8.429840440993232,-8.364798887388112,-8.429785968310785,-8.479697884725415,-8.4412192454896,-8.388610003251669,-8.445517153545957,-8.28738407990221,-8.50301997879652,-8.343964589543146,-8.38638100347263,-8.491944750232149,-8.239173680120123,-8.503608875842923,-8.399078079057979,-8.315409556440414,-8.577063075622853,-8.432898854304437,-8.454199240889318,-8.472201130822649,-8.265088980752529,-8.429469938632694,-8.47008399595514,-8.33766688421495,-8.427015242981192,-8.391250843411713,-8.651461443163484,-8.298150121712787,-8.490841735108512,-8.405661391735471,-8.408224026533166,-8.456981972841957,-8.397513199264093,-8.26322519818373,-8.235565350556222,-8.373146042792937,-8.531846231667569,-8.537442963124725,-8.531244027549004,-8.358603712498738,-8.443865330140914,-8.364993953467403,-8.44146964257367,-8.236493759616208,-8.356074069483839,-8.534016386475374,-8.294128320196618,-8.369900453560675,-8.405560899916251,-8.20661884207897,-8.382267416253752,-8.245371966229726,-8.360075483846222,-8.469564751834843,-8.440394478445684,-8.447411212461475,-8.556678067382935,-8.243429368593237,-8.372714044348562,-8.458280239638361,-8.353404706103099,-8.457997077072832,-8.508129435455107,-8.348517138569996,-8.42321651428458,-8.37551467671825,-8.256135963910094,-8.55583079627257,-8.565355582859548,-8.324748450191237,-8.381340479818371,-8.352372436141358,-8.412676047316372,-8.261127134205625,-8.400958612908132,-8.344000545090646,-8.476253088051871,-8.543529095539894,-8.388103169251911,-8.412432628260774,-8.113597845627728,-8.34995061270319,-8.426460252901709,-8.42813371789693,-8.37101567991133,-8.39440818124466,-8.57449327293518,-8.399469487666217,-8.51965417275097,-8.385069372269117,-8.569828717167189,-8.45194301928941,-8.371581370167334,-8.388057638752164,-8.562583585001518,-8.367085872775032,-8.298027463232986,-8.431509462988116,-8.338072143367219,-8.559805094481984,-8.634201501161995,-8.42801498791626,-8.368990509236006,-8.532074132119273,-8.462005441991492,-8.392725905473565,-8.442144143813772,-8.488735576376618,-8.367855926815098,-8.462087637833257,-8.446813188981485,-8.389035079460564,-8.524705582063314,-8.385719281381268,-8.454718100625406,-8.250252605461645,-8.38375510711808,-8.641300845987727,-8.490003987896618,-8.43641444708459,-8.708039108714852,-8.53565032431283,-8.211013761651165,-8.475915151015267,-8.26393496629278,-8.372570607744668,-8.381499105275976,-8.338653087055318,-8.504725136493956,-8.366939536889847,-8.414146014382492,-8.263560221193634,-8.313274943271981],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=1<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"1\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"1\",\"showlegend\":true,\"x\":[1.1337483447339574,0.9792466023548707,0.7519357234005501,1.0605260834669683,1.2047198561483543,1.0267091274344935,1.0264339513454313,1.1557121203335643,1.2015554886001354,0.9207481813504792,1.116977454773484,0.9809021729415901,1.0368967235549744,1.0519144973271877,0.8839829272128874,0.9626426456010889,0.9890568432616937,0.8861161359242787,1.0128278569304818,0.9328037234146144,1.1115882192969633,0.9781317994699505,0.750132638515325,0.9118669760793183,0.9866823193807539,0.9276196732455896,0.9901615249859429,1.1478759098954945,0.8819906520874592,0.9827799114376342,1.0085695691858034,0.881433461678939,1.0725697422994054,0.8709716667702713,1.0957491711926441,0.7987889795761658,1.0159752704546348,0.9374179142325421,1.129632086548367,0.9370184765983376,1.0806823740208658,1.064937700513066,0.9482822427349996,1.0197074249862155,0.8897245866384221,1.1616239417081888,1.1032470090457671,0.9785088928487213,0.8542008406836583,0.9638172332031344,0.9697706629427532,0.8629490496753004,0.9923774985756186,1.0219812463834064,1.118009050809199,1.1667258260585625,0.9173270234108966,1.0783679469244618,1.0344641682393754,0.9394752187759187,0.9760769329533453,0.9091204552625932,0.9679827369023078,1.1132734427956976,0.9363883572765259,1.083238466974473,1.0779029352934035,1.2627922939960947,0.9093983132537605,0.8499622840630858,1.062848898094277,0.9943100872115583,0.8705892527240943,1.0072649747685996,1.0210176539498845,1.0309142686181965,0.9354406426982764,0.9449373026743093,0.9629648163607187,0.9197356447476689,0.9828846595524098,0.6605625468285283,0.990094820283821,1.0184803800419102,1.0849619503588088,0.9473141008525526,0.9923224090959278,0.9585672240977047,1.042988052014058,1.058441186351895,0.7811722239650871,0.8352426053054167,1.0224109079738777,0.741811686474404,1.2347752355122674,1.0777787391739708,1.1217061629275527,1.0563814739605024,1.1218516332519337,1.0453451844051822,1.0271969379542065,1.0710360728809083,1.0213543727605205,0.909556312092663,0.9729984193435642,0.8868092519233574,1.0652639636332628,0.9855767180774557,1.3243175633989572,1.0177637560473871,1.0299088773448324,0.994267212866105,0.9785552388093014,1.0244211540101438,1.0222503897812778,0.900354662991474,1.0449871348553283,0.9395751706395622,0.9574123098558603,1.0714386308796793,0.9451810200152835,0.9409753722832778,1.044652467404951,0.9073959498422941,0.9633769732528665,0.9766424695244421,1.0939731189646025,0.9984023159107629,1.002978118428605,0.9315908756830512,1.0085205835073614,0.8517916919978656,1.081000747346544,1.018541969165001,1.0671133372729267,1.121181608124161,1.0064996483200053,1.0482633591976223,1.098818714074445,0.8253785831692316,0.8641346529080286,1.0018664799014925,0.8907066907283274,1.200772290544885,0.9005887580199566,1.0575449819566936,1.1378946033142985,1.2011872226978388,1.014992556011437,1.03992876001367,1.0194700961725687,1.2941926764298404,0.9474748982969592,1.082008436914204,1.0451601132823947,1.029845455919006,1.0151111334108929,1.173680767215163,1.1126866366219907,1.1319485688160398,0.9071052320161055,1.0597352933346689,0.912047904400787,1.0872948376222509,1.0569207728541021,1.1228093125059935,0.9378284954900432,0.9269076829787831,0.9775943313299628,1.0750346167594784,1.113240424947179,1.0735259265830934,1.0217937013721812,0.8732418460873036,0.965335046321063,0.9569271057592975,0.9752758979870642,1.078947779799621,0.9557102372549683,1.1194638616673012,1.025761668108741,1.0107636298083607,0.8549907160891277,1.068476574115963,0.9043689032024702,1.107125663415816,0.9452881320914246,0.8424763197935249,0.9505144639962516,1.0515549252110385,1.026963443474659,0.7740587592938839,0.92395973087394,1.0703843317222101,0.897493649240007,0.9057442776440707,1.0403795469041042,0.9765521736849141,1.0285108313280018,0.9260031428957044,0.9456733382351425,0.9070592499015526,1.162237685096818,1.1666554120128019,0.9066369968835112,1.0660732408895588,1.0026443690803863,1.0299463673704226,1.0573963704916265,1.0258826326003667,0.9581294620891284,1.068905366877178,1.1024204205958767,1.0668216272556834,0.9234330992608535,1.1401974627688711,1.1319072246052015,0.9836537305687498,1.0475464819787634,1.0341757236786988,1.0710861453446037,0.8867984924063419,0.934004168581128,0.9072399484348546,1.1552302265025274,0.9161333703244554,0.9648233921823942,1.1683992360590887,0.8749617180268464,0.8833083451251964,1.1476372172996596,0.9562126193679706,0.9786100933641825,1.0587082361338227,0.8315960172392085,1.0141656402238453,1.0945788447516145,0.7992865880774831,1.0097943845450275,1.0250816309521538,1.0779407793784148,0.9878950319757321,1.105576787088459,0.9953432273687329,1.0138421032958465,1.0693943978867588,1.1177732751518539,0.8424996048524914,0.934481622953939,1.1296823465988748,1.0865337471329901,0.9505924771903949,1.0312123760902066],\"xaxis\":\"x\",\"y\":[-1.315862214529939,-1.428819899838683,-1.3648226080261043,-1.216877718195188,-1.3076629219434843,-1.4029688023180436,-1.2272570356786279,-1.2309798016604216,-1.3954654607026893,-1.2941693436837711,-1.2994688947075095,-1.4015105402847374,-1.1991983910797241,-1.310438132567909,-1.31537781329264,-1.3494654663372638,-1.2832974175328442,-1.2376808756044704,-1.4442561731448227,-1.2819704332944324,-1.2560764905874677,-1.236019599054909,-1.3355312572136044,-1.3217817776833765,-1.4896011892513725,-1.2731803003303857,-1.4027093519687797,-1.2025737903323799,-1.2038061502862831,-1.2125427931484365,-1.4669190798207161,-1.300599852722475,-1.360729636720994,-1.2289578271556034,-1.4099781662963824,-1.3685032007612963,-1.2282476062523588,-1.4403102898850635,-1.4488279309172345,-1.281760789383088,-1.3382188152955086,-1.2587240867906004,-1.3574346255850362,-1.1930577325850846,-1.222699394314175,-1.1320862526159496,-1.232284398497908,-1.2042491163772349,-1.2699503065030386,-1.3287348454309515,-1.3425903856216754,-1.3727792662859983,-1.3851080539249754,-1.4136887313433686,-1.1348719255164696,-1.1846750843086598,-1.2325083715089769,-1.1866199109549584,-1.2992267996375313,-1.2672294711627954,-1.1840093711797832,-1.1069925977918444,-1.326394609741333,-1.2639031091925248,-1.4579064287734245,-1.219526979235603,-1.2822886142558703,-1.2037681794354942,-1.1277368845093922,-1.350363710745073,-1.094944639703777,-1.2067008254126563,-1.2579219660799807,-1.300691499826765,-1.3040571779971175,-1.303843973184341,-1.2711831191397982,-1.4468601728847974,-1.2135550807863154,-1.3731202557149205,-1.3364116129474597,-1.365758817670591,-1.2413714505716187,-1.3092830703712313,-1.4349482023985634,-1.2558240717095523,-1.3452149869565355,-1.400133776655251,-1.3061587509197412,-1.1576227108422035,-1.4257133518209733,-1.276123779578815,-1.3822718744225078,-1.3350663446117808,-1.3363464816675035,-1.2871965428708938,-1.359009734152061,-1.3346430459867904,-1.128757684292804,-1.448698172887119,-1.3090547567512392,-1.2879818684508764,-1.3594537880042947,-1.3342977899711443,-1.3603029729317697,-1.3263765969105221,-1.1739805769502814,-1.2683692430033915,-1.4352388892430126,-1.4489469826204076,-1.4389981293228924,-1.308691155224125,-1.1396108088783412,-1.3676572848713675,-1.2311245795694887,-1.1955490637756712,-1.1501643182590269,-1.416806061952818,-1.3855602067431578,-1.3354362348177484,-1.266082151951966,-1.34534338590346,-1.2947783504599535,-1.4534426378317906,-1.2197504399700019,-1.2320217263810704,-1.2802861093913214,-1.2978448393919184,-1.0756772965991939,-1.1127868511016377,-1.3205829812162682,-1.3393949662086286,-1.257777454898569,-1.3514207893587935,-1.452281705282457,-1.379573837540501,-1.328151389757954,-1.4560744975264888,-1.2280489345809305,-1.1813634877521564,-1.0894603722609069,-1.1794799378858105,-1.2482468400763573,-1.2229275860238926,-1.2335211082240614,-1.3867235223211205,-1.3680854556712876,-1.344801510978694,-1.3439146158619573,-1.3922481942640328,-1.4103829332475075,-1.2783874384080944,-1.307014212614129,-1.524666979866471,-1.2363597320629542,-1.343802328416532,-1.4060477097990254,-1.2839125161795895,-1.3523279097555374,-1.314142586369469,-1.3915599643994856,-1.0600083487821255,-1.1389182754396698,-1.2759879851028584,-1.2976799962732553,-1.3488328154280371,-1.253277763877077,-1.321840854860653,-1.3357699623241945,-1.3144893320210524,-1.2915570520724464,-1.3192714060431903,-1.2475512579809636,-1.272099435549173,-1.2517819135658579,-1.3056359751973632,-1.3339269899191766,-1.1057049761672693,-1.385865737434434,-1.2111527264807307,-1.2781263345735197,-1.2289171151983158,-1.368184046619392,-1.2438724498181508,-1.3526199428780608,-1.3108057728281353,-1.4497529087483012,-1.404545445194267,-1.0804274988510003,-1.2423994151068238,-1.1354976859212038,-1.513554346489601,-1.2066121299646164,-1.2701364602684417,-1.3038997917319957,-1.4767879945113578,-1.3729671533789989,-1.2856428381612057,-1.2809898377342563,-1.449814902363904,-1.2930406999183404,-1.3481427216444415,-1.3314509264553773,-1.2220664137980195,-1.1534998998679487,-1.5191460974802238,-1.3455302523684365,-1.2914807392921757,-1.315455955376,-1.1383186861231156,-1.319378855816041,-1.2086503002533528,-1.2461360623218096,-1.2762295966600667,-1.4192094294758462,-1.3739509246224648,-1.2614746063064888,-1.2304549914391771,-1.235044543241947,-1.3631635598859253,-1.2812838170140897,-1.3191349299089281,-1.4225454892020286,-1.1564201004353625,-1.198225859436486,-1.3843123050337893,-1.334787671273055,-1.2216186798332478,-1.1871210592166326,-1.2997208011797992,-1.4788280806609073,-1.2593999465758938,-1.2362178567836148,-1.2569385562201574,-1.2123367623442727,-1.2590870644343783,-1.1177790652928346,-1.3563163763627573,-1.3698080059895186,-1.2103078310788649,-1.269108964410132,-1.1831245535300965,-1.3809885573007947,-1.3575242231351978,-1.2624085598058081,-1.2033265085545284,-1.174810772733738,-1.4139085086312746,-1.3938138022056403,-1.2237747600526867,-1.2495745094689734,-1.2446981088881648,-1.3854481761851756],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=17<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"17\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"17\",\"showlegend\":true,\"x\":[0.04776932008283538,0.10848142278394146,0.07399661604411686,0.11342096058269485,0.06623110274443603,0.07300384651316816,0.37523314696152327,0.3151943715612331,-0.035995044496347606,-0.07591382142337699,0.19553673166412247,0.13146338356168022,0.20357240852091502,0.1507693116426842,0.031811459622398855,0.053943198970565764,0.2023799389604773,0.1262905582384041,0.12200507035756915,0.0753230732409534,0.18345552732274623,0.23304172833302705,-0.11121593961882503,0.047037039285949586,0.21695324952558584,0.11261141636808114,0.15540183849577457,0.07102692693120186,-0.01065068979803735,0.10775019673557293,0.10180341078136856,-0.1595684082916881,0.1584244784897736,0.13857824108856773,0.1440445136365989,0.10201834419104457,0.08560036606981068,0.1467200053018753,0.18273355149148335,0.14927582131927003,0.1816287062209001,0.05435936406887499,0.010036913405977968,0.1008062423893711,0.2119898898929681,-0.060016653298055805,-0.002551571528364771,-0.10452809385709877,0.03206354084228437,0.04747298789696631,-0.08370142263079838,0.10776983468409193,-0.0907872715170423,0.05012908231909813,0.04178517917892473,0.11179824060155236,0.12947565327217553,0.06194904474863896,0.12204859034329736,0.1862572435348986,0.08573843615065062,0.0623368822115721,0.19410091262990403,0.08632538818704197,0.08632264058516982,0.12411668669801863,-0.05619928501287011,0.3010899037240031,0.18509070128293825,0.158726483196322,0.1637767685294655,0.15196203456008917,0.023528019581464096,0.08802979608799577,0.2003047016274107,0.14810590729065112,-0.13848881677496042,0.23002594230618661,0.09575550405153824,0.032615903558329676,0.26990422742098574,0.057770737327987196,-0.023523106143566647,-0.06512090006302215,0.003645101699161407,0.07662175753810022,-0.029882399852017433,0.15227186187197964,0.2418343318697722,0.23358408386387935,0.09833030352449597,0.18648434802038544,0.12771832672698805,0.12326964440202687,0.17900046019709134,0.08488419038261648,-0.018750273498708045,0.031221447260523824,0.059456912670244264,0.00903090319356395,-0.05626837103499016,0.09420374735970902,-0.03764794967677207,-0.1381886944471339,0.10868244531490276,0.2490214570201521,0.06688747474716766,0.20211730345664758,0.1663164050800239,0.16211658794924155,0.09630824713153789,0.23782455854643203,0.07417033414416592,0.11287588456636105,0.25619901358986563,0.03674518814512295,0.17476508644906943,0.09372792721358024,0.21355462428102268,-0.1052123298548173,0.2852575794791191,0.21074277377057327,0.1614610445282332,-0.03555879570283865,0.006361447424078237,0.23638519618488046,0.02113627176134522,0.20504002902417695,-0.0037009169734044944,0.0506451621271181,0.08517700099156064,0.22510348927829998,0.08601831100171116,0.14530151792575147,0.19445667011065068,0.1886597264486991,-0.10242975715295399,0.06260422265230993,-0.1039854314294677,0.14194756718502732,0.299810614482956,0.11175192899759752,0.14584343074004952,0.07617914981980119,0.0550329209030842,0.2544787226277901,0.1535476260875694,0.13079637285259113,0.007154339670049553,0.15910040433091358,0.06529195591307045,0.1444903454413539,0.12521217058916323,0.16314031892899694,-0.06298888606082453,0.18775477911336957,0.021099608746951617,0.16627749465071212,0.038833056136521896,-0.04319151842257413,0.2477825714595574,0.31568729326928213,0.1613488815891303,0.18768348489346692,0.09666060861326907,0.13839496900627712,0.2509867000745767,0.06436901697064892,0.14973829202018735,0.12079779078823272,0.1158964520755528,0.028259975862089004,0.006234239068250505,0.06796728208300673,0.054335641925211293,0.15213266301383632,0.06680420729512059,0.1321098246930963,-0.09820177301507518,0.3232111503984816,-0.011317433262448606,-0.03714390107361895,0.18700037455555324,0.014223190840880903,0.18693793184808277,0.07809021688521334,0.19270832645457275,0.16304054433812443,0.08469653086715283,-0.08912247328593886,0.10886739640946039,0.12747182156306724,0.11104008319460053,0.12609432353013453,0.20871397048763343,0.041070926854135575,0.03941068506497193,0.14837021068370804,0.13116029496007725,0.089908601158055,0.15899308414117921,0.22306318804800143,0.1286371431286789,0.2566398254006337,-0.19562514332135122,0.09438497079259592,0.08766553025782628,0.04356604120046241,0.03306299877652312,0.22247152903449713,0.2882582815384942,0.24165103697778778,0.19264169076552062,0.16305418590241047,-0.0018273582448224968,0.20256897301866228,0.04723418438599098,0.13867161203819117,0.05811411566471394,0.044604628953359815,0.03949597337738585,0.19195891227395634,0.08681146122253597,0.04832283032843079,0.1624575388321508,0.1473750288237679,0.22937833740188573,0.18784324787735024,0.33868235413064834,0.1174339904163304,0.10885376177630765,0.34256237589686434,0.17797737693277133,0.11454959549794327,0.1972454186369742,0.12077668841693961,0.01350252148996739,-0.06929259863460213,0.1396390653099172,-0.13607408565888682,0.2681765342256841,0.13763210824581776,0.11613538083360588,0.16124649348057082,0.2069011253945725,0.04637793194229103,-0.12276210537607832,0.11238702290751883,0.10284344567161656,0.08812545202083877,0.19846685105761674,0.006603349076726439,0.25984413940991746,0.13165954414392345,0.0949723464586545],\"xaxis\":\"x\",\"y\":[-2.270457198734203,-2.4927851617919754,-2.4835022044102426,-2.1530917735859414,-2.2219268231992633,-2.1821434685776495,-2.15354906478924,-2.2998009630873995,-2.2414985576299427,-2.3426042168214622,-2.211862875123002,-2.0826915672030006,-2.098223672389044,-2.391431354306036,-2.2916622999885896,-2.1715409582825136,-2.195386904472541,-2.2778225522825646,-2.488539383400635,-2.222067542418949,-2.3166134260886286,-2.228572489164928,-2.1750875439562454,-2.2846354724482922,-2.154968649337709,-2.113998068214833,-2.2156819089081328,-2.2718398394986794,-2.2455533640625673,-2.148749410015374,-2.2611238349440725,-2.2067448066677517,-2.3039054564143777,-2.1924515401542846,-2.2023587816766104,-2.2426535774016996,-2.1468214393107683,-2.1573369335370214,-2.160096111915323,-2.252525640865577,-2.416594921113042,-2.3956632479979296,-2.204161813919149,-2.1317388173698104,-2.2634593364527866,-2.3844483656883244,-2.327407671761424,-2.193459133652455,-2.225627347043846,-2.36892084506456,-2.2985200223147193,-2.1191065796801567,-2.1869507332777673,-2.288532652349118,-2.4400523477379243,-2.190962339411393,-2.085945717230392,-2.100981812724015,-2.11681063368796,-2.1855765000667184,-2.323757139770333,-2.1252081344787244,-2.288209641452208,-2.2284440795610956,-2.413402664525495,-2.167934936350502,-2.353410905885528,-2.2247987298365643,-2.1357979989457014,-2.2071473396396093,-2.3758717585115847,-2.183375208705079,-2.3754119346974196,-2.2262410869898703,-2.1566302242180124,-2.507500765974454,-2.377027646188364,-2.2438036013848346,-2.1626480446514744,-2.155214243315684,-2.2740976088057683,-2.3003112611012,-2.2211166981778763,-2.440720424094573,-2.2923135184667314,-2.2239779213837485,-2.3298517690977594,-2.2826578898551633,-2.1728142848858014,-2.2372257941705103,-2.171426094956224,-2.253876243905841,-2.179870574688174,-2.164454681163409,-2.161041841622273,-2.3050831825386444,-2.277874707155844,-2.36032155751697,-2.3252043776367746,-2.283176491843831,-2.2679797125048333,-2.2899616511704752,-2.221760850136161,-2.166477897370869,-2.3821834407218345,-2.370049203975368,-2.307711969118269,-2.3897121610297094,-2.156647843932816,-2.2958018134562224,-2.280891359821838,-2.133706361250316,-2.2512158143403926,-2.2677238268209328,-2.0528968440582775,-2.344041997169843,-2.401909045366472,-2.2691727473935126,-2.00349599343843,-2.2720537822856803,-2.30617695716679,-2.246360256709349,-2.2888825953063257,-2.488018143369235,-2.3572901289526835,-2.1526880913205835,-2.281423156236562,-2.2767587738455264,-2.2187042066418394,-2.2842904300494475,-2.2396748390897385,-2.2869808779653473,-2.104848386034248,-2.1485254169205956,-2.383413762825733,-2.246160369763768,-2.2535721370031974,-2.250315393071074,-2.3860666581547116,-2.425693669181373,-2.3951013322828762,-2.331940788307741,-2.2416260875399048,-2.0437532846558795,-2.2170521921852813,-2.1758482759692,-2.243871224125967,-2.4383170584406133,-2.322953769196309,-2.253404233871682,-2.3573046227320598,-2.407401916455371,-2.309363320912135,-2.3260275111970947,-2.1677014923437437,-2.3225285685255,-2.273898435538406,-2.157616178016294,-2.4306355315123738,-2.1834644843664783,-2.323413424890478,-2.373410138222666,-2.2070710000618394,-2.2957817596297665,-2.2586740226120705,-2.3263922567947883,-2.085606895105307,-2.2622400498590665,-2.3297606348496207,-2.1727227152449355,-2.0134493217982397,-2.3899378052014497,-2.168620065923222,-2.2323736871953703,-2.2407432888592966,-2.225609352662182,-2.107492896994035,-2.3423335074804634,-2.0927523252621514,-2.177409069700953,-2.170009573523449,-2.359772428274371,-2.2494108775100172,-2.154937367740416,-2.223495713599125,-2.0154982003842496,-2.2808860967215514,-2.3847768696844702,-2.2335795096949567,-2.189907677111185,-2.2888996200514504,-2.239318836698418,-2.3171398560473273,-2.277101161327738,-2.074866187292856,-2.3889274183384757,-2.2282729612939693,-2.141213368079646,-2.3926610772669354,-2.3031565636650586,-2.3175851755999073,-2.127932767450866,-2.3314414774629437,-2.4092423543353183,-2.3551780357689176,-2.2670922449862503,-2.2137109760794598,-2.2585883932111988,-2.3292902518959098,-2.0841255343233307,-2.2553885134504883,-2.348193776137391,-2.3497238763279897,-2.183783459383938,-2.1628755415955205,-2.322829657033667,-2.3924368945921297,-2.292048282454815,-2.28330056585162,-2.3068426934029302,-2.0759287247481315,-2.0704131184095225,-2.2432436013298083,-2.4922891245564234,-2.178963399968061,-2.3052429986284024,-2.2658289677116183,-2.193236067802447,-2.3778174660166256,-2.343944162964268,-2.2994861946769123,-2.144372422165936,-2.469968309218548,-2.2565431170658568,-2.3179853938427173,-2.30653056004034,-2.2081240061850242,-2.3956182650493525,-2.364795161541074,-2.4016472311934915,-2.297801276208664,-2.3989928733197905,-2.2718393814202775,-2.2396807316333835,-2.1218061166206947,-2.502995060914298,-2.278814343327635,-2.335023833950086,-2.297968974242116,-2.3198821627185002,-2.2986652707010395,-2.4117746740429844,-2.4827759880058964,-2.404553668705239,-2.203636745870299],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=6<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"6\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"6\",\"showlegend\":true,\"x\":[-7.267437983997604,-7.214779307013778,-7.475043213125976,-7.361384762169621,-7.25214305345033,-7.127285489183105,-7.217754517224135,-7.193019436647176,-7.212202455144335,-7.301513428781536,-7.271101834043522,-7.09628651901596,-7.4516763915393245,-7.274937186847789,-7.4043264617294176,-7.536674211147173,-7.288253261977941,-7.244685013944568,-7.298375060109075,-7.439243404934559,-7.157229149212889,-7.265172443502271,-7.366578439502868,-7.24724443737627,-7.205029985015981,-7.265738381005597,-7.351015697262532,-7.279573138955685,-7.154432509381213,-7.319501997986006,-7.1989180173250045,-7.385401609264331,-7.147818950558768,-7.346485724072327,-7.288802072701621,-7.381105555114803,-7.271515436468143,-7.2302023987001105,-7.369039051480402,-7.36175542190233,-7.347918925038382,-7.122261040900809,-7.266867626430001,-7.231832035752237,-7.300700016461053,-7.3793965600423,-7.277708496636477,-7.302378384572733,-7.344478020109068,-7.184920581469621,-7.3444606859418355,-7.384202021888342,-7.198920783476942,-7.272868149499312,-7.3642038558646,-7.3215015246290065,-7.310186107034596,-7.183996819664043,-7.400744426706224,-7.448996037284979,-7.219402994456849,-7.295876455559322,-7.470070030363335,-7.273003461422185,-7.227669235646449,-7.114745321955937,-7.399444567623174,-7.391387620223547,-7.3265121480950715,-7.232159582717083,-7.333057238800358,-7.481536013045854,-7.388999816923957,-7.375886671710587,-7.439297656078694,-7.275111578885249,-7.2730676114244845,-7.228218270342966,-7.3738093778939735,-7.236803022266713,-7.290653428656435,-7.348638924098138,-7.278687575354392,-7.19072949022794,-7.368800718506444,-7.356010532986301,-7.433164390810287,-7.274156730250472,-7.283763597098677,-7.349750068158837,-7.4225318456016,-7.4557482453872765,-7.259874411091226,-7.260404683253607,-7.298136464968416,-7.27549846944027,-7.2688143961788585,-7.383181602424647,-7.496321542002424,-7.190162785149095,-7.087729967162971,-7.383292593479936,-7.27104827912742,-7.289136776035959,-7.2483789601091395,-7.373242437232238,-7.374033007688249,-7.3535381686259536,-7.196382687405742,-7.314213342245826,-7.35882530657267,-7.224551680882201,-7.489601060347068,-7.307453307359949,-7.382477175838943,-7.107619768684106,-7.372551253120293,-7.297330175699753,-7.372221799143732,-7.466915036613576,-7.389987169253852,-7.328751973943403,-7.335622646754038,-7.337562824117264,-7.390918260095343,-7.486941870182817,-7.347966962838523,-7.335959885396762,-7.298181457627159,-7.25743794302655,-7.247258309740606,-7.433957980541654,-7.233924551693363,-7.443816050481161,-7.256880321869535,-7.361014073575057,-7.324825167412119,-7.494931201125334,-7.196226129642608,-7.25457399506961,-7.373340197775375,-7.426513153252439,-7.190863527015413,-7.3744566926301625,-7.165648309122915,-7.2073765126039975,-7.28120770863938,-7.1989083758833745,-7.399594650457666,-7.343394791912591,-7.382692395446666,-7.3687994778222,-7.229049230411727,-7.353990848909956,-7.458200636090089,-7.175023885832551,-7.176171947013049,-7.257608599107964,-7.329543087004445,-7.411188500763257,-7.227464375657419,-7.279340893642619,-7.265601577746868,-7.322004173065466,-7.231031573977432,-7.268694406698358,-7.11947923039898,-7.563147698441068,-7.393070091285229,-7.1569093616270525,-7.398135216877598,-7.369779820668688,-7.2355619112050436,-7.226239129041826,-7.324301697603458,-7.305806654029559,-7.1354093767761,-7.433043430192895,-7.247175346438737,-7.246599802481279,-7.287985222365651,-7.362783547186714,-7.296183537468346,-7.558314784305235,-7.382932779428879,-7.4991017163849465,-7.254135717100982,-7.301771410709475,-7.1919045264541746,-7.1908701269019355,-7.251374228122256,-7.289894275709006,-7.318717687470227,-7.238829247197493,-7.363233236268502,-7.332677935738473,-7.278648313390487,-7.387877841580854,-7.332455735488088,-7.263647336733824,-7.382678017485381,-7.209565414484563,-7.373600664217478,-7.343253949230023,-7.497537085825292,-7.556743720522285,-7.19939842700714,-7.235116382537179,-7.266241210967851,-7.303815799086209,-7.358720703399059,-7.203111981701529,-7.378700399667615,-7.355134926271315,-7.520285574301656,-7.363682108310851,-7.4370943364451865,-7.308199491928074,-7.385268613952416,-7.364838656943484,-7.26085885609139,-7.306222161491092,-7.38070991101025,-7.248831541685177,-7.303031213643288,-7.243437668794508],\"xaxis\":\"x\",\"y\":[0.3306141781242147,0.31577370003070154,0.29032240540065557,0.4886887777455444,0.2890203892915262,0.32961303642964856,0.08460681548370597,0.30552590036568567,0.34959233075369267,0.14864727890595586,0.299397212332017,0.21013972374211443,0.31594661166508947,0.17258617561978318,0.4854352895815668,0.45027227655066626,0.3317750255145706,0.03089299585272734,-0.019761116525163158,0.1520521389857443,0.072202086299502,0.3630841174887386,0.021989571690379628,0.3464461389327813,0.10239756441437056,0.09203977947100428,0.19465529612440913,0.3413364573341596,0.37568198377171846,0.2005329402722573,0.32986476751514593,0.32486621916653186,0.38796242299765027,0.22798556074057758,0.45104041622099844,0.3208410995026328,0.2770367331817291,0.48899785894526204,0.13601474070134914,0.17890439027535054,0.283301675709738,0.40161434591984024,0.2688934325521408,0.2549480793389464,0.2177043741664155,0.24895154366477548,0.25923801355286014,0.2286473361438864,0.1807490832814695,0.00696563872693684,0.23840725962617026,0.14715280666137326,0.3465184588715174,0.2493710344484687,0.4337224922722741,0.40559546499444865,0.35076266074361545,0.2819616231826209,0.31836858213258973,0.4638379484634601,0.15889377905815405,0.14559886220470755,0.13176969853578488,0.13816561859801482,0.35249243752992415,0.14852927818393924,0.3884175808114589,0.252489165261627,0.36465949046000734,0.22463086051538456,0.3230351683046764,0.10116972179213612,0.10647560997807293,0.03372262401541007,0.42148895336695114,0.28823905990132515,0.35018196256726775,0.2663314590279227,0.1889262447488072,0.21299366397644032,0.4946061703814671,0.288839696376043,0.12854516958406895,0.32186084688264155,0.2354284821889043,0.3760684270310445,0.20872672117781885,0.3877388748610023,0.2395066408892921,0.2451657140627717,0.2156809382599198,0.4599921021375537,0.13885342438366047,0.13509205863508075,0.33000057163032137,0.2610784505590282,0.3503986378240156,0.23346525510953278,0.13748108025880576,0.2032612893241913,0.3885488667095872,0.20845948979496193,0.19675758254460562,0.23566645460671934,0.12552873843853654,0.3363186037573706,0.3293528216797547,0.2836942244069242,0.23389097373623075,0.2531705920096058,0.3189279529389611,0.3554961981417313,0.34571717659910445,0.25148869812587976,0.2037766514686823,0.1757621163689237,0.09930248521598453,0.17177768106790378,0.3279105417918702,0.5035491830793196,0.09731204653684894,0.20663785868355466,0.4887252477426751,0.278091508858213,0.26643562249727615,0.2703093536308441,0.4166331991723111,0.3538727406442349,0.5538149518958964,0.4015389758719284,0.2707125090266977,0.1466736966093422,0.25768613133575663,0.05254181261717758,0.31439335894725434,0.5761331706424003,0.31618240098452466,0.25851017236708107,0.2552000073041265,0.3103865983211903,0.24032705957193767,0.37331716264591325,0.23961511602319963,0.2511073311532945,0.2463391272958268,0.41105946251491887,0.3377880147876581,0.24581275876248296,0.2424271424305352,0.4711588501405942,0.3611177353502483,0.09833201989355245,0.2695688278354755,0.17257795105627355,0.33288656687143037,0.23326669359576965,0.3444117568341002,0.37600146619558267,0.09142826602922258,0.05166034857365584,0.2886605095351434,0.32365485725197196,0.11776065668914304,0.30453440085292327,0.36979074741469,0.41485246160492395,0.3677892930849597,0.16402767059118095,0.20731082644010218,0.24310879115479941,0.2308996457995856,0.21794397614835498,0.35850707533080406,0.4725278690945395,0.20458942539375782,0.15851223285056637,0.32144318120594984,0.2560956288224526,0.19719013228987756,0.28340328029288997,0.28959230783970613,0.3865304276356553,0.33634254333614105,0.29830898169022607,0.3705155004157593,0.21076065321897056,0.2103147256949136,0.15096795832128196,0.3321707978424964,0.22404361390407293,0.41323262786050763,0.32110709423468226,0.3450173909047485,0.41265294956334997,0.2792329541568408,0.1294100076216193,0.305809640911077,0.2696452613214608,0.26577855723720306,0.30718236933493304,0.23986370982033184,0.12484328053130736,0.30469418855769786,0.1757937213568223,0.2010647351943285,0.1409983370722099,0.24819265214139644,0.11249337556725317,0.30239698755704164,0.2853380021305871,0.3417645474115786,-0.0023528123827173952,0.1643103903880634,0.1831309168471706,0.21029578572819682,0.06437446293265675,0.20782565010604637,0.30069408679545995,0.4894752660883265,0.28076672957486404,0.24006513704091154,0.36539431720384763,0.47123233316813246,0.279049037028555,0.2821807696919452,0.3325695514245515],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=11<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"11\",\"marker\":{\"color\":\"#ab63fa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"11\",\"showlegend\":true,\"x\":[-1.343568214326784,-1.5324329817919362,-1.3104059130365775,-1.43186840613152,-1.5011883225524054,-1.5146761459472478,-1.58617248094865,-1.5063412166852934,-1.3220139389188272,-1.484642663278034,-1.4482650421563992,-1.3836051256109425,-1.5171871970084885,-1.3721576046476756,-1.5051440748627474,-1.4740669567748046,-1.3031145171928147,-1.6092375443648141,-1.4796063392117733,-1.7210857737030891,-1.512241970388952,-1.4879970689810926,-1.4505293421804197,-1.454726608309426,-1.2355248959083784,-1.3176633653351288,-1.3113557863017624,-1.4616449694215423,-1.4393438365441749,-1.536178951211671,-1.3864936973207997,-1.6503391206735658,-1.4495892382242055,-1.1956890139900995,-1.580396520940824,-1.4923355823493607,-1.4094558539271334,-1.334537317679869,-1.2826807950305688,-1.546710778300335,-1.2890552116889105,-1.3441074108051552,-1.5320787357706194,-1.327745705283434,-1.4052600649944873,-1.579396247310354,-1.4991054582428678,-1.6293015498759993,-1.447063383242576,-1.307302015390257,-1.1874289811934857,-1.3776983783923875,-1.4622707479512262,-1.6481294200790417,-1.3640802917727273,-1.321001765935122,-1.3756025643247864,-1.4919197261504602,-1.298778205245146,-1.2865460088148464,-1.6300936936949422,-1.4100010214619672,-1.4375242407014066,-1.66376802513292,-1.591156456283934,-1.5608057780239744,-1.4610607215944593,-1.5640452059986527,-1.5679713224166951,-1.514009957112679,-1.1998114316688984,-1.2657608976009649,-1.5652991223803772,-1.2343427640319145,-1.5836076509680073,-1.4892464455931875,-1.6047169836667794,-1.5378796664617989,-1.332687885984173,-1.490567725469312,-1.463948805574548,-1.4506629109976241,-1.4190514670233492,-1.4800443529868936,-1.3978768014145306,-1.4780189121180547,-1.418495287010126,-1.4160129653855111,-1.5931567560931668,-1.4028528734326364,-1.30641389243543,-1.4038439144870531,-1.4847290734887102,-1.4037811107998663,-1.492002134629527,-1.4766068029875985,-1.3879480500728278,-1.4316380161897877,-1.4336375534105847,-1.3948520495522152,-1.614486527732061,-1.5175901771591396,-1.5651073772629696,-1.2929675719288947,-1.424930380839007,-1.4100899430952631,-1.3263892707972509,-1.4466462406425982,-1.647266530333616,-1.5712780197492655,-1.2811412881181707,-1.4659102699618307,-1.369316649069475,-1.3029263946092213,-1.48903505822934,-1.5253110247004737,-1.4898318272135518,-1.4497147509284625,-1.5295945851074844,-1.3380261736440222,-1.414496872306774,-1.2707217691213908,-1.471098576920054,-1.5469374041125628,-1.2769154159219138,-1.444795111793521,-1.5118760349119285,-1.2505380179110168,-1.4935545517926136,-1.4411607177627879,-1.3882653007557355,-1.5294007722252954,-1.297001227264166,-1.423838178611876,-1.4416564140721733,-1.5067058222961158,-1.4059362921117893,-1.5443323238780036,-1.4572050233570597,-1.3855051571732924,-1.5504917895735373,-1.381466026216657,-1.3638727208035848,-1.4635101429037298,-1.4389512551175616,-1.2927432772770886,-1.3965683315238078,-1.4139767002982133,-1.3744729578531876,-1.490439779714926,-1.47792004469056,-1.4625063033841965,-1.4996403620070746,-1.3237340565532985,-1.348863444000693,-1.5269930889175318,-1.4530330825350621,-1.392118262401374,-1.4741609129905173,-1.364403087680358,-1.574645958939985,-1.5184407676335852,-1.5789868035516812,-1.449747696900925,-1.6305750341304452,-1.425025942660843,-1.4513943304114183,-1.4703146789059587,-1.6600427088817913,-1.6012170623018023,-1.2578742814627872,-1.5203596836993885,-1.5472204241028582,-1.4181603911378988,-1.5434842041150771,-1.3637513878590284,-1.3775255507071444,-1.4005544072441067,-1.5263266305441476,-1.5693409220763164,-1.3363092878657565,-1.4336590617058684,-1.5993369270875777,-1.452302629332054,-1.5833339828767985,-1.5158038778827485,-1.3646465256783125,-1.251794427277444,-1.518652728624055,-1.5789910948577581,-1.2562443119380466,-1.2972006246331689,-1.389491930913228,-1.369871249470416,-1.5432396226831429,-1.3955910164271448,-1.4839963324042618,-1.2901862666068007,-1.448435602923418,-1.3161556129718661,-1.3467973870251924,-1.3187284596085789,-1.4649274431273487,-1.4865057685354113,-1.6521483725377055,-1.441867616859258,-1.1722535962154208,-1.2620814757152756,-1.5839482098305562,-1.4840816999259623,-1.43666243157866,-1.3834975323838543,-1.590824620588394,-1.231858891333457,-1.452090286644728,-1.5657026896752577,-1.2768622284450055,-1.6919417014407996,-1.480328510082205,-1.5829059494622415,-1.5510819785628316,-1.4316895217439112,-1.5316641832501008,-1.3607886680797858,-1.4602984573595326,-1.563225695480788,-1.4822895270729621,-1.3729424488810642,-1.4948900784996693,-1.5865060007846101,-1.4059569130345075,-1.538990891809917,-1.3670125295852378,-1.4462440108343528,-1.3480260930832941,-1.4876599915467965,-1.5573328427422788,-1.2775448460547312,-1.5300276569833557],\"xaxis\":\"x\",\"y\":[-8.086514400319707,-8.050201698716194,-8.212081673004764,-8.085452090673664,-8.161415688777,-8.222084225070247,-8.139381872368622,-8.235731002684924,-8.19070605297919,-8.32592543188889,-7.970587090718724,-7.947664838064771,-8.067077006337785,-8.08529242330494,-8.078439675676773,-7.9836570694604925,-8.003782081466746,-8.069349775726845,-8.080967287623228,-8.15499406365185,-8.101625185765693,-8.023673233261356,-8.162316367302509,-8.059318403446474,-7.981418171042974,-8.057733396862753,-8.186003726653816,-8.095974385320632,-7.997419818067258,-8.071689883474097,-7.921643092176881,-8.158585993406975,-7.872502900157394,-7.875656849032243,-8.123956713947686,-7.942073670374686,-8.053156683568243,-8.108747333263446,-7.7899338868959465,-8.142185058819786,-7.898131408681389,-8.126689419469871,-8.26745496013343,-8.028815583094875,-8.088804706456544,-8.241286822435214,-7.958539901295569,-8.181541281642213,-8.04956607647721,-8.019906528730141,-8.128697168599258,-8.12907626171877,-8.046485707154647,-8.089407875191116,-7.987746355353526,-8.07132995065803,-8.059365832512073,-8.029127825179126,-8.034498370437415,-8.029750185838685,-8.125249374586025,-8.01176510586272,-8.09234184313541,-8.028618201261581,-8.10665269847952,-8.053951004862034,-8.095295798631751,-7.991311390866831,-8.046833745498517,-8.119946999363377,-8.193384168944789,-7.928554986829625,-8.108845320792462,-8.003909307594453,-8.144838315559282,-7.955002717809398,-7.911151022672765,-8.123690083324556,-8.001357468204052,-8.094240708679932,-8.12010710817302,-8.21231305312006,-8.054093068194668,-7.9133502046820094,-8.08995444813987,-8.167278500958153,-7.996830483339955,-7.988815823148174,-8.110993667341774,-8.241889513761187,-8.244859323180327,-7.936891168060112,-8.104044377549362,-8.177659605919967,-8.052305518064204,-8.20211330094954,-8.00572155072098,-7.996694901990004,-8.192622274339788,-8.175010288237658,-8.078298729190601,-8.098347228042101,-8.07856843534465,-8.051301324476057,-8.226829797793199,-8.023786229435917,-8.184358610928074,-7.964817718954026,-8.015041462267657,-8.019990362783927,-7.992889340576925,-7.969855869923265,-7.9729302198003,-8.038719108232659,-8.15399266823453,-8.044386859392565,-8.158347519356418,-7.943214326755645,-7.919341770474926,-8.0275514398085,-8.077071774077723,-8.131436076084093,-8.024997521847048,-8.20762755487215,-7.958561351289617,-8.057452182349623,-8.105913066568858,-7.9643502591540365,-8.142164740171063,-8.072799450301769,-8.22810560977499,-8.071002411440533,-7.932778524462866,-8.017489697258492,-8.132555057694631,-8.047329113288578,-8.109103529746866,-7.9526818657363405,-8.188858359422774,-7.962121139816165,-7.83652187659318,-7.977469197923072,-8.11495516753112,-8.164822413341033,-8.08894693912939,-8.158084480322714,-7.9922799412791825,-8.210116751180458,-8.021443627785011,-7.953050092111004,-8.17704555417649,-7.875470510805657,-8.105872760577274,-8.114209257028426,-8.081538234851694,-8.280636433566398,-8.044760822355968,-8.010693586613584,-8.157158606537138,-7.952423337862266,-8.063893254532521,-8.088314506002822,-8.023704490972074,-7.994986444831225,-8.065285716299256,-8.005806306118135,-8.187591827423848,-7.9561888635479665,-7.909517093882685,-8.204024581378647,-8.106425840092607,-8.16230552474051,-7.96668394911295,-8.121422422665,-8.011425291711248,-8.06883347691807,-8.10847058891432,-8.212941225576015,-7.950600241029377,-8.075317872886952,-8.161868034408284,-8.182114825749334,-8.17914536854763,-8.161741568156545,-8.150295354470721,-7.9515005069834155,-8.020204528271275,-8.04279301946125,-7.956647078193466,-8.073973333880184,-8.154435071284615,-8.16964248521324,-8.15825673613989,-8.026557762250778,-8.07931957471141,-8.029530154662083,-8.056869449282948,-8.117421003807644,-8.180233961874938,-7.871011779437494,-8.007409493330018,-8.08922933401978,-8.131799189580583,-8.014741687772046,-8.11378178580325,-7.919302551625101,-7.966473750952365,-8.19966865786856,-8.12230852547426,-8.181421005992972,-8.053501805210358,-8.166234439465251,-8.09567911334581,-8.120089195673856,-8.160424225559293,-7.973036057111782,-7.9570913537224275,-8.12292643528211,-7.898554482360205,-7.910958518695742,-8.14909536891229,-7.996955534476222,-8.286752068181649,-8.020111116270169,-8.003255305979266,-8.041584732659471,-8.074677700450561,-7.8057266577104345,-8.075997703677356,-8.062553084877583,-8.128679937634491,-8.015913339251442,-8.011764333354153,-8.086606899834262,-8.070764299788095,-7.8847111768491684,-8.171854065085157,-7.882939933657181,-7.954873274436667],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=10<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"10\",\"marker\":{\"color\":\"#FFA15A\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"10\",\"showlegend\":true,\"x\":[0.1864385252036127,0.07105904952198902,0.16972477620308365,0.07898184899230432,0.22971804159425152,0.06380965251476307,0.144874891200607,0.07095373078920272,0.023949400716500008,0.23401668683356489,0.03133321010628258,0.3171541522060429,0.12562890990085052,0.010751798016311598,0.06290147734643198,0.21679712200481716,0.09864216482961673,-0.0006998504677583339,0.0949407274063268,0.014405459000449788,0.2794891450546604,0.054627984725892115,0.16258789051311354,-0.09367505688992817,0.13266204981793414,-0.018568203342427952,-0.015776414829854868,0.08801910808469926,-0.020316662113790657,0.23555456789215914,0.029662105470704234,0.16827869782582214,0.08327759002920845,0.03968242449830792,0.05059293550867779,0.041988775364818945,0.08457542784962103,0.14364491831709808,0.1632271962165608,0.1711097062398383,0.23869786088387465,-0.1389920113919979,0.09988828238952224,0.09213233575130383,-0.009920461229943944,0.16513689855437771,0.119025769175098,-0.012785649199872517,0.03600400391947099,0.11871031932342563,0.3027728925021531,-0.14930836107049167,0.02164644065162412,0.10618360382911851,0.2130049807265877,0.0834567890671768,0.1421457654903848,-0.17481665878072833,0.24378512419388007,0.3342615939040583,0.14216533124842443,0.0038199959815759105,0.008615526487315964,0.2807760907476605,0.1510037383455568,0.2932970791456725,0.24007088502239957,0.14267253672670466,0.03865777306439146,0.1458745406143321,0.14071976111711088,0.09193611869338089,0.03233953092516498,0.18750273344037655,-0.010529656797501619,0.2636154501039881,0.1767697243408547,0.22454070159899298,-0.015908908764087237,0.21011149825576408,0.12185483456490688,0.05883367923045017,0.25337135463165184,0.17799869875823582,0.07662639448548876,0.07815931861985939,0.21319375216139394,0.21464100028447108,0.050071267342419346,-0.04725279398078966,0.06985174357261813,-0.08632532663263867,0.05440569750553091,-0.12098864716957158,-0.038894663797616524,0.233678730704448,-0.06707186111898633,0.10015243163925175,-0.09661207698507154,-0.051850501792371856,0.1216882716973334,0.2913885929928456,0.035150144615716666,-0.030976578704285163,-0.023423299321236546,0.05963717259745756,0.26750287554840435,0.09184966752331084,-0.01743290889283644,0.11088254654656883,0.30774571004365303,-0.013253854886920977,-0.10969421133861915,0.10386201920322144,-0.07007946246357524,0.11467041129838448,0.2055882797710255,0.1688129406346628,0.18460575415388286,0.12674035791744054,0.20475480114179595,0.2090859683769936,0.0437313042314976,0.24590491689355548,0.07482414483020387,0.04744829433031724,0.0698484049659702,0.09212402625760313,0.04729783408870137,-0.011738908917122912,-0.01029954311480906,0.19399483703752635,-0.014587792701230146,0.13490141820741883,0.2115112664824296,-0.07092469438507187,0.36984454206070005,0.11055386205825886,0.00746174031592077,0.10943045103516418,0.12127771510558272,0.14051770289086135,0.09593899283038919,0.1547418896389219,0.16330420237945958,0.09960080613533734,0.15652025668325031,-0.011473516183143392,0.21933062287774535,-0.09137121973030596,-0.009133677057408862,0.25181993214072346,0.17378165782160768,0.17049428564281655,-0.07081196197926362,0.042219699081412654,0.005362940012477974,0.3466704458203672,-0.004083530491184373,-0.04199987737493138,0.14571259266577896,0.01880950052445013,0.12373160036057917,0.0667488399983575,0.07188086378587666,-0.009248120968006757,-0.01089602366192717,0.028346031397606775,0.1433406842747061,0.09810183931575231,-0.0421498567036091,0.25985062730519287,0.1766930298522495,0.21692183535749288,-0.009393226429039683,0.24857218300620917,0.02459585196167123,0.052812698877037045,0.1906947777573839,0.06969196954363745,0.12397043587252729,-0.0183813462144215,0.06069496277043285,0.24500641039201956,0.21598415461249987,0.05179549363258069,0.10185899598236435,0.1881432223915476,0.12396427772833248,0.08196167091827564,0.18692759864847502,0.25336245627925635,0.12165649393363376,0.17805559426594542,0.1368650916681614,0.08421023560449255,0.05647280156845684,0.0028268452296028312,0.017792163783226095,-0.012813851998315931,-0.04598807005282257,0.0009493943044516645,0.22059790013464078,-0.00718859000918691,0.06930464944155831,0.14999510596820212,0.16842152984507922,0.23054904356752345,0.17453029398808584,0.15387673147874492,0.11648187899451318,0.20443235202276033,-0.09627011910090985,0.11834419107183482,0.0706832235619175,0.23474034240453287,0.3274668233821776,0.04534837042470149,0.287666366984544,0.053610824683369716,0.11207747150258265,0.22813773280368416,0.081680491224888,0.07870692320555463,0.16306060424607002,0.29059065390119354,0.0744447053714486,0.13360591700931984,0.2030485740098382,0.09763772831859374,0.05220004674411659,0.052297352262124806,-0.04443069633805338,-0.02283052953432499,0.062327041294683506,-0.1434794391895522,0.16487461555537494,0.1414299016998488,0.10813525085810771,0.30759387296463525,0.07656524828643956,-0.037800715129578805],\"xaxis\":\"x\",\"y\":[-8.633684968040633,-8.575982924051232,-8.786018224093665,-8.786833586776641,-8.668447496818091,-8.596765006592758,-8.678343500004129,-8.666426772166952,-8.715212865574763,-8.763046424731467,-8.713690794931024,-8.882222442140494,-8.750990451584816,-8.538342206107004,-8.636765550873598,-8.576446945152066,-8.672656648111888,-8.72677193641426,-8.758533773470235,-8.777328377101345,-8.70491376278885,-8.773362081865024,-8.563415024252079,-8.757474180557644,-8.59876301803705,-8.764679930040218,-8.747995914323877,-8.658415164011474,-8.677433567047157,-8.774631967806929,-8.575043564006934,-8.83510942465153,-8.74293425662707,-8.820036267031801,-8.658347341972208,-8.79822702741231,-8.657906050549192,-8.682050828683536,-8.461522243102031,-8.752665825043557,-8.846719947578885,-8.687583277415735,-8.790846986867415,-8.774482187618965,-8.71112898767617,-8.681048416959573,-8.595077999735413,-8.832004059511506,-8.544457493573,-8.766172070704819,-8.868846181455186,-8.65440903877103,-8.656043016701043,-8.588854319551238,-8.641182301796018,-8.599081117144872,-8.7947983110189,-8.6017395494777,-8.548869858268729,-8.610455563681278,-8.492241548515143,-8.792551545392303,-8.619982421577417,-8.674733541992422,-8.727521347628098,-8.714308122816222,-8.57884601078889,-8.658220636694377,-8.73157944885937,-8.75457524972243,-8.709788573443483,-8.628243715622128,-8.74019135957934,-8.716696270959112,-8.410922612161636,-8.64937598556906,-8.701641731700795,-8.634148286952504,-8.917986452974565,-8.696344809843232,-8.815602643184135,-8.766277252129818,-8.803764952554083,-8.590453264308051,-8.65888246852983,-8.784986095760962,-8.606677185397412,-8.647922803093387,-8.67484438969722,-8.6926238919948,-8.65159016220071,-8.637782402920331,-8.61303117395854,-8.668776750114583,-8.594765004007225,-8.705015667263051,-8.75255427521406,-8.691363769283702,-8.702448997604497,-8.774802724904465,-8.598310103927437,-8.809064976330355,-8.715807976232872,-8.755338790569022,-8.720051723955718,-8.732341831895225,-8.722948414362172,-8.729121713239522,-8.7414189237974,-8.71961513143448,-8.629214116863771,-8.775922627708232,-8.821692078009658,-8.868567651493976,-8.686893188194047,-8.598440283650378,-8.69665117159248,-8.666396524854594,-8.560465165472708,-8.628557612586839,-8.91360273300973,-8.69849304629673,-8.911046819233139,-8.624754893463551,-8.72946349337139,-8.733683798600289,-8.526640114276923,-8.783179544078592,-8.659131752117707,-8.746329566447292,-8.694816098988555,-8.68328922521172,-8.63317243353375,-8.514164279886852,-8.703947222716437,-8.414505096572748,-8.569965809534443,-8.680364754442914,-8.681337394779307,-8.806440319807411,-8.544584419717932,-8.619216482975517,-8.776313143381614,-8.784786372086247,-8.735167548336168,-8.762012544200475,-8.692167830359377,-8.64440209594096,-8.826495015433858,-8.658470652325365,-8.640622586967547,-8.753136032643269,-8.820225130848021,-8.8639476551963,-8.758959539553938,-8.66332653172085,-8.64325286168787,-8.662938561949858,-8.836038487167478,-8.620893196207396,-8.652365713426686,-8.693252631064642,-8.807261919657527,-8.700851491518419,-8.718148916211279,-8.80043050443319,-8.664353558115543,-8.582538137880501,-8.717859439932594,-8.913266535139325,-8.644029859859648,-8.647183344626972,-8.77803869371179,-8.602050152344074,-8.75261689215076,-8.670036455740323,-8.647681714764914,-8.67554372094744,-8.65832798595996,-8.597825947802498,-8.786877149493694,-8.776806268666325,-8.710784222647565,-8.565335352722949,-8.649900655817051,-8.70332433529649,-8.570766901664255,-8.79381520679249,-8.873401583263208,-8.756530040702597,-8.618975706585346,-8.517814010432383,-8.584035317193146,-8.811257017169405,-8.675006927035502,-8.845299154236486,-8.681345049864785,-8.927957249635625,-8.636255776187168,-8.86983015098237,-8.769353670454684,-8.725369272931271,-8.735954060150792,-8.857601782266729,-8.75396879032877,-8.677516616110935,-8.667645863668604,-8.665892971510848,-8.690574540932367,-8.785995302735603,-8.695393012787369,-8.758095833604918,-8.807196784068417,-8.664314944262278,-8.693425154570656,-8.684662884726073,-8.654531779926561,-8.688530797196698,-8.526850523855911,-8.76897678764755,-8.765545734220076,-8.687474939667137,-8.671453408223856,-8.807891298571578,-8.68014053935251,-8.6374615363155,-8.681470763957066,-8.711556799845232,-8.628655864962143,-8.790334948802068,-8.779275228958667,-8.650391934374365,-8.623340031651425,-8.509592025914605,-8.689754651601499,-8.525242135191423,-8.617120966740508,-8.55290073040568,-8.642511904307089,-8.702372377324947,-8.604919749240787,-8.711924361370611],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=3<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"3\",\"marker\":{\"color\":\"#19d3f3\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"3\",\"showlegend\":true,\"x\":[-5.854397396225087,-6.001016286154547,-5.94108648097571,-5.634569385762653,-5.982416909435177,-5.980913338184736,-5.919402662001747,-5.968332034427788,-6.035593784462637,-5.901008867937557,-5.917967457208203,-5.848678992416736,-5.762429117251172,-5.795689756558771,-5.951083251477868,-5.930882956955244,-5.948359331227127,-5.974830305402373,-5.982007236747505,-5.841813060425584,-5.946195453579784,-5.711839356312041,-5.973657072848305,-6.0292405758581555,-6.004323598012096,-5.841267479189791,-6.105044630510925,-5.788307139749988,-5.8899112335233,-5.762948118400339,-5.898427955383768,-5.9506554874274515,-5.778799327854144,-5.857678923992092,-5.775503290137758,-5.7000589067764045,-5.88774034654602,-5.939226345574743,-5.8055836558376495,-6.0606147808261275,-5.939374700833861,-5.867656594696235,-5.901529545580625,-6.000958065942075,-5.986949338589118,-5.875407314708743,-5.810546759317498,-5.946528309449257,-5.753442927354606,-5.7187272738305195,-5.877077571398771,-5.844032926715761,-5.9656030190285625,-5.839526212620773,-5.826720531478529,-5.9479416224290045,-5.93054827146671,-5.882456892071277,-5.824262672270095,-5.862457923663194,-5.875213628454606,-5.9670441414031306,-5.796988024501013,-5.929163614050912,-5.975875889657502,-5.995807260990231,-5.8782341555742965,-5.730983479431463,-5.927162123879984,-5.873005378416301,-5.990624737498784,-5.920878956210453,-5.8768596812619025,-5.859076322998907,-5.804661494001277,-6.007993731021133,-5.979390769155766,-5.8103774200942,-6.069333287621069,-5.862457398402188,-5.837028099511822,-5.828683880145862,-5.886972374280246,-5.709053610517381,-5.977911511286317,-5.865560307495559,-6.09175188700974,-5.792994943787625,-5.902044922919878,-5.89893014374731,-5.7932012929742385,-5.943970902602687,-5.964756076511217,-5.949571087586941,-5.7630777280475405,-5.910219917522061,-5.964635396478138,-5.835643521995463,-5.784029015846959,-5.946457582810954,-5.941679476758294,-6.064438146126911,-5.854069159932987,-5.970812113998927,-5.957759811888768,-5.840589350039194,-5.936271661444834,-5.893664844990429,-6.087445185972725,-5.810938951760527,-5.826394643389826,-5.82052003687293,-6.04646620706721,-5.785589847319291,-5.829022114654493,-5.843510581344682,-5.763239250152992,-5.98502162773517,-5.943410948856732,-5.814880428938496,-5.982579781737219,-5.9780789981929106,-5.996439860743284,-5.949149155771895,-6.018023228753351,-5.867241730359434,-5.8757591511548615,-5.7790909317495816,-5.915600800693236,-6.107740447780891,-6.038594218994137,-5.947631113972242,-5.8442614189024535,-5.991065712075582,-5.849013581857576,-5.827884920547693,-5.786509155810742,-5.814952741127246,-5.812395678391918,-5.82747930934045,-6.10065996256265,-5.843725041238889,-5.777045784540424,-6.072114081355149,-6.040397269742666,-5.847087897026634,-5.965090131448634,-5.912157609603318,-5.925215471380571,-5.989792477692911,-5.839781550052797,-5.911290880070125,-5.959437878314005,-5.8502307786646,-5.991766344793386,-5.745596522066365,-5.988115626037311,-5.927206091062825,-5.881012813726422,-5.929127973976147,-6.148943885986442,-5.897861560659024,-5.9095194867325525,-5.780803250678438,-5.9041067530382065,-5.908033488515117,-5.93381531017774,-5.971652063252748,-5.908452678683858,-5.7060348277972235,-6.109999144333278,-5.900812196391182,-6.071017178554994,-5.801091551362596,-5.807319340147349,-6.028418969919725,-5.798369833832465,-5.984393033397614,-5.8598636669473,-5.96088588233208,-5.917266771430303,-5.80795488608479,-5.817744382238667,-6.166545147487997,-6.035781936001206,-6.073720348558125,-5.953500200943664,-5.968792959979767,-5.9180342275018925,-5.989420365023719,-5.995230967857246,-5.998071765999748,-5.781678442732573,-6.020451187954129,-5.759834018222181,-5.887067491278973,-5.912901475922859,-5.983829890537846,-6.114659399487033,-5.671802050718321,-5.818767330515854,-5.895733181244325,-5.773210867709885,-6.057356207583931,-5.90894378256352,-5.9287956689257015,-5.74540653253088,-5.855691335010646,-5.9820696916107226,-6.039424514502595,-5.836787860005798,-6.002288283415479,-6.00858391334422,-5.655226171277972,-5.798131057568135,-5.897508993635027,-5.733244871859606,-5.916584414623242,-5.761432932985534,-5.902415476204251,-5.969581158356107,-5.893384508760065,-5.875934771937616,-6.030007813878002,-5.941969580891797,-5.762099052397294,-5.926711874893286,-6.00589160604126,-5.895228471603518,-6.006747319939416,-5.8171956764129975,-6.003366228968949,-6.181872002116339,-6.005003125502736,-5.937076958586311,-5.79584992727509,-5.792114563712552,-5.969162892112436,-5.896987406994359,-5.8061265667528765,-5.868010503110097,-5.999697266501529,-6.005643400438439,-5.981921644478111,-5.890441266332631,-5.751829574064161,-5.802731700853511,-5.893426337906678,-5.884403903783169,-5.86255368987104,-5.961763346880438,-5.921886798543302,-6.072748139993773,-5.8776479986895,-5.834121815868106,-5.86096473859609,-5.757986910951778,-5.927734451294741,-5.8878525080345385,-5.960967978878725,-5.855296715036735,-5.8689402928914385,-6.070671172101286,-5.8666943810223415,-5.93892987407677],\"xaxis\":\"x\",\"y\":[2.564198101247167,2.390906898249511,2.4601855494161917,2.4057763686807574,2.4369534469575718,2.281259579614937,2.3793681331465866,2.252052945886504,2.463265791680883,2.3543615740970982,2.506768663153526,2.3408412478024734,2.299256280612501,2.4692108339455485,2.495010043012789,2.4101017725051714,2.4059868068421135,2.276680753612288,2.5272624914226602,2.4468959154023655,2.407002244668211,2.3509339350988454,2.4778104074453804,2.3281180200915523,2.3717907999466106,2.500939823969633,2.391031155736666,2.1753150104557517,2.17049579180841,2.4099522087071024,2.3253664780268286,2.4444790941693406,2.518070546881536,2.1922962105573123,2.2939814269035192,2.5688569974886812,2.325539059760113,2.343050872214533,2.246949723368245,2.3910747844852636,2.2808715089566705,2.331494853822856,2.371031428774519,2.335711739244522,2.442655607923197,2.349802241594299,2.325157954769407,2.350639745662317,2.313089286626425,2.4962438793461854,2.5349036113275556,2.2396465955624283,2.1803784782140165,2.3844901356047665,2.1791126515825145,2.33619117741666,2.298311071487484,2.3557999705641373,2.304258941335494,2.5214301200406566,2.5363664130843935,2.555234285724723,2.504275569431835,2.3495238062697137,2.404543108827233,2.3846679125992827,2.4258134318270272,2.3502350524877267,2.301160258698801,2.3281669573371206,2.589837364933279,2.3026363524019913,2.507816202263026,2.5446051919792527,2.4498442449245337,2.3581160109695527,2.489263715032917,2.413701969154988,2.3684547508057032,2.331594322414774,2.323475585687333,2.404852640333029,2.388107734196948,2.3751439564116184,2.375705100211399,2.302695015081667,2.4428126709983036,2.2985638563256705,2.572160925631838,2.473650200471239,2.2871455185414753,2.365077307229103,2.5376708099427048,2.487480687981585,2.2563499128713276,2.3620802010388506,2.4072461617982293,2.3374110142818405,2.351306492400723,2.099080935070277,2.350073139428708,2.3085783840825913,2.2806294597005174,2.392002674485663,2.5214418224765045,2.2559194951207635,2.4358987992392165,2.4107920667927836,2.2622914249206456,2.3671808015151785,2.712350364431561,2.2729807975716523,2.3491544891524527,2.4931803880965298,2.3220065298910613,2.4678704649899794,2.474042968763314,2.3821151812477677,2.2587158386800503,2.455479849981514,2.3618019228375493,2.3366324854160125,2.0576661987159426,2.2957694123565062,2.408354687973248,2.3600023659327922,2.5918177890245877,2.401673385287455,2.444714793859069,2.2119415427165325,2.254314055735285,2.4494567081354526,2.390203952221388,2.2145101531783533,2.4900286423705698,2.4324461272806,2.32083480575476,2.495135620293105,2.4495415040787525,2.491715037955474,2.3574329180343807,2.3933247266681716,2.390778774770149,2.360058752981654,2.3301794172254033,2.4986495534386277,2.306431837704953,2.371131735586222,2.226189846440953,2.5834468413871634,2.330681400395385,2.521679082058312,2.3760349952667092,2.288253736411331,2.2554167310656057,2.485310072972269,2.372441807015611,2.372174081482073,2.5661190999803565,2.3131369734283593,2.315757690208228,2.5293869990647937,2.379180845931766,2.3974692601189074,2.3305246573337617,2.322330567794473,2.4067291021092085,2.454945802730264,2.4553927636490958,2.3844879416235942,2.301893358227415,2.4197342513714326,2.3405874995927025,2.4079596859358015,2.4583946216539867,2.5457347389738794,2.327466000540904,2.4354593468992403,2.4827520005886745,2.3902581874478437,2.435271573164444,2.4948543960989316,2.5216762235747856,2.36942065229636,2.571903200720371,2.4571439196120646,2.249938381121724,2.368247768623128,2.2916599062162453,2.2834157347456814,2.3279909804242465,2.3473695816149793,2.4154521291112427,2.308229741085862,2.291387333513648,2.423409462273749,2.3971413566064594,2.497775771511658,2.4251494366533044,2.2535079944727485,2.361431939868027,2.3485835250436327,2.4440391435382955,2.364357974910665,2.2865094213885553,2.559946170753364,2.2747927286627276,2.524862946348717,2.458142352340756,2.4018347192204836,2.414079306543996,2.5951963646677436,2.340237310972011,2.4879560182901845,2.3454840356894833,2.3510439462788093,2.376987058868365,2.2241488149402997,2.4409120138042577,2.3003754474325406,2.4346383751620375,2.5510982569874407,2.431978094875792,2.386348088387276,2.3699962757408564,2.2470050423357275,2.3562081703177733,2.526694916422107,2.4291702046426664,2.52385064759666,2.432444514993304,2.3900933755286,2.234556079088686,2.469998917405828,2.537837622863385,2.38833273131492,2.4758610511596446,2.3176826440336336,2.363126707429558,2.4945819983049384,2.2035206390152102,2.344707880548296,2.308696111138897,2.4785977604395706,2.3334173231087108,2.140571530226885,2.3381001190913753,2.4366562865253933,2.304502104717808,2.2421901992081548,2.3103843619055398,2.548633196699811,2.34275354930958,2.420572020992788,2.3270667797332667,2.418046365544002,2.511610849478445,2.3634961768202114,2.3480573720340825,2.4672375782069524,2.428743141805867,2.265145262413055,2.390990757146616,2.3080928521811517,2.348176261377931],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=19<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"19\",\"marker\":{\"color\":\"#FF6692\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"19\",\"showlegend\":true,\"x\":[-6.774043083584032,-6.7013417447013275,-6.554200242692146,-6.983412353294745,-6.717925696233928,-6.737603219533005,-6.7783262763566965,-6.84971845811669,-6.608127266745551,-6.687348393135922,-6.702891568442058,-6.648682271652459,-6.518237064819902,-6.714480438298094,-6.85491439120601,-6.887036021382764,-6.803131128306319,-6.896734902608264,-6.72657500470722,-6.769270241136235,-6.7193627061739125,-6.5705747353150175,-6.83599657292738,-6.629631383337985,-7.085950995024263,-6.752275893377991,-6.691260642676871,-6.8238077874314405,-6.755904237006976,-6.692982791350005,-6.65842544111319,-6.672831048092197,-6.886634687761236,-6.798448121369527,-6.905375163404754,-6.594923042670599,-6.680855697399708,-6.930940707130446,-6.726348983680673,-6.557291769090839,-6.715151074176337,-6.672217625888049,-6.8136353794024656,-6.71359435515656,-6.6632336339658655,-6.651164300928185,-6.66133888878151,-6.853002537531321,-6.81650646324217,-6.837997040008605,-6.886024222052369,-6.579814430091291,-6.798725765767835,-6.79115730563514,-6.680018128860456,-6.776922178623996,-6.843283299696162,-6.660524223988843,-6.840622495996733,-6.925343354277768,-6.678738440463243,-6.687756743986181,-6.731222866595908,-6.824962727400215,-6.632113682665167,-6.801010995593851,-6.711772219281282,-6.599459652771483,-6.678046366935823,-6.680227522631375,-6.616592437720235,-6.71664736183481,-6.945008779015118,-6.8863365121436955,-6.790568310006454,-6.9240486627727424,-6.879555324674509,-6.532684992445987,-6.597879887148504,-6.924375186418441,-6.625504696947698,-6.802292195886554,-6.625104432149982,-6.8378282790360245,-6.909152581510478,-6.7640388710699755,-6.747486559809398,-6.7750969455182695,-6.827196655371062,-6.669401752112843,-6.856533856284937,-6.8057583536991535,-6.650639386064943,-6.694036428467098,-6.6819954747450145,-6.685431038419231,-6.701438912378254,-6.570474133742318,-6.6192031296661975,-6.845938078690684,-6.732345715775014,-6.744097447011184,-6.692405926522512,-6.770419355716437,-6.8146234788103,-6.7224144236872805,-6.729391955192867,-6.791981085699635,-6.6524842540075335,-6.540050491339058,-6.847033963447594,-6.748872033664547,-6.717160478916337,-6.692157738870439,-6.778635672334829,-6.735155849541132,-6.717125885822919,-6.8405378314077705,-6.8318482277511485,-6.889694138170832,-6.8253673540992175,-6.870433581734766,-6.9367755057354366,-6.643035964335139,-6.732945924843151,-6.704478680994613,-6.815190814065689,-6.652665687497546,-6.570510703059581,-6.7120842644218435,-6.709537164606374,-6.730560899276121,-6.654022363359092,-6.762012425067645,-6.665043551962623,-6.8362065718932055,-6.6752809710010235,-6.600091502081745,-6.861627959099438,-6.741537666017325,-6.808058403690563,-6.665921793667328,-6.755248564390303,-6.895139071491249,-6.676929265807908,-6.811778607159441,-6.647446000422548,-6.771904228436054,-6.8052050978055245,-6.744286777563086,-6.707110560814188,-6.599531580763691,-6.848241686517114,-6.76851323791389,-6.699627321889447,-6.834657725322956,-6.827595676663058,-6.778817110792977,-6.803791457933255,-6.5814598424378525,-6.729000638574137,-6.845571657016311,-6.687403905627451,-6.7910249992439145,-6.70927539545708,-6.72687370231964,-6.605562578816656,-6.8012377103133135,-6.960149229361418,-6.835863415551839,-6.603920921534595,-6.692445287025453,-6.801254044899577,-6.63203305677858,-6.771599750987579,-6.738764429177639,-6.711432758840093,-6.790641226329981,-6.694960630236848,-6.744234541929985,-6.74034286799989,-6.80125439553303,-6.7963598731659065,-6.750090256197425,-6.545304376972816,-6.733021907396133,-6.57494824518004,-6.764159492510098,-6.659014899774747,-6.5550850753419,-6.783954158478574,-6.730476170839601,-6.703164969448246,-6.9236423335749855,-6.755918977457096,-6.880118420377363,-6.728293744900557,-6.590357396540097,-6.7160656126940195,-6.900808955100102,-6.677494697878756,-6.957292305303737,-6.704301297454071,-6.7017664830300365,-6.682824370492662,-6.9087358046436105,-6.80141331444673,-6.958901296761944,-6.736967493595966,-6.671695155992761,-6.632621889957219,-6.515795862416402,-6.754795889289408,-6.696118914113331,-6.744899660231816,-6.775090528941599,-6.779920652531508,-6.800828543709691,-6.78039567578402,-6.6650536576109305,-6.712908920110229,-6.84718057879968,-6.8799061344487695,-6.644228520094146,-6.819460779685936,-6.706395936282526,-6.533576349854188,-6.747475585597109,-6.758533036768349,-6.498293450674602,-6.784316642995687,-6.872898763855583,-6.635100013741017,-6.551549396862798,-6.524311203380876,-6.766531858102662,-6.711024567718832,-6.65939850877465,-6.7486034016382686,-6.8470874198073854,-6.683974077601027,-6.953863308076619,-6.8556679675056715,-6.71750883700688,-6.933775676515297,-7.0159182283841455],\"xaxis\":\"x\",\"y\":[3.9699416106393532,4.034446240854986,4.193691143420298,4.020380671330898,4.088660369638529,3.9985962438431053,3.874994195491861,4.1920337540904615,3.9138415417101466,4.115517862408445,4.012960656618856,3.9447818934767946,4.068856555920399,4.00124746732269,4.058984752334517,3.9654832524545705,3.9684464870816596,4.0440262914109395,4.056458045702419,4.10003312302494,4.077238644083968,3.9750770798286865,3.9154563600638594,4.0796260554124855,4.097735258834438,3.936280257212053,3.9035925931867923,3.9330289754515113,4.057475878355569,4.117179847375884,3.9139564280273937,3.9342414765897518,3.997652052236514,3.962211642392999,4.020775712962663,4.071902323956772,4.001979505176556,3.897509904584005,4.117519292710001,3.9449405110406977,3.9842961143581888,3.9896536190824397,4.013387142683124,4.026584645134146,4.029790515870393,4.028739890143946,3.955167638567046,4.181024884947602,4.000974048954506,4.154112265659987,4.015039572025417,3.8400424362179306,3.962724650955388,3.874458607124625,4.0102718440171135,4.122036753342169,3.972008527950195,3.9701145080723412,4.170965075725405,3.8245585711058987,4.0091093061173435,4.06432293951193,4.159034945665088,3.8451833604072814,4.257226343445452,4.0347696979535055,4.156871065969753,4.040019382811683,4.078213310916564,3.9443309692947803,3.908345442341022,4.122917026893692,3.975908946658596,4.123014563519521,3.9912160576722067,3.9418335078160265,4.1464575489457625,4.098139091091519,3.993451514278195,3.98110301772589,4.084828101814616,3.9027502842137527,4.109227204757207,3.9142124831932485,4.09463242231778,3.951594233467731,3.9234807589182483,4.05596851114015,3.977553556969735,4.11846315226537,3.847868503881893,4.053386562035862,3.9413521274479066,3.894821430595637,3.9894323318205704,4.155896588156508,3.9348221565756463,4.12019126292452,3.998284964488998,3.9145164664003405,3.938397635528452,4.128326819583323,4.0833790796210065,4.065544837136049,3.9603720040878345,4.012068303399214,3.947370548306164,3.863299130153871,3.8670727895347494,3.9876704038148927,3.9678521022982887,4.152858126138116,3.886095341801993,3.9524070181106192,4.052791037350544,3.962344617753566,3.895513212367231,4.039462634093865,4.227097882721914,4.096588437219564,3.9103192194264755,4.083905543866729,4.007828224033292,3.901344039362017,3.9611968056475866,3.9947464706206026,3.954668769503755,3.788226618250652,4.039957087837648,3.977785988524545,3.9421038602753344,3.944143333235009,4.073393212211319,3.946702907564801,4.167851300802743,3.9451262628958057,3.9822299807400574,4.108448537628472,4.013070034436658,4.015952462702992,3.9629967362164593,4.037208621677206,4.029200448166251,3.927266641071961,3.858264564785178,4.036746557363243,4.245159599236248,4.210691537728711,3.9079509044386844,4.102724244960516,4.118421572547915,3.9124883900581966,4.148741989954141,3.9082866515000863,3.9965316062485234,4.040880617235498,3.988984464268239,4.038000913892265,4.049636819110601,4.012340697109375,4.035999266376951,3.997162164770273,3.9275913799639977,3.9265988919230033,4.21695325259047,3.9229418464425367,4.068456468575803,4.029484692533103,4.195756528327259,3.9980299941533057,3.943373235870351,3.960084569220032,4.031000743322357,4.11447359267398,4.066953729789401,3.919724642111674,4.030453037394463,4.078613863214722,3.957325415397189,4.0361718228125865,3.999188540460153,3.922046789387518,4.052038527901484,4.201363224817522,3.935626645678495,4.011461061421456,4.06264767247722,3.952863665707441,3.9352974628914663,3.9346801005758962,4.034045220405423,3.9945052526923086,4.034582408445764,3.985504225936755,3.9790484573449145,4.045706738008479,4.065001894571796,3.9312869507267925,3.9247412902920717,4.019961232597049,4.062032528612827,3.817091308659308,4.204722894123761,3.8931299314372927,3.98959823781546,3.9439142380996453,4.064920158701633,4.080358297096564,3.9368416057341657,4.002267682438992,4.105366159388562,4.12399020857291,4.024952484451128,4.032436275208844,3.9609786035835186,3.8564156523635225,4.057417064408702,4.1466335792721996,4.026413970243063,3.8393081867965133,4.050819197836193,3.9275045721936075,4.1112970873161,4.016149850260162,4.062236785862899,4.040138569703696,3.7786597341255757,4.056959900466794,3.7789759431293164,3.8312423671163844,4.0158044654487695,4.0262178590668185,4.042651496121075,3.8777090708496065,3.811531812122953,3.9861891755726737,3.996638490981902,4.140317081421927,4.1369861562556585,3.9489596926470982,4.006780140866594,4.228256916930853,3.7938831737842262,3.982174885824231,3.9275594049671123,3.915421729628444],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=13<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"13\",\"marker\":{\"color\":\"#B6E880\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"13\",\"showlegend\":true,\"x\":[-5.467971005768173,-5.542272313432788,-5.521335518576159,-5.382348663374405,-5.277918796558486,-5.380484433558716,-5.4261834064763095,-5.379112069056954,-5.498286485409702,-5.477525884061668,-5.276740494710398,-5.6353286379151575,-5.360537629393431,-5.434288314129855,-5.745409330442593,-5.5469399404546715,-5.46410052362605,-5.366197829479911,-5.329729486559621,-5.542455476131664,-5.525764929717943,-5.505784618140587,-5.582283802290281,-5.425036603540638,-5.549748343599664,-5.566820759351193,-5.430843066585149,-5.4931432937359475,-5.3350918951897475,-5.413645925175498,-5.624492719701893,-5.434086608744759,-5.2372985497948195,-5.516069500467224,-5.463899226928446,-5.669742829721077,-5.495113291785773,-5.431638450170033,-5.503709042328914,-5.586691766722503,-5.485836057663783,-5.2392306151517545,-5.529190993104436,-5.561501815862333,-5.578301801586976,-5.617866532943801,-5.507706538778434,-5.432199160384254,-5.485678162759371,-5.333531713970097,-5.528013833127899,-5.446311440672848,-5.4508282553167495,-5.555648783563714,-5.471522320324735,-5.4111964418233605,-5.40065217275967,-5.628492051610957,-5.4586025078326035,-5.396833328257562,-5.626122888342147,-5.402032058479332,-5.454911833105851,-5.401687339140542,-5.410328558353364,-5.41866119772807,-5.367521659059422,-5.381817511210248,-5.461923284932969,-5.362706809918219,-5.3824875115421404,-5.41012231970113,-5.324282030430263,-5.220554921378107,-5.5059945676288935,-5.419079097613722,-5.594354863831523,-5.544025481369667,-5.275966830301687,-5.456391564195433,-5.530054359083509,-5.42261452088944,-5.517007445138056,-5.55666702200857,-5.278048713041334,-5.591365769067236,-5.466448871068924,-5.524347747935311,-5.427923075551616,-5.458032570304268,-5.493632050318305,-5.624429989282307,-5.395221126935183,-5.562293944497786,-5.533711489721734,-5.706557346613774,-5.391593420116264,-5.56765522900088,-5.641084504682652,-5.367040507433393,-5.277423523985747,-5.443915530459893,-5.487779289941057,-5.34106103443402,-5.422683715963677,-5.227338934407816,-5.355388803869336,-5.573029262598706,-5.661113549893856,-5.486328901248908,-5.398320949855914,-5.5090694721094575,-5.553317310350279,-5.42030744319508,-5.531919503552892,-5.455505124574679,-5.6781713777615925,-5.551073582881468,-5.60969887850554,-5.478248885103616,-5.38852289592318,-5.527159082533925,-5.735404079948488,-5.5183911033330215,-5.334714604861085,-5.410576102681321,-5.525319573090121,-5.537985078637886,-5.431240571144103,-5.452359742061472,-5.335714211038711,-5.3332020935568885,-5.5420581672588,-5.637352733453896,-5.3955672048651,-5.3248760349189155,-5.287692930954355,-5.496293700196697,-5.566861333665672,-5.417931297448732,-5.450835516841634,-5.32997555028439,-5.5007671610257205,-5.488461220250521,-5.541705322200032,-5.481765307815383,-5.4126854927651875,-5.298204439280715,-5.527150751407358,-5.429664814177505,-5.548046109229004,-5.519655754989002,-5.554497952773842,-5.454617251824955,-5.617035180977771,-5.449687733081597,-5.476596416086348,-5.321772612015739,-5.484266138872876,-5.3330283504067815,-5.489763880826269,-5.570757697187283,-5.511461624359031,-5.7057282128108495,-5.55098329760166,-5.5508253704840005,-5.51195871949712,-5.656038071332201,-5.586832101341777,-5.505061992662505,-5.506270634569034,-5.33965348167278,-5.610225530081257,-5.490294915709516,-5.581346155118508,-5.412935191065485,-5.32485751776527,-5.456302801995169,-5.542882477712962,-5.348467821044769,-5.56950003190011,-5.5251794539753964,-5.558669559809283,-5.454285230306603,-5.264795355605776,-5.644531673469983,-5.465612193931171,-5.414619084060388,-5.438116637922873,-5.552611619775199,-5.271031294774344,-5.506224686496829,-5.364773577236687,-5.370052318662378,-5.489200468334323,-5.570685111232548,-5.574100161421516,-5.455601195458805,-5.662277448496087,-5.452606019425952,-5.513119798537252,-5.499476214584284,-5.350820949355143,-5.508295720877321,-5.748463527618579,-5.616995405452843,-5.477742867409386,-5.66814403839894,-5.579616811428444,-5.478111894065028,-5.3196813629659525,-5.455863059374324,-5.457278940817476,-5.462166385011719,-5.5068122497564564,-5.518932674949398,-5.585097385707896,-5.478271886036049,-5.457904378363188,-5.386979209547391,-5.703470654141971,-5.527922880199573,-5.351300483284033,-5.301695011070545,-5.3974865986311995,-5.410240941504939,-5.393805300924933,-5.553163952300851,-5.541346013723542,-5.445178948447108,-5.274730167140757,-5.478664261345107,-5.548607314690161,-5.510117233164203,-5.3217908177738495,-5.635445450548054,-5.504396730805392,-5.347750224491444,-5.19864724311941,-5.49667042476195,-5.342993976001647,-5.489258487548183,-5.527576850327819,-5.524631941672297,-5.508746558840448,-5.543252175066776,-5.471440951926603,-5.606796561793002,-5.444206624382979,-5.592764000574382,-5.431292085680744,-5.542452802019348,-5.502133325964638,-5.503114316673173,-5.472443244574036,-5.60057765749052,-5.577297279133472,-5.559561755299926,-5.477422683781782,-5.440291494900508],\"xaxis\":\"x\",\"y\":[-7.764471625667368,-7.875671415812057,-7.800116947676216,-7.903413042353343,-7.715169515115187,-8.065793870588147,-7.887301001605057,-7.84129823146734,-7.702233709995426,-7.876946326250032,-7.864541550569425,-8.04229677401155,-7.807875399430853,-7.79005162478623,-7.980417833768086,-7.99560899943271,-7.686385477870212,-7.920665281579271,-7.654511904817498,-7.883720055308145,-7.68984723216649,-7.696700458327195,-7.792270201108652,-7.552765197957796,-7.9009835927926035,-7.853271634181556,-7.897437530041948,-7.976306982935563,-7.674611064515186,-7.814432318738185,-8.040766541990706,-7.7844757959991195,-7.754280209604201,-7.893959497958796,-7.595554326047901,-7.658339721277925,-7.8855955787160665,-7.9065314241584925,-7.723314445976534,-8.062230006737893,-7.959232107308221,-7.779698958561633,-7.857036133903957,-7.781868170401999,-7.96541590761646,-7.927061820405245,-7.7987447161007095,-7.800233837183472,-7.944789390712459,-7.9784753860239,-8.031648147728244,-7.7813521514461375,-7.8130817143317985,-7.900060761370199,-7.861728212022897,-7.975409571533367,-7.847600415211612,-7.79816030601131,-7.7911491075526005,-7.815498193594229,-7.694634743097092,-7.960982642530822,-7.878645453996067,-7.893819809526235,-7.764598356622576,-7.7141185532481895,-7.793173251291884,-7.875978973368321,-7.775087541105076,-7.879744301999719,-7.9404486084322246,-7.875684581506073,-7.86336382406831,-7.785461322533306,-7.940654867370997,-8.07377927807188,-7.8634943436791405,-7.803966440550665,-7.910964702770494,-7.907282624363612,-7.720404792519883,-7.736719043213992,-7.897856784470481,-7.695748621747,-7.937699630985108,-7.828557077022754,-8.029199506517733,-7.849138524503735,-7.949811165709761,-7.955382443632837,-7.810253375784654,-7.9090074244088076,-7.963120198727307,-7.810905519035022,-7.806278109838164,-7.88592790924869,-7.883503246846138,-7.977874953764908,-7.715763630830617,-7.8763571246770265,-7.864830719214846,-7.980237029806469,-7.97314015465585,-7.9333101285859,-7.7191420757761975,-7.790693512948128,-7.842148390721288,-7.724925501225742,-7.705852824518168,-7.833389198278384,-7.890209190428176,-7.831381961037758,-7.778954501884207,-7.75152925630613,-7.887970017083259,-7.862401752843437,-7.838888026660797,-7.948872519334361,-7.841856454699923,-7.783423799416577,-7.749330150993172,-7.77150004466198,-7.963213936682979,-7.887382208059266,-7.8875472403319895,-7.844261601605832,-7.974219718880969,-7.856789946303005,-7.673454950468456,-7.809192398958743,-7.842685443480717,-7.7618504621321875,-7.994307672358282,-7.918682587721781,-7.855628101084895,-7.966924068776208,-7.7533395207349365,-7.8173206243073174,-7.876360916494888,-7.877575814851986,-7.917782536539301,-7.862798240852978,-8.00990408252253,-8.097451776857422,-7.884769147684738,-7.979681802028067,-7.930391794831341,-7.810772187825322,-7.860774501813312,-7.820494143573641,-7.628531585503974,-7.8645801033303355,-7.8915994065300765,-7.879763776090014,-7.978236514779692,-7.812758725324504,-7.887045364995859,-7.67169433683956,-7.943847779466967,-7.940744445545304,-7.7316245426307955,-7.959024684460284,-8.013329010478472,-7.844708400062157,-7.884268270067859,-7.780680033473601,-7.9472794984526365,-7.891933033267135,-7.73278952614768,-7.941144741473055,-7.923584677917632,-7.882229865202428,-8.06372023611558,-7.908358746868477,-7.733547664890067,-7.79669357416422,-7.713516581921961,-7.7719294658536295,-7.826447771415699,-7.9669949430260605,-7.859388274639731,-7.979411835391976,-7.91553800968183,-8.011797826818222,-7.977593970399725,-7.862893205939351,-7.9283271198776895,-8.025929071264644,-7.771837993528272,-7.7898601114513175,-7.891450789253124,-7.889269465414992,-7.872023381129576,-7.69954432227419,-7.787013918510817,-7.933454643244851,-7.735825528883274,-7.944978367233409,-7.91023555548561,-8.060455977897806,-7.925841551039896,-7.819754076977145,-7.851464548501961,-7.9380476947319085,-7.722759367235272,-7.9340309351729905,-7.93497143035922,-7.9255033792989185,-7.67926728100016,-7.679145733263925,-7.892498803429936,-8.115430760383369,-7.8422517018037405,-7.685127539363416,-7.873004575914279,-7.927932728798272,-7.875603808471339,-7.862741087829968,-7.751045998427351,-7.873364576367127,-7.840448174963519,-7.55939854451673,-8.034227581762401,-7.901978114130043,-7.816600020305562,-7.754631436434933,-7.986481010183573,-8.030785716638313,-7.835389049933586,-7.838647352609786,-8.005576476726342,-7.87761012855433,-7.922024213049614,-7.84930671045735,-7.982786583622997,-7.985857621876603,-7.80077135900329,-7.940962071308817,-7.739685146015132,-8.144087989388519,-7.89442126382403,-7.828247473963934,-7.792562533256989,-7.922164750868991,-7.904278475570035,-7.9758215398565095,-7.749289475462312,-7.838987969377966,-7.7977598645572295,-7.9336921896055035,-7.87945113413462,-7.931041308718434,-7.70159359114892,-7.877474163759181,-7.809899448355949,-7.862386984023901,-7.8175170006881425,-7.780906366382717,-7.771583801378102,-7.957741984852913],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=7<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"7\",\"marker\":{\"color\":\"#FF97FF\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"7\",\"showlegend\":true,\"x\":[-6.360644490577516,-6.227560550452722,-6.386460571431562,-6.239339323599439,-6.35442996634818,-6.037579127782786,-6.2405382354107575,-6.497793708101785,-6.352875424026051,-6.451664271557056,-6.149691279626158,-6.243237631511563,-6.3750382315872205,-6.39126523554389,-6.214572381914178,-6.258160254220259,-6.483039734420088,-6.336221832911234,-6.322663198535674,-6.471074521699901,-6.467855974973571,-6.2288784234880445,-6.266801163994503,-6.21353490327017,-6.145086763929159,-6.389173362264943,-6.267530359625842,-6.300820156530278,-6.258971376512196,-6.314513001745536,-6.381481687950591,-6.1945948876052235,-6.2983273277544525,-6.2513106497068005,-6.341376999694827,-6.203823859173603,-6.493912153775564,-6.361219002984165,-6.141518518938694,-6.371756421338916,-6.348151844097686,-6.23609492220843,-6.511590999128472,-6.377996050685429,-6.424642373249699,-6.431979782120778,-6.283424144938472,-6.364792995827898,-6.480739198933032,-6.328660230408949,-6.3396743951993715,-6.351941472099568,-6.565958948793116,-6.403901812490686,-6.2864704874787005,-6.269229795694721,-6.5560751754529685,-6.241295681040245,-6.466562652521821,-6.471742504704431,-6.074834429210551,-6.421192730494848,-6.161686745372557,-6.163481655966813,-6.536786112333308,-6.410902469456066,-6.404452777834979,-6.141628233755571,-6.394591303093247,-6.378852561880541,-6.176934085875766,-6.413179540546528,-6.269512731816687,-6.2727267050109194,-6.414288221296934,-6.371376813126946,-6.269030797296651,-6.336618118816686,-6.332341186760378,-6.363005988324235,-6.351919541793321,-6.291792425594903,-6.279031718605383,-6.367456778859638,-6.276347097042166,-6.274355062915509,-6.356641773937128,-6.150405891687826,-6.44584965069876,-6.289804006414601,-6.264711871996,-6.221863706064704,-6.151920952083418,-6.395113883009033,-6.301767448193735,-6.27781351129726,-6.210039987632157,-6.335922472529738,-6.282078990378435,-6.282566856764099,-6.203598734079008,-6.087627562283892,-6.355011090786347,-6.586987069918742,-6.438956969645496,-6.189311591287358,-6.351984347648673,-6.414330683860205,-6.313815737581317,-6.292384767415445,-6.259464634934521,-6.439596319780835,-6.286330216528704,-6.280415148558718,-6.380224450753121,-6.2915002309506365,-6.240469266662623,-6.2211686319842165,-6.259563075574562,-6.537703185454279,-6.364851523820569,-6.32809686698317,-6.480214852942189,-6.428338758021995,-6.152753328764306,-6.384855383309894,-6.419296577585836,-6.4400860021498145,-6.351024111002661,-6.239997099416706,-6.335235967737285,-6.36693115069412,-6.388537983467334,-6.306002379359942,-6.355482123052283,-6.234230010396443,-6.382018383783362,-6.2017420584721865,-6.360268488990074,-6.367576459200807,-6.230739429948151,-6.146510808158314,-6.287970431380936,-6.47626826691398,-6.081794003458158,-6.365575552785766,-6.389288902417045,-6.348004303262713,-6.444526957163168,-6.264219695794857,-6.365704997183948,-6.228409828043779,-6.40551475841393,-6.273935923833048,-6.291039719682359,-6.584548141619825,-6.253429146807096,-6.331730155268593,-6.30631822649789,-6.39868640572374,-6.428749529359816,-6.264556458591799,-6.414073260457391,-6.3987850963891235,-6.218518047524753,-6.388583955300126,-6.218870249390754,-6.316119529450689,-6.225661408940866,-6.2277526188798555,-6.072010282530614,-6.303179526522556,-6.134384639114257,-6.167619934084562,-6.218540577641542,-6.3167338602530005,-6.175570323252105,-6.263921141547462,-6.350392119906407,-6.381922083858536,-6.37029167544414,-6.333312952711034,-6.26585798376518,-6.184690612916545,-6.283253958713684,-6.203040714365491,-6.274896089912706,-6.426115568216507,-6.384282782292899,-6.354773721004274,-6.488883511572203,-6.323455246510265,-6.430196612878237,-6.323812057798463,-6.315533736188538,-6.3862706882901765,-6.265468172525922,-6.298912032458114,-6.366194962768847,-6.322063570879847,-6.199431168705945,-6.245483268345107,-6.269267801474039,-6.263859245531835,-6.467393182381102,-6.36728805836325,-6.442044347773084,-6.352422853314557,-6.2282840917637206,-6.341933895073452,-6.399553366470704,-6.385573041307823,-6.0059438734605015,-6.322742117239483,-6.391225882042608,-6.313864195432035,-6.162290702842628,-6.5014899459415725,-6.184547121554538,-6.382710028343425,-6.437598157491728,-6.180750490928355,-6.238640706587471,-6.290726199470428,-6.330800870890641,-6.193193726381012,-6.3156494685725475,-6.201961277595614,-6.2599917729259085,-6.26002174485899,-6.3906340999712015,-6.39973617657513,-6.494163988179402,-6.370445959055272,-6.25668577284105,-6.436204258303957,-6.352617636311973,-6.4323148579717,-6.33962914876147,-6.356353460849035,-6.280672442016688,-6.365957057844728,-6.090417246398756,-6.305510626312391,-6.2123564158690865,-6.3957797552160995,-6.282716505991916,-6.381480694254396,-6.366379893346133,-6.4535368986680295,-6.353501307303716,-6.364279696524482],\"xaxis\":\"x\",\"y\":[5.754518761668957,5.964447586540604,5.756624843464722,5.620690154693606,5.6489020410294675,5.62038436949981,5.537665099015692,5.694848777972122,5.648073440676854,5.489303408420135,5.487020867311929,5.886922692085964,5.707409986199515,5.566064558215391,5.634923820560949,5.790519868150389,5.812848891241741,5.881736362024,5.7946835324594925,5.772980829754385,5.814194146607493,5.644434938403801,5.6736999591029615,5.667085930491528,5.751237353721109,5.85594108334179,5.70263456834984,5.717393967308445,5.833603342103657,5.6789024050139485,5.704504926768499,5.9041411552451795,5.445619382683362,5.741026348852008,5.662414155776345,5.688632292188297,5.65524848865926,5.585102773139525,5.552426401485931,5.767316144853611,5.686333538184846,5.667651568118946,5.815536863991041,5.756738473047485,5.757655289097209,5.614102911487586,5.700831067102784,5.808315597031996,5.553553214562606,5.697971264286054,5.944042458500411,5.67667702090121,5.595289040286694,5.707745173254956,5.714663527119028,5.396460875445365,5.728663203218855,5.762559938388646,5.563839943191507,6.027887064751805,5.657162756330953,5.797362531522403,5.785738426189385,5.61130773136761,5.566654911246759,5.737254624966902,5.571727869740739,5.729328841012374,5.772994945600724,5.808996435324492,5.633315832078801,5.646519952219082,5.646018215151912,5.772730225451592,5.761610410007436,5.692544391574388,5.871669669839411,5.824204482862007,5.79387667303573,5.5676192747603235,5.704386102679731,5.6902347184981545,5.806971192169862,5.785830033550201,5.768657934961485,5.629390857063188,5.630971253474703,5.6585683241296545,5.741657417962668,5.814774390440133,5.606365045589671,5.615126222685223,5.610786176159875,5.848876830802181,5.585292972360136,5.637979641186039,5.9271836978315955,5.6180485930538655,5.668575106401834,5.648471706410172,5.622285825877705,5.705111394412458,5.589770758040068,5.555053235258912,5.8308303114666,5.61406453306984,5.86030074449184,5.649414664649674,5.700027099114021,5.664390580271884,5.4649813539911,5.804676135134736,5.897407911575263,5.588255954009339,5.837166767845984,5.741487520372856,5.663366955517021,5.690715175688456,5.598875966250968,5.742249376769851,5.7944917608317725,5.680515555536048,5.524672545524456,5.774929396251806,5.746608433628217,5.6230932400924925,5.673385737811203,5.521646737970554,5.599592773810542,5.788565232413473,5.699315967292152,5.7585805347752395,5.5902067923645,5.588905676425149,5.6716737194747875,5.628021109574459,5.771862243742923,5.7836266856011775,5.7376304449291275,5.994209474472159,5.629797985582301,5.642339795696477,5.773301859557764,5.774116934927215,5.616477750161112,5.588414393035943,5.699306271431011,5.81387304350511,5.7405223757456945,5.650498262462887,5.671650116311641,5.568333968854928,5.554769996565936,5.589688227551607,5.8019646359060335,5.692832272525996,5.724144543445044,5.848474155324559,5.7101482774423165,5.729670271789944,5.7210355316851205,5.816589838122099,5.674633178830854,5.64284307962835,5.620301309497969,5.732783667991048,5.510028704558751,5.952806446785984,5.795973559641665,5.771889102010921,5.72699996727457,5.749663741293857,5.729852537457153,5.673506890898062,5.795478558502859,5.874524563531426,5.555917815176787,5.751961153885402,5.836574948845013,5.802007751927662,5.785658594970936,5.722280784143549,5.561691941515825,5.786955808798949,5.734705988834692,5.7371713330902,5.6645738620987025,5.56598711479414,5.7203513045527306,5.908567465532967,5.793157266654086,5.632224115357118,5.6705874781386765,5.763696958257636,5.709812248043748,5.655760531781955,5.86836152159505,5.621623346533574,5.64541437591174,5.880632743181467,5.663008605763815,5.588725310415586,5.701018698395651,5.7178557164796935,5.5337286801239465,5.62101857065301,5.681311566803591,5.852339930750884,5.7076182169669485,5.578917868103417,5.546438757698196,5.668107755179904,5.860008075278244,5.7556293075355835,5.566175751604547,5.84246524141183,5.624124746494796,5.894993922327149,5.790625339948785,5.541124077981382,5.520418517164983,5.842282997467858,5.685907243005835,5.6776470822375735,5.759268553859364,5.653368933956671,5.714328290031294,5.697075181802882,5.641233279112826,5.546645410459527,5.669991089946074,5.645632615849638,5.863448400955675,5.616087325222298,5.866991813413376,5.928886924967748,5.7702329891976465,5.691332504234405,5.808660166862211,5.630723396755214,5.783590406761376,5.791912154685452,5.628761620493242,5.656334449731777,5.627686097202586,5.688845356612721,5.873925211338148,5.663680434586464,5.888835257438313,5.465059247992818,5.797197276141432,5.629460958863957],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"class=12<br>x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"12\",\"marker\":{\"color\":\"#FECB52\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"12\",\"showlegend\":true,\"x\":[-7.398161248286669,-7.396382817970886,-7.591399545865424,-7.4423660137295125,-7.277519279026566,-7.424507380848434,-7.468178554682763,-7.436343625134527,-7.549065444160753,-7.363575796791563,-7.33492561268455,-7.373493247814908,-7.332714108036347,-7.5745863124277895,-7.586468579114466,-7.433620017449452,-7.520144439544293,-7.396537797837734,-7.572729718167482,-7.268718501192678,-7.388572184372122,-7.360221931097464,-7.478034630358158,-7.503719949090984,-7.350437098087312,-7.611900593189058,-7.405132602340621,-7.529916128153909,-7.398553716817085,-7.4693886172243005,-7.330211957859592,-7.559301764332509,-7.454529586367375,-7.506122852032369,-7.397347545038639,-7.40550426255759,-7.509690191847541,-7.361013459180974,-7.46651751190216,-7.362387019726934,-7.5996885589299765,-7.4414266232511,-7.521719283717821,-7.576805647705775,-7.3599436019481725,-7.628257859688591,-7.600762592522578,-7.344026195570606,-7.494549227119004,-7.412914677076916,-7.474610935944687,-7.480940738251524,-7.4253941078329495,-7.400310370755973,-7.397409347832283,-7.400344187450811,-7.648684219585624,-7.514605265992203,-7.328396024909688,-7.3908712865317785,-7.387175429901541,-7.536710368767135,-7.499768631394901,-7.400862518262135,-7.343123584176867,-7.369769301324216,-7.335675708542906,-7.6461588084480585,-7.852838295192899,-7.38624510906298,-7.477541920423022,-7.350734745189143,-7.481137771121031,-7.462970582374843,-7.32594040514564,-7.489340972502891,-7.2700417135317625,-7.378273742418378,-7.645663820590381,-7.468467519856893,-7.475385714336459,-7.259338524148097,-7.323411191321124,-7.376618992406301,-7.550729211483001,-7.29416177378087,-7.383184455717413,-7.430983962654107,-7.457717744684952,-7.453711758697726,-7.548970627649428,-7.458827069311701,-7.466794195138159,-7.435179131456974,-7.507298608965596,-7.286452760799237,-7.580010836864404,-7.294932683469533,-7.383463357647127,-7.492392231509267,-7.503360611709754,-7.622885438846369,-7.594520094829503,-7.27832546024195,-7.518824274091292,-7.446239353158547,-7.412792946442177,-7.387134366884155,-7.447045734073818,-7.428483511986106,-7.385946280879786,-7.321822853267737,-7.3957871640871495,-7.399563244656744,-7.415093646859584,-7.456290339679467,-7.497271344469962,-7.553880579795625,-7.484142706596138,-7.5054525207486815,-7.51499443538484,-7.478090149184945,-7.5179221557087965,-7.505048936878199,-7.345867199676718,-7.390298119556266,-7.424781577725582,-7.448248336199295,-7.440039307000805,-7.542946538309065,-7.434529115101384,-7.3331963285925434,-7.427633045863292,-7.327713680795982,-7.611612139567536,-7.554901571951926,-7.487494465907029,-7.468266684869229,-7.452438517837552,-7.545791058001211,-7.518610959924386,-7.482720920032508,-7.493953786417731,-7.498415214998434,-7.578370727294023,-7.495967266674968,-7.321259238948219,-7.423028975545539,-7.414562049940192,-7.566783199931999,-7.351211674451873,-7.4111410477499975,-7.512531837827045,-7.471491693264689,-7.336173799288698,-7.58030657659521,-7.331668839064521,-7.333311049940437,-7.714450631367109,-7.554002602812925,-7.392454440432979,-7.534687810173943,-7.367054646542739,-7.570884031177075,-7.4954228402441245,-7.441744436275165,-7.401902585532709,-7.530687387759726,-7.283216554303708,-7.46109854117734,-7.456446949629137,-7.2478799150013735,-7.451283294306476,-7.433841775898766,-7.391338109511495,-7.47582340717935,-7.5616528669180685,-7.325440074800522,-7.436947091104767,-7.476937170678115,-7.563316785584801,-7.151274783988284,-7.487207534712331,-7.312748909301444,-7.625315977154928,-7.5209449552434275,-7.452957954487617,-7.451304391650491,-7.416192568746881,-7.394821319241646,-7.4970887563626585,-7.640830522539734,-7.199314849937225,-7.3853293000714615,-7.374140940929691,-7.428092302764349,-7.43614279528651,-7.259585208338293,-7.514906770792454,-7.454421636273864,-7.432001094876154,-7.439069474526446,-7.425619183864813,-7.506838947252571,-7.630931397865065,-7.4626249241704,-7.572059853375274,-7.565071496201898,-7.46145058506315,-7.5448887198225,-7.509667535859282,-7.229872212783716,-7.337767180771438,-7.413507099213323,-7.555662376398548,-7.476072078654613,-7.492363252880031,-7.478665630392532,-7.434910867625815,-7.476920718664288,-7.3747437200745924,-7.382263149268096,-7.469381903068277,-7.361620918106326,-7.587180322611244,-7.4833848503931,-7.429250911540838,-7.443607115246633,-7.489068764373889,-7.5173451765934844,-7.440251180374994,-7.622315911967825,-7.500244104572864,-7.606857197792633,-7.500286492822696,-7.36481809388288,-7.375223618181703,-7.479874423136172,-7.34578770267135,-7.551311451642835,-7.428338857663732,-7.443922220496285,-7.442419292050516,-7.5053985180955465,-7.384997590695556,-7.34915843442883,-7.560252725311015,-7.4666741946215085,-7.253085345415209,-7.505269850440459,-7.4574206639779,-7.501915791498153,-7.518732245040261,-7.341510813579783],\"xaxis\":\"x\",\"y\":[2.1305020033001614,1.9531904121159753,2.0696479089052993,2.0129823942228997,1.8231191663606698,1.9547879933024392,2.028328991361993,2.082976038716121,1.971350484508529,1.8064995191740045,1.9487050064284281,1.9591341129456425,2.0642551076907134,1.87696631984515,2.07526923242149,1.9234424243010606,1.969716919535165,1.9055508154516194,1.8085724372400258,1.8931917178336761,1.9776800635112755,1.952269440216138,1.9063120080863756,2.0300071344941153,1.7397286762662403,1.982536535659918,2.006378186417927,1.7491355958170438,1.8697419662827366,1.9432383969504499,1.8984003557918943,1.89372795989136,2.0005232157240744,2.1096744021377174,2.012538706815378,1.954668058930345,2.081936501367422,2.15934299162035,1.9217039248930279,1.952783076294182,1.7789570380255706,2.0584498698442095,1.7288730155400627,1.8083233223575699,2.0355966098661127,1.9515823477903405,1.938465096413098,1.8977653792004638,2.0590328424441298,2.0793466711846387,1.9356645722082746,1.7756506089002282,2.1235335602327092,2.1972701369219383,2.007754917831077,1.7922316257968296,1.9312215050304338,2.1565667292821105,2.1038458034470993,1.8527325213730441,1.696673100230533,1.9297797583121432,1.9741290382865868,1.9384918295809819,1.9645805088507666,2.038396087212628,1.9210888895544647,2.0889695046885834,1.8531957479679182,1.8073548634424046,2.1153881651702906,1.9370572456867803,1.9845907194381107,1.972915703490135,1.825986027036226,1.954225093210173,1.9498167020880124,2.0775740861619787,2.0454616071104343,1.9460094372825503,1.857952581458777,2.004398374941142,1.9413695840743008,2.014292983963235,1.933598712905935,1.8560057749580843,2.1007643628962605,1.9134413372123704,1.8280255315369778,2.052552190166812,1.9464677675162394,1.8023837254741708,1.7959054698083328,2.011980373290114,1.962390188566908,2.0744522974276425,1.9917102488614389,1.933848641088678,2.051518912310977,1.8265673690574018,1.8876528143491635,1.7924869188778083,1.851084968452829,2.091848074924984,1.9552646988429057,1.9472653615873685,2.0270931062268085,1.9183923506502651,2.023467294898898,1.8416901449965013,1.8687101068113612,1.872630068770941,1.8781209477675387,1.989564149403321,1.8453553002047158,1.6977619105276336,1.8165347312396423,2.0083813789608467,1.9245350855027097,2.1907960244981566,1.917536872370365,1.8787506910439693,2.0425382229973708,1.9780358306137062,1.861231614770221,2.0026057202493934,1.986489758096156,1.9876912976175538,1.912174403885741,1.9959252706466284,1.9091098745306574,1.7721581185108484,1.8855533239028792,1.8887881495219132,1.8067361542742284,1.962189042744227,1.846323586598892,1.9161639290791586,1.9719887596430352,1.9277121707085574,2.002335646285758,1.8800199747335269,2.0748868080200373,1.9430825204889512,2.114318191553781,1.743470323018711,2.1671961040862886,1.8863703790051347,1.8361139508521362,2.2041287117036465,1.8694847159699484,1.7579138971822688,1.937808528542792,1.9516607403311317,2.0596090045578923,2.052650290735514,1.9914085039655436,1.958552492043697,2.124613868438496,1.8592002921196003,1.9517434018841384,1.9052050257725435,2.070980680874384,1.8685665994132212,1.9758478706028022,2.0847783319320814,1.870533547792837,2.0535597779543053,2.0116045716337414,1.886247941795461,1.9938852181489173,1.9386590394176633,1.8456580190515444,2.0044436891386095,1.9080312564486281,2.0353307416071384,1.6979151034125919,1.8172026574980473,1.980909641074203,1.8999294144644177,2.041599788406701,1.9722089986031541,2.012234005339126,2.172396877017185,2.1868752643839646,1.8105515775075753,1.7045876589816884,2.04603469879988,1.9211356674049616,1.9968973354309647,1.9502618219217862,1.8715227471916263,1.9002915238870055,2.1166035665238505,1.7720274038065722,2.016696088416747,2.0509348094886803,2.0757526309387324,1.7052743874669942,1.9993602791165004,1.937236056067877,1.935580607163942,1.9352030898896777,1.8699708149052217,1.957041806524493,1.9011272912421204,1.8465130544847022,1.9629600102812481,1.8577054963178625,1.9564199203450465,2.0766366741536095,2.033974362097006,1.9999592212726967,1.8198081336981642,1.969606593671064,2.0293560007287472,1.9161697326591962,1.9127091738864408,2.1336831797385405,1.8903969925614759,1.852530845422056,1.9619919438170903,1.8751218934184393,1.8745019833244208,1.9603666692760746,1.8763832389606634,1.9744958587321484,1.8737093416581452,1.7321533011320986,1.8586860181584566,1.9339241969281877,1.95756827713067,2.1365039019478984,2.1475516612786913,1.9281843598520454,1.8693176620288423,1.9847395713041176,1.7391397662979713,2.0044526910908638,2.076546205937254,2.06816688212099,1.9490810519673198,1.7919901745152977,1.8510515993589747,1.9881921909145799,2.104955917657308,2.0502681026300635,1.89961849514425,1.950325271719311,1.6840323181296006,1.827566863965609,1.861674349618438,1.9920619876652133,1.986649441116154],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"title\":{\"text\":\"class\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('dd26d6a1-f85c-4266-8fdb-9c03e0366f6a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "นิยาม Model แบบ 20 Class โดยกำหนด Activation Function ใน Layer สุดท้ายเป็น softmax"
      ],
      "metadata": {
        "id": "pwpjRg3u5vNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(60, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(20, activation='softmax'))"
      ],
      "metadata": {
        "id": "bojq49cf5wJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile Model โดยกำหนด Loss Function เป็น sparse_categorical_crossentropy"
      ],
      "metadata": {
        "id": "HeueWdI25xfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XvVePE6Q5ydC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f09795-1fc9-40b8-8f22-81db14ccd1b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len( y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez17N2Nrg9Y3",
        "outputId": "42323d44-4edb-48af-9cfb-33e5b7883a7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model"
      ],
      "metadata": {
        "id": "fHv_51GX5zS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "his = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=1000, verbose=1, batch_size = 128)\n"
      ],
      "metadata": {
        "id": "OAh8_Hbm50L2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "857f03e8-cf12-46ae-f953-9b4ed7b5dbfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "40/40 [==============================] - 1s 6ms/step - loss: 3.3935 - accuracy: 0.3204 - val_loss: 1.1953 - val_accuracy: 0.4868\n",
            "Epoch 2/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1.2832 - accuracy: 0.5106 - val_loss: 0.8375 - val_accuracy: 0.5626\n",
            "Epoch 3/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9572 - accuracy: 0.6092 - val_loss: 0.9664 - val_accuracy: 0.6808\n",
            "Epoch 4/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9305 - accuracy: 0.6510 - val_loss: 0.7891 - val_accuracy: 0.6672\n",
            "Epoch 5/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7697 - accuracy: 0.6980 - val_loss: 0.6906 - val_accuracy: 0.7294\n",
            "Epoch 6/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7385 - accuracy: 0.7406 - val_loss: 0.6241 - val_accuracy: 0.7624\n",
            "Epoch 7/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.7666 - val_loss: 0.6082 - val_accuracy: 0.7590\n",
            "Epoch 8/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.8064 - val_loss: 0.5043 - val_accuracy: 0.8236\n",
            "Epoch 9/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.8270 - val_loss: 0.5138 - val_accuracy: 0.8624\n",
            "Epoch 10/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.8184 - val_loss: 0.3920 - val_accuracy: 0.9196\n",
            "Epoch 11/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.8408 - val_loss: 0.4902 - val_accuracy: 0.8184\n",
            "Epoch 12/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.8570 - val_loss: 0.4144 - val_accuracy: 0.9306\n",
            "Epoch 13/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.8616 - val_loss: 0.3340 - val_accuracy: 0.8938\n",
            "Epoch 14/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8884 - val_loss: 0.3961 - val_accuracy: 0.8884\n",
            "Epoch 15/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.8602 - val_loss: 0.4233 - val_accuracy: 0.8972\n",
            "Epoch 16/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.8624 - val_loss: 0.3654 - val_accuracy: 0.8520\n",
            "Epoch 17/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8790 - val_loss: 0.2645 - val_accuracy: 0.9582\n",
            "Epoch 18/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8802 - val_loss: 0.2691 - val_accuracy: 0.9714\n",
            "Epoch 19/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3512 - accuracy: 0.8982 - val_loss: 0.2704 - val_accuracy: 0.9494\n",
            "Epoch 20/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.8886 - val_loss: 0.2395 - val_accuracy: 0.9432\n",
            "Epoch 21/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3016 - accuracy: 0.9164 - val_loss: 0.1966 - val_accuracy: 0.9952\n",
            "Epoch 22/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.2804 - accuracy: 0.9306 - val_loss: 0.1959 - val_accuracy: 0.9546\n",
            "Epoch 23/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3116 - accuracy: 0.9076 - val_loss: 0.2019 - val_accuracy: 0.9836\n",
            "Epoch 24/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.2791 - accuracy: 0.9186 - val_loss: 0.2153 - val_accuracy: 0.9320\n",
            "Epoch 25/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.2614 - accuracy: 0.9270 - val_loss: 0.1800 - val_accuracy: 0.9554\n",
            "Epoch 26/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.2621 - accuracy: 0.9262 - val_loss: 0.1516 - val_accuracy: 0.9878\n",
            "Epoch 27/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.2219 - accuracy: 0.9508 - val_loss: 0.1851 - val_accuracy: 0.9200\n",
            "Epoch 28/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.2351 - accuracy: 0.9422 - val_loss: 0.1564 - val_accuracy: 0.9540\n",
            "Epoch 29/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.2378 - accuracy: 0.9352 - val_loss: 0.1930 - val_accuracy: 0.9340\n",
            "Epoch 30/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.2651 - accuracy: 0.9220 - val_loss: 0.1458 - val_accuracy: 0.9736\n",
            "Epoch 31/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.2055 - accuracy: 0.9494 - val_loss: 0.1313 - val_accuracy: 0.9830\n",
            "Epoch 32/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.1974 - accuracy: 0.9540 - val_loss: 0.1487 - val_accuracy: 0.9336\n",
            "Epoch 33/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.1904 - accuracy: 0.9568 - val_loss: 0.1140 - val_accuracy: 0.9960\n",
            "Epoch 34/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.1682 - accuracy: 0.9700 - val_loss: 0.0989 - val_accuracy: 0.9970\n",
            "Epoch 35/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.1755 - accuracy: 0.9684 - val_loss: 0.1014 - val_accuracy: 0.9940\n",
            "Epoch 36/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9690 - val_loss: 0.1138 - val_accuracy: 0.9686\n",
            "Epoch 37/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.1669 - accuracy: 0.9630 - val_loss: 0.0939 - val_accuracy: 0.9976\n",
            "Epoch 38/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.1750 - accuracy: 0.9552 - val_loss: 0.0998 - val_accuracy: 0.9814\n",
            "Epoch 39/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.1492 - accuracy: 0.9694 - val_loss: 0.0874 - val_accuracy: 0.9978\n",
            "Epoch 40/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9710 - val_loss: 0.0930 - val_accuracy: 0.9904\n",
            "Epoch 41/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.1515 - accuracy: 0.9666 - val_loss: 0.1377 - val_accuracy: 0.9306\n",
            "Epoch 42/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9656 - val_loss: 0.1056 - val_accuracy: 0.9756\n",
            "Epoch 43/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.1397 - accuracy: 0.9716 - val_loss: 0.0664 - val_accuracy: 0.9990\n",
            "Epoch 44/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.1272 - accuracy: 0.9802 - val_loss: 0.0744 - val_accuracy: 0.9982\n",
            "Epoch 45/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.1199 - accuracy: 0.9818 - val_loss: 0.0628 - val_accuracy: 0.9988\n",
            "Epoch 46/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.1187 - accuracy: 0.9806 - val_loss: 0.0623 - val_accuracy: 0.9988\n",
            "Epoch 47/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9794 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 48/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.1158 - accuracy: 0.9802 - val_loss: 0.0583 - val_accuracy: 0.9988\n",
            "Epoch 49/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.1260 - accuracy: 0.9756 - val_loss: 0.0608 - val_accuracy: 0.9972\n",
            "Epoch 50/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.1109 - accuracy: 0.9790 - val_loss: 0.0559 - val_accuracy: 0.9970\n",
            "Epoch 51/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.1060 - accuracy: 0.9816 - val_loss: 0.0618 - val_accuracy: 0.9938\n",
            "Epoch 52/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.1022 - accuracy: 0.9826 - val_loss: 0.0505 - val_accuracy: 0.9990\n",
            "Epoch 53/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.1096 - accuracy: 0.9772 - val_loss: 0.0489 - val_accuracy: 0.9988\n",
            "Epoch 54/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9764 - val_loss: 0.0531 - val_accuracy: 0.9982\n",
            "Epoch 55/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.1032 - accuracy: 0.9806 - val_loss: 0.0603 - val_accuracy: 0.9946\n",
            "Epoch 56/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.1058 - accuracy: 0.9800 - val_loss: 0.0530 - val_accuracy: 0.9974\n",
            "Epoch 57/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.1030 - accuracy: 0.9788 - val_loss: 0.0547 - val_accuracy: 0.9914\n",
            "Epoch 58/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0915 - accuracy: 0.9832 - val_loss: 0.0452 - val_accuracy: 0.9980\n",
            "Epoch 59/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0910 - accuracy: 0.9822 - val_loss: 0.0411 - val_accuracy: 0.9990\n",
            "Epoch 60/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0952 - accuracy: 0.9824 - val_loss: 0.0450 - val_accuracy: 0.9986\n",
            "Epoch 61/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0841 - accuracy: 0.9858 - val_loss: 0.0417 - val_accuracy: 0.9988\n",
            "Epoch 62/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0885 - accuracy: 0.9820 - val_loss: 0.0386 - val_accuracy: 0.9978\n",
            "Epoch 63/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0865 - accuracy: 0.9842 - val_loss: 0.0365 - val_accuracy: 0.9988\n",
            "Epoch 64/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0889 - accuracy: 0.9812 - val_loss: 0.0359 - val_accuracy: 0.9992\n",
            "Epoch 65/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0834 - accuracy: 0.9818 - val_loss: 0.0452 - val_accuracy: 0.9938\n",
            "Epoch 66/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0771 - accuracy: 0.9852 - val_loss: 0.0350 - val_accuracy: 0.9986\n",
            "Epoch 67/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0877 - accuracy: 0.9816 - val_loss: 0.0372 - val_accuracy: 0.9980\n",
            "Epoch 68/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0754 - accuracy: 0.9862 - val_loss: 0.0347 - val_accuracy: 0.9982\n",
            "Epoch 69/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0992 - accuracy: 0.9738 - val_loss: 0.0496 - val_accuracy: 0.9884\n",
            "Epoch 70/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0762 - accuracy: 0.9874 - val_loss: 0.0313 - val_accuracy: 0.9992\n",
            "Epoch 71/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0880 - accuracy: 0.9788 - val_loss: 0.0319 - val_accuracy: 0.9986\n",
            "Epoch 72/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0781 - accuracy: 0.9864 - val_loss: 0.0361 - val_accuracy: 0.9978\n",
            "Epoch 73/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.9894 - val_loss: 0.0280 - val_accuracy: 0.9990\n",
            "Epoch 74/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9866 - val_loss: 0.0317 - val_accuracy: 0.9984\n",
            "Epoch 75/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9864 - val_loss: 0.0266 - val_accuracy: 0.9990\n",
            "Epoch 76/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.9890 - val_loss: 0.0264 - val_accuracy: 0.9992\n",
            "Epoch 77/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0728 - accuracy: 0.9858 - val_loss: 0.0282 - val_accuracy: 0.9974\n",
            "Epoch 78/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9884 - val_loss: 0.0246 - val_accuracy: 0.9992\n",
            "Epoch 79/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9868 - val_loss: 0.0255 - val_accuracy: 0.9990\n",
            "Epoch 80/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.9902 - val_loss: 0.0244 - val_accuracy: 0.9990\n",
            "Epoch 81/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9906 - val_loss: 0.0275 - val_accuracy: 0.9976\n",
            "Epoch 82/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.9874 - val_loss: 0.0367 - val_accuracy: 0.9922\n",
            "Epoch 83/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9900 - val_loss: 0.0220 - val_accuracy: 0.9990\n",
            "Epoch 84/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.9908 - val_loss: 0.0229 - val_accuracy: 0.9986\n",
            "Epoch 85/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9876 - val_loss: 0.0298 - val_accuracy: 0.9968\n",
            "Epoch 86/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.9858 - val_loss: 0.0397 - val_accuracy: 0.9900\n",
            "Epoch 87/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0906 - accuracy: 0.9744 - val_loss: 0.0356 - val_accuracy: 0.9916\n",
            "Epoch 88/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.9824 - val_loss: 0.0264 - val_accuracy: 0.9964\n",
            "Epoch 89/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0842 - accuracy: 0.9780 - val_loss: 0.0236 - val_accuracy: 0.9980\n",
            "Epoch 90/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0602 - accuracy: 0.9878 - val_loss: 0.0279 - val_accuracy: 0.9964\n",
            "Epoch 91/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9876 - val_loss: 0.0185 - val_accuracy: 0.9992\n",
            "Epoch 92/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.9906 - val_loss: 0.0204 - val_accuracy: 0.9992\n",
            "Epoch 93/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.9864 - val_loss: 0.0222 - val_accuracy: 0.9990\n",
            "Epoch 94/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.9820 - val_loss: 0.0210 - val_accuracy: 0.9976\n",
            "Epoch 95/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0543 - accuracy: 0.9890 - val_loss: 0.0171 - val_accuracy: 0.9990\n",
            "Epoch 96/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0523 - accuracy: 0.9916 - val_loss: 0.0188 - val_accuracy: 0.9992\n",
            "Epoch 97/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.9896 - val_loss: 0.0170 - val_accuracy: 0.9992\n",
            "Epoch 98/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9922 - val_loss: 0.0192 - val_accuracy: 0.9992\n",
            "Epoch 99/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 0.9914 - val_loss: 0.0259 - val_accuracy: 0.9966\n",
            "Epoch 100/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9842 - val_loss: 0.0185 - val_accuracy: 0.9992\n",
            "Epoch 101/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9904 - val_loss: 0.0183 - val_accuracy: 0.9978\n",
            "Epoch 102/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0520 - accuracy: 0.9900 - val_loss: 0.0148 - val_accuracy: 0.9992\n",
            "Epoch 103/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0482 - accuracy: 0.9926 - val_loss: 0.0155 - val_accuracy: 0.9992\n",
            "Epoch 104/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9902 - val_loss: 0.0153 - val_accuracy: 0.9994\n",
            "Epoch 105/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 0.9916 - val_loss: 0.0180 - val_accuracy: 0.9988\n",
            "Epoch 106/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9912 - val_loss: 0.0170 - val_accuracy: 0.9992\n",
            "Epoch 107/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.9872 - val_loss: 0.0188 - val_accuracy: 0.9974\n",
            "Epoch 108/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.9890 - val_loss: 0.0150 - val_accuracy: 0.9990\n",
            "Epoch 109/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9900 - val_loss: 0.0154 - val_accuracy: 0.9990\n",
            "Epoch 110/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9894 - val_loss: 0.0188 - val_accuracy: 0.9986\n",
            "Epoch 111/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9914 - val_loss: 0.0149 - val_accuracy: 0.9992\n",
            "Epoch 112/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9890 - val_loss: 0.0204 - val_accuracy: 0.9964\n",
            "Epoch 113/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0505 - accuracy: 0.9892 - val_loss: 0.0149 - val_accuracy: 0.9992\n",
            "Epoch 114/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0416 - accuracy: 0.9938 - val_loss: 0.0135 - val_accuracy: 0.9990\n",
            "Epoch 115/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9900 - val_loss: 0.0172 - val_accuracy: 0.9986\n",
            "Epoch 116/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9896 - val_loss: 0.0137 - val_accuracy: 0.9994\n",
            "Epoch 117/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9818 - val_loss: 0.0161 - val_accuracy: 0.9988\n",
            "Epoch 118/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9816 - val_loss: 0.0120 - val_accuracy: 0.9992\n",
            "Epoch 119/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9914 - val_loss: 0.0162 - val_accuracy: 0.9986\n",
            "Epoch 120/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9940 - val_loss: 0.0137 - val_accuracy: 0.9982\n",
            "Epoch 121/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9914 - val_loss: 0.0128 - val_accuracy: 0.9990\n",
            "Epoch 122/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0448 - accuracy: 0.9896 - val_loss: 0.0130 - val_accuracy: 0.9990\n",
            "Epoch 123/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9920 - val_loss: 0.0141 - val_accuracy: 0.9992\n",
            "Epoch 124/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9876 - val_loss: 0.0297 - val_accuracy: 0.9908\n",
            "Epoch 125/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9826 - val_loss: 0.0132 - val_accuracy: 0.9994\n",
            "Epoch 126/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9900 - val_loss: 0.0151 - val_accuracy: 0.9978\n",
            "Epoch 127/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.9914 - val_loss: 0.0158 - val_accuracy: 0.9974\n",
            "Epoch 128/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9918 - val_loss: 0.0187 - val_accuracy: 0.9988\n",
            "Epoch 129/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9860 - val_loss: 0.0139 - val_accuracy: 0.9982\n",
            "Epoch 130/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9920 - val_loss: 0.0169 - val_accuracy: 0.9968\n",
            "Epoch 131/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9918 - val_loss: 0.0119 - val_accuracy: 0.9990\n",
            "Epoch 132/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9924 - val_loss: 0.0111 - val_accuracy: 0.9992\n",
            "Epoch 133/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9922 - val_loss: 0.0109 - val_accuracy: 0.9992\n",
            "Epoch 134/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9924 - val_loss: 0.0101 - val_accuracy: 0.9992\n",
            "Epoch 135/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9922 - val_loss: 0.0150 - val_accuracy: 0.9992\n",
            "Epoch 136/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.9852 - val_loss: 0.0172 - val_accuracy: 0.9972\n",
            "Epoch 137/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.9904 - val_loss: 0.0109 - val_accuracy: 0.9990\n",
            "Epoch 138/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0364 - accuracy: 0.9924 - val_loss: 0.0109 - val_accuracy: 0.9992\n",
            "Epoch 139/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9930 - val_loss: 0.0112 - val_accuracy: 0.9994\n",
            "Epoch 140/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.9914 - val_loss: 0.0101 - val_accuracy: 0.9992\n",
            "Epoch 141/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9938 - val_loss: 0.0097 - val_accuracy: 0.9994\n",
            "Epoch 142/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9932 - val_loss: 0.0104 - val_accuracy: 0.9994\n",
            "Epoch 143/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9914 - val_loss: 0.0114 - val_accuracy: 0.9990\n",
            "Epoch 144/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9926 - val_loss: 0.0108 - val_accuracy: 0.9996\n",
            "Epoch 145/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9934 - val_loss: 0.0094 - val_accuracy: 0.9992\n",
            "Epoch 146/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9928 - val_loss: 0.0101 - val_accuracy: 0.9992\n",
            "Epoch 147/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.9936 - val_loss: 0.0096 - val_accuracy: 0.9994\n",
            "Epoch 148/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.9942 - val_loss: 0.0093 - val_accuracy: 0.9994\n",
            "Epoch 149/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.9926 - val_loss: 0.0117 - val_accuracy: 0.9988\n",
            "Epoch 150/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9932 - val_loss: 0.0091 - val_accuracy: 0.9996\n",
            "Epoch 151/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9932 - val_loss: 0.0085 - val_accuracy: 0.9996\n",
            "Epoch 152/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.9862 - val_loss: 0.0110 - val_accuracy: 0.9994\n",
            "Epoch 153/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 0.9920 - val_loss: 0.0086 - val_accuracy: 0.9994\n",
            "Epoch 154/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9934 - val_loss: 0.0179 - val_accuracy: 0.9962\n",
            "Epoch 155/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.9932 - val_loss: 0.0080 - val_accuracy: 0.9992\n",
            "Epoch 156/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9924 - val_loss: 0.0086 - val_accuracy: 0.9994\n",
            "Epoch 157/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9938 - val_loss: 0.0100 - val_accuracy: 0.9992\n",
            "Epoch 158/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9940 - val_loss: 0.0082 - val_accuracy: 0.9994\n",
            "Epoch 159/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.9936 - val_loss: 0.0097 - val_accuracy: 0.9990\n",
            "Epoch 160/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9900 - val_loss: 0.0108 - val_accuracy: 0.9992\n",
            "Epoch 161/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9916 - val_loss: 0.0079 - val_accuracy: 0.9994\n",
            "Epoch 162/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0367 - accuracy: 0.9918 - val_loss: 0.0079 - val_accuracy: 0.9992\n",
            "Epoch 163/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 0.9940 - val_loss: 0.0088 - val_accuracy: 0.9996\n",
            "Epoch 164/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9956 - val_loss: 0.0091 - val_accuracy: 0.9992\n",
            "Epoch 165/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9944 - val_loss: 0.0076 - val_accuracy: 0.9998\n",
            "Epoch 166/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0293 - accuracy: 0.9944 - val_loss: 0.0084 - val_accuracy: 0.9994\n",
            "Epoch 167/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9950 - val_loss: 0.0096 - val_accuracy: 0.9990\n",
            "Epoch 168/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.9930 - val_loss: 0.0097 - val_accuracy: 0.9992\n",
            "Epoch 169/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.9928 - val_loss: 0.0092 - val_accuracy: 0.9992\n",
            "Epoch 170/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0326 - accuracy: 0.9942 - val_loss: 0.0082 - val_accuracy: 0.9994\n",
            "Epoch 171/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.9932 - val_loss: 0.0077 - val_accuracy: 0.9996\n",
            "Epoch 172/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0311 - accuracy: 0.9938 - val_loss: 0.0079 - val_accuracy: 0.9996\n",
            "Epoch 173/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 0.9940 - val_loss: 0.0085 - val_accuracy: 0.9994\n",
            "Epoch 174/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 0.9936 - val_loss: 0.0083 - val_accuracy: 0.9994\n",
            "Epoch 175/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.9946 - val_loss: 0.0077 - val_accuracy: 0.9992\n",
            "Epoch 176/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9922 - val_loss: 0.0079 - val_accuracy: 0.9994\n",
            "Epoch 177/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0326 - accuracy: 0.9932 - val_loss: 0.0082 - val_accuracy: 0.9992\n",
            "Epoch 178/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.9896 - val_loss: 0.0077 - val_accuracy: 0.9998\n",
            "Epoch 179/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0295 - accuracy: 0.9944 - val_loss: 0.0070 - val_accuracy: 0.9992\n",
            "Epoch 180/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9946 - val_loss: 0.0076 - val_accuracy: 0.9994\n",
            "Epoch 181/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.9928 - val_loss: 0.0129 - val_accuracy: 0.9974\n",
            "Epoch 182/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.9914 - val_loss: 0.0070 - val_accuracy: 0.9994\n",
            "Epoch 183/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9942 - val_loss: 0.0078 - val_accuracy: 0.9994\n",
            "Epoch 184/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 0.9942 - val_loss: 0.0100 - val_accuracy: 0.9988\n",
            "Epoch 185/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.9946 - val_loss: 0.0072 - val_accuracy: 0.9996\n",
            "Epoch 186/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0309 - accuracy: 0.9938 - val_loss: 0.0080 - val_accuracy: 0.9992\n",
            "Epoch 187/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9926 - val_loss: 0.0068 - val_accuracy: 0.9994\n",
            "Epoch 188/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9894 - val_loss: 0.0108 - val_accuracy: 0.9986\n",
            "Epoch 189/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 0.9960 - val_loss: 0.0097 - val_accuracy: 0.9988\n",
            "Epoch 190/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 0.9880 - val_loss: 0.0078 - val_accuracy: 0.9998\n",
            "Epoch 191/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9814 - val_loss: 0.0074 - val_accuracy: 0.9996\n",
            "Epoch 192/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.9938 - val_loss: 0.0076 - val_accuracy: 0.9990\n",
            "Epoch 193/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 0.9946 - val_loss: 0.0073 - val_accuracy: 0.9992\n",
            "Epoch 194/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0342 - accuracy: 0.9930 - val_loss: 0.0160 - val_accuracy: 0.9966\n",
            "Epoch 195/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.9944 - val_loss: 0.0135 - val_accuracy: 0.9970\n",
            "Epoch 196/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9928 - val_loss: 0.0082 - val_accuracy: 0.9992\n",
            "Epoch 197/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9934 - val_loss: 0.0075 - val_accuracy: 0.9990\n",
            "Epoch 198/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 0.9934 - val_loss: 0.0062 - val_accuracy: 0.9996\n",
            "Epoch 199/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 0.9928 - val_loss: 0.0097 - val_accuracy: 0.9986\n",
            "Epoch 200/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9958 - val_loss: 0.0059 - val_accuracy: 0.9996\n",
            "Epoch 201/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9950 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 202/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9944 - val_loss: 0.0065 - val_accuracy: 0.9996\n",
            "Epoch 203/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9922 - val_loss: 0.0062 - val_accuracy: 0.9994\n",
            "Epoch 204/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9918 - val_loss: 0.0070 - val_accuracy: 0.9992\n",
            "Epoch 205/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0285 - accuracy: 0.9938 - val_loss: 0.0062 - val_accuracy: 0.9994\n",
            "Epoch 206/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 0.9966 - val_loss: 0.0057 - val_accuracy: 0.9996\n",
            "Epoch 207/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9924 - val_loss: 0.0064 - val_accuracy: 0.9996\n",
            "Epoch 208/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0303 - accuracy: 0.9924 - val_loss: 0.0058 - val_accuracy: 0.9996\n",
            "Epoch 209/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0295 - accuracy: 0.9932 - val_loss: 0.0062 - val_accuracy: 0.9996\n",
            "Epoch 210/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9934 - val_loss: 0.0074 - val_accuracy: 0.9992\n",
            "Epoch 211/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.9918 - val_loss: 0.0065 - val_accuracy: 0.9994\n",
            "Epoch 212/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 0.9914 - val_loss: 0.0090 - val_accuracy: 0.9990\n",
            "Epoch 213/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9966 - val_loss: 0.0053 - val_accuracy: 0.9996\n",
            "Epoch 214/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.9944 - val_loss: 0.0056 - val_accuracy: 0.9996\n",
            "Epoch 215/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 0.9940 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 216/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9950 - val_loss: 0.0072 - val_accuracy: 0.9994\n",
            "Epoch 217/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9926 - val_loss: 0.0057 - val_accuracy: 0.9994\n",
            "Epoch 218/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 0.9966 - val_loss: 0.0051 - val_accuracy: 0.9996\n",
            "Epoch 219/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.9956 - val_loss: 0.0057 - val_accuracy: 0.9996\n",
            "Epoch 220/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.9956 - val_loss: 0.0053 - val_accuracy: 0.9994\n",
            "Epoch 221/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 0.9940 - val_loss: 0.0054 - val_accuracy: 0.9996\n",
            "Epoch 222/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 0.9940 - val_loss: 0.0058 - val_accuracy: 0.9994\n",
            "Epoch 223/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9930 - val_loss: 0.0052 - val_accuracy: 0.9994\n",
            "Epoch 224/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9946 - val_loss: 0.0049 - val_accuracy: 0.9996\n",
            "Epoch 225/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 0.9928 - val_loss: 0.0056 - val_accuracy: 0.9996\n",
            "Epoch 226/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9958 - val_loss: 0.0065 - val_accuracy: 0.9992\n",
            "Epoch 227/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.9944 - val_loss: 0.0054 - val_accuracy: 0.9994\n",
            "Epoch 228/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9962 - val_loss: 0.0051 - val_accuracy: 0.9996\n",
            "Epoch 229/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 0.9956 - val_loss: 0.0058 - val_accuracy: 0.9996\n",
            "Epoch 230/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.9960 - val_loss: 0.0057 - val_accuracy: 0.9994\n",
            "Epoch 231/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 0.9944 - val_loss: 0.0060 - val_accuracy: 0.9996\n",
            "Epoch 232/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9958 - val_loss: 0.0047 - val_accuracy: 0.9994\n",
            "Epoch 233/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 0.9928 - val_loss: 0.0047 - val_accuracy: 0.9998\n",
            "Epoch 234/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9946 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
            "Epoch 235/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 0.9942 - val_loss: 0.0084 - val_accuracy: 0.9988\n",
            "Epoch 236/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9966 - val_loss: 0.0128 - val_accuracy: 0.9966\n",
            "Epoch 237/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9918 - val_loss: 0.0062 - val_accuracy: 0.9994\n",
            "Epoch 238/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 0.9958 - val_loss: 0.0056 - val_accuracy: 0.9996\n",
            "Epoch 239/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.9948 - val_loss: 0.0049 - val_accuracy: 0.9996\n",
            "Epoch 240/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9952 - val_loss: 0.0055 - val_accuracy: 0.9992\n",
            "Epoch 241/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9938 - val_loss: 0.0051 - val_accuracy: 0.9996\n",
            "Epoch 242/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9958 - val_loss: 0.0088 - val_accuracy: 0.9988\n",
            "Epoch 243/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 0.9948 - val_loss: 0.0044 - val_accuracy: 0.9996\n",
            "Epoch 244/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 0.9938 - val_loss: 0.0087 - val_accuracy: 0.9990\n",
            "Epoch 245/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9952 - val_loss: 0.0058 - val_accuracy: 0.9994\n",
            "Epoch 246/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9946 - val_loss: 0.0099 - val_accuracy: 0.9978\n",
            "Epoch 247/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9922 - val_loss: 0.0047 - val_accuracy: 0.9996\n",
            "Epoch 248/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 0.9950 - val_loss: 0.0053 - val_accuracy: 0.9996\n",
            "Epoch 249/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9942 - val_loss: 0.0059 - val_accuracy: 0.9998\n",
            "Epoch 250/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9946 - val_loss: 0.0053 - val_accuracy: 0.9994\n",
            "Epoch 251/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.9912 - val_loss: 0.0046 - val_accuracy: 0.9996\n",
            "Epoch 252/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9950 - val_loss: 0.0051 - val_accuracy: 0.9998\n",
            "Epoch 253/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.9968 - val_loss: 0.0053 - val_accuracy: 0.9994\n",
            "Epoch 254/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 0.9954 - val_loss: 0.0055 - val_accuracy: 0.9994\n",
            "Epoch 255/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 0.9956 - val_loss: 0.0062 - val_accuracy: 0.9990\n",
            "Epoch 256/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9938 - val_loss: 0.0052 - val_accuracy: 0.9994\n",
            "Epoch 257/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 0.9914 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
            "Epoch 258/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 0.9954 - val_loss: 0.0110 - val_accuracy: 0.9976\n",
            "Epoch 259/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9938 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
            "Epoch 260/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9950 - val_loss: 0.0043 - val_accuracy: 0.9996\n",
            "Epoch 261/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 0.9948 - val_loss: 0.0047 - val_accuracy: 0.9994\n",
            "Epoch 262/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 0.9944 - val_loss: 0.0047 - val_accuracy: 0.9998\n",
            "Epoch 263/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9966 - val_loss: 0.0045 - val_accuracy: 0.9996\n",
            "Epoch 264/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.9952 - val_loss: 0.0046 - val_accuracy: 0.9994\n",
            "Epoch 265/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9976 - val_loss: 0.0050 - val_accuracy: 0.9994\n",
            "Epoch 266/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9950 - val_loss: 0.0041 - val_accuracy: 0.9996\n",
            "Epoch 267/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9956 - val_loss: 0.0130 - val_accuracy: 0.9966\n",
            "Epoch 268/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.9946 - val_loss: 0.0042 - val_accuracy: 0.9996\n",
            "Epoch 269/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9956 - val_loss: 0.0092 - val_accuracy: 0.9976\n",
            "Epoch 270/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9874 - val_loss: 0.0062 - val_accuracy: 0.9994\n",
            "Epoch 271/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 0.9942 - val_loss: 0.0040 - val_accuracy: 0.9998\n",
            "Epoch 272/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.9958 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 273/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9936 - val_loss: 0.0165 - val_accuracy: 0.9948\n",
            "Epoch 274/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 0.9956 - val_loss: 0.0040 - val_accuracy: 0.9998\n",
            "Epoch 275/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9962 - val_loss: 0.0041 - val_accuracy: 0.9998\n",
            "Epoch 276/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9958 - val_loss: 0.0054 - val_accuracy: 0.9994\n",
            "Epoch 277/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 0.9962 - val_loss: 0.0045 - val_accuracy: 0.9996\n",
            "Epoch 278/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9956 - val_loss: 0.0048 - val_accuracy: 0.9994\n",
            "Epoch 279/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 0.9946 - val_loss: 0.0042 - val_accuracy: 0.9998\n",
            "Epoch 280/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9962 - val_loss: 0.0043 - val_accuracy: 0.9996\n",
            "Epoch 281/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9954 - val_loss: 0.0046 - val_accuracy: 0.9994\n",
            "Epoch 282/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9948 - val_loss: 0.0050 - val_accuracy: 0.9994\n",
            "Epoch 283/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9940 - val_loss: 0.0068 - val_accuracy: 0.9988\n",
            "Epoch 284/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9952 - val_loss: 0.0041 - val_accuracy: 0.9996\n",
            "Epoch 285/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 0.9946 - val_loss: 0.0049 - val_accuracy: 0.9994\n",
            "Epoch 286/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9944 - val_loss: 0.0135 - val_accuracy: 0.9966\n",
            "Epoch 287/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9952 - val_loss: 0.0036 - val_accuracy: 0.9998\n",
            "Epoch 288/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9980 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
            "Epoch 289/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9958 - val_loss: 0.0041 - val_accuracy: 0.9996\n",
            "Epoch 290/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.9954 - val_loss: 0.0147 - val_accuracy: 0.9966\n",
            "Epoch 291/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 0.9946 - val_loss: 0.0043 - val_accuracy: 0.9996\n",
            "Epoch 292/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.9960 - val_loss: 0.0044 - val_accuracy: 0.9992\n",
            "Epoch 293/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9976 - val_loss: 0.0034 - val_accuracy: 0.9996\n",
            "Epoch 294/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9948 - val_loss: 0.0040 - val_accuracy: 0.9996\n",
            "Epoch 295/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9968 - val_loss: 0.0038 - val_accuracy: 0.9996\n",
            "Epoch 296/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9956 - val_loss: 0.0036 - val_accuracy: 0.9998\n",
            "Epoch 297/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9970 - val_loss: 0.0032 - val_accuracy: 0.9998\n",
            "Epoch 298/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9950 - val_loss: 0.0058 - val_accuracy: 0.9992\n",
            "Epoch 299/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.9936 - val_loss: 0.0044 - val_accuracy: 0.9996\n",
            "Epoch 300/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9954 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 301/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.9968 - val_loss: 0.0033 - val_accuracy: 0.9996\n",
            "Epoch 302/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9962 - val_loss: 0.0057 - val_accuracy: 0.9992\n",
            "Epoch 303/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9964 - val_loss: 0.0127 - val_accuracy: 0.9966\n",
            "Epoch 304/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9934 - val_loss: 0.0048 - val_accuracy: 0.9994\n",
            "Epoch 305/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9956 - val_loss: 0.0037 - val_accuracy: 0.9996\n",
            "Epoch 306/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9944 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
            "Epoch 307/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9946 - val_loss: 0.0036 - val_accuracy: 0.9996\n",
            "Epoch 308/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.9954 - val_loss: 0.0050 - val_accuracy: 0.9994\n",
            "Epoch 309/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.9948 - val_loss: 0.0057 - val_accuracy: 0.9992\n",
            "Epoch 310/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9882 - val_loss: 0.0037 - val_accuracy: 0.9998\n",
            "Epoch 311/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9960 - val_loss: 0.0065 - val_accuracy: 0.9982\n",
            "Epoch 312/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9960 - val_loss: 0.0034 - val_accuracy: 0.9996\n",
            "Epoch 313/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 0.9954 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 314/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.9960 - val_loss: 0.0033 - val_accuracy: 0.9998\n",
            "Epoch 315/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 0.9948 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 316/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 0.9968 - val_loss: 0.0031 - val_accuracy: 0.9996\n",
            "Epoch 317/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9936 - val_loss: 0.0048 - val_accuracy: 0.9994\n",
            "Epoch 318/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9962 - val_loss: 0.0040 - val_accuracy: 0.9996\n",
            "Epoch 319/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0194 - accuracy: 0.9952 - val_loss: 0.0034 - val_accuracy: 0.9996\n",
            "Epoch 320/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.9962 - val_loss: 0.0032 - val_accuracy: 0.9998\n",
            "Epoch 321/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9950 - val_loss: 0.0047 - val_accuracy: 0.9990\n",
            "Epoch 322/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9964 - val_loss: 0.0035 - val_accuracy: 0.9996\n",
            "Epoch 323/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9960 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 324/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9964 - val_loss: 0.0041 - val_accuracy: 0.9996\n",
            "Epoch 325/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.9964 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 326/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9958 - val_loss: 0.0034 - val_accuracy: 0.9998\n",
            "Epoch 327/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9952 - val_loss: 0.0033 - val_accuracy: 0.9996\n",
            "Epoch 328/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0198 - accuracy: 0.9952 - val_loss: 0.0046 - val_accuracy: 0.9994\n",
            "Epoch 329/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9962 - val_loss: 0.0035 - val_accuracy: 0.9996\n",
            "Epoch 330/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0180 - accuracy: 0.9962 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
            "Epoch 331/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 0.0179 - val_accuracy: 0.9948\n",
            "Epoch 332/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0434 - accuracy: 0.9866 - val_loss: 0.0047 - val_accuracy: 0.9990\n",
            "Epoch 333/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.9920 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
            "Epoch 334/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9958 - val_loss: 0.0031 - val_accuracy: 0.9998\n",
            "Epoch 335/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9958 - val_loss: 0.0051 - val_accuracy: 0.9990\n",
            "Epoch 336/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 0.9946 - val_loss: 0.0041 - val_accuracy: 0.9996\n",
            "Epoch 337/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9968 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
            "Epoch 338/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9948 - val_loss: 0.0030 - val_accuracy: 0.9996\n",
            "Epoch 339/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0186 - accuracy: 0.9958 - val_loss: 0.0028 - val_accuracy: 0.9996\n",
            "Epoch 340/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 0.9960 - val_loss: 0.0038 - val_accuracy: 0.9996\n",
            "Epoch 341/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 0.0038 - val_accuracy: 0.9998\n",
            "Epoch 342/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9948 - val_loss: 0.0145 - val_accuracy: 0.9950\n",
            "Epoch 343/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0500 - accuracy: 0.9832 - val_loss: 0.0075 - val_accuracy: 0.9982\n",
            "Epoch 344/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.9940 - val_loss: 0.0029 - val_accuracy: 0.9998\n",
            "Epoch 345/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9970 - val_loss: 0.0030 - val_accuracy: 0.9998\n",
            "Epoch 346/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9964 - val_loss: 0.0031 - val_accuracy: 0.9996\n",
            "Epoch 347/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9954 - val_loss: 0.0079 - val_accuracy: 0.9978\n",
            "Epoch 348/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9958 - val_loss: 0.0060 - val_accuracy: 0.9988\n",
            "Epoch 349/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9962 - val_loss: 0.0034 - val_accuracy: 0.9996\n",
            "Epoch 350/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9972 - val_loss: 0.0035 - val_accuracy: 0.9996\n",
            "Epoch 351/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9980 - val_loss: 0.0030 - val_accuracy: 0.9996\n",
            "Epoch 352/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9966 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 353/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 0.9970 - val_loss: 0.0026 - val_accuracy: 0.9998\n",
            "Epoch 354/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9974 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
            "Epoch 355/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9978 - val_loss: 0.0026 - val_accuracy: 0.9998\n",
            "Epoch 356/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9944 - val_loss: 0.0057 - val_accuracy: 0.9992\n",
            "Epoch 357/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9946 - val_loss: 0.0047 - val_accuracy: 0.9994\n",
            "Epoch 358/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.9956 - val_loss: 0.0042 - val_accuracy: 0.9994\n",
            "Epoch 359/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9950 - val_loss: 0.0028 - val_accuracy: 0.9998\n",
            "Epoch 360/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9960 - val_loss: 0.0032 - val_accuracy: 0.9996\n",
            "Epoch 361/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 0.9956 - val_loss: 0.0034 - val_accuracy: 0.9992\n",
            "Epoch 362/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9966 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 363/1000\n",
            "40/40 [==============================] - 1s 14ms/step - loss: 0.0192 - accuracy: 0.9962 - val_loss: 0.0032 - val_accuracy: 0.9996\n",
            "Epoch 364/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9962 - val_loss: 0.0026 - val_accuracy: 0.9998\n",
            "Epoch 365/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9948 - val_loss: 0.0108 - val_accuracy: 0.9966\n",
            "Epoch 366/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.1155 - accuracy: 0.9726 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
            "Epoch 367/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 0.9922 - val_loss: 0.0068 - val_accuracy: 0.9984\n",
            "Epoch 368/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0326 - accuracy: 0.9900 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
            "Epoch 369/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 0.9942 - val_loss: 0.0059 - val_accuracy: 0.9990\n",
            "Epoch 370/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9944 - val_loss: 0.0033 - val_accuracy: 0.9996\n",
            "Epoch 371/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9968 - val_loss: 0.0026 - val_accuracy: 0.9998\n",
            "Epoch 372/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.9966 - val_loss: 0.0027 - val_accuracy: 0.9998\n",
            "Epoch 373/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9952 - val_loss: 0.0029 - val_accuracy: 0.9996\n",
            "Epoch 374/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9980 - val_loss: 0.0028 - val_accuracy: 0.9998\n",
            "Epoch 375/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9962 - val_loss: 0.0024 - val_accuracy: 0.9998\n",
            "Epoch 376/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9974 - val_loss: 0.0028 - val_accuracy: 0.9996\n",
            "Epoch 377/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9966 - val_loss: 0.0026 - val_accuracy: 0.9998\n",
            "Epoch 378/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9968 - val_loss: 0.0031 - val_accuracy: 0.9996\n",
            "Epoch 379/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9956 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 380/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9958 - val_loss: 0.0029 - val_accuracy: 0.9996\n",
            "Epoch 381/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.9956 - val_loss: 0.0027 - val_accuracy: 0.9998\n",
            "Epoch 382/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9980 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
            "Epoch 383/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9956 - val_loss: 0.0026 - val_accuracy: 0.9998\n",
            "Epoch 384/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9962 - val_loss: 0.0028 - val_accuracy: 0.9996\n",
            "Epoch 385/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9928 - val_loss: 0.0032 - val_accuracy: 0.9998\n",
            "Epoch 386/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9940 - val_loss: 0.0028 - val_accuracy: 0.9992\n",
            "Epoch 387/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0294 - accuracy: 0.9912 - val_loss: 0.0178 - val_accuracy: 0.9954\n",
            "Epoch 388/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.0024 - val_accuracy: 0.9998\n",
            "Epoch 389/1000\n",
            "40/40 [==============================] - 1s 13ms/step - loss: 0.0168 - accuracy: 0.9958 - val_loss: 0.0024 - val_accuracy: 0.9998\n",
            "Epoch 390/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0149 - accuracy: 0.9968 - val_loss: 0.0072 - val_accuracy: 0.9988\n",
            "Epoch 391/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0175 - accuracy: 0.9962 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 392/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9974 - val_loss: 0.0030 - val_accuracy: 0.9996\n",
            "Epoch 393/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9966 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 394/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 0.9966 - val_loss: 0.0024 - val_accuracy: 0.9998\n",
            "Epoch 395/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 0.9956 - val_loss: 0.0034 - val_accuracy: 0.9996\n",
            "Epoch 396/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0445 - accuracy: 0.9860 - val_loss: 0.0031 - val_accuracy: 0.9998\n",
            "Epoch 397/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9964 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
            "Epoch 398/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0185 - accuracy: 0.9952 - val_loss: 0.0046 - val_accuracy: 0.9994\n",
            "Epoch 399/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 0.9962 - val_loss: 0.0044 - val_accuracy: 0.9996\n",
            "Epoch 400/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0306 - accuracy: 0.9910 - val_loss: 0.0028 - val_accuracy: 0.9996\n",
            "Epoch 401/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9960 - val_loss: 0.0036 - val_accuracy: 0.9992\n",
            "Epoch 402/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0186 - accuracy: 0.9958 - val_loss: 0.0030 - val_accuracy: 0.9994\n",
            "Epoch 403/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9956 - val_loss: 0.0030 - val_accuracy: 0.9996\n",
            "Epoch 404/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9962 - val_loss: 0.0031 - val_accuracy: 0.9996\n",
            "Epoch 405/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9962 - val_loss: 0.0024 - val_accuracy: 0.9998\n",
            "Epoch 406/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9958 - val_loss: 0.0028 - val_accuracy: 0.9998\n",
            "Epoch 407/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9980 - val_loss: 0.0029 - val_accuracy: 0.9996\n",
            "Epoch 408/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9964 - val_loss: 0.0023 - val_accuracy: 0.9996\n",
            "Epoch 409/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9968 - val_loss: 0.0030 - val_accuracy: 0.9996\n",
            "Epoch 410/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0186 - accuracy: 0.9958 - val_loss: 0.0059 - val_accuracy: 0.9994\n",
            "Epoch 411/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9962 - val_loss: 0.0026 - val_accuracy: 0.9998\n",
            "Epoch 412/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.9970 - val_loss: 0.0043 - val_accuracy: 0.9994\n",
            "Epoch 413/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9968 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
            "Epoch 414/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9950 - val_loss: 0.0028 - val_accuracy: 0.9996\n",
            "Epoch 415/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9974 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 416/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9964 - val_loss: 0.0034 - val_accuracy: 0.9992\n",
            "Epoch 417/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9970 - val_loss: 0.0023 - val_accuracy: 0.9998\n",
            "Epoch 418/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9964 - val_loss: 0.0029 - val_accuracy: 0.9998\n",
            "Epoch 419/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 0.9962 - val_loss: 0.0025 - val_accuracy: 0.9998\n",
            "Epoch 420/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9964 - val_loss: 0.0022 - val_accuracy: 0.9998\n",
            "Epoch 421/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9964 - val_loss: 0.0064 - val_accuracy: 0.9986\n",
            "Epoch 422/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9962 - val_loss: 0.0026 - val_accuracy: 0.9996\n",
            "Epoch 423/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
            "Epoch 424/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.9962 - val_loss: 0.0022 - val_accuracy: 0.9998\n",
            "Epoch 425/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 426/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9972 - val_loss: 0.0022 - val_accuracy: 0.9998\n",
            "Epoch 427/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9976 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
            "Epoch 428/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
            "Epoch 429/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 0.9968 - val_loss: 0.0054 - val_accuracy: 0.9992\n",
            "Epoch 430/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9960 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
            "Epoch 431/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9960 - val_loss: 0.0043 - val_accuracy: 0.9996\n",
            "Epoch 432/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9944 - val_loss: 0.0064 - val_accuracy: 0.9990\n",
            "Epoch 433/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9972 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
            "Epoch 434/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9974 - val_loss: 0.0024 - val_accuracy: 0.9998\n",
            "Epoch 435/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9978 - val_loss: 0.0047 - val_accuracy: 0.9994\n",
            "Epoch 436/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9970 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
            "Epoch 437/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 0.0028 - val_accuracy: 0.9996\n",
            "Epoch 438/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9974 - val_loss: 0.0027 - val_accuracy: 0.9996\n",
            "Epoch 439/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9952 - val_loss: 0.0023 - val_accuracy: 0.9998\n",
            "Epoch 440/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9974 - val_loss: 0.0024 - val_accuracy: 0.9998\n",
            "Epoch 441/1000\n",
            "40/40 [==============================] - 1s 14ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 0.0020 - val_accuracy: 0.9998\n",
            "Epoch 442/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.0031 - val_accuracy: 0.9994\n",
            "Epoch 443/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9964 - val_loss: 0.0029 - val_accuracy: 0.9996\n",
            "Epoch 444/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0133 - accuracy: 0.9972 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 445/1000\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.0156 - accuracy: 0.9970 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 446/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9956 - val_loss: 0.0026 - val_accuracy: 0.9998\n",
            "Epoch 447/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9962 - val_loss: 0.0026 - val_accuracy: 0.9996\n",
            "Epoch 448/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.0025 - val_accuracy: 0.9998\n",
            "Epoch 449/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9962 - val_loss: 0.0022 - val_accuracy: 0.9998\n",
            "Epoch 450/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9970 - val_loss: 0.0025 - val_accuracy: 0.9996\n",
            "Epoch 451/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 452/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9976 - val_loss: 0.0033 - val_accuracy: 0.9996\n",
            "Epoch 453/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9968 - val_loss: 0.0022 - val_accuracy: 0.9998\n",
            "Epoch 454/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9978 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
            "Epoch 455/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9976 - val_loss: 0.0028 - val_accuracy: 0.9994\n",
            "Epoch 456/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.9906 - val_loss: 0.0022 - val_accuracy: 0.9996\n",
            "Epoch 457/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.0024 - val_accuracy: 0.9996\n",
            "Epoch 458/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 0.9968 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 459/1000\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0120 - accuracy: 0.9980 - val_loss: 0.0024 - val_accuracy: 0.9996\n",
            "Epoch 460/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.0049 - val_accuracy: 0.9988\n",
            "Epoch 461/1000\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0158 - accuracy: 0.9972 - val_loss: 0.0020 - val_accuracy: 0.9998\n",
            "Epoch 462/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9962 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
            "Epoch 463/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9954 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 464/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9970 - val_loss: 0.0021 - val_accuracy: 0.9998\n",
            "Epoch 465/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9972 - val_loss: 0.0019 - val_accuracy: 0.9998\n",
            "Epoch 466/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9996\n",
            "Epoch 467/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9962 - val_loss: 0.0025 - val_accuracy: 0.9998\n",
            "Epoch 468/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9960 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 469/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9982 - val_loss: 0.0022 - val_accuracy: 0.9998\n",
            "Epoch 470/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.0022 - val_accuracy: 0.9998\n",
            "Epoch 471/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9972 - val_loss: 0.0025 - val_accuracy: 0.9996\n",
            "Epoch 472/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.0022 - val_accuracy: 0.9998\n",
            "Epoch 473/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9972 - val_loss: 0.0024 - val_accuracy: 0.9996\n",
            "Epoch 474/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9972 - val_loss: 0.0024 - val_accuracy: 0.9998\n",
            "Epoch 475/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9972 - val_loss: 0.0033 - val_accuracy: 0.9996\n",
            "Epoch 476/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9968 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
            "Epoch 477/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.9980 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 478/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9968 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
            "Epoch 479/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9960 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 480/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9976 - val_loss: 0.0021 - val_accuracy: 0.9998\n",
            "Epoch 481/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9996\n",
            "Epoch 482/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9976 - val_loss: 0.0021 - val_accuracy: 0.9998\n",
            "Epoch 483/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9960 - val_loss: 0.0020 - val_accuracy: 0.9998\n",
            "Epoch 484/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9976 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 485/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9982 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 486/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9968 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
            "Epoch 487/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9960 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
            "Epoch 488/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
            "Epoch 489/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
            "Epoch 490/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9968 - val_loss: 0.0021 - val_accuracy: 0.9998\n",
            "Epoch 491/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9948 - val_loss: 0.0022 - val_accuracy: 0.9998\n",
            "Epoch 492/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9982 - val_loss: 0.0025 - val_accuracy: 0.9996\n",
            "Epoch 493/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 0.0025 - val_accuracy: 0.9996\n",
            "Epoch 494/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.0019 - val_accuracy: 0.9998\n",
            "Epoch 495/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9970 - val_loss: 0.0029 - val_accuracy: 0.9996\n",
            "Epoch 496/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
            "Epoch 497/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 0.9896 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
            "Epoch 498/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.0026 - val_accuracy: 0.9996\n",
            "Epoch 499/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.0022 - val_accuracy: 0.9996\n",
            "Epoch 500/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9950 - val_loss: 0.0025 - val_accuracy: 0.9996\n",
            "Epoch 501/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 502/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9966 - val_loss: 0.0024 - val_accuracy: 0.9996\n",
            "Epoch 503/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9968 - val_loss: 0.0019 - val_accuracy: 0.9998\n",
            "Epoch 504/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 0.0020 - val_accuracy: 0.9998\n",
            "Epoch 505/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9978 - val_loss: 0.0023 - val_accuracy: 0.9996\n",
            "Epoch 506/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9966 - val_loss: 0.0029 - val_accuracy: 0.9996\n",
            "Epoch 507/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.0055 - val_accuracy: 0.9988\n",
            "Epoch 508/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 0.0019 - val_accuracy: 0.9998\n",
            "Epoch 509/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9964 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
            "Epoch 510/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
            "Epoch 511/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9974 - val_loss: 0.0024 - val_accuracy: 0.9996\n",
            "Epoch 512/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9968 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
            "Epoch 513/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 514/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9958 - val_loss: 0.0023 - val_accuracy: 0.9996\n",
            "Epoch 515/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9972 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
            "Epoch 516/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9970 - val_loss: 0.0025 - val_accuracy: 0.9996\n",
            "Epoch 517/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.0026 - val_accuracy: 0.9996\n",
            "Epoch 518/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9966 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 519/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9960 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
            "Epoch 520/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.0027 - val_accuracy: 0.9996\n",
            "Epoch 521/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9984 - val_loss: 0.0026 - val_accuracy: 0.9996\n",
            "Epoch 522/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9978 - val_loss: 0.0022 - val_accuracy: 0.9996\n",
            "Epoch 523/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.9962 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
            "Epoch 524/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 525/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.0136 - accuracy: 0.9972 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 526/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9972 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
            "Epoch 527/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9972 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
            "Epoch 528/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.0137 - accuracy: 0.9970 - val_loss: 0.0020 - val_accuracy: 0.9998\n",
            "Epoch 529/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0187 - accuracy: 0.9946 - val_loss: 0.0022 - val_accuracy: 0.9998\n",
            "Epoch 530/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0173 - accuracy: 0.9968 - val_loss: 0.0031 - val_accuracy: 0.9996\n",
            "Epoch 531/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9962 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 532/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 0.9974 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
            "Epoch 533/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9976 - val_loss: 0.0019 - val_accuracy: 0.9998\n",
            "Epoch 534/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.0110 - accuracy: 0.9982 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 535/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 536/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9984 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 537/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 538/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9970 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 539/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9970 - val_loss: 0.0024 - val_accuracy: 0.9996\n",
            "Epoch 540/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: 0.0026 - val_accuracy: 0.9996\n",
            "Epoch 541/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9966 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 542/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 543/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
            "Epoch 544/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 545/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 546/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
            "Epoch 547/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9974 - val_loss: 0.0025 - val_accuracy: 0.9996\n",
            "Epoch 548/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
            "Epoch 549/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 0.0052 - val_accuracy: 0.9990\n",
            "Epoch 550/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9966 - val_loss: 0.0023 - val_accuracy: 0.9996\n",
            "Epoch 551/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9970 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
            "Epoch 552/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.0019 - val_accuracy: 0.9998\n",
            "Epoch 553/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 554/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9964 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 555/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9964 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 556/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.9964 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
            "Epoch 557/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9978 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
            "Epoch 558/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
            "Epoch 559/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9980 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
            "Epoch 560/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9980 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 561/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 0.0055 - val_accuracy: 0.9992\n",
            "Epoch 562/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 563/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9966 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
            "Epoch 564/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9982 - val_loss: 0.0022 - val_accuracy: 0.9996\n",
            "Epoch 565/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
            "Epoch 566/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9980 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
            "Epoch 567/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9996\n",
            "Epoch 568/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9970 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
            "Epoch 569/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9968 - val_loss: 0.0020 - val_accuracy: 0.9998\n",
            "Epoch 570/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.0026 - val_accuracy: 0.9996\n",
            "Epoch 571/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
            "Epoch 572/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9966 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 573/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9966 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
            "Epoch 574/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 0.0019 - val_accuracy: 0.9994\n",
            "Epoch 575/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9972 - val_loss: 0.0023 - val_accuracy: 0.9996\n",
            "Epoch 576/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9980 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
            "Epoch 577/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
            "Epoch 578/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9978 - val_loss: 0.0023 - val_accuracy: 0.9996\n",
            "Epoch 579/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9978 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
            "Epoch 580/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.0019 - val_accuracy: 0.9998\n",
            "Epoch 581/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9970 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 582/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9970 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 583/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 584/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9974 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
            "Epoch 585/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9978 - val_loss: 0.0026 - val_accuracy: 0.9996\n",
            "Epoch 586/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
            "Epoch 587/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9964 - val_loss: 0.0019 - val_accuracy: 0.9998\n",
            "Epoch 588/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9972 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 589/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9966 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 590/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9964 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 591/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9974 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
            "Epoch 592/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.0023 - val_accuracy: 0.9996\n",
            "Epoch 593/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
            "Epoch 594/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.0019 - val_accuracy: 0.9998\n",
            "Epoch 595/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9986 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
            "Epoch 596/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.0127 - accuracy: 0.9972 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 597/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
            "Epoch 598/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 0.0020 - val_accuracy: 0.9998\n",
            "Epoch 599/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9984 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 600/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 0.9972 - val_loss: 0.0031 - val_accuracy: 0.9992\n",
            "Epoch 601/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
            "Epoch 602/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.0099 - accuracy: 0.9980 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 603/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9986 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 604/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9966 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
            "Epoch 605/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9976 - val_loss: 0.0020 - val_accuracy: 0.9998\n",
            "Epoch 606/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
            "Epoch 607/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9984 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 608/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 609/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 610/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9978 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
            "Epoch 611/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
            "Epoch 612/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 613/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 614/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.0021 - val_accuracy: 0.9992\n",
            "Epoch 615/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.9916 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
            "Epoch 616/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 617/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 618/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9986 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 619/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
            "Epoch 620/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9970 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
            "Epoch 621/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 622/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9976 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
            "Epoch 623/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9972 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
            "Epoch 624/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
            "Epoch 625/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9976 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
            "Epoch 626/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9976 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
            "Epoch 627/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
            "Epoch 628/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9984 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 629/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9976 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
            "Epoch 630/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9976 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
            "Epoch 631/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 632/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9988 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 633/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9978 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
            "Epoch 634/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
            "Epoch 635/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9980 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
            "Epoch 636/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9984 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 637/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 638/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 639/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9976 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 640/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
            "Epoch 641/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 642/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 643/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9966 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 644/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 645/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9984 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 646/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9978 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 647/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9978 - val_loss: 0.0019 - val_accuracy: 0.9994\n",
            "Epoch 648/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 649/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 650/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 651/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.0028 - val_accuracy: 0.9996\n",
            "Epoch 652/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9980 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
            "Epoch 653/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 654/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.0022 - val_accuracy: 0.9996\n",
            "Epoch 655/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
            "Epoch 656/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 657/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9978 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
            "Epoch 658/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
            "Epoch 659/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
            "Epoch 660/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.0070 - val_accuracy: 0.9986\n",
            "Epoch 661/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9970 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 662/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9968 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 663/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9996\n",
            "Epoch 664/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9996\n",
            "Epoch 665/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 666/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 667/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 0.9984 - val_loss: 0.0019 - val_accuracy: 0.9994\n",
            "Epoch 668/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
            "Epoch 669/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
            "Epoch 670/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.0320 - accuracy: 0.9886 - val_loss: 0.0046 - val_accuracy: 0.9990\n",
            "Epoch 671/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
            "Epoch 672/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0137 - accuracy: 0.9976 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 673/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.0019 - val_accuracy: 0.9994\n",
            "Epoch 674/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9972 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
            "Epoch 675/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9984 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 676/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 677/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 678/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9978 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 679/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 680/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 681/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9984 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
            "Epoch 682/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 683/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 0.0022 - val_accuracy: 0.9996\n",
            "Epoch 684/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 685/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9966 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 686/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 687/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 688/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 689/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 690/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9986 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 691/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
            "Epoch 692/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 693/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 694/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 695/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 696/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9978 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 697/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 698/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 699/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 700/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9978 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
            "Epoch 701/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 702/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9972 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 703/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.0075 - val_accuracy: 0.9990\n",
            "Epoch 704/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9910 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 705/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.9964 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
            "Epoch 706/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9966 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 707/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
            "Epoch 708/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 709/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 710/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9972 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 711/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 712/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
            "Epoch 713/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
            "Epoch 714/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9978 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 715/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9978 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 716/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
            "Epoch 717/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9972 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 718/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9984 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
            "Epoch 719/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 720/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9978 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 721/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9982 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
            "Epoch 722/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
            "Epoch 723/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 0.0024 - val_accuracy: 0.9996\n",
            "Epoch 724/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0287 - accuracy: 0.9906 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 725/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 726/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0087 - val_accuracy: 0.9978\n",
            "Epoch 727/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.9862 - val_loss: 0.0070 - val_accuracy: 0.9972\n",
            "Epoch 728/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.0032 - val_accuracy: 0.9996\n",
            "Epoch 729/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 730/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 731/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 732/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9986 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 733/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.0114 - accuracy: 0.9978 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
            "Epoch 734/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0260 - accuracy: 0.9924 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 735/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 9.3242e-04 - val_accuracy: 1.0000\n",
            "Epoch 736/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 737/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 738/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
            "Epoch 739/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 740/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 741/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 742/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9984 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 743/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 744/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 745/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9984 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
            "Epoch 746/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 9.6068e-04 - val_accuracy: 0.9998\n",
            "Epoch 747/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 9.9406e-04 - val_accuracy: 1.0000\n",
            "Epoch 748/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 749/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9986 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
            "Epoch 750/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
            "Epoch 751/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 0.9916 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
            "Epoch 752/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 753/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 754/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 9.6191e-04 - val_accuracy: 1.0000\n",
            "Epoch 755/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 756/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
            "Epoch 757/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 758/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 759/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
            "Epoch 760/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 761/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 762/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9978 - val_loss: 0.0020 - val_accuracy: 0.9992\n",
            "Epoch 763/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 764/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 765/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 766/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
            "Epoch 767/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 9.8486e-04 - val_accuracy: 1.0000\n",
            "Epoch 768/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 769/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9990 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 770/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9978 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 771/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 772/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9984 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 773/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 774/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
            "Epoch 775/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
            "Epoch 776/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 777/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 778/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 779/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 780/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
            "Epoch 781/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9984 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 782/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0015 - val_accuracy: 0.9994\n",
            "Epoch 783/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 784/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 785/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 786/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9976 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 787/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.0026 - val_accuracy: 0.9996\n",
            "Epoch 788/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 789/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
            "Epoch 790/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 791/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 792/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 793/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9978 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 794/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9984 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
            "Epoch 795/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 9.9363e-04 - val_accuracy: 1.0000\n",
            "Epoch 796/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.9984 - val_loss: 9.1921e-04 - val_accuracy: 1.0000\n",
            "Epoch 797/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9986 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 798/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.0101 - accuracy: 0.9984 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 799/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
            "Epoch 800/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 9.8643e-04 - val_accuracy: 0.9998\n",
            "Epoch 801/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
            "Epoch 802/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
            "Epoch 803/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9980 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
            "Epoch 804/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 805/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 806/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
            "Epoch 807/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 808/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9984 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
            "Epoch 809/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9978 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 810/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
            "Epoch 811/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9984 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 812/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 813/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9986 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
            "Epoch 814/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 815/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 816/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 817/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 818/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9980 - val_loss: 9.3370e-04 - val_accuracy: 1.0000\n",
            "Epoch 819/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 820/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 821/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9986 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 822/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 823/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9980 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 824/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
            "Epoch 825/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9990 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
            "Epoch 826/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9984 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 827/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9930 - val_loss: 0.0027 - val_accuracy: 0.9992\n",
            "Epoch 828/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 829/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 9.7263e-04 - val_accuracy: 1.0000\n",
            "Epoch 830/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 831/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 832/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 833/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 9.9027e-04 - val_accuracy: 1.0000\n",
            "Epoch 834/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 9.7613e-04 - val_accuracy: 1.0000\n",
            "Epoch 835/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
            "Epoch 836/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 837/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 9.4081e-04 - val_accuracy: 1.0000\n",
            "Epoch 838/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 839/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9986 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 840/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9978 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
            "Epoch 841/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 842/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 843/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9988 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 844/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 9.9040e-04 - val_accuracy: 0.9998\n",
            "Epoch 845/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 846/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 9.7338e-04 - val_accuracy: 1.0000\n",
            "Epoch 847/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 848/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
            "Epoch 849/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.0024 - val_accuracy: 0.9996\n",
            "Epoch 850/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 851/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 8.7103e-04 - val_accuracy: 1.0000\n",
            "Epoch 852/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9978 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 853/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9986 - val_loss: 9.2159e-04 - val_accuracy: 0.9998\n",
            "Epoch 854/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
            "Epoch 855/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 856/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 857/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 9.7276e-04 - val_accuracy: 1.0000\n",
            "Epoch 858/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9978 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 859/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
            "Epoch 860/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9988 - val_loss: 8.4294e-04 - val_accuracy: 1.0000\n",
            "Epoch 861/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 9.3335e-04 - val_accuracy: 0.9998\n",
            "Epoch 862/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 8.8164e-04 - val_accuracy: 1.0000\n",
            "Epoch 863/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 864/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9984 - val_loss: 9.7553e-04 - val_accuracy: 1.0000\n",
            "Epoch 865/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 866/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.0121 - accuracy: 0.9976 - val_loss: 9.6812e-04 - val_accuracy: 0.9998\n",
            "Epoch 867/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9980 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
            "Epoch 868/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0150 - accuracy: 0.9964 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 869/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 9.7743e-04 - val_accuracy: 1.0000\n",
            "Epoch 870/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 9.4395e-04 - val_accuracy: 0.9998\n",
            "Epoch 871/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 872/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 873/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 874/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 875/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
            "Epoch 876/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 877/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 878/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9986 - val_loss: 9.6013e-04 - val_accuracy: 1.0000\n",
            "Epoch 879/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 9.6699e-04 - val_accuracy: 1.0000\n",
            "Epoch 880/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 9.3508e-04 - val_accuracy: 1.0000\n",
            "Epoch 881/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 8.9425e-04 - val_accuracy: 0.9998\n",
            "Epoch 882/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 9.1956e-04 - val_accuracy: 0.9998\n",
            "Epoch 883/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 9.2152e-04 - val_accuracy: 0.9998\n",
            "Epoch 884/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9978 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 885/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 886/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
            "Epoch 887/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
            "Epoch 888/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
            "Epoch 889/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 8.7442e-04 - val_accuracy: 1.0000\n",
            "Epoch 890/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9980 - val_loss: 9.5597e-04 - val_accuracy: 1.0000\n",
            "Epoch 891/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9978 - val_loss: 9.2642e-04 - val_accuracy: 1.0000\n",
            "Epoch 892/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 8.3133e-04 - val_accuracy: 1.0000\n",
            "Epoch 893/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 9.6155e-04 - val_accuracy: 0.9998\n",
            "Epoch 894/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 9.7258e-04 - val_accuracy: 0.9998\n",
            "Epoch 895/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9994 - val_loss: 9.9943e-04 - val_accuracy: 1.0000\n",
            "Epoch 896/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 897/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 9.0675e-04 - val_accuracy: 1.0000\n",
            "Epoch 898/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9986 - val_loss: 7.8993e-04 - val_accuracy: 0.9998\n",
            "Epoch 899/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 9.9598e-04 - val_accuracy: 1.0000\n",
            "Epoch 900/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.0022 - val_accuracy: 0.9992\n",
            "Epoch 901/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
            "Epoch 902/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 903/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 904/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 905/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
            "Epoch 906/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9984 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 907/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 908/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9986 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 909/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 8.6428e-04 - val_accuracy: 1.0000\n",
            "Epoch 910/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 911/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 912/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 913/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 914/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 9.3782e-04 - val_accuracy: 1.0000\n",
            "Epoch 915/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 7.4273e-04 - val_accuracy: 1.0000\n",
            "Epoch 916/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 8.1300e-04 - val_accuracy: 0.9998\n",
            "Epoch 917/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 9.2025e-04 - val_accuracy: 1.0000\n",
            "Epoch 918/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 919/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 0.0025 - val_accuracy: 0.9992\n",
            "Epoch 920/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0219 - accuracy: 0.9938 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 921/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 9.7210e-04 - val_accuracy: 1.0000\n",
            "Epoch 922/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9978 - val_loss: 8.2635e-04 - val_accuracy: 1.0000\n",
            "Epoch 923/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
            "Epoch 924/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 7.8435e-04 - val_accuracy: 1.0000\n",
            "Epoch 925/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
            "Epoch 926/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 9.9507e-04 - val_accuracy: 0.9996\n",
            "Epoch 927/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 8.6822e-04 - val_accuracy: 1.0000\n",
            "Epoch 928/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 8.8776e-04 - val_accuracy: 1.0000\n",
            "Epoch 929/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 930/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 931/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 7.9903e-04 - val_accuracy: 1.0000\n",
            "Epoch 932/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 8.9014e-04 - val_accuracy: 1.0000\n",
            "Epoch 933/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
            "Epoch 934/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 8.4659e-04 - val_accuracy: 1.0000\n",
            "Epoch 935/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.0122 - val_accuracy: 0.9950\n",
            "Epoch 936/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.0435 - accuracy: 0.9888 - val_loss: 0.0030 - val_accuracy: 0.9992\n",
            "Epoch 937/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
            "Epoch 938/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 8.5752e-04 - val_accuracy: 1.0000\n",
            "Epoch 939/1000\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 9.9271e-04 - val_accuracy: 0.9998\n",
            "Epoch 940/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 9.4816e-04 - val_accuracy: 1.0000\n",
            "Epoch 941/1000\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 8.3218e-04 - val_accuracy: 0.9998\n",
            "Epoch 942/1000\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 7.4715e-04 - val_accuracy: 1.0000\n",
            "Epoch 943/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 7.9481e-04 - val_accuracy: 1.0000\n",
            "Epoch 944/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 8.6008e-04 - val_accuracy: 1.0000\n",
            "Epoch 945/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 9.9019e-04 - val_accuracy: 0.9998\n",
            "Epoch 946/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 9.8899e-04 - val_accuracy: 0.9998\n",
            "Epoch 947/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
            "Epoch 948/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
            "Epoch 949/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 7.6074e-04 - val_accuracy: 0.9998\n",
            "Epoch 950/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 9.8539e-04 - val_accuracy: 0.9998\n",
            "Epoch 951/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 8.8833e-04 - val_accuracy: 1.0000\n",
            "Epoch 952/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.0022 - val_accuracy: 0.9996\n",
            "Epoch 953/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 9.3402e-04 - val_accuracy: 1.0000\n",
            "Epoch 954/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 7.4648e-04 - val_accuracy: 1.0000\n",
            "Epoch 955/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 9.3884e-04 - val_accuracy: 1.0000\n",
            "Epoch 956/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 7.5833e-04 - val_accuracy: 1.0000\n",
            "Epoch 957/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 9.4789e-04 - val_accuracy: 0.9998\n",
            "Epoch 958/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9978 - val_loss: 8.6643e-04 - val_accuracy: 1.0000\n",
            "Epoch 959/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9986 - val_loss: 9.3552e-04 - val_accuracy: 1.0000\n",
            "Epoch 960/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
            "Epoch 961/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9956 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
            "Epoch 962/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 9.7035e-04 - val_accuracy: 1.0000\n",
            "Epoch 963/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
            "Epoch 964/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9988 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 965/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 8.1526e-04 - val_accuracy: 1.0000\n",
            "Epoch 966/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 967/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9986 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 968/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 6.8945e-04 - val_accuracy: 1.0000\n",
            "Epoch 969/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9978 - val_loss: 8.0486e-04 - val_accuracy: 1.0000\n",
            "Epoch 970/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 8.4408e-04 - val_accuracy: 1.0000\n",
            "Epoch 971/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 972/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 7.6939e-04 - val_accuracy: 1.0000\n",
            "Epoch 973/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9986 - val_loss: 9.8125e-04 - val_accuracy: 0.9998\n",
            "Epoch 974/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 7.4433e-04 - val_accuracy: 1.0000\n",
            "Epoch 975/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 7.5590e-04 - val_accuracy: 1.0000\n",
            "Epoch 976/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 8.9773e-04 - val_accuracy: 0.9998\n",
            "Epoch 977/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
            "Epoch 978/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 0.9922 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
            "Epoch 979/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9978 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
            "Epoch 980/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9972 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
            "Epoch 981/1000\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 9.5532e-04 - val_accuracy: 0.9998\n",
            "Epoch 982/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
            "Epoch 983/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 8.4837e-04 - val_accuracy: 0.9998\n",
            "Epoch 984/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
            "Epoch 985/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9852 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
            "Epoch 986/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 8.7677e-04 - val_accuracy: 1.0000\n",
            "Epoch 987/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9980 - val_loss: 7.1751e-04 - val_accuracy: 1.0000\n",
            "Epoch 988/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 989/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 9.2026e-04 - val_accuracy: 0.9998\n",
            "Epoch 990/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 9.1174e-04 - val_accuracy: 1.0000\n",
            "Epoch 991/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 6.8822e-04 - val_accuracy: 1.0000\n",
            "Epoch 992/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 9.2619e-04 - val_accuracy: 0.9998\n",
            "Epoch 993/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 994/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 7.7803e-04 - val_accuracy: 1.0000\n",
            "Epoch 995/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 8.7384e-04 - val_accuracy: 1.0000\n",
            "Epoch 996/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 7.9418e-04 - val_accuracy: 1.0000\n",
            "Epoch 997/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9986 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 998/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 6.7522e-04 - val_accuracy: 1.0000\n",
            "Epoch 999/1000\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 7.8947e-04 - val_accuracy: 0.9998\n",
            "Epoch 1000/1000\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 7.5905e-04 - val_accuracy: 0.9998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Loss"
      ],
      "metadata": {
        "id": "QCmv99GN519D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = go.Scatter(y=his.history['loss'],\n",
        "                    mode=\"lines\",\n",
        "                    line=dict(\n",
        "                        width=2,\n",
        "                        color='blue'),\n",
        "                        name=\"loss\"\n",
        "                   )\n",
        "h2 = go.Scatter(y=his.history['val_loss'],\n",
        "                    mode=\"lines\",\n",
        "                    line=dict(\n",
        "                        width=2,\n",
        "                        color='red'),\n",
        "                        name=\"val_loss\"\n",
        "                   )\n",
        "\n",
        "data = [h1,h2]\n",
        "layout1 = go.Layout(title='Loss',\n",
        "                   xaxis=dict(title='epochs'),\n",
        "                   yaxis=dict(title=''))\n",
        "fig1 = go.Figure(data = data, layout=layout1)\n",
        "plotly.offline.iplot(fig1)"
      ],
      "metadata": {
        "id": "reSSWGe_54Da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "23bb1b30-7c24-444a-b5a1-9196859736f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"5b083c61-4676-46f3-b828-f46d72da8c3e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5b083c61-4676-46f3-b828-f46d72da8c3e\")) {                    Plotly.newPlot(                        \"5b083c61-4676-46f3-b828-f46d72da8c3e\",                        [{\"line\":{\"color\":\"blue\",\"width\":2},\"mode\":\"lines\",\"name\":\"loss\",\"y\":[3.272571563720703,1.1389832496643066,1.0637001991271973,0.8789897561073303,0.7189458012580872,0.6702888607978821,0.6020039319992065,0.5690560936927795,0.5295753479003906,0.5071263909339905,0.42798203229904175,0.41984155774116516,0.47186392545700073,0.5009960532188416,0.36303049325942993,0.35067203640937805,0.39527252316474915,0.3223899006843567,0.29793399572372437,0.2996938228607178,0.2669162154197693,0.2577781081199646,0.2899448275566101,0.24715089797973633,0.212554469704628,0.20294779539108276,0.29038962721824646,0.20107969641685486,0.1915343552827835,0.1866137534379959,0.21028703451156616,0.18936684727668762,0.1759069561958313,0.16289402544498444,0.14850106835365295,0.15523572266101837,0.17165924608707428,0.16356879472732544,0.14587433636188507,0.1476520597934723,0.1347300112247467,0.1364741325378418,0.1271047592163086,0.11907962709665298,0.20182615518569946,0.12886428833007812,0.12317131459712982,0.11928365379571915,0.1052132174372673,0.10426267236471176,0.12207488715648651,0.11160250008106232,0.11579018831253052,0.1036473885178566,0.10275217145681381,0.10478226095438004,0.09285230934619904,0.10812879353761673,0.10065450519323349,0.10371662676334381,0.09869606047868729,0.0962219089269638,0.09317120909690857,0.08810602128505707,0.09066937118768692,0.08214537054300308,0.08986655622720718,0.1268020123243332,0.0888846293091774,0.08807839453220367,0.10700063407421112,0.08648533374071121,0.08190663158893585,0.0793951004743576,0.07549410313367844,0.07444439083337784,0.07198116928339005,0.08845280110836029,0.07724688947200775,0.0732799842953682,0.08943235129117966,0.07874570786952972,0.10705582052469254,0.07706189900636673,0.06786397099494934,0.06709196418523788,0.07387122511863708,0.06502357125282288,0.07252579182386398,0.06559684872627258,0.08745863288640976,0.07252327352762222,0.07374614477157593,0.06586194038391113,0.0765841007232666,0.06447251886129379,0.09456493705511093,0.07197742909193039,0.2000517100095749,0.07032562792301178,0.0904042050242424,0.06272121518850327,0.06410212069749832,0.05913500487804413,0.06183960661292076,0.05950748920440674,0.05706962198019028,0.05588062107563019,0.06637271493673325,0.053355757147073746,0.06001818925142288,0.05953165143728256,0.05357779562473297,0.053480375558137894,0.05327267944812775,0.05312187597155571,0.05240878462791443,0.0636724978685379,0.058120548725128174,0.057331763207912445,0.05655301362276077,0.057512182742357254,0.053124696016311646,0.05100226402282715,0.05373065173625946,0.05752100050449371,0.05256761983036995,0.05373147502541542,0.052655741572380066,0.053926240652799606,0.050129905343055725,0.04763907939195633,0.05200609192252159,0.05262378975749016,0.04729577526450157,0.056399621069431305,0.05951445922255516,0.05173257365822792,0.046190209686756134,0.044049836695194244,0.0452352911233902,0.042996782809495926,0.04605768993496895,0.04589611291885376,0.044618189334869385,0.049603354185819626,0.04743259400129318,0.04787168279290199,0.04458408057689667,0.04318160563707352,0.04661371558904648,0.046462297439575195,0.0760936364531517,0.04981009662151337,0.04389392212033272,0.042337916791439056,0.04360194131731987,0.039876196533441544,0.04285949841141701,0.04187679663300514,0.04498597979545593,0.04111354798078537,0.04122302308678627,0.05316689983010292,0.042200036346912384,0.042991381138563156,0.037327516824007034,0.04713788256049156,0.039855584502220154,0.041237544268369675,0.048565708100795746,0.05152348801493645,0.04222805052995682,0.0468657948076725,0.036478642374277115,0.03952567279338837,0.04594605788588524,0.04125908762216568,0.037495631724596024,0.03762795031070709,0.04214240238070488,0.04212699458003044,0.04021012783050537,0.04888176545500755,0.03608589619398117,0.04015706479549408,0.041997525840997696,0.03799273073673248,0.03836863860487938,0.03612542897462845,0.0358324758708477,0.03593435510993004,0.05514730140566826,0.044710852205753326,0.040951427072286606,0.04250306636095047,0.03365227207541466,0.036285400390625,0.0398542657494545,0.04149242118000984,0.045737605541944504,0.03970113769173622,0.03606132045388222,0.03780244290828705,0.0353519432246685,0.03692271187901497,0.03650261089205742,0.03584589809179306,0.0685170441865921,0.036870431154966354,0.03447902202606201,0.03032679669559002,0.03973780944943428,0.035638973116874695,0.035827554762363434,0.03501839563250542,0.03481128066778183,0.031166071072220802,0.033353812992572784,0.03258657082915306,0.03565515950322151,0.03333725407719612,0.03179626166820526,0.03565666079521179,0.039446715265512466,0.03398195281624794,0.07881025224924088,0.03474068269133568,0.031378474086523056,0.04065707325935364,0.039118967950344086,0.03519037738442421,0.03327375650405884,0.032934654504060745,0.033724647015333176,0.03519243001937866,0.034398403018713,0.04223097860813141,0.04284347966313362,0.03451715409755707,0.03920939937233925,0.03154348209500313,0.030714044347405434,0.02922278828918934,0.030829953029751778,0.02950793132185936,0.030806099995970726,0.030951201915740967,0.03175444155931473,0.032342638820409775,0.02860209345817566,0.035636208951473236,0.030621206387877464,0.0336587019264698,0.0386207140982151,0.030761225149035454,0.030104229226708412,0.027671465650200844,0.028056396171450615,0.029497243463993073,0.03657292202115059,0.030067749321460724,0.028168216347694397,0.031852543354034424,0.03483593463897705,0.032500628381967545,0.03391445800662041,0.029134325683116913,0.034466300159692764,0.030321264639496803,0.02792096883058548,0.04151985049247742,0.11468811333179474,0.06292304396629333,0.040397465229034424,0.04088422656059265,0.041336651891469955,0.037337783724069595,0.04719867929816246,0.037231508642435074,0.035172343254089355,0.025523534044623375,0.028132736682891846,0.02978934720158577,0.027294714003801346,0.02703177183866501,0.029599975794553757,0.037838224321603775,0.029652168974280357,0.030258169397711754,0.025262296199798584,0.03461392968893051,0.0278981514275074,0.029126431792974472,0.02699885331094265,0.027138620615005493,0.024447420611977577,0.026315215975046158,0.02856120839715004,0.03176450729370117,0.025509808212518692,0.06086030229926109,0.028903717175126076,0.03580861538648605,0.028999697417020798,0.027680017054080963,0.02743110992014408,0.02854653261601925,0.02661011926829815,0.03068258985877037,0.0302495788782835,0.028588684275746346,0.03710661828517914,0.026812497526407242,0.028655098751187325,0.027293026447296143,0.024864019826054573,0.024046294391155243,0.02668307162821293,0.028223354369401932,0.026995856314897537,0.02500366047024727,0.027554919943213463,0.025896664708852768,0.030766550451517105,0.026158396154642105,0.021655485033988953,0.027545569464564323,0.02701888419687748,0.02711580879986286,0.02728359028697014,0.026630181819200516,0.025005711242556572,0.024979732930660248,0.02898089960217476,0.025414178147912025,0.023948485031723976,0.02956295758485794,0.023728959262371063,0.026302509009838104,0.020278071984648705,0.02823910489678383,0.02331298589706421,0.02684369497001171,0.02617610991001129,0.024294549599289894,0.026312394067645073,0.02561863139271736,0.023676225915551186,0.025447320193052292,0.02484813891351223,0.02452187053859234,0.02374975197017193,0.025063280016183853,0.024193692952394485,0.02994244359433651,0.026225250214338303,0.08903095871210098,0.04684467986226082,0.03917073830962181,0.030347729101777077,0.026758532971143723,0.028863614425063133,0.025761296972632408,0.03157170116901398,0.03080669604241848,0.026029683649539948,0.023816263303160667,0.035199809819459915,0.03577891364693642,0.037054721266031265,0.020766377449035645,0.025528939440846443,0.02386879362165928,0.017960049211978912,0.020871462300419807,0.02461373805999756,0.021002842113375664,0.026473505422472954,0.026948871091008186,0.02660263143479824,0.02295832335948944,0.020882098004221916,0.025258800014853477,0.02408815547823906,0.02568111941218376,0.0307523962110281,0.020050659775733948,0.023585382848978043,0.02371963858604431,0.02484799735248089,0.02452213503420353,0.021954473108053207,0.02348392643034458,0.035582754760980606,0.05118314549326897,0.024770645424723625,0.02098281867802143,0.02275518886744976,0.020833265036344528,0.027837589383125305,0.02546336129307747,0.03658507391810417,0.02541753463447094,0.023071501404047012,0.024149032309651375,0.022411469370126724,0.03923061490058899,0.026456153020262718,0.020871520042419434,0.02095998451113701,0.035214684903621674,0.020428545773029327,0.02296629175543785,0.019370708614587784,0.021777844056487083,0.020663881674408913,0.02160142920911312,0.02007458359003067,0.023192645981907845,0.02227294072508812,0.026782479137182236,0.026397356763482094,0.024581003934144974,0.025416212156414986,0.027953404933214188,0.02471098303794861,0.03651069104671478,0.02182183414697647,0.02067473530769348,0.021572818979620934,0.02078358829021454,0.023779962211847305,0.020511943846940994,0.034589339047670364,0.02836022339761257,0.02429148554801941,0.026590757071971893,0.02432946301996708,0.024704638868570328,0.024738965556025505,0.02261928841471672,0.024713754653930664,0.019057538360357285,0.018471334129571915,0.019382987171411514,0.02096674218773842,0.021663479506969452,0.02999388799071312,0.04405685514211655,0.024393528699874878,0.024992426857352257,0.026896566152572632,0.0195314884185791,0.017693471163511276,0.018087930977344513,0.02033662609755993,0.025737155228853226,0.019474957138299942,0.016792500391602516,0.01888858526945114,0.025174938142299652,0.017283178865909576,0.0206349678337574,0.019702577963471413,0.01935335248708725,0.024500105530023575,0.018848149105906487,0.01703615114092827,0.019032981246709824,0.020119599997997284,0.023974929004907608,0.019441217184066772,0.022094612941145897,0.020713480189442635,0.02061527781188488,0.020171726122498512,0.020331675186753273,0.020655548200011253,0.018721194937825203,0.030536791309714317,0.022543609142303467,0.07054706662893295,0.023810410872101784,0.02265261672437191,0.022115400061011314,0.019971754401922226,0.019234078004956245,0.021161038428544998,0.021610569208860397,0.017760485410690308,0.02418489381670952,0.01885327883064747,0.016742808744311333,0.01836157776415348,0.01802065223455429,0.018147720023989677,0.018777530640363693,0.02172074466943741,0.01977643370628357,0.019849596545100212,0.020301006734371185,0.02072373405098915,0.017338858917355537,0.017214784398674965,0.02151336893439293,0.017534352838993073,0.019728200510144234,0.021484317258000374,0.022852858528494835,0.018068674951791763,0.02112056501209736,0.02388436533510685,0.016398990526795387,0.01750965788960457,0.017688656225800514,0.01971757970750332,0.023100901395082474,0.021061426028609276,0.020508114248514175,0.024105824530124664,0.04769076406955719,0.020312057808041573,0.027193283662199974,0.017071137204766273,0.020276203751564026,0.017455121502280235,0.01716245897114277,0.02205282263457775,0.02062707394361496,0.017347659915685654,0.01752389408648014,0.018350467085838318,0.019695943221449852,0.024336474016308784,0.01864450052380562,0.025368448346853256,0.03404795378446579,0.02498309127986431,0.02293592132627964,0.01574166864156723,0.01636396162211895,0.02399846725165844,0.021729739382863045,0.016920750960707664,0.015513458289206028,0.018886340782046318,0.01669011451303959,0.015081947669386864,0.02140064910054207,0.017049219459295273,0.017444083467125893,0.02238236553966999,0.019725432619452477,0.01383474562317133,0.017980949953198433,0.02098672091960907,0.017625542357563972,0.02012949436903,0.020111538469791412,0.043532878160476685,0.02371865138411522,0.055113062262535095,0.021315516903996468,0.0177103653550148,0.01696765050292015,0.01876211166381836,0.017869150266051292,0.016119759529829025,0.016772780567407608,0.01597840152680874,0.02241116762161255,0.02395572140812874,0.019359653815627098,0.021602019667625427,0.02060347981750965,0.017102506011724472,0.01894301548600197,0.014451851136982441,0.01583069935441017,0.015533908270299435,0.016176829114556313,0.01675419695675373,0.01635453663766384,0.016753697767853737,0.01589292846620083,0.015101232565939426,0.017345385625958443,0.020403780043125153,0.016343342140316963,0.018550466746091843,0.01578211598098278,0.023235032334923744,0.017203781753778458,0.017807673662900925,0.01851852983236313,0.04288170486688614,0.021413622424006462,0.019884927198290825,0.02061852253973484,0.01880425028502941,0.018280768766999245,0.017744548618793488,0.015936804935336113,0.0150685990229249,0.018195122480392456,0.016894647851586342,0.0159057155251503,0.01762099377810955,0.016506923362612724,0.020551951602101326,0.01622295193374157,0.017932452261447906,0.01485474407672882,0.016308074817061424,0.01669205166399479,0.02751401625573635,0.014643396250903606,0.022907616570591927,0.01678641140460968,0.018344495445489883,0.018112769350409508,0.015745732933282852,0.03203651309013367,0.0157325342297554,0.017992358654737473,0.024269985035061836,0.01791395992040634,0.01739765889942646,0.016202013939619064,0.016080444678664207,0.016882188618183136,0.01607474684715271,0.019546611234545708,0.02004399336874485,0.018391352146863937,0.01739252172410488,0.020489497110247612,0.01878722943365574,0.015722142532467842,0.016416022554039955,0.018512062728405,0.017236653715372086,0.015369388274848461,0.01972319930791855,0.027602365240454674,0.01691761612892151,0.014330186881124973,0.016803694888949394,0.021828753873705864,0.021006159484386444,0.018806057050824165,0.018781054764986038,0.014971684664487839,0.016782334074378014,0.016417471691966057,0.019860640168190002,0.015371528454124928,0.015010504052042961,0.016572415828704834,0.01589513011276722,0.014889764599502087,0.011621593497693539,0.015405720099806786,0.017056291922926903,0.02021370641887188,0.016066627576947212,0.0181175135076046,0.018334021791815758,0.020021934062242508,0.01900174282491207,0.019820408895611763,0.015234614722430706,0.012914779596030712,0.016422081738710403,0.017991960048675537,0.019675111398100853,0.015294424258172512,0.015120570547878742,0.011954626068472862,0.01569952443242073,0.013857865706086159,0.012617042288184166,0.016434647142887115,0.020133258774876595,0.01625388115644455,0.014156169258058071,0.01921984925866127,0.020897574722766876,0.013647761195898056,0.017724717035889626,0.016157211735844612,0.014023288153111935,0.015821758657693863,0.015554800629615784,0.013827549293637276,0.023550324141979218,0.01757797971367836,0.014378300867974758,0.018146969377994537,0.01731361448764801,0.018024366348981857,0.018962020054459572,0.012354517355561256,0.017567938193678856,0.014616076834499836,0.015893932431936264,0.014437123201787472,0.01673208549618721,0.019238939508795738,0.013452711515128613,0.014714066870510578,0.013235790655016899,0.013011980801820755,0.013745071366429329,0.014972970820963383,0.01592068374156952,0.016735047101974487,0.015166311524808407,0.01626300811767578,0.016571801155805588,0.027154909446835518,0.018126580864191055,0.017108038067817688,0.014670271426439285,0.014108416624367237,0.014244604855775833,0.01706838794052601,0.014421147294342518,0.017767777666449547,0.015451306477189064,0.013301522471010685,0.017306899651885033,0.015763791278004646,0.013638502918183804,0.014731734059751034,0.016038088127970695,0.014253061264753342,0.017531830817461014,0.020112834870815277,0.018995504826307297,0.01717735081911087,0.01876225508749485,0.021222863346338272,0.015616055577993393,0.014316934160888195,0.01601709984242916,0.015276712365448475,0.020416146144270897,0.01724361442029476,0.014655026607215405,0.018687503412365913,0.01424353662878275,0.017173653468489647,0.015769390389323235,0.015399142168462276,0.01892681047320366,0.015503237955272198,0.016724400222301483,0.015299101360142231,0.015649117529392242,0.016477340832352638,0.01376901101320982,0.012939087115228176,0.013974273577332497,0.011967860162258148,0.012059859000146389,0.016069021075963974,0.013959228061139584,0.016514400020241737,0.018097680062055588,0.0151823153719306,0.013702115043997765,0.013497037813067436,0.020056227222085,0.01939036138355732,0.0129008237272501,0.013305223546922207,0.013749280013144016,0.015110893175005913,0.014713450334966183,0.017698979005217552,0.01615004800260067,0.02193722128868103,0.013756953179836273,0.02228851243853569,0.01517725083976984,0.012615790590643883,0.012727617286145687,0.01629156433045864,0.0145346038043499,0.01604035310447216,0.014683032408356667,0.014580036513507366,0.012753226794302464,0.016414040699601173,0.014585779048502445,0.013388944789767265,0.0202861949801445,0.015400408767163754,0.0162128247320652,0.018991421908140182,0.017792101949453354,0.056260108947753906,0.024955837056040764,0.015546830371022224,0.015480304136872292,0.014995800331234932,0.01895342580974102,0.01926615461707115,0.012862836010754108,0.015313485637307167,0.020599309355020523,0.029239457100629807,0.01593715138733387,0.013513031415641308,0.016537947580218315,0.01709926314651966,0.01396237313747406,0.012591267935931683,0.013805829919874668,0.009369881823658943,0.018072543665766716,0.015805745497345924,0.01423715054988861,0.013762817718088627,0.013032086193561554,0.014920846559107304,0.01325640082359314,0.014833909459412098,0.015183455310761929,0.012179252691566944,0.013467736542224884,0.013767598196864128,0.012700974941253662,0.013273925520479679,0.016786502674221992,0.015090839937329292,0.014810848981142044,0.015423107892274857,0.016093570739030838,0.01218993030488491,0.0164078027009964,0.013763059861958027,0.010810183361172676,0.017259616404771805,0.012964381836354733,0.012272626161575317,0.01762685365974903,0.012873322702944279,0.02720390073955059,0.015842366963624954,0.014676576480269432,0.013906199485063553,0.01199991162866354,0.0179352518171072,0.014819898642599583,0.01941526122391224,0.016937442123889923,0.010249591432511806,0.012705449014902115,0.013653186149895191,0.010734780691564083,0.023402811959385872,0.012656883336603642,0.018723580986261368,0.013575171120464802,0.014023138210177422,0.018083520233631134,0.013088308274745941,0.012902090325951576,0.013040679506957531,0.013721100054681301,0.015941154211759567,0.01249674428254366,0.012019171379506588,0.011877735145390034,0.014314889907836914,0.02155829779803753,0.01675533317029476,0.013903823681175709,0.013182800263166428,0.012492811307311058,0.014319628477096558,0.013695480301976204,0.014187932945787907,0.016320209950208664,0.027453487738966942,0.014016496017575264,0.016888825222849846,0.01715906895697117,0.013432065956294537,0.012823281809687614,0.013564993627369404,0.013959497213363647,0.012004861608147621,0.014106035232543945,0.015446229837834835,0.01247588824480772,0.012786343693733215,0.013222342357039452,0.015539826825261116,0.009986735880374908,0.014196176081895828,0.013669437728822231,0.012774900533258915,0.012898622080683708,0.020329434424638748,0.012101076543331146,0.01537235826253891,0.012851939536631107,0.014698434621095657,0.011944251134991646,0.013453326188027859,0.015784768387675285,0.015140530653297901,0.01169863622635603,0.01152023021131754,0.021556420251727104,0.013444076292216778,0.012952541001141071,0.01547711156308651,0.014449750073254108,0.014945660717785358,0.012895851396024227,0.011873725801706314,0.013799107633531094,0.014401045627892017,0.013387593440711498,0.014108830131590366,0.011530645191669464,0.026177911087870598,0.018482906743884087,0.014516443945467472,0.031203655526041985,0.014066705480217934,0.014048004522919655,0.010407691821455956,0.015045813284814358,0.014853281900286674,0.011263677850365639,0.010633342899382114,0.012664172798395157,0.012929350137710571,0.012774846516549587,0.015216757543385029,0.00881698727607727,0.014289801008999348,0.01146529708057642,0.011742103844881058,0.013183973729610443,0.010204112157225609,0.013732308521866798,0.011907685548067093,0.014579981565475464,0.011101520620286465,0.013569585978984833,0.01086209062486887,0.012586677446961403,0.01111473236232996,0.012957768514752388,0.013596663251519203,0.015947049483656883,0.01235919538885355,0.012851721607148647,0.014292066916823387,0.013077819719910622,0.014933781698346138,0.013797896914184093,0.010983843356370926,0.011071906425058842,0.013946662656962872,0.015969056636095047,0.010640532709658146,0.011299068108201027,0.010648934170603752,0.013794276863336563,0.02968539111316204,0.016437603160738945,0.013436644338071346,0.011276665143668652,0.013516029343008995,0.014769967645406723,0.012189571745693684,0.011519107967615128,0.01345137506723404,0.012165438383817673,0.011107662692666054,0.011737202294170856,0.013075677677989006,0.01308504305779934,0.012856588698923588,0.013779262080788612,0.013599824160337448,0.010429573245346546,0.013954093679785728,0.011898103170096874,0.012427077628672123,0.012026721611618996,0.009987711906433105],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\",\"width\":2},\"mode\":\"lines\",\"name\":\"val_loss\",\"y\":[1.1111652851104736,0.8628492951393127,0.8583187460899353,0.6761096119880676,0.7098478078842163,0.6239144206047058,0.5511913299560547,0.46420347690582275,0.41708213090896606,0.3496220111846924,0.4180237650871277,0.5298628807067871,0.3171398937702179,0.27594780921936035,0.3069447875022888,0.32045963406562805,0.34261322021484375,0.24869385361671448,0.2603563964366913,0.1985480785369873,0.17095376551151276,0.22487123310565948,0.25167152285575867,0.1343006044626236,0.12846149504184723,0.29139065742492676,0.12346094846725464,0.17153063416481018,0.13545803725719452,0.13136032223701477,0.1496914178133011,0.11574043333530426,0.09435807168483734,0.08317273110151291,0.10156861692667007,0.12060579657554626,0.11590294539928436,0.08793318271636963,0.11212433874607086,0.07547122985124588,0.0942382737994194,0.07380710542201996,0.06945054978132248,0.15478037297725677,0.06311547756195068,0.06779225170612335,0.05263959988951683,0.05971387401223183,0.05758221447467804,0.0491463840007782,0.051599495112895966,0.11214449256658554,0.04491547867655754,0.05266640707850456,0.06594802439212799,0.041676849126815796,0.10833225399255753,0.04751908406615257,0.060453418642282486,0.05612705647945404,0.06981658935546875,0.04600256681442261,0.03956635296344757,0.0376361645758152,0.04673735797405243,0.04023559018969536,0.07646288722753525,0.03891276195645332,0.030705774202942848,0.07354030013084412,0.039748795330524445,0.029566388577222824,0.027502603828907013,0.027031805366277695,0.026516195386648178,0.026372063905000687,0.05129561200737953,0.03620010241866112,0.03304882347583771,0.04751279577612877,0.02929988130927086,0.06939206272363663,0.030013181269168854,0.025250907987356186,0.029779911041259766,0.03800482675433159,0.0220336876809597,0.02274855226278305,0.023358948528766632,0.02831451967358589,0.03087024576961994,0.02660568244755268,0.021684985607862473,0.03790208324790001,0.019247734919190407,0.0845898911356926,0.02546975016593933,0.2614057958126068,0.027082012966275215,0.056752245873212814,0.024272147566080093,0.027921222150325775,0.017537860199809074,0.03182913735508919,0.01709035225212574,0.016630738973617554,0.0219894889742136,0.02047116309404373,0.016966450959444046,0.017268937081098557,0.024050911888480186,0.017424730584025383,0.01947225257754326,0.016575869172811508,0.017884643748402596,0.015531434677541256,0.015883920714259148,0.027970874682068825,0.0138921570032835,0.019712699577212334,0.016963064670562744,0.012989582493901253,0.014393827877938747,0.014615035615861416,0.01621752791106701,0.012943461537361145,0.013777300715446472,0.012685343623161316,0.02077852003276348,0.01231452077627182,0.012774663977324963,0.019176144152879715,0.01340527180582285,0.012150255963206291,0.02709549479186535,0.028854964300990105,0.03091597929596901,0.012742741033434868,0.011240478605031967,0.019549474120140076,0.010998012498021126,0.012754378840327263,0.012450557202100754,0.011240776628255844,0.0194783303886652,0.010801684111356735,0.014092388562858105,0.012173152528703213,0.013007125817239285,0.011159677058458328,0.011419103480875492,0.012945791706442833,0.012101175263524055,0.01172533817589283,0.014394336380064487,0.010662762448191643,0.012055098079144955,0.009846932254731655,0.01004821341484785,0.010370060801506042,0.010311390273272991,0.008908459916710854,0.012019275687634945,0.01159199234098196,0.008529621176421642,0.010463235899806023,0.01199951209127903,0.009635950438678265,0.010227649472653866,0.035351548343896866,0.009042526595294476,0.008073100820183754,0.019249556586146355,0.00970056839287281,0.010768523439764977,0.009033226408064365,0.009416138753294945,0.011516701430082321,0.011097694747149944,0.008527770638465881,0.008979219943284988,0.009996914304792881,0.010556213557720184,0.008976448327302933,0.010336438193917274,0.011477665975689888,0.010468567721545696,0.008039251901209354,0.007289511151611805,0.012056768871843815,0.00932739581912756,0.01646600477397442,0.013228421099483967,0.01847396045923233,0.011174436658620834,0.007457692641764879,0.0078550074249506,0.007002736441791058,0.010795244947075844,0.013438516296446323,0.020571965724229813,0.007050913292914629,0.008345378562808037,0.01137452945113182,0.00782928429543972,0.014796841889619827,0.008340290747582912,0.0371008925139904,0.007826714776456356,0.00693873967975378,0.006903457455337048,0.007473394740372896,0.006316150538623333,0.011934795416891575,0.008523760363459587,0.006561959628015757,0.00819892343133688,0.007264978718012571,0.006587531417608261,0.007782734464854002,0.006136410869657993,0.005828718654811382,0.006010475568473339,0.00595553033053875,0.015803679823875427,0.008630516938865185,0.007005573250353336,0.005440960172563791,0.005404646508395672,0.006905680987983942,0.007973860949277878,0.006514361593872309,0.009811458177864552,0.005190310068428516,0.006524249445647001,0.018981024622917175,0.006733723450452089,0.010061919689178467,0.007629393134266138,0.006859361194074154,0.0056152637116611,0.006300343666225672,0.005347907543182373,0.006048174109309912,0.006440113764256239,0.0049739801324903965,0.005012138746678829,0.004796978551894426,0.00834419671446085,0.005912921857088804,0.005305305123329163,0.004940114449709654,0.005546009633690119,0.009683779440820217,0.004580983892083168,0.004742124117910862,0.005026266910135746,0.006267798598855734,0.008704452775418758,0.004947793669998646,0.008891912177205086,0.005936784669756889,0.005193605087697506,0.005793299525976181,0.006473169662058353,0.006290774326771498,0.0048547289334237576,0.004930402152240276,0.007805967703461647,0.008096103556454182,0.00893013272434473,0.029311206191778183,0.016361955553293228,0.011636405251920223,0.019766759127378464,0.012282037176191807,0.014294330030679703,0.008070667274296284,0.03297910466790199,0.0061018685810267925,0.005346057470887899,0.009138819761574268,0.007546721026301384,0.004700326360762119,0.005089084152132273,0.004262614995241165,0.008538935333490372,0.004126909654587507,0.005212008021771908,0.005067005287855864,0.005714418366551399,0.006026527378708124,0.0047501916997134686,0.004129213280975819,0.004958652891218662,0.005256073083728552,0.005100883077830076,0.004353972617536783,0.00675215246155858,0.005374561063945293,0.0048900144174695015,0.0056531354784965515,0.00793636217713356,0.004720817320048809,0.006319195963442326,0.00429812865331769,0.009072748012840748,0.006799111142754555,0.004061347339302301,0.005253497511148453,0.004331180825829506,0.004702250473201275,0.0038360499311238527,0.004571184050291777,0.0059637813828885555,0.0050657023675739765,0.003552038688212633,0.004141553305089474,0.015760915353894234,0.004712131340056658,0.0036724379751831293,0.004055703990161419,0.0042017195373773575,0.012171093374490738,0.0057349675334990025,0.0037894202396273613,0.0038332652766257524,0.007622747216373682,0.0059938328340649605,0.003568066516891122,0.007211871445178986,0.0034904838539659977,0.004089021123945713,0.01244497299194336,0.007174550089985132,0.004005432594567537,0.00561639154329896,0.003912018612027168,0.0046656872145831585,0.003823136445134878,0.003410965669900179,0.003819116624072194,0.004670005291700363,0.004172463435679674,0.003985035233199596,0.005271489731967449,0.003527731401845813,0.0036145548801869154,0.0074434587731957436,0.006185261998325586,0.003484182758256793,0.003627180587500334,0.004387970548123121,0.012946945615112782,0.0030783223919570446,0.013863434083759785,0.03234032168984413,0.00476821418851614,0.004600706044584513,0.0050223167054355145,0.004161295015364885,0.00433411356061697,0.003130709519609809,0.01129944808781147,0.004867999814450741,0.0057201385498046875,0.004056354984641075,0.005327913910150528,0.004728404805064201,0.00584451574832201,0.005496031604707241,0.0032181343995034695,0.005829340312629938,0.003010340267792344,0.002834758721292019,0.003019954776391387,0.003089877776801586,0.003475725883617997,0.007213098928332329,0.006520272232592106,0.003113230923190713,0.0027648902032524347,0.003969102632254362,0.003032999811694026,0.0036159653682261705,0.036226537078619,0.00373537908308208,0.008966992609202862,0.002829385455697775,0.003751826472580433,0.003125375835224986,0.005381501279771328,0.003886256832629442,0.006578286178410053,0.007272071670740843,0.0028510098345577717,0.003407267853617668,0.006154627073556185,0.0025452887639403343,0.004562923219054937,0.007731595076620579,0.004629479255527258,0.00841289572417736,0.0035346958320587873,0.005895459093153477,0.0048194765113294125,0.010531843639910221,0.0035539832897484303,0.0031541811767965555,0.004281781148165464,0.0029468813445419073,0.0025392293464392424,0.002325683133676648,0.0024492170196026564,0.0023966541048139334,0.003294596914201975,0.005573841277509928,0.002546953968703747,0.010379370301961899,0.002467634156346321,0.002600549254566431,0.0064290184527635574,0.0026643704622983932,0.008313281461596489,0.01766134425997734,0.0036916218232363462,0.00322844204492867,0.003926622215658426,0.0034883201587945223,0.0035868878476321697,0.0025500492192804813,0.012164081446826458,0.0024529609363526106,0.004079621285200119,0.0025169379077851772,0.0067639825865626335,0.0026604256127029657,0.0038882808294147253,0.004191542975604534,0.004518246278166771,0.0024933312088251114,0.0026110594626516104,0.002758580492809415,0.005185876972973347,0.002806694945320487,0.0023595120292156935,0.0025544650852680206,0.004285681527107954,0.009267104789614677,0.00342186214402318,0.0032543991692364216,0.005471676588058472,0.009858230128884315,0.002658101497218013,0.00233953888528049,0.0029813721776008606,0.0022058202885091305,0.002310104900971055,0.0029235619585961103,0.0022839719895273447,0.003006900893524289,0.00517685804516077,0.002315664663910866,0.0026999551337212324,0.003031917382031679,0.003439446212723851,0.0029566476587206125,0.002063864143565297,0.0020407780539244413,0.002960486337542534,0.0027168754022568464,0.0023029064759612083,0.002257537329569459,0.003318857168778777,0.0027890102937817574,0.002833322621881962,0.002161990851163864,0.0023838509805500507,0.0021613913122564554,0.002135222777724266,0.009350331500172615,0.023035233840346336,0.004097569268196821,0.0019964014645665884,0.002233400009572506,0.0032400593627244234,0.0028052874840795994,0.002813511062413454,0.00951997097581625,0.002110319910570979,0.002048881258815527,0.004006579518318176,0.001998655032366514,0.003148704767227173,0.0027071423828601837,0.002627942943945527,0.004289081785827875,0.003250421956181526,0.0024234685115516186,0.00323760649189353,0.0020131964702159166,0.002605338115245104,0.0031783722806721926,0.0036929489579051733,0.0018956174608319998,0.001993165584281087,0.0019889301620423794,0.0023443386889994144,0.008533783257007599,0.00922466441988945,0.0021051031071692705,0.00804175529628992,0.003509514732286334,0.00362731353379786,0.002119150711223483,0.0027097295969724655,0.0019714045338332653,0.002166600665077567,0.0020033814944326878,0.005715104751288891,0.015828898176550865,0.002252174075692892,0.00530835147947073,0.004084194544702768,0.00188294833060354,0.0058035883121192455,0.0024603065103292465,0.0020972907077521086,0.004737318959087133,0.0030236365273594856,0.0018745504785329103,0.0018119366141036153,0.002247507916763425,0.002802995964884758,0.0023047931026667356,0.0026083264965564013,0.0047460817731916904,0.004582911729812622,0.0036213889252394438,0.0017826482653617859,0.0030704315286129713,0.0019612808246165514,0.00838401447981596,0.004712151829153299,0.0026984713040292263,0.0032639731653034687,0.00492278253659606,0.0017609588103368878,0.0019414762500673532,0.0021629424300044775,0.0018730653682723641,0.0052485293708741665,0.0036068386398255825,0.002464570105075836,0.0016391483368352056,0.0022389842197299004,0.0028407571371644735,0.0023232668172568083,0.001966328825801611,0.003933478146791458,0.002273654332384467,0.04087420180439949,0.0018029684433713555,0.0027970788069069386,0.002776153851300478,0.0017652763053774834,0.0018156305886805058,0.002423725789412856,0.003367477096617222,0.00192542327567935,0.002081050304695964,0.0037097069434821606,0.0018944366602227092,0.003195191267877817,0.0028954758308827877,0.004709504544734955,0.003820572979748249,0.002718964358791709,0.0018370551988482475,0.001559161813929677,0.0015283803222700953,0.0017622127197682858,0.002903415123000741,0.0014128239126875997,0.0017742833588272333,0.001551860012114048,0.002522998256608844,0.0021116433199495077,0.0015787207521498203,0.0015547142829746008,0.003951613791286945,0.006126759573817253,0.0017418056959286332,0.001826938590966165,0.0016002790071070194,0.0014933376805856824,0.0023464388214051723,0.0016216813819482923,0.002434738678857684,0.002427410101518035,0.0016016144072636962,0.0022382624447345734,0.0016174092888832092,0.003967276308685541,0.002154924673959613,0.0020655784755945206,0.004462392535060644,0.0018197431927546859,0.0044486429542303085,0.0017512039048597217,0.0018252445152029395,0.0019838265143334866,0.003342627314850688,0.0013647788437083364,0.0021279517095535994,0.0052168723195791245,0.0024892641231417656,0.0029128235764801502,0.001359734684228897,0.0015721084782853723,0.007787582464516163,0.0014786252286285162,0.0023154807277023792,0.004031199496239424,0.0034844325855374336,0.001981073757633567,0.0020353212021291256,0.003298262832686305,0.001564310397952795,0.0027119985315948725,0.011403457261621952,0.006871585734188557,0.001717021339572966,0.005372597370296717,0.0017572402721270919,0.004034505225718021,0.005132288206368685,0.0067352186888456345,0.0017170676728710532,0.0018413658253848553,0.0015227445401251316,0.0028718169778585434,0.0018689456628635526,0.001754388096742332,0.001844008220359683,0.0016475942684337497,0.0022717423271387815,0.001440826221369207,0.0016885839868336916,0.010519656352698803,0.0015843207947909832,0.0022476313170045614,0.0014631717931479216,0.002330220304429531,0.0022501549683511257,0.005048110615462065,0.0017113672802224755,0.0016111814184114337,0.0014507678570225835,0.0018005752936005592,0.0018380718538537621,0.0016508308472111821,0.0015309004811570048,0.0013915525050833821,0.007951751351356506,0.0021884150337427855,0.004613586235791445,0.0017793886363506317,0.0070478948764503,0.0015682202065363526,0.002930370159447193,0.001301202573813498,0.00237733474932611,0.0013725374592468143,0.0013935324968770146,0.001897734124213457,0.0013988751452416182,0.0020044627599418163,0.00180201162584126,0.0017968033207580447,0.0031662043184041977,0.0012567768571898341,0.0014676686841994524,0.005295461509376764,0.001573633635416627,0.0014576672110706568,0.0017917485674843192,0.0018844070145860314,0.0018047468038275838,0.0014580790884792805,0.0012733733747154474,0.0014257566072046757,0.0015734453918412328,0.0012737585930153728,0.00324827223084867,0.0022760287392884493,0.0015022121369838715,0.0020647391211241484,0.0017332202987745404,0.0033229778055101633,0.001385966083034873,0.008549132384359837,0.0024761187378317118,0.001562490244396031,0.0026157256215810776,0.0015974226407706738,0.0014583423035219312,0.0012011819053441286,0.008105681277811527,0.00364101305603981,0.0011245900532230735,0.0017199304420500994,0.002137388801202178,0.0018197152530774474,0.0012514039408415556,0.0015504007460549474,0.0014278965536504984,0.0011560836574062705,0.0011773038422688842,0.0013080675853416324,0.0013443861389532685,0.0014566464815288782,0.0016312425723299384,0.0022553037852048874,0.0012634354643523693,0.0019296695245429873,0.0022115311585366726,0.0017504082061350346,0.0015268913703039289,0.0016354741528630257,0.001503370818682015,0.0012302268296480179,0.0014697967562824488,0.0012225460959598422,0.0012132541742175817,0.0018158266320824623,0.0020894266199320555,0.0012104313354939222,0.003510270966216922,0.0017278020968660712,0.0017596423858776689,0.004538876004517078,0.003146682633087039,0.0030299851205199957,0.0017700366443023086,0.0012347593437880278,0.0017702390905469656,0.001630658283829689,0.003903366858139634,0.0014005086850374937,0.0015112034743651748,0.0023958557285368443,0.0029793919529765844,0.0014170948415994644,0.0018816194497048855,0.0011688894592225552,0.004345814231783152,0.0029280928429216146,0.0013507883995771408,0.0011100723640993237,0.00506611168384552,0.0013235475635156035,0.001591197564266622,0.0013312086230143905,0.0013757116394117475,0.002592736389487982,0.003509900299832225,0.0016859605675563216,0.0016532279551029205,0.0021106970962136984,0.0013239491963759065,0.0013411480467766523,0.0011827220441773534,0.0014770935522392392,0.008155385963618755,0.0011391185689717531,0.0013827679213136435,0.001250464585609734,0.0012438650010153651,0.001386176678352058,0.0033210658002644777,0.0014410704607143998,0.01773729920387268,0.004091405309736729,0.0012427499750629067,0.001740088453516364,0.0016359430737793446,0.002926988760009408,0.0016114598838612437,0.0011602721642702818,0.0011239650193601847,0.0020499741658568382,0.001069305813871324,0.0015838055405765772,0.0016140973893925548,0.0015775957144796848,0.0011125837918370962,0.006021399516612291,0.0024963279720395803,0.0016156515339389443,0.0021928688511252403,0.0021289533469825983,0.011994586326181889,0.03871231526136398,0.0013939719647169113,0.0018687935080379248,0.0014683707850053906,0.0014819446951150894,0.003921613097190857,0.001355879008769989,0.0012784909922629595,0.004406142979860306,0.0012421675492078066,0.0013867839006707072,0.0016139568760991096,0.002210816601291299,0.006890441756695509,0.0014566577738150954,0.00125511409714818,0.0029203251469880342,0.0011896018404513597,0.0014745515072718263,0.002187978243455291,0.001797532313503325,0.0010950115974992514,0.001969450619071722,0.0010412660194560885,0.001001297147013247,0.0016762117156758904,0.00338347046636045,0.0015467411139979959,0.0019405512139201164,0.0017720222240313888,0.0009849524358287454,0.0012958351289853454,0.0011526682646945119,0.0015059357974678278,0.0018877525581046939,0.0011164762545377016,0.0013519206549972296,0.0012342194095253944,0.0017003573011606932,0.001583463978022337,0.0011116939131170511,0.0033476664684712887,0.005259671248495579,0.0010215406073257327,0.001120686181820929,0.001219919417053461,0.0013317615957930684,0.0012575999135151505,0.0018100416054949164,0.001454011769965291,0.001441444270312786,0.001350736478343606,0.0012086726492270827,0.005341715179383755,0.007530359551310539,0.0014342193026095629,0.0009163017966784537,0.0067610726691782475,0.0010510763386264443,0.001055230270139873,0.0012146405642852187,0.0011767424875870347,0.0012111383257433772,0.0019036582671105862,0.0016820818418636918,0.0018258915515616536,0.0010989790316671133,0.0015768947778269649,0.002583431778475642,0.002327153692021966,0.0011577055556699634,0.0009557818411849439,0.0012055718107149005,0.00105180440004915,0.001488475245423615,0.0012843518052250147,0.001705633127130568,0.0009624671074561775,0.00250815786421299,0.001537052565254271,0.0012790727196261287,0.002956890035420656,0.0013000461040064692,0.0027066615875810385,0.0009326039580628276,0.003864527214318514,0.0008691827533766627,0.0013277867110446095,0.001440257066860795,0.003421319182962179,0.0010011923732236028,0.0014603615272790194,0.0009434750536456704,0.00310193607583642,0.0010532505111768842,0.0023855569306761026,0.0009341269615106285,0.0009469941142015159,0.0014459345256909728,0.0009400408016517758,0.0015341900289058685,0.002765818266198039,0.002311491873115301,0.0012882509035989642,0.0012332933256402612,0.001333625870756805,0.0011354745365679264,0.0009370901389047503,0.0009604076622053981,0.0013444257201626897,0.0013952588196843863,0.0010882564820349216,0.001064351643435657,0.0013763390015810728,0.0010559553047642112,0.0016588037833571434,0.0010245292214676738,0.0019851122051477432,0.0010391842806711793,0.0028961156494915485,0.002164798555895686,0.0009764078422449529,0.0012159065809100866,0.000963462283834815,0.0013400756288319826,0.003409437835216522,0.005983339156955481,0.0011181479785591364,0.005913735367357731,0.00376151199452579,0.0021864534355700016,0.0024613160640001297,0.00132119155023247,0.0012595088919624686,0.0012584469513967633,0.0029177353717386723,0.0013331910595297813,0.0008646243368275464,0.0019950270652770996,0.0013724003219977021,0.0012859506532549858,0.003304837504401803,0.0018013740191236138,0.0010961937950924039,0.000831844110507518,0.0011202774476259947,0.0015563647029921412,0.0009791126940399408,0.0008816820336505771,0.0013134697219356894,0.0008947461028583348,0.0007713520317338407,0.0028793271631002426,0.0011234590783715248,0.002036723541095853,0.0009026543702930212,0.0030085043981671333,0.0011214574333280325,0.0014304278884083033,0.002125815022736788,0.003778685349971056,0.006094334181398153,0.0013852317351847887,0.0009417271357960999,0.0017519744578748941,0.001969962613657117,0.0008265741635113955,0.0010503423400223255,0.0014309983234852552,0.0025081951171159744,0.0010315347462892532,0.0009828165639191866,0.0054935431107878685,0.008657468482851982,0.002267552074044943,0.001954458886757493,0.0015788896707817912,0.0028388071805238724,0.0011734047438949347,0.00682959146797657,0.0009141721529886127,0.0017434402834624052,0.0022117772605270147,0.0012504057958722115,0.0009023030288517475,0.0008978596888482571,0.00197757501155138,0.0007472540601156652,0.001250894507393241,0.0009708997677080333,0.0010617560474202037,0.001144598238170147,0.0009569615358486772,0.0009631685097701848,0.0007768345531076193,0.0011293127899989486,0.001113186590373516],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Loss\"},\"xaxis\":{\"title\":{\"text\":\"epochs\"}},\"yaxis\":{\"title\":{\"text\":\"\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5b083c61-4676-46f3-b828-f46d72da8c3e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Accuracy"
      ],
      "metadata": {
        "id": "sx-Sl8Ix55OK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = go.Scatter(y=his.history['accuracy'],\n",
        "                    mode=\"lines\",\n",
        "                    line=dict(\n",
        "                        width=2,\n",
        "                        color='blue'),\n",
        "                        name=\"acc\"\n",
        "                   )\n",
        "h2 = go.Scatter(y=his.history['val_accuracy'],\n",
        "                    mode=\"lines\",\n",
        "                    line=dict(\n",
        "                        width=2,\n",
        "                        color='red'),\n",
        "                        name=\"val_acc\"\n",
        "                   )\n",
        "\n",
        "data = [h1,h2]\n",
        "layout1 = go.Layout(title='Accuracy',\n",
        "                   xaxis=dict(title='epochs'),\n",
        "                   yaxis=dict(title=''))\n",
        "fig1 = go.Figure(data = data, layout=layout1)\n",
        "plotly.offline.iplot(fig1)"
      ],
      "metadata": {
        "id": "A_ZpDKph56JF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "009f2e26-4fc3-4ef8-f593-b788636a2ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"573ecf20-c550-47f5-b7fd-aad46761447b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"573ecf20-c550-47f5-b7fd-aad46761447b\")) {                    Plotly.newPlot(                        \"573ecf20-c550-47f5-b7fd-aad46761447b\",                        [{\"line\":{\"color\":\"blue\",\"width\":2},\"mode\":\"lines\",\"name\":\"acc\",\"y\":[0.3057999908924103,0.5351999998092651,0.5853999853134155,0.6583999991416931,0.7148000001907349,0.7617999911308289,0.8180000185966492,0.8130000233650208,0.817799985408783,0.8238000273704529,0.8794000148773193,0.8835999965667725,0.8802000284194946,0.8658000230789185,0.9025999903678894,0.9038000106811523,0.8884000182151794,0.9186000227928162,0.9211999773979187,0.9146000146865845,0.9273999929428101,0.9333999752998352,0.9139999747276306,0.932200014591217,0.9526000022888184,0.9562000036239624,0.9222000241279602,0.9455999732017517,0.9506000280380249,0.9549999833106995,0.9401999711990356,0.9485999941825867,0.954800009727478,0.9646000266075134,0.9697999954223633,0.9664000272750854,0.9538000226020813,0.9553999900817871,0.9656000137329102,0.9639999866485596,0.9706000089645386,0.965399980545044,0.9742000102996826,0.9760000109672546,0.9431999921798706,0.9685999751091003,0.97079998254776,0.97079998254776,0.9814000129699707,0.9801999926567078,0.9710000157356262,0.9732000231742859,0.9728000164031982,0.9789999723434448,0.9779999852180481,0.9753999710083008,0.9833999872207642,0.9715999960899353,0.9800000190734863,0.9750000238418579,0.9783999919891357,0.9805999994277954,0.9768000245094299,0.9832000136375427,0.9796000123023987,0.9828000068664551,0.980400025844574,0.9620000123977661,0.980400025844574,0.9801999926567078,0.9692000150680542,0.9805999994277954,0.9818000197410583,0.9832000136375427,0.984000027179718,0.9833999872207642,0.9876000285148621,0.9746000170707703,0.9819999933242798,0.9843999743461609,0.9753999710083008,0.980400025844574,0.9661999940872192,0.9818000197410583,0.9873999953269958,0.9879999756813049,0.9811999797821045,0.9861999750137329,0.9854000210762024,0.9883999824523926,0.9753999710083008,0.9815999865531921,0.9832000136375427,0.9847999811172485,0.9810000061988831,0.9851999878883362,0.9728000164031982,0.9818000197410583,0.9567999839782715,0.9807999730110168,0.975600004196167,0.9873999953269958,0.9847999811172485,0.9887999892234802,0.9872000217437744,0.9886000156402588,0.9879999756813049,0.9894000291824341,0.9847999811172485,0.9878000020980835,0.9876000285148621,0.9876000285148621,0.9894000291824341,0.9896000027656555,0.9905999898910522,0.9887999892234802,0.9887999892234802,0.9824000000953674,0.9868000149726868,0.9847999811172485,0.9879999756813049,0.9850000143051147,0.9879999756813049,0.9900000095367432,0.9883999824523926,0.9847999811172485,0.9876000285148621,0.9900000095367432,0.9876000285148621,0.9873999953269958,0.9896000027656555,0.9914000034332275,0.9882000088691711,0.9879999756813049,0.9900000095367432,0.9854000210762024,0.9860000014305115,0.9872000217437744,0.9900000095367432,0.9922000169754028,0.989799976348877,0.9909999966621399,0.9900000095367432,0.9900000095367432,0.9911999702453613,0.9876000285148621,0.9883999824523926,0.9887999892234802,0.9901999831199646,0.9923999905586243,0.9890000224113464,0.9894000291824341,0.979200005531311,0.9872000217437744,0.9926000237464905,0.9936000108718872,0.9914000034332275,0.9919999837875366,0.9900000095367432,0.9896000027656555,0.9891999959945679,0.9914000034332275,0.9918000102043152,0.9865999817848206,0.9894000291824341,0.9908000230789185,0.9922000169754028,0.9890000224113464,0.9901999831199646,0.9900000095367432,0.9873999953269958,0.9850000143051147,0.9911999702453613,0.9876000285148621,0.9926000237464905,0.9918000102043152,0.9887999892234802,0.9900000095367432,0.9923999905586243,0.9927999973297119,0.9901999831199646,0.9914000034332275,0.9908000230789185,0.9879999756813049,0.9922000169754028,0.9896000027656555,0.991599977016449,0.9918000102043152,0.9914000034332275,0.9919999837875366,0.9923999905586243,0.991599977016449,0.9842000007629395,0.989799976348877,0.9908000230789185,0.9883999824523926,0.9929999709129333,0.9922000169754028,0.9908000230789185,0.9896000027656555,0.9851999878883362,0.9891999959945679,0.9914000034332275,0.9909999966621399,0.9918000102043152,0.991599977016449,0.9901999831199646,0.9918000102043152,0.9779999852180481,0.991599977016449,0.9929999709129333,0.9937999844551086,0.9894000291824341,0.991599977016449,0.9908000230789185,0.993399977684021,0.993399977684021,0.993399977684021,0.9936000108718872,0.993399977684021,0.9900000095367432,0.9914000034332275,0.9926000237464905,0.9918000102043152,0.989799976348877,0.9918000102043152,0.9775999784469604,0.9922000169754028,0.9932000041007996,0.9896000027656555,0.9894000291824341,0.9932000041007996,0.9932000041007996,0.9929999709129333,0.9911999702453613,0.989799976348877,0.9918000102043152,0.9876000285148621,0.9882000088691711,0.9909999966621399,0.9886000156402588,0.9909999966621399,0.9932000041007996,0.9932000041007996,0.9914000034332275,0.9940000176429749,0.991599977016449,0.991599977016449,0.9927999973297119,0.9926000237464905,0.9932000041007996,0.9904000163078308,0.9929999709129333,0.991599977016449,0.9882000088691711,0.9918000102043152,0.9914000034332275,0.9937999844551086,0.9936000108718872,0.9926000237464905,0.9904000163078308,0.9941999912261963,0.9937999844551086,0.9922000169754028,0.9911999702453613,0.9918000102043152,0.9914000034332275,0.9936000108718872,0.9909999966621399,0.9918000102043152,0.9937999844551086,0.9868000149726868,0.9714000225067139,0.9793999791145325,0.9883999824523926,0.9886000156402588,0.9876000285148621,0.9900000095367432,0.9860000014305115,0.9883999824523926,0.9901999831199646,0.9950000047683716,0.9937999844551086,0.9932000041007996,0.993399977684021,0.9937999844551086,0.9922000169754028,0.989799976348877,0.9932000041007996,0.9922000169754028,0.9947999715805054,0.9882000088691711,0.9926000237464905,0.9926000237464905,0.9937999844551086,0.993399977684021,0.9950000047683716,0.995199978351593,0.9929999709129333,0.9922000169754028,0.9940000176429749,0.9805999994277954,0.9922000169754028,0.9900000095367432,0.9927999973297119,0.9941999912261963,0.9922000169754028,0.9922000169754028,0.993399977684021,0.9909999966621399,0.9932000041007996,0.9922000169754028,0.9872000217437744,0.993399977684021,0.9927999973297119,0.9929999709129333,0.9947999715805054,0.9936000108718872,0.9927999973297119,0.9927999973297119,0.9937999844551086,0.993399977684021,0.9923999905586243,0.9927999973297119,0.9918000102043152,0.9936000108718872,0.9955999851226807,0.9936000108718872,0.9932000041007996,0.9940000176429749,0.9927999973297119,0.9940000176429749,0.9932000041007996,0.9940000176429749,0.991599977016449,0.9926000237464905,0.9936000108718872,0.9905999898910522,0.9941999912261963,0.9937999844551086,0.9959999918937683,0.9922000169754028,0.9940000176429749,0.9936000108718872,0.9932000041007996,0.9936000108718872,0.993399977684021,0.9926000237464905,0.9937999844551086,0.9932000041007996,0.9937999844551086,0.993399977684021,0.995199978351593,0.9937999844551086,0.9937999844551086,0.9901999831199646,0.9927999973297119,0.9747999906539917,0.9860000014305115,0.9886000156402588,0.9919999837875366,0.9918000102043152,0.9929999709129333,0.9932000041007996,0.9909999966621399,0.9923999905586243,0.993399977684021,0.9941999912261963,0.9882000088691711,0.9891999959945679,0.9890000224113464,0.9947999715805054,0.9927999973297119,0.9932000041007996,0.9968000054359436,0.9945999979972839,0.9937999844551086,0.9962000250816345,0.9927999973297119,0.9914000034332275,0.9927999973297119,0.9944000244140625,0.9954000115394592,0.9927999973297119,0.9937999844551086,0.9936000108718872,0.9918000102043152,0.9968000054359436,0.9941999912261963,0.9940000176429749,0.9932000041007996,0.9927999973297119,0.996399998664856,0.9944000244140625,0.9901999831199646,0.9836000204086304,0.9936000108718872,0.9944000244140625,0.9940000176429749,0.9944000244140625,0.9922000169754028,0.9919999837875366,0.9878000020980835,0.9932000041007996,0.9945999979972839,0.9927999973297119,0.9936000108718872,0.9864000082015991,0.9932000041007996,0.9959999918937683,0.9955999851226807,0.9900000095367432,0.9947999715805054,0.9929999709129333,0.9941999912261963,0.9944000244140625,0.9945999979972839,0.9944000244140625,0.9944000244140625,0.9923999905586243,0.9941999912261963,0.9923999905586243,0.9918000102043152,0.9932000041007996,0.9922000169754028,0.9914000034332275,0.9926000237464905,0.9878000020980835,0.9944000244140625,0.9941999912261963,0.9944000244140625,0.9955999851226807,0.9929999709129333,0.9947999715805054,0.989799976348877,0.991599977016449,0.993399977684021,0.9932000041007996,0.9929999709129333,0.9944000244140625,0.993399977684021,0.9937999844551086,0.9932000041007996,0.9958000183105469,0.996399998664856,0.9947999715805054,0.9944000244140625,0.9945999979972839,0.9914000034332275,0.9864000082015991,0.9932000041007996,0.9940000176429749,0.9929999709129333,0.9941999912261963,0.9962000250816345,0.9958000183105469,0.9944000244140625,0.9932000041007996,0.9954000115394592,0.9976000189781189,0.995199978351593,0.9926000237464905,0.9955999851226807,0.995199978351593,0.9959999918937683,0.9947999715805054,0.9923999905586243,0.9959999918937683,0.9962000250816345,0.9944000244140625,0.995199978351593,0.993399977684021,0.9944000244140625,0.9940000176429749,0.9950000047683716,0.9944000244140625,0.9944000244140625,0.9947999715805054,0.9950000047683716,0.9955999851226807,0.9904000163078308,0.9955999851226807,0.9778000116348267,0.9922000169754028,0.9923999905586243,0.9944000244140625,0.9929999709129333,0.9958000183105469,0.9941999912261963,0.9945999979972839,0.9958000183105469,0.9923999905586243,0.9954000115394592,0.996399998664856,0.9959999918937683,0.9958000183105469,0.9954000115394592,0.9944000244140625,0.9932000041007996,0.9950000047683716,0.9932000041007996,0.9941999912261963,0.9941999912261963,0.9954000115394592,0.9962000250816345,0.9941999912261963,0.9959999918937683,0.9947999715805054,0.9937999844551086,0.9932000041007996,0.9954000115394592,0.9941999912261963,0.9918000102043152,0.995199978351593,0.9968000054359436,0.9950000047683716,0.9950000047683716,0.9926000237464905,0.9937999844551086,0.9944000244140625,0.9923999905586243,0.9872000217437744,0.9944000244140625,0.991599977016449,0.995199978351593,0.9945999979972839,0.9959999918937683,0.9959999918937683,0.9947999715805054,0.9927999973297119,0.9959999918937683,0.9945999979972839,0.9941999912261963,0.9950000047683716,0.9932000041007996,0.9936000108718872,0.9911999702453613,0.9890000224113464,0.9932000041007996,0.993399977684021,0.9968000054359436,0.9959999918937683,0.9932000041007996,0.9927999973297119,0.9950000047683716,0.995199978351593,0.9945999979972839,0.9954000115394592,0.9965999722480774,0.993399977684021,0.9947999715805054,0.9959999918937683,0.993399977684021,0.9950000047683716,0.996399998664856,0.9958000183105469,0.9936000108718872,0.9965999722480774,0.9945999979972839,0.9937999844551086,0.9854000210762024,0.993399977684021,0.98580002784729,0.9932000041007996,0.9955999851226807,0.995199978351593,0.9940000176429749,0.995199978351593,0.9954000115394592,0.9958000183105469,0.9965999722480774,0.9932000041007996,0.9927999973297119,0.9941999912261963,0.9941999912261963,0.993399977684021,0.9954000115394592,0.9945999979972839,0.996399998664856,0.996399998664856,0.9958000183105469,0.995199978351593,0.9955999851226807,0.996399998664856,0.9955999851226807,0.9958000183105469,0.9972000122070312,0.9955999851226807,0.9940000176429749,0.9954000115394592,0.9947999715805054,0.9972000122070312,0.993399977684021,0.9958000183105469,0.9950000047683716,0.9955999851226807,0.9882000088691711,0.9940000176429749,0.9937999844551086,0.9940000176429749,0.9944000244140625,0.995199978351593,0.9944000244140625,0.995199978351593,0.9962000250816345,0.9945999979972839,0.9954000115394592,0.9968000054359436,0.9954000115394592,0.9962000250816345,0.9940000176429749,0.9959999918937683,0.9945999979972839,0.996399998664856,0.995199978351593,0.9958000183105469,0.9909999966621399,0.9959999918937683,0.9941999912261963,0.995199978351593,0.9945999979972839,0.9937999844551086,0.9954000115394592,0.9908000230789185,0.9958000183105469,0.9947999715805054,0.9927999973297119,0.9955999851226807,0.9955999851226807,0.9945999979972839,0.9959999918937683,0.9950000047683716,0.996399998664856,0.9926000237464905,0.9941999912261963,0.9947999715805054,0.9945999979972839,0.9940000176429749,0.9941999912261963,0.9945999979972839,0.9955999851226807,0.9940000176429749,0.995199978351593,0.9972000122070312,0.9945999979972839,0.991599977016449,0.9945999979972839,0.9965999722480774,0.9959999918937683,0.9937999844551086,0.9926000237464905,0.9954000115394592,0.9941999912261963,0.9955999851226807,0.995199978351593,0.9950000047683716,0.9950000047683716,0.9945999979972839,0.9954000115394592,0.9965999722480774,0.9968000054359436,0.9962000250816345,0.9977999925613403,0.9954000115394592,0.9944000244140625,0.9937999844551086,0.9968000054359436,0.9945999979972839,0.9954000115394592,0.9927999973297119,0.9936000108718872,0.9944000244140625,0.9962000250816345,0.996399998664856,0.9955999851226807,0.9944000244140625,0.9947999715805054,0.9950000047683716,0.995199978351593,0.9976000189781189,0.9955999851226807,0.9972000122070312,0.9968000054359436,0.995199978351593,0.993399977684021,0.9950000047683716,0.9973999857902527,0.9940000176429749,0.9937999844551086,0.9962000250816345,0.9945999979972839,0.9947999715805054,0.9962000250816345,0.9962000250816345,0.9958000183105469,0.9968000054359436,0.9923999905586243,0.9959999918937683,0.996399998664856,0.995199978351593,0.9944000244140625,0.995199978351593,0.993399977684021,0.9968000054359436,0.9941999912261963,0.9962000250816345,0.9959999918937683,0.9962000250816345,0.9955999851226807,0.9950000047683716,0.9965999722480774,0.9954000115394592,0.9965999722480774,0.996999979019165,0.996399998664856,0.9959999918937683,0.995199978351593,0.995199978351593,0.9954000115394592,0.9968000054359436,0.9954000115394592,0.9911999702453613,0.9936000108718872,0.9959999918937683,0.9968000054359436,0.9962000250816345,0.996999979019165,0.9959999918937683,0.9955999851226807,0.9941999912261963,0.9962000250816345,0.9965999722480774,0.9945999979972839,0.9945999979972839,0.9973999857902527,0.9959999918937683,0.995199978351593,0.9958000183105469,0.9955999851226807,0.9937999844551086,0.9941999912261963,0.9941999912261963,0.9954000115394592,0.9929999709129333,0.995199978351593,0.9958000183105469,0.9954000115394592,0.995199978351593,0.9936000108718872,0.995199978351593,0.9954000115394592,0.9936000108718872,0.996399998664856,0.995199978351593,0.9947999715805054,0.9954000115394592,0.9941999912261963,0.9955999851226807,0.9955999851226807,0.996999979019165,0.9958000183105469,0.9950000047683716,0.9958000183105469,0.9958000183105469,0.9965999722480774,0.996999979019165,0.9972000122070312,0.9954000115394592,0.9955999851226807,0.9954000115394592,0.9944000244140625,0.996399998664856,0.9962000250816345,0.9965999722480774,0.9936000108718872,0.9937999844551086,0.9980000257492065,0.9973999857902527,0.9972000122070312,0.995199978351593,0.9959999918937683,0.9945999979972839,0.995199978351593,0.9936000108718872,0.9965999722480774,0.9941999912261963,0.9955999851226807,0.9962000250816345,0.9972000122070312,0.9954000115394592,0.9958000183105469,0.995199978351593,0.9959999918937683,0.9968000054359436,0.996999979019165,0.9936000108718872,0.9955999851226807,0.995199978351593,0.993399977684021,0.9947999715805054,0.9954000115394592,0.9937999844551086,0.9941999912261963,0.9843999743461609,0.9918000102043152,0.995199978351593,0.9959999918937683,0.9962000250816345,0.9941999912261963,0.9944000244140625,0.9962000250816345,0.9950000047683716,0.9940000176429749,0.9896000027656555,0.9947999715805054,0.9958000183105469,0.9941999912261963,0.9958000183105469,0.9954000115394592,0.9959999918937683,0.9954000115394592,0.998199999332428,0.9944000244140625,0.9959999918937683,0.9958000183105469,0.9976000189781189,0.9965999722480774,0.9965999722480774,0.996999979019165,0.995199978351593,0.9958000183105469,0.9962000250816345,0.9965999722480774,0.9965999722480774,0.9962000250816345,0.996999979019165,0.9944000244140625,0.9954000115394592,0.9968000054359436,0.9954000115394592,0.9932000041007996,0.9965999722480774,0.9947999715805054,0.9959999918937683,0.9976000189781189,0.9945999979972839,0.9965999722480774,0.996399998664856,0.9947999715805054,0.996399998664856,0.9911999702453613,0.9945999979972839,0.9962000250816345,0.9959999918937683,0.996999979019165,0.9954000115394592,0.9962000250816345,0.9954000115394592,0.9947999715805054,0.9973999857902527,0.996399998664856,0.996399998664856,0.996999979019165,0.993399977684021,0.9959999918937683,0.9944000244140625,0.996399998664856,0.996399998664856,0.9940000176429749,0.9968000054359436,0.9962000250816345,0.9968000054359436,0.9965999722480774,0.995199978351593,0.9962000250816345,0.9968000054359436,0.996399998664856,0.9959999918937683,0.993399977684021,0.995199978351593,0.996399998664856,0.9955999851226807,0.996999979019165,0.9959999918937683,0.9955999851226807,0.9962000250816345,0.9941999912261963,0.9909999966621399,0.9950000047683716,0.9955999851226807,0.9937999844551086,0.9962000250816345,0.996399998664856,0.9968000054359436,0.9962000250816345,0.9965999722480774,0.9959999918937683,0.9950000047683716,0.9972000122070312,0.9962000250816345,0.9962000250816345,0.9955999851226807,0.9976000189781189,0.9962000250816345,0.996399998664856,0.9965999722480774,0.996399998664856,0.9932000041007996,0.996399998664856,0.9955999851226807,0.9962000250816345,0.9954000115394592,0.9965999722480774,0.9954000115394592,0.9947999715805054,0.995199978351593,0.9977999925613403,0.9968000054359436,0.993399977684021,0.9965999722480774,0.9955999851226807,0.9955999851226807,0.9958000183105469,0.9965999722480774,0.9959999918937683,0.996999979019165,0.9958000183105469,0.9955999851226807,0.9959999918937683,0.9954000115394592,0.9976000189781189,0.991599977016449,0.9923999905586243,0.9945999979972839,0.9901999831199646,0.9954000115394592,0.995199978351593,0.9980000257492065,0.995199978351593,0.9954000115394592,0.9972000122070312,0.9962000250816345,0.9965999722480774,0.9954000115394592,0.9965999722480774,0.9950000047683716,0.9977999925613403,0.9955999851226807,0.9962000250816345,0.9962000250816345,0.9958000183105469,0.9977999925613403,0.995199978351593,0.9976000189781189,0.9944000244140625,0.996999979019165,0.9972000122070312,0.9973999857902527,0.9965999722480774,0.9968000054359436,0.9962000250816345,0.9954000115394592,0.9954000115394592,0.9965999722480774,0.9965999722480774,0.9947999715805054,0.9965999722480774,0.9955999851226807,0.9962000250816345,0.9968000054359436,0.9968000054359436,0.9959999918937683,0.9941999912261963,0.9968000054359436,0.9965999722480774,0.9973999857902527,0.9958000183105469,0.9923999905586243,0.9959999918937683,0.996399998664856,0.9968000054359436,0.9959999918937683,0.9950000047683716,0.9973999857902527,0.9958000183105469,0.996399998664856,0.9959999918937683,0.996999979019165,0.9965999722480774,0.9962000250816345,0.9965999722480774,0.9955999851226807,0.9955999851226807,0.9962000250816345,0.9977999925613403,0.9947999715805054,0.9965999722480774,0.9968000054359436,0.996399998664856,0.9973999857902527],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\",\"width\":2},\"mode\":\"lines\",\"name\":\"val_acc\",\"y\":[0.602400004863739,0.7017999887466431,0.6341999769210815,0.6759999990463257,0.819599986076355,0.8388000130653381,0.8108000159263611,0.8835999965667725,0.8388000130653381,0.9345999956130981,0.84579998254776,0.8611999750137329,0.906000018119812,0.9419999718666077,0.9124000072479248,0.8587999939918518,0.9246000051498413,0.900600016117096,0.8989999890327454,0.9850000143051147,0.995199978351593,0.9495999813079834,0.9440000057220459,0.9968000054359436,0.9950000047683716,0.8981999754905701,0.9959999918937683,0.9395999908447266,0.9498000144958496,0.9685999751091003,0.9498000144958496,0.9585999846458435,0.9872000217437744,0.996999979019165,0.9739999771118164,0.9498000144958496,0.9498000144958496,0.9959999918937683,0.9567999839782715,0.9865999817848206,0.9700000286102295,0.9872000217437744,0.9937999844551086,0.9477999806404114,0.9968000054359436,0.9851999878883362,0.9973999857902527,0.9945999979972839,0.995199978351593,0.998199999332428,0.9976000189781189,0.9549999833106995,0.9986000061035156,0.998199999332428,0.982200026512146,0.998199999332428,0.9485999941825867,0.9965999722480774,0.982200026512146,0.9814000129699707,0.9765999913215637,0.9914000034332275,0.9937999844551086,0.9972000122070312,0.9890000224113464,0.9922000169754028,0.973800003528595,0.993399977684021,0.9986000061035156,0.974399983882904,0.996399998664856,0.9986000061035156,0.9987999796867371,0.9990000128746033,0.9983999729156494,0.9986000061035156,0.9836000204086304,0.9965999722480774,0.9973999857902527,0.993399977684021,0.9954000115394592,0.9703999757766724,0.9983999729156494,0.998199999332428,0.9950000047683716,0.9968000054359436,0.9983999729156494,0.9990000128746033,0.998199999332428,0.996399998664856,0.9972000122070312,0.9959999918937683,0.9987999796867371,0.9890000224113464,0.9983999729156494,0.9606000185012817,0.995199978351593,0.9467999935150146,0.9954000115394592,0.9768000245094299,0.9972000122070312,0.9950000047683716,0.9990000128746033,0.9908000230789185,0.9983999729156494,0.9983999729156494,0.996999979019165,0.9976000189781189,0.9987999796867371,0.9990000128746033,0.996999979019165,0.9987999796867371,0.9972000122070312,0.9987999796867371,0.9976000189781189,0.9990000128746033,0.998199999332428,0.991599977016449,0.9987999796867371,0.9965999722480774,0.9983999729156494,0.9991999864578247,0.9986000061035156,0.9983999729156494,0.9986000061035156,0.9991999864578247,0.9987999796867371,0.9990000128746033,0.9945999979972839,0.9994000196456909,0.9991999864578247,0.995199978351593,0.9987999796867371,0.9991999864578247,0.991599977016449,0.9908000230789185,0.9900000095367432,0.9986000061035156,0.9991999864578247,0.9950000047683716,0.9990000128746033,0.9991999864578247,0.9986000061035156,0.9991999864578247,0.995199978351593,0.9994000196456909,0.9980000257492065,0.9987999796867371,0.9986000061035156,0.9987999796867371,0.9983999729156494,0.9987999796867371,0.9987999796867371,0.9987999796867371,0.9977999925613403,0.9990000128746033,0.9987999796867371,0.9990000128746033,0.9990000128746033,0.9987999796867371,0.9986000061035156,0.9991999864578247,0.998199999332428,0.9986000061035156,0.9991999864578247,0.9987999796867371,0.9986000061035156,0.9987999796867371,0.9986000061035156,0.9873999953269958,0.9991999864578247,0.9991999864578247,0.9947999715805054,0.9987999796867371,0.9983999729156494,0.9991999864578247,0.9987999796867371,0.9983999729156494,0.998199999332428,0.9991999864578247,0.9990000128746033,0.9990000128746033,0.9987999796867371,0.9987999796867371,0.9987999796867371,0.9977999925613403,0.9980000257492065,0.9987999796867371,0.9991999864578247,0.9986000061035156,0.9986000061035156,0.9954000115394592,0.9965999722480774,0.995199978351593,0.9976000189781189,0.9994000196456909,0.9990000128746033,0.9991999864578247,0.998199999332428,0.9990000128746033,0.9940000176429749,0.9994000196456909,0.9987999796867371,0.9976000189781189,0.9991999864578247,0.9968000054359436,0.9987999796867371,0.9846000075340271,0.9987999796867371,0.9991999864578247,0.9990000128746033,0.9990000128746033,0.9991999864578247,0.9972000122070312,0.9987999796867371,0.9994000196456909,0.9991999864578247,0.9990000128746033,0.9994000196456909,0.9991999864578247,0.9991999864578247,0.9994000196456909,0.9994000196456909,0.9994000196456909,0.9944000244140625,0.998199999332428,0.9991999864578247,0.9991999864578247,0.9994000196456909,0.9994000196456909,0.9987999796867371,0.9987999796867371,0.9986000061035156,0.9991999864578247,0.9990000128746033,0.9923999905586243,0.9987999796867371,0.9972000122070312,0.9990000128746033,0.9987999796867371,0.9994000196456909,0.9990000128746033,0.9991999864578247,0.9990000128746033,0.9987999796867371,0.9991999864578247,0.9991999864578247,0.9994000196456909,0.9983999729156494,0.9987999796867371,0.9994000196456909,0.9994000196456909,0.9990000128746033,0.9980000257492065,0.9994000196456909,0.9991999864578247,0.9994000196456909,0.9994000196456909,0.998199999332428,0.9994000196456909,0.9977999925613403,0.9987999796867371,0.9994000196456909,0.9987999796867371,0.9987999796867371,0.9986000061035156,0.9994000196456909,0.9991999864578247,0.9987999796867371,0.998199999332428,0.998199999332428,0.9869999885559082,0.996399998664856,0.9980000257492065,0.9937999844551086,0.9976000189781189,0.9954000115394592,0.998199999332428,0.9868000149726868,0.9987999796867371,0.9990000128746033,0.9983999729156494,0.9987999796867371,0.9994000196456909,0.9991999864578247,0.9994000196456909,0.9980000257492065,0.9994000196456909,0.9987999796867371,0.9995999932289124,0.9987999796867371,0.9990000128746033,0.9990000128746033,0.9994000196456909,0.9991999864578247,0.9994000196456909,0.9991999864578247,0.9991999864578247,0.9987999796867371,0.9987999796867371,0.9991999864578247,0.9991999864578247,0.9983999729156494,0.9991999864578247,0.9983999729156494,0.9991999864578247,0.9983999729156494,0.9986000061035156,0.9994000196456909,0.9991999864578247,0.9991999864578247,0.9995999932289124,0.9994000196456909,0.9990000128746033,0.9986000061035156,0.9991999864578247,0.9994000196456909,0.9994000196456909,0.9941999912261963,0.9991999864578247,0.9994000196456909,0.9995999932289124,0.9990000128746033,0.9968000054359436,0.9987999796867371,0.9994000196456909,0.9994000196456909,0.9977999925613403,0.9987999796867371,0.9991999864578247,0.9991999864578247,0.9994000196456909,0.9995999932289124,0.9968000054359436,0.9977999925613403,0.9991999864578247,0.9987999796867371,0.9994000196456909,0.9987999796867371,0.9995999932289124,0.9998000264167786,0.9995999932289124,0.9990000128746033,0.9991999864578247,0.9991999864578247,0.9987999796867371,0.9994000196456909,0.9994000196456909,0.998199999332428,0.9986000061035156,0.9994000196456909,0.9994000196456909,0.9991999864578247,0.9959999918937683,0.9995999932289124,0.996399998664856,0.9876000285148621,0.9991999864578247,0.9990000128746033,0.9986000061035156,0.9991999864578247,0.9991999864578247,0.9995999932289124,0.9968000054359436,0.9987999796867371,0.9991999864578247,0.9991999864578247,0.9987999796867371,0.9987999796867371,0.9983999729156494,0.9987999796867371,0.9994000196456909,0.9987999796867371,0.9994000196456909,0.9995999932289124,0.9995999932289124,0.9994000196456909,0.9995999932289124,0.9983999729156494,0.9987999796867371,0.9994000196456909,0.9998000264167786,0.9998000264167786,0.9995999932289124,0.9998000264167786,0.9854000210762024,0.9995999932289124,0.996999979019165,0.9994000196456909,0.9994000196456909,0.9994000196456909,0.9987999796867371,0.9991999864578247,0.9983999729156494,0.9977999925613403,0.9994000196456909,0.9994000196456909,0.9983999729156494,0.9998000264167786,0.9987999796867371,0.9976000189781189,0.9994000196456909,0.9986000061035156,0.9991999864578247,0.9986000061035156,0.9987999796867371,0.9972000122070312,0.9995999932289124,0.9991999864578247,0.9987999796867371,0.9995999932289124,0.9995999932289124,0.9994000196456909,0.9998000264167786,0.9995999932289124,0.9994000196456909,0.9986000061035156,0.9998000264167786,0.9962000250816345,0.9998000264167786,0.9998000264167786,0.998199999332428,0.9995999932289124,0.9972000122070312,0.9932000041007996,0.9991999864578247,0.9995999932289124,0.9987999796867371,0.9991999864578247,0.9990000128746033,1.0,0.9962000250816345,0.9998000264167786,0.9987999796867371,0.9998000264167786,0.9983999729156494,0.9994000196456909,0.9987999796867371,0.9987999796867371,0.9987999796867371,0.9994000196456909,0.9998000264167786,0.9994000196456909,0.9986000061035156,0.9995999932289124,0.9995999932289124,1.0,0.9987999796867371,0.9973999857902527,0.9991999864578247,0.9994000196456909,0.9986000061035156,0.9972000122070312,0.9994000196456909,1.0,0.9994000196456909,0.9998000264167786,0.9998000264167786,0.9994000196456909,0.9995999932289124,0.9994000196456909,0.9986000061035156,0.9994000196456909,0.9995999932289124,0.9994000196456909,0.9991999864578247,0.9998000264167786,1.0,0.9995999932289124,0.9994000196456909,0.9995999932289124,0.9995999932289124,0.9998000264167786,0.9995999932289124,0.9995999932289124,0.9994000196456909,0.9995999932289124,0.9994000196456909,0.9995999932289124,0.9998000264167786,0.9962000250816345,0.9901999831199646,0.9987999796867371,0.9995999932289124,0.9998000264167786,0.9990000128746033,0.9991999864578247,0.9991999864578247,0.9962000250816345,0.9995999932289124,0.9998000264167786,0.9987999796867371,0.9998000264167786,0.9994000196456909,0.9998000264167786,0.9994000196456909,0.9987999796867371,0.9991999864578247,0.9991999864578247,0.9991999864578247,0.9995999932289124,0.9998000264167786,0.9990000128746033,0.9987999796867371,0.9995999932289124,0.9995999932289124,0.9995999932289124,0.9995999932289124,0.9973999857902527,0.996999979019165,0.9998000264167786,0.9972000122070312,0.9991999864578247,0.9990000128746033,1.0,0.9994000196456909,0.9998000264167786,0.9998000264167786,0.9998000264167786,0.9980000257492065,0.9941999912261963,0.9994000196456909,0.9983999729156494,0.9987999796867371,0.9998000264167786,0.998199999332428,0.9994000196456909,0.9994000196456909,0.9983999729156494,0.9990000128746033,0.9995999932289124,0.9998000264167786,0.9998000264167786,0.9994000196456909,0.9995999932289124,0.9991999864578247,0.9987999796867371,0.9983999729156494,0.9987999796867371,0.9998000264167786,0.9995999932289124,0.9995999932289124,0.9972000122070312,0.9986000061035156,0.9994000196456909,0.9990000128746033,0.9987999796867371,0.9998000264167786,0.9994000196456909,0.9994000196456909,0.9998000264167786,0.9987999796867371,0.9991999864578247,0.9994000196456909,0.9998000264167786,0.9994000196456909,0.9994000196456909,0.9991999864578247,0.9994000196456909,0.9991999864578247,0.9995999932289124,0.9851999878883362,1.0,0.9994000196456909,0.9991999864578247,0.9998000264167786,0.9998000264167786,0.9994000196456909,0.9987999796867371,0.9994000196456909,0.9994000196456909,0.9987999796867371,0.9998000264167786,0.9991999864578247,0.9995999932289124,0.9994000196456909,0.9987999796867371,0.9991999864578247,0.9998000264167786,0.9998000264167786,0.9998000264167786,0.9998000264167786,0.9994000196456909,0.9998000264167786,0.9995999932289124,0.9998000264167786,0.9994000196456909,0.9998000264167786,1.0,0.9998000264167786,0.9987999796867371,0.9976000189781189,0.9998000264167786,1.0,0.9998000264167786,1.0,0.9991999864578247,0.9995999932289124,0.9994000196456909,0.9994000196456909,1.0,0.9998000264167786,0.9998000264167786,0.9987999796867371,0.9994000196456909,0.9994000196456909,0.9987999796867371,0.9998000264167786,0.9983999729156494,0.9998000264167786,0.9998000264167786,0.9995999932289124,0.9990000128746033,0.9998000264167786,0.9998000264167786,0.9986000061035156,0.9994000196456909,0.9990000128746033,1.0,0.9995999932289124,0.9972000122070312,0.9995999932289124,0.9994000196456909,0.9987999796867371,0.9991999864578247,0.9994000196456909,0.9994000196456909,0.9987999796867371,0.9998000264167786,0.9998000264167786,0.9954000115394592,0.9977999925613403,0.9995999932289124,0.998199999332428,0.9995999932289124,0.9987999796867371,0.9987999796867371,0.9980000257492065,0.9994000196456909,0.9994000196456909,1.0,0.9994000196456909,1.0,1.0,1.0,0.9995999932289124,0.9994000196456909,0.9998000264167786,0.9995999932289124,0.996399998664856,0.9998000264167786,0.9991999864578247,1.0,0.9995999932289124,0.9994000196456909,0.9986000061035156,0.9998000264167786,0.9998000264167786,0.9998000264167786,0.9998000264167786,0.9998000264167786,1.0,0.9995999932289124,0.9998000264167786,0.9972000122070312,1.0,0.9986000061035156,1.0,0.9972000122070312,0.9994000196456909,0.9991999864578247,1.0,0.9998000264167786,0.9998000264167786,1.0,0.9995999932289124,1.0,0.9994000196456909,0.9998000264167786,0.9998000264167786,0.9991999864578247,1.0,0.9998000264167786,0.9987999796867371,0.9995999932289124,0.9998000264167786,0.9994000196456909,0.9994000196456909,0.9995999932289124,0.9998000264167786,1.0,0.9998000264167786,0.9998000264167786,1.0,0.9987999796867371,0.9994000196456909,0.9995999932289124,0.9994000196456909,0.9998000264167786,0.9987999796867371,0.9998000264167786,0.9972000122070312,0.9994000196456909,1.0,0.9990000128746033,0.9998000264167786,1.0,1.0,0.9973999857902527,0.9994000196456909,1.0,0.9994000196456909,0.9991999864578247,1.0,0.9998000264167786,0.9995999932289124,1.0,1.0,1.0,0.9998000264167786,1.0,0.9994000196456909,0.9998000264167786,0.9994000196456909,0.9998000264167786,0.9994000196456909,0.9994000196456909,0.9995999932289124,0.9994000196456909,0.9994000196456909,0.9998000264167786,0.9998000264167786,0.9998000264167786,1.0,1.0,0.9998000264167786,0.9994000196456909,0.9998000264167786,0.9987999796867371,0.9998000264167786,0.9998000264167786,0.9987999796867371,0.9991999864578247,0.9991999864578247,0.9998000264167786,0.9998000264167786,0.9994000196456909,0.9995999932289124,0.9987999796867371,0.9998000264167786,0.9998000264167786,0.9994000196456909,0.9991999864578247,0.9998000264167786,0.9995999932289124,1.0,0.9983999729156494,0.9991999864578247,0.9998000264167786,1.0,0.9983999729156494,0.9998000264167786,0.9998000264167786,1.0,0.9995999932289124,0.9991999864578247,0.9991999864578247,0.9998000264167786,0.9994000196456909,0.9991999864578247,1.0,1.0,0.9998000264167786,0.9995999932289124,0.9972000122070312,0.9998000264167786,1.0,0.9998000264167786,1.0,1.0,0.9991999864578247,0.9995999932289124,0.9927999973297119,0.9987999796867371,0.9995999932289124,0.9994000196456909,0.9994000196456909,0.9987999796867371,0.9995999932289124,1.0,1.0,0.9995999932289124,1.0,0.9994000196456909,0.9994000196456909,0.9994000196456909,1.0,0.9977999925613403,0.9990000128746033,0.9998000264167786,0.9994000196456909,0.9995999932289124,0.995199978351593,0.9846000075340271,0.9995999932289124,0.9994000196456909,1.0,0.9994000196456909,0.9987999796867371,0.9998000264167786,0.9998000264167786,0.9987999796867371,0.9998000264167786,1.0,0.9998000264167786,0.9991999864578247,0.9972000122070312,0.9998000264167786,0.9998000264167786,0.9990000128746033,0.9995999932289124,0.9995999932289124,0.9991999864578247,0.9994000196456909,1.0,0.9994000196456909,0.9998000264167786,0.9998000264167786,1.0,0.9987999796867371,0.9998000264167786,0.9991999864578247,0.9994000196456909,1.0,0.9994000196456909,0.9998000264167786,0.9998000264167786,0.9991999864578247,1.0,0.9998000264167786,1.0,0.9998000264167786,0.9998000264167786,1.0,0.9987999796867371,0.9977999925613403,0.9998000264167786,0.9998000264167786,1.0,1.0,1.0,0.9994000196456909,0.9998000264167786,0.9994000196456909,0.9998000264167786,0.9995999932289124,0.9983999729156494,0.9972000122070312,0.9998000264167786,0.9998000264167786,0.9977999925613403,1.0,0.9998000264167786,0.9995999932289124,1.0,0.9998000264167786,0.9994000196456909,0.9994000196456909,0.9991999864578247,0.9998000264167786,0.9998000264167786,0.9991999864578247,0.9994000196456909,0.9998000264167786,1.0,0.9995999932289124,0.9998000264167786,0.9995999932289124,0.9995999932289124,1.0,0.9998000264167786,0.9990000128746033,0.9994000196456909,0.9998000264167786,0.9987999796867371,0.9994000196456909,0.9991999864578247,1.0,0.9987999796867371,0.9998000264167786,0.9995999932289124,0.9994000196456909,0.9987999796867371,1.0,0.9995999932289124,0.9998000264167786,0.9987999796867371,0.9998000264167786,0.9991999864578247,1.0,1.0,1.0,0.9998000264167786,0.9995999932289124,0.9991999864578247,0.9991999864578247,0.9995999932289124,0.9998000264167786,0.9994000196456909,0.9998000264167786,1.0,1.0,0.9998000264167786,0.9994000196456909,1.0,1.0,0.9998000264167786,0.9998000264167786,0.9994000196456909,1.0,0.9991999864578247,0.9995999932289124,0.9991999864578247,0.9991999864578247,1.0,0.9995999932289124,1.0,1.0,0.9990000128746033,0.998199999332428,1.0,0.9976000189781189,0.9986000061035156,0.9991999864578247,0.9991999864578247,1.0,0.9998000264167786,1.0,0.9990000128746033,0.9998000264167786,1.0,0.9991999864578247,0.9998000264167786,0.9998000264167786,0.9987999796867371,0.9994000196456909,1.0,1.0,0.9995999932289124,0.9998000264167786,1.0,1.0,1.0,1.0,1.0,0.9987999796867371,0.9998000264167786,0.9991999864578247,1.0,0.9990000128746033,0.9995999932289124,0.9995999932289124,0.9994000196456909,0.9983999729156494,0.9973999857902527,0.9998000264167786,0.9998000264167786,0.9994000196456909,0.9991999864578247,1.0,0.9995999932289124,0.9994000196456909,0.9994000196456909,1.0,1.0,0.9986000061035156,0.9968000054359436,0.9990000128746033,0.9994000196456909,0.9994000196456909,0.9987999796867371,0.9995999932289124,0.9973999857902527,1.0,0.9994000196456909,0.9990000128746033,0.9994000196456909,0.9998000264167786,1.0,0.9994000196456909,1.0,1.0,1.0,1.0,0.9998000264167786,0.9998000264167786,0.9998000264167786,0.9998000264167786,0.9998000264167786,0.9998000264167786],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Accuracy\"},\"xaxis\":{\"title\":{\"text\":\"epochs\"}},\"yaxis\":{\"title\":{\"text\":\"\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('573ecf20-c550-47f5-b7fd-aad46761447b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Model"
      ],
      "metadata": {
        "id": "7A8XWoHg57db"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
        "_, val_acc = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Train: %.4f, Validation: %.4f' % (train_acc, val_acc))"
      ],
      "metadata": {
        "id": "zVkCMy1y58cm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54053561-eeb4-4897-eb6b-395ddf4fbfda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.9996, Validation: 0.9998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.predict(x_train)\n",
        "\n",
        "print(np.round(res[:1],3))"
      ],
      "metadata": {
        "id": "F8TBpYJr59uG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a38886-f321-4f08-cebd-3967775c48ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 0s 997us/step\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "จากภาพด้านบน แสดงค่าความเชื่อมั่นในการทำนายของแต่ละ Class (Class 0 - 19) จาก Input Data 1 Record โดยค่าความเชื่อมั่นทุก Class รวมกันเท่ากับ 1.0"
      ],
      "metadata": {
        "id": "HA_Sz4Wd5-75"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5sFCjg1xCGff"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}